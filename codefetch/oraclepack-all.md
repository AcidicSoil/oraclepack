<filetree>
Project Structure:
├── .config
│   ├── commands
│   │   └── oracle-pack_v2.toml
│   ├── completion
│   │   └── oraclepack.completion.sh
│   ├── mcp
│   │   ├── mcp-builder
│   │   │   ├── reference
│   │   │   │   ├── evaluation.md
│   │   │   │   ├── mcp_best_practices.md
│   │   │   │   ├── node_mcp_server.md
│   │   │   │   └── python_mcp_server.md
│   │   │   ├── scripts
│   │   │   │   ├── connections.py
│   │   │   │   ├── evaluation.py
│   │   │   │   ├── example_evaluation.xml
│   │   │   │   └── requirements.txt
│   │   │   └── SKILL.md
│   │   ├── oraclepack-gold-pack
│   │   │   ├── references
│   │   │   │   ├── attachment-minimization.md
│   │   │   │   ├── inference-first-discovery.md
│   │   │   │   ├── oracle-pack-template.md
│   │   │   │   └── oracle-scratch-format.md
│   │   │   ├── scripts
│   │   │   │   ├── lint_attachments.py
│   │   │   │   └── validate_pack.py
│   │   │   └── SKILL.md
│   │   └── oraclepack-taskify
│   │       ├── assets
│   │       │   ├── action-pack-template.md
│   │       │   ├── actions-json-schema.md
│   │       │   └── prd-synthesis-prompt.md
│   │       ├── references
│   │       │   ├── determinism-and-safety.md
│   │       │   ├── task-master-cli-cheatsheet.md
│   │       │   └── workflow-overview.md
│   │       ├── scripts
│   │       │   ├── detect-oracle-outputs.sh
│   │       │   └── validate-action-pack.sh
│   │       └── SKILL.md
│   ├── scripts
│   │   ├── build_install_oraclepack.md
│   │   ├── build_install_oraclepack.sh
│   │   ├── codefetch_skill.sh
│   │   ├── install-global.ps1
│   │   ├── install-global.sh
│   │   └── tag-release.sh
│   └── skills
│       ├── oraclepack-pipeline-improver
│       │   ├── assets
│       │   │   ├── backlog-template.md
│       │   │   ├── change-plan-template.md
│       │   │   └── normalized.example.jsonl
│       │   ├── references
│       │   │   ├── actionizer-spec.md
│       │   │   ├── cli-contract.md
│       │   │   ├── run-manifest-spec.md
│       │   │   └── stage1-prompt-metadata.md
│       │   └── SKILL.md
│       └── oraclepack-tickets-pack
│           ├── references
│           │   ├── attachment-minimization.md
│           │   ├── ticket-bundling.md
│           │   └── tickets-pack-template.md
│           ├── scripts
│           │   ├── lint_attachments.py
│           │   └── validate_pack.py
│           └── SKILL.md
├── .github
│   └── workflows
│       ├── ci.yml
│       └── release.yml
├── .mypy_cache
│   ├── 3.12
│   │   ├── _typeshed
│   │   │   ├── __init__.data.json
│   │   │   ├── __init__.meta.json
│   │   │   ├── importlib.data.json
│   │   │   └── importlib.meta.json
│   │   ├── collections
│   │   │   ├── __init__.data.json
│   │   │   ├── __init__.meta.json
│   │   │   ├── abc.data.json
│   │   │   └── abc.meta.json
│   │   ├── email
│   │   │   ├── __init__.data.json
│   │   │   ├── __init__.meta.json
│   │   │   ├── _policybase.data.json
│   │   │   ├── _policybase.meta.json
│   │   │   ├── charset.data.json
│   │   │   ├── charset.meta.json
│   │   │   ├── contentmanager.data.json
│   │   │   ├── contentmanager.meta.json
│   │   │   ├── errors.data.json
│   │   │   ├── errors.meta.json
│   │   │   ├── header.data.json
│   │   │   ├── header.meta.json
│   │   │   ├── message.data.json
│   │   │   ├── message.meta.json
│   │   │   ├── policy.data.json
│   │   │   └── policy.meta.json
│   │   ├── importlib
│   │   │   ├── metadata
│   │   │   │   ├── __init__.data.json
│   │   │   │   ├── __init__.meta.json
│   │   │   │   ├── _meta.data.json
│   │   │   │   └── _meta.meta.json
│   │   │   ├── resources
│   │   │   │   ├── __init__.data.json
│   │   │   │   ├── __init__.meta.json
│   │   │   │   ├── _common.data.json
│   │   │   │   ├── _common.meta.json
│   │   │   │   ├── abc.data.json
│   │   │   │   └── abc.meta.json
│   │   │   ├── __init__.data.json
│   │   │   ├── __init__.meta.json
│   │   │   ├── _abc.data.json
│   │   │   ├── _abc.meta.json
│   │   │   ├── _bootstrap.data.json
│   │   │   ├── _bootstrap.meta.json
│   │   │   ├── _bootstrap_external.data.json
│   │   │   ├── _bootstrap_external.meta.json
│   │   │   ├── abc.data.json
│   │   │   ├── abc.meta.json
│   │   │   ├── machinery.data.json
│   │   │   ├── machinery.meta.json
│   │   │   ├── readers.data.json
│   │   │   └── readers.meta.json
│   │   ├── os
│   │   │   ├── __init__.data.json
│   │   │   ├── __init__.meta.json
│   │   │   ├── path.data.json
│   │   │   └── path.meta.json
│   │   ├── sys
│   │   │   ├── __init__.data.json
│   │   │   ├── __init__.meta.json
│   │   │   ├── _monitoring.data.json
│   │   │   └── _monitoring.meta.json
│   │   ├── zipfile
│   │   │   ├── _path
│   │   │   │   ├── __init__.data.json
│   │   │   │   └── __init__.meta.json
│   │   │   ├── __init__.data.json
│   │   │   └── __init__.meta.json
│   │   ├── @plugins_snapshot.json
│   │   ├── _ast.data.json
│   │   ├── _ast.meta.json
│   │   ├── _codecs.data.json
│   │   ├── _codecs.meta.json
│   │   ├── _collections_abc.data.json
│   │   ├── _collections_abc.meta.json
│   │   ├── _frozen_importlib.data.json
│   │   ├── _frozen_importlib.meta.json
│   │   ├── _frozen_importlib_external.data.json
│   │   ├── _frozen_importlib_external.meta.json
│   │   ├── _io.data.json
│   │   ├── _io.meta.json
│   │   ├── _sitebuiltins.data.json
│   │   ├── _sitebuiltins.meta.json
│   │   ├── abc.data.json
│   │   ├── abc.meta.json
│   │   ├── ast.data.json
│   │   ├── ast.meta.json
│   │   ├── builtins.data.json
│   │   ├── builtins.meta.json
│   │   ├── codecs.data.json
│   │   ├── codecs.meta.json
│   │   ├── contextlib.data.json
│   │   ├── contextlib.meta.json
│   │   ├── dataclasses.data.json
│   │   ├── dataclasses.meta.json
│   │   ├── enum.data.json
│   │   ├── enum.meta.json
│   │   ├── genericpath.data.json
│   │   ├── genericpath.meta.json
│   │   ├── io.data.json
│   │   ├── io.meta.json
│   │   ├── pathlib.data.json
│   │   ├── pathlib.meta.json
│   │   ├── posixpath.data.json
│   │   ├── posixpath.meta.json
│   │   ├── re.data.json
│   │   ├── re.meta.json
│   │   ├── resource.data.json
│   │   ├── resource.meta.json
│   │   ├── sre_compile.data.json
│   │   ├── sre_compile.meta.json
│   │   ├── sre_constants.data.json
│   │   ├── sre_constants.meta.json
│   │   ├── sre_parse.data.json
│   │   ├── sre_parse.meta.json
│   │   ├── subprocess.data.json
│   │   ├── subprocess.meta.json
│   │   ├── test.data.json
│   │   ├── test.meta.json
│   │   ├── types.data.json
│   │   ├── types.meta.json
│   │   ├── typing.data.json
│   │   ├── typing.meta.json
│   │   ├── typing_extensions.data.json
│   │   └── typing_extensions.meta.json
│   └── CACHEDIR.TAG
├── .ruler
│   ├── AGENTS.md
│   ├── ruler.toml
│   ├── skill-usage.md
│   └── tm-AGENTS.md
├── .rules
│   ├── dev_workflow.md
│   ├── rules.md
│   ├── self_improve.md
│   └── taskmaster.md
├── .tickets
│   ├── actions
│   │   ├── Enable Action Packs Dispatch.md
│   │   ├── Improving Oraclepack Workflow.md
│   │   ├── Oraclepack Action Pack Integration.md
│   │   ├── Oraclepack Action Pack Issue.md
│   │   ├── Oraclepack Action Packs.md
│   │   └── Oraclepack Compatibility Issues.md
│   ├── mcp
│   │   ├── Expose Oraclepack as MCP.md
│   │   ├── MCP Server for Oraclepack.md
│   │   ├── gaps-still-not-covered.md
│   │   ├── gaps_part2-mcp-builder.md
│   │   ├── oraclepack-MCP.md
│   │   └── oraclepack_mcp_server.md
│   ├── other
│   │   ├── Oraclepack Pipeline Improvements.md
│   │   ├── Oraclepack Prompt Generator.md
│   │   ├── Oraclepack Workflow Enhancement.md
│   │   └── Verbose Payload Rendering TUI.md
│   ├── PRD-TUI
│   │   ├── Oraclepack TUI Integration.md
│   │   └── PRD-generator URL routing.md
│   ├── Oraclepack File Storage.md
│   ├── Oraclepack Schema Approach.md
│   ├── Oraclepack bash fix.md
│   └── Publish OraclePack MCP.md
├── docs
│   └── oracle-questions-2026-01-08
│       ├── actions
│       │   ├── 01-contracts-interfaces-ticket-surface.md
│       │   ├── 02-contracts-interfaces-integration-points.md
│       │   ├── 03-invariants-invariant-map.md
│       │   ├── 04-invariants-validation-boundaries.md
│       │   └── 05-caching-state-state-artifacts.md
│       ├── packs
│       │   ├── actions.md
│       │   ├── mcp.md
│       │   ├── misc.md
│       │   ├── other.md
│       │   └── prd-tui.md
│       ├── _groups.json
│       └── manifest.json
├── internal
│   ├── app
│   │   ├── app.go
│   │   ├── app_test.go
│   │   ├── run.go
│   │   └── run_test.go
│   ├── cli
│   │   ├── cmds.go
│   │   ├── root.go
│   │   └── run.go
│   ├── errors
│   │   ├── errors.go
│   │   └── errors_test.go
│   ├── exec
│   │   ├── flags.go
│   │   ├── inject.go
│   │   ├── inject_test.go
│   │   ├── oracle_scan.go
│   │   ├── oracle_scan_test.go
│   │   ├── oracle_validate.go
│   │   ├── oracle_validate_test.go
│   │   ├── runner.go
│   │   ├── runner_test.go
│   │   ├── sanitize.go
│   │   ├── sanitize_test.go
│   │   └── stream.go
│   ├── overrides
│   │   ├── merge.go
│   │   ├── merge_test.go
│   │   └── types.go
│   ├── pack
│   │   ├── parser.go
│   │   ├── parser_test.go
│   │   └── types.go
│   ├── render
│   │   ├── render.go
│   │   └── render_test.go
│   ├── report
│   │   ├── generate.go
│   │   ├── report_test.go
│   │   └── types.go
│   ├── state
│   │   ├── persist.go
│   │   ├── state_test.go
│   │   └── types.go
│   └── tui
│       ├── clipboard.go
│       ├── filter_test.go
│       ├── overrides_confirm.go
│       ├── overrides_flags.go
│       ├── overrides_flow.go
│       ├── overrides_steps.go
│       ├── overrides_url.go
│       ├── preview_test.go
│       ├── tui.go
│       ├── tui_test.go
│       ├── url_picker.go
│       ├── url_store.go
│       └── url_store_test.go
├── oraclepack-mcp-server
│   ├── .pytest_cache
│   │   ├── v
│   │   │   └── cache
│   │   │       ├── lastfailed
│   │   │       └── nodeids
│   │   └── CACHEDIR.TAG
│   ├── oraclepack_mcp_server
│   │   ├── __init__.py
│   │   ├── __main__.py
│   │   ├── config.py
│   │   ├── oraclepack_cli.py
│   │   ├── security.py
│   │   ├── server.py
│   │   └── taskify.py
│   ├── oraclepack_mcp_server.egg-info
│   │   ├── PKG-INFO
│   │   ├── SOURCES.txt
│   │   ├── dependency_links.txt
│   │   ├── entry_points.txt
│   │   ├── requires.txt
│   │   └── top_level.txt
│   ├── tests
│   │   ├── test_cli.py
│   │   ├── test_config.py
│   │   ├── test_integration.py
│   │   ├── test_security.py
│   │   └── test_taskify.py
│   ├── inspector.config.json
│   ├── pyproject.toml
│   └── requirements.txt
├── scripts
│   ├── build_install_oraclepack.md
│   ├── build_install_oraclepack.sh
│   ├── codefetch_skill.sh
│   ├── install-global.ps1
│   ├── install-global.sh
│   └── tag-release.sh
├── skills
│   ├── oraclepack-pipeline-improver
│   │   ├── assets
│   │   │   ├── backlog-template.md
│   │   │   ├── change-plan-template.md
│   │   │   └── normalized.example.jsonl
│   │   ├── references
│   │   │   ├── actionizer-spec.md
│   │   │   ├── cli-contract.md
│   │   │   ├── run-manifest-spec.md
│   │   │   └── stage1-prompt-metadata.md
│   │   └── SKILL.md
│   ├── oraclepack-tickets-pack
│   │   ├── references
│   │   │   ├── attachment-minimization.md
│   │   │   ├── ticket-bundling.md
│   │   │   └── tickets-pack-template.md
│   │   ├── scripts
│   │   │   ├── lint_attachments.py
│   │   │   └── validate_pack.py
│   │   └── SKILL.md
│   ├── oraclepack-tickets-pack-common
│   │   └── scripts
│   │       └── validate_pack.py
│   └── oraclepack-tickets-pack-grouped
│       ├── references
│       │   ├── attachment-minimization.md
│       │   ├── ticket-grouping.md
│       │   ├── tickets-pack-template-bundle.md
│       │   └── tickets-pack-template.md
│       ├── scripts
│       │   ├── generate_grouped_packs.py
│       │   ├── lint_attachments.py
│       │   ├── render_group_packs.py
│       │   ├── shard_tickets.py
│       │   ├── validate_pack.py
│       │   └── validate_shards.py
│       └── SKILL.md
├── .browser-echo-mcp.json
├── .goreleaser.yaml
├── actions.state.json
├── go.mod
├── inspector.config.json
├── oracle-pack-2026-01-02.chatgpt-urls.json
├── oracle-pack-2026-01-02.state.json
├── oracle-pack-2026-01-07.report.json
├── oracle-pack-2026-01-07.state.json
├── package.json
├── ticket-action-pack.chatgpt-urls.json
└── tickets_prd.chatgpt-urls.json

</filetree>

<source_code>
.browser-echo-mcp.json
```
{"url":"http://127.0.0.1:45425","route":"/__client-logs","timestamp":1767909167004,"pid":78991}
```

.goreleaser.yaml
```
# path: .goreleaser.yaml
version: 2

project_name: oraclepack

before:
  hooks:
    - go mod download

builds:
  - id: oraclepack
    main: ./cmd/oraclepack
    binary: oraclepack
    env:
      - CGO_ENABLED=0
    goos:
      - linux
      - darwin
      - windows
    goarch:
      - amd64
      - arm64
    flags:
      - -trimpath

archives:
  - id: default
    builds:
      - oraclepack
    name_template: "{{ .ProjectName }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}"
    format: tar.gz
    format_overrides:
      - goos: windows
        format: zip

checksum:
  name_template: "checksums.txt"

changelog:
  sort: asc
  filters:
    exclude:
      - "^docs:"
      - "^test:"
      - "^chore:"
```

actions.state.json
```
{
  "schema_version": 1,
  "pack_hash": "",
  "start_time": "0001-01-01T00:00:00Z",
  "step_statuses": {},
  "roi_threshold": 4.7,
  "roi_mode": "over"
}
```

go.mod
```
module github.com/user/oraclepack

go 1.24.0

toolchain go1.24.11

require (
	github.com/charmbracelet/bubbles v0.21.0
	github.com/charmbracelet/bubbletea v1.3.10
	github.com/charmbracelet/glamour v0.10.0
	github.com/charmbracelet/lipgloss v1.1.1-0.20250404203927-76690c660834
	github.com/spf13/cobra v1.10.2
)

require (
	github.com/alecthomas/chroma/v2 v2.14.0 // indirect
	github.com/atotto/clipboard v0.1.4 // indirect
	github.com/aymanbagabas/go-osc52/v2 v2.0.1 // indirect
	github.com/aymerick/douceur v0.2.0 // indirect
	github.com/charmbracelet/colorprofile v0.2.3-0.20250311203215-f60798e515dc // indirect
	github.com/charmbracelet/x/ansi v0.10.1 // indirect
	github.com/charmbracelet/x/cellbuf v0.0.13 // indirect
	github.com/charmbracelet/x/exp/slice v0.0.0-20250327172914-2fdc97757edf // indirect
	github.com/charmbracelet/x/term v0.2.1 // indirect
	github.com/dlclark/regexp2 v1.11.0 // indirect
	github.com/erikgeiser/coninput v0.0.0-20211004153227-1c3628e74d0f // indirect
	github.com/gorilla/css v1.0.1 // indirect
	github.com/inconshreveable/mousetrap v1.1.0 // indirect
	github.com/lucasb-eyer/go-colorful v1.2.0 // indirect
	github.com/mattn/go-isatty v0.0.20 // indirect
	github.com/mattn/go-localereader v0.0.1 // indirect
	github.com/mattn/go-runewidth v0.0.16 // indirect
	github.com/microcosm-cc/bluemonday v1.0.27 // indirect
	github.com/muesli/ansi v0.0.0-20230316100256-276c6243b2f6 // indirect
	github.com/muesli/cancelreader v0.2.2 // indirect
	github.com/muesli/reflow v0.3.0 // indirect
	github.com/muesli/termenv v0.16.0 // indirect
	github.com/rivo/uniseg v0.4.7 // indirect
	github.com/sahilm/fuzzy v0.1.1 // indirect
	github.com/spf13/pflag v1.0.9 // indirect
	github.com/xo/terminfo v0.0.0-20220910002029-abceb7e1c41e // indirect
	github.com/yuin/goldmark v1.7.8 // indirect
	github.com/yuin/goldmark-emoji v1.0.5 // indirect
	golang.org/x/net v0.33.0 // indirect
	golang.org/x/sys v0.36.0 // indirect
	golang.org/x/term v0.31.0 // indirect
	golang.org/x/text v0.24.0 // indirect
)
```

inspector.config.json
```
{
  "mcpServers": {
    "oraclepack": {
      "command": "/home/user/projects/temp/oraclepack/oraclepack-mcp-server/venv/bin/python",
      "args": ["-m", "oraclepack_mcp_server", "--transport", "stdio"],
      "env": {
        "ORACLEPACK_BIN": "oraclepack",
        "ORACLEPACK_ALLOWED_ROOTS": "/home/user/projects/temp/oraclepack",
        "ORACLEPACK_ENABLE_EXEC": "1"
      }
    }
  }
}
```

oracle-pack-2026-01-02.chatgpt-urls.json
```
{
  "default": "",
  "items": [
    {
      "name": "oracle",
      "url": "https://chatgpt.com/g/g-p-694ed925bab08191acaf80aefaf27dfc-oracle/project",
      "lastUsed": "2026-01-02T22:40:05Z"
    }
  ]
}
```

oracle-pack-2026-01-02.state.json
```
{
  "schema_version": 1,
  "pack_hash": "",
  "start_time": "0001-01-01T00:00:00Z",
  "step_statuses": {},
  "roi_threshold": 1.6,
  "roi_mode": "over"
}
```

oracle-pack-2026-01-07.report.json
```
{
  "summary": {
    "total_steps": 1,
    "success_count": 0,
    "failure_count": 1,
    "skipped_count": 0,
    "total_duration": 41869173156,
    "total_duration_ms": 41869
  },
  "pack_info": {
    "name": "oracle-pack-2026-01-07.md",
    "hash": ""
  },
  "steps": [
    {
      "id": "01",
      "status": "failed",
      "exit_code": 0,
      "duration": 41869173156,
      "duration_ms": 41869,
      "error": "execution failed: exit status 1"
    }
  ],
  "generated_at": "2026-01-07T20:36:07.853021394-06:00"
}
```

oracle-pack-2026-01-07.state.json
```
{
  "schema_version": 1,
  "pack_hash": "",
  "start_time": "2026-01-07T20:35:28.45875924-06:00",
  "step_statuses": {
    "01": {
      "status": "failed",
      "exit_code": 0,
      "started_at": "2026-01-07T20:35:28.467108546-06:00",
      "ended_at": "2026-01-07T20:36:07.852649398-06:00",
      "error": "execution failed: exit status 1"
    }
  }
}
```

package.json
```
{
  "devDependencies": {
    "codefetch": "^2.2.0"
  },
  "scripts": {
    "code": "pnpm code:tui && pnpm code:all && pnpm code:t && pnpm code:op && pnpm code:opt && pnpm code:mcp",
    "code:tui": "codefetch -t 5 --include-dir cmd,internal -o oraclepack-tui.md --max-tokens 50000 --token-limiter truncated",
    "code:all": "codefetch -t 5 -o oraclepack-all.md",
    "code:temp": "codefetch -t 5 --include-dir .rules -o rules.md --max-tokens 50000",
    "build": "bash .config/scripts/build_install_oraclepack.sh && exec bash",
    "tag": "bash .config/scripts/tag-release.sh",
    "code:op": "codefetch -t 5 --include-files \".config/skills/**/oracle*\",\".config/skills/**/oracle*/**/*\" -o oracle_SKILLS_and_PROMPTS.md --max-tokens 75000",
    "code:t": "codefetch -t 5 --include-dir .tickets -o oraclepack-tickets.md --max-tokens 50000 --token-limiter truncated",
    "code:mcp": "codefetch -t 5 --include-dir oraclepack-mcp-server -o oraclepack-mcp.md --max-tokens 50000 --token-limiter truncated",
    "code:tm": "codefetch -t 5 --include-files \"**/tm-*\",\"**/tm-*/**/*\" -o tm_SKILL_and_PROMPTS.md --max-tokens 75000",
    "code:opt": "codefetch -t 5 --include-dir oraclepack-mcp-server,internal,cmd -o oraclepack-op-mcp.md --max-tokens 75000 --token-limiter truncated",
    "scri": "bash scripts/codefetch_skill.sh"
  }
}
```

ticket-action-pack.chatgpt-urls.json
```
{
  "default": "",
  "items": null
}
```

tickets_prd.chatgpt-urls.json
```
{
  "default": "",
  "items": null
}
```

.ruler/AGENTS.md
```
# AGENTS.md

Centralised AI agent instructions. Add coding guidelines, style guides, and project context here.

Ruler concatenates all .md files in this directory (and subdirectories), starting with AGENTS.md (if present), then remaining files in sorted order.
```

.ruler/ruler.toml
```
# Ruler Configuration File
# See https://ai.intellectronica.net/ruler for documentation.

# To specify which agents are active by default when --agents is not used,
# uncomment and populate the following line. If omitted, all agents are active.
default_agents = ["codex"]

# Enable nested rule loading from nested .ruler directories
# When enabled, ruler will search for and process .ruler directories throughout the project hierarchy
nested = true

# --- Agent Specific Configurations ---
# You can enable/disable agents and override their default output paths here.
# Use lowercase agent identifiers: amp, copilot, claude, codex, cursor, windsurf, cline, aider, kilocode

# [agents.copilot]
# enabled = true
# output_path = ".github/copilot-instructions.md"

# [agents.aider]
# enabled = true
# output_path_instructions = "AGENTS.md"
# output_path_config = ".aider.conf.yml"

# [agents.gemini-cli]
# enabled = true

# --- MCP Servers ---
# Define Model Context Protocol servers here. Two examples:
# 1. A stdio server (local executable)
# 2. A remote server (HTTP-based)

# [mcp_servers.example_stdio]
# command = "node"
# args = ["scripts/your-mcp-server.js"]
# env = { API_KEY = "replace_me" }

# [mcp_servers.example_remote]
# url = "https://api.example.com/mcp"
# headers = { Authorization = "Bearer REPLACE_ME" }
```

.ruler/skill-usage.md
```
## Skills usage

You have a library of reusable skill prompts stored under `$CODEX_HOME/skills/` (commonly `~/.codex/skills/`).

Treat each **skill folder** in `$CODEX_HOME/skills/` as a named skill:

- A folder `$CODEX_HOME/skills/<SKILL_NAME>/SKILL.md` defines the canonical flow and constraints for the `<SKILL_NAME>` skill.
- Skill folders may also include `scripts/`, `references/`, and `assets/` that the assistant should use when the skill requires them.
- These skills are the primary reference for how to handle common or important task types.

General rule:

- Before starting work on any task, briefly classify it (for example: architecture, implementation, refactoring, performance, reliability, data, documentation, tests, tooling, pack generation, etc.).
- If there is a relevant skill under `$CODEX_HOME/skills/` for that class of task, base the approach on the instructions in that skill instead of inventing new, ad-hoc instructions.
- When a skill exists for a task type, follow its steps, constraints, and return format as the default behavior.

Task-type rule:

- When working on any task that corresponds to an existing skill:
  - Consult the corresponding `$CODEX_HOME/skills/<SKILL_NAME>/SKILL.md` as the first step.
  - Let the skill’s instructions drive the approach (checks to perform, constraints to respect, preferred output format).
  - Only add additional reasoning or deviations after the skill’s instructions have been applied.

Reporting rule:

- When following a skill, explicitly mention which skill is being used (for example: “Using the guidance from `$CODEX_HOME/skills/<SKILL_NAME>/SKILL.md`”) so the link between behavior and skill remains clear.
- Do not modify or overwrite skill files themselves unless explicitly instructed to adjust the underlying skill behavior.

---

## Oraclepack Stage-1 pack generation (grouped mini-packs)

When the user asks to generate **oraclepack Stage-1 question packs** (runner-ingestible Markdown packs with strict schema: single `bash` fence, exactly 20 steps, deterministic attachments, and a Coverage check), prefer these skills over ad-hoc prompting:

1) `$CODEX_HOME/skills/oraclepack-tickets-pack-grouped/SKILL.md`
   - Use when the task is **ticket-driven** (user references `.tickets/`, “tickets as primary context”, “group by ticket topic/domain”, or wants per-topic mini-packs from tickets).
   - Produces multiple per-topic/per-domain packs grouped by ticket subdirs + deterministic inference for loose tickets.
   - Packs must be direct-attach (no bundle dependency) and validated/linted per the skill.

2) `$CODEX_HOME/skills/oraclepack-codebase-pack-grouped/SKILL.md`
   - Use when the task is **codebase-driven** (user wants per-topic/per-domain mini-packs derived from repository structure/modules, and tickets are not the primary context).
   - Produces multiple per-topic/per-domain packs grouped by codebase subdirs + deterministic inference for loose files.
   - Packs must be direct-attach and validated/linted per the skill.

Selection decision (apply in order):

- If the user mentions tickets or `.tickets/` or provides “attached tickets” as primary context → use `oraclepack-tickets-pack-grouped`.
- Else → use `oraclepack-codebase-pack-grouped`.

Mandatory follow-through for either skill:

- Run the skill’s required validation and attachment linting for every generated pack.
- Enforce the skill’s size-control guidance (dry-run the largest pack and reduce scope if needed).
- Report the produced pack paths (e.g., `{{out_dir}}/packs/*.md`) and any group manifests the skill generates (e.g., `{{out_dir}}/_groups.json`), and explicitly state which skill drove the result.
```

.ruler/tm-AGENTS.md
```
# Agent Instructions

## Task Master AI and Workflow Instructions
**Import Task Master's development workflow commands and guidelines, treat as if import is in the main AGENT.md file.**
@./.taskmaster/AGENTS.md @./.rules/dev_workflow.md @./.rules/rules.md @./.rules/self_improve.md @./.rules/taskmaster.md
```

.mypy_cache/CACHEDIR.TAG
```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag automatically created by mypy.
# For information about cache directory tags see https://bford.info/cachedir/
```

.rules/dev_workflow.md
```
---
description: Guide for using Taskmaster to manage task-driven development workflows
---

# Taskmaster Development Workflow

This guide outlines the standard process for using Taskmaster to manage software development projects. It is written as a set of instructions for you, the AI agent.

- **Your Default Stance**: For most projects, the user can work directly within the `master` task context. Your initial actions should operate on this default context unless a clear pattern for multi-context work emerges.
- **Your Goal**: Your role is to elevate the user's workflow by intelligently introducing advanced features like **Tagged Task Lists** when you detect the appropriate context. Do not force tags on the user; suggest them as a helpful solution to a specific need.

## The Basic Loop
The fundamental development cycle you will facilitate is:
1.  **`list`**: Show the user what needs to be done.
2.  **`next`**: Help the user decide what to work on.
3.  **`show <id>`**: Provide details for a specific task.
4.  **`expand <id>`**: Break down a complex task into smaller, manageable subtasks.
5.  **Implement**: The user writes the code and tests.
6.  **`update-subtask`**: Log progress and findings on behalf of the user.
7.  **`set-status`**: Mark tasks and subtasks as `done` as work is completed.
8.  **Repeat**.

All your standard command executions should operate on the user's current task context, which defaults to `master`.

---

## Standard Development Workflow Process

### Simple Workflow (Default Starting Point)

For new projects or when users are getting started, operate within the `master` tag context:

-   Start new projects by running `initialize_project` tool / `task-master init` or `parse_prd` / `task-master parse-prd --input='<prd-file.txt>'` (see @`taskmaster.md`) to generate initial tasks.json with tagged structure
-   Configure rule sets during initialization with `--rules` flag (e.g., `task-master init --rules <AGENT>,windsurf`) or manage them later with `task-master rules add/remove` commands
-   Begin coding sessions with `get_tasks` / `task-master list` (see @`taskmaster.md`) to see current tasks, status, and IDs
-   Determine the next task to work on using `next_task` / `task-master next` (see @`taskmaster.md`)
-   Analyze task complexity with `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) before breaking down tasks
-   Review complexity report using `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`)
-   Select tasks based on dependencies (all marked 'done'), priority level, and ID order
-   View specific task details using `get_task` / `task-master show <id>` (see @`taskmaster.md`) to understand implementation requirements
-   Break down complex tasks using `expand_task` / `task-master expand --id=<id> --force --research` (see @`taskmaster.md`) with appropriate flags like `--force` (to replace existing subtasks) and `--research`
-   Implement code following task details, dependencies, and project standards
-   Mark completed tasks with `set_task_status` / `task-master set-status --id=<id> --status=done` (see @`taskmaster.md`)
-   Update dependent tasks when implementation differs from original plan using `update` / `task-master update --from=<id> --prompt="..."` or `update_task` / `task-master update-task --id=<id> --prompt="..."` (see @`taskmaster.md`)

---

## Leveling Up: Agent-Led Multi-Context Workflows

While the basic workflow is powerful, your primary opportunity to add value is by identifying when to introduce **Tagged Task Lists**. These patterns are your tools for creating a more organized and efficient development environment for the user, especially if you detect agentic or parallel development happening across the same session.

**Critical Principle**: Most users should never see a difference in their experience. Only introduce advanced workflows when you detect clear indicators that the project has evolved beyond simple task management.

### When to Introduce Tags: Your Decision Patterns

Here are the patterns to look for. When you detect one, you should propose the corresponding workflow to the user.

#### Pattern 1: Simple Git Feature Branching
This is the most common and direct use case for tags.

- **Trigger**: The user creates a new git branch (e.g., `git checkout -b feature/user-auth`).
- **Your Action**: Propose creating a new tag that mirrors the branch name to isolate the feature's tasks from `master`.
- **Your Suggested Prompt**: *"I see you've created a new branch named 'feature/user-auth'. To keep all related tasks neatly organized and separate from your main list, I can create a corresponding task tag for you. This helps prevent merge conflicts in your `tasks.json` file later. Shall I create the 'feature-user-auth' tag?"*
- **Tool to Use**: `task-master add-tag --from-branch`

#### Pattern 2: Team Collaboration
- **Trigger**: The user mentions working with teammates (e.g., "My teammate Alice is handling the database schema," or "I need to review Bob's work on the API.").
- **Your Action**: Suggest creating a separate tag for the user's work to prevent conflicts with shared master context.
- **Your Suggested Prompt**: *"Since you're working with Alice, I can create a separate task context for your work to avoid conflicts. This way, Alice can continue working with the master list while you have your own isolated context. When you're ready to merge your work, we can coordinate the tasks back to master. Shall I create a tag for your current work?"*
- **Tool to Use**: `task-master add-tag my-work --copy-from-current --description="My tasks while collaborating with Alice"`

#### Pattern 3: Experiments or Risky Refactors
- **Trigger**: The user wants to try something that might not be kept (e.g., "I want to experiment with switching our state management library," or "Let's refactor the old API module, but I want to keep the current tasks as a reference.").
- **Your Action**: Propose creating a sandboxed tag for the experimental work.
- **Your Suggested Prompt**: *"This sounds like a great experiment. To keep these new tasks separate from our main plan, I can create a temporary 'experiment-zustand' tag for this work. If we decide not to proceed, we can simply delete the tag without affecting the main task list. Sound good?"*
- **Tool to Use**: `task-master add-tag experiment-zustand --description="Exploring Zustand migration"`

#### Pattern 4: Large Feature Initiatives (PRD-Driven)
This is a more structured approach for significant new features or epics.

- **Trigger**: The user describes a large, multi-step feature that would benefit from a formal plan.
- **Your Action**: Propose a comprehensive, PRD-driven workflow.
- **Your Suggested Prompt**: *"This sounds like a significant new feature. To manage this effectively, I suggest we create a dedicated task context for it. Here's the plan: I'll create a new tag called 'feature-xyz', then we can draft a Product Requirements Document (PRD) together to scope the work. Once the PRD is ready, I'll automatically generate all the necessary tasks within that new tag. How does that sound?"*
- **Your Implementation Flow**:
    1.  **Create an empty tag**: `task-master add-tag feature-xyz --description "Tasks for the new XYZ feature"`. You can also start by creating a git branch if applicable, and then create the tag from that branch.
    2.  **Collaborate & Create PRD**: Work with the user to create a detailed PRD file (e.g., `.taskmaster/docs/feature-xyz-prd.txt`).
    3.  **Parse PRD into the new tag**: `task-master parse-prd .taskmaster/docs/feature-xyz-prd.txt --tag feature-xyz`
    4.  **Prepare the new task list**: Follow up by suggesting `analyze-complexity` and `expand-all` for the newly created tasks within the `feature-xyz` tag.

#### Pattern 5: Version-Based Development
Tailor your approach based on the project maturity indicated by tag names.

- **Prototype/MVP Tags** (`prototype`, `mvp`, `poc`, `v0.x`):
  - **Your Approach**: Focus on speed and functionality over perfection
  - **Task Generation**: Create tasks that emphasize "get it working" over "get it perfect"
  - **Complexity Level**: Lower complexity, fewer subtasks, more direct implementation paths
  - **Research Prompts**: Include context like "This is a prototype - prioritize speed and basic functionality over optimization"
  - **Example Prompt Addition**: *"Since this is for the MVP, I'll focus on tasks that get core functionality working quickly rather than over-engineering."*

- **Production/Mature Tags** (`v1.0+`, `production`, `stable`):
  - **Your Approach**: Emphasize robustness, testing, and maintainability
  - **Task Generation**: Include comprehensive error handling, testing, documentation, and optimization
  - **Complexity Level**: Higher complexity, more detailed subtasks, thorough implementation paths
  - **Research Prompts**: Include context like "This is for production - prioritize reliability, performance, and maintainability"
  - **Example Prompt Addition**: *"Since this is for production, I'll ensure tasks include proper error handling, testing, and documentation."*

### Advanced Workflow (Tag-Based & PRD-Driven)

**When to Transition**: Recognize when the project has evolved (or has initiated a project which existing code) beyond simple task management. Look for these indicators:
- User mentions teammates or collaboration needs
- Project has grown to 15+ tasks with mixed priorities
- User creates feature branches or mentions major initiatives
- User initializes Taskmaster on an existing, complex codebase
- User describes large features that would benefit from dedicated planning

**Your Role in Transition**: Guide the user to a more sophisticated workflow that leverages tags for organization and PRDs for comprehensive planning.

#### Master List Strategy (High-Value Focus)
Once you transition to tag-based workflows, the `master` tag should ideally contain only:
- **High-level deliverables** that provide significant business value
- **Major milestones** and epic-level features
- **Critical infrastructure** work that affects the entire project
- **Release-blocking** items

**What NOT to put in master**:
- Detailed implementation subtasks (these go in feature-specific tags' parent tasks)
- Refactoring work (create dedicated tags like `refactor-auth`)
- Experimental features (use `experiment-*` tags)
- Team member-specific tasks (use person-specific tags)

#### PRD-Driven Feature Development

**For New Major Features**:
1. **Identify the Initiative**: When user describes a significant feature
2. **Create Dedicated Tag**: `add_tag feature-[name] --description="[Feature description]"`
3. **Collaborative PRD Creation**: Work with user to create comprehensive PRD in `.taskmaster/docs/feature-[name]-prd.txt`
4. **Parse & Prepare**:
   - `parse_prd .taskmaster/docs/feature-[name]-prd.txt --tag=feature-[name]`
   - `analyze_project_complexity --tag=feature-[name] --research`
   - `expand_all --tag=feature-[name] --research`
5. **Add Master Reference**: Create a high-level task in `master` that references the feature tag

**For Existing Codebase Analysis**:
When users initialize Taskmaster on existing projects:
1. **Codebase Discovery**: Use your native tools for producing deep context about the code base. You may use `research` tool with `--tree` and `--files` to collect up to date information using the existing architecture as context.
2. **Collaborative Assessment**: Work with user to identify improvement areas, technical debt, or new features
3. **Strategic PRD Creation**: Co-author PRDs that include:
   - Current state analysis (based on your codebase research)
   - Proposed improvements or new features
   - Implementation strategy considering existing code
4. **Tag-Based Organization**: Parse PRDs into appropriate tags (`refactor-api`, `feature-dashboard`, `tech-debt`, etc.)
5. **Master List Curation**: Keep only the most valuable initiatives in master

The parse-prd's `--append` flag enables the user to parse multiple PRDs within tags or across tags. PRDs should be focused and the number of tasks they are parsed into should be strategically chosen relative to the PRD's complexity and level of detail.

### Workflow Transition Examples

**Example 1: Simple → Team-Based**
```
User: "Alice is going to help with the API work"
Your Response: "Great! To avoid conflicts, I'll create a separate task context for your work. Alice can continue with the master list while you work in your own context. When you're ready to merge, we can coordinate the tasks back together."
Action: add_tag my-api-work --copy-from-current --description="My API tasks while collaborating with Alice"
```

**Example 2: Simple → PRD-Driven**
```
User: "I want to add a complete user dashboard with analytics, user management, and reporting"
Your Response: "This sounds like a major feature that would benefit from detailed planning. Let me create a dedicated context for this work and we can draft a PRD together to ensure we capture all requirements."
Actions:
1. add_tag feature-dashboard --description="User dashboard with analytics and management"
2. Collaborate on PRD creation
3. parse_prd dashboard-prd.txt --tag=feature-dashboard
4. Add high-level "User Dashboard" task to master
```

**Example 3: Existing Project → Strategic Planning**
```
User: "I just initialized Taskmaster on my existing React app. It's getting messy and I want to improve it."
Your Response: "Let me research your codebase to understand the current architecture, then we can create a strategic plan for improvements."
Actions:
1. research "Current React app architecture and improvement opportunities" --tree --files=src/
2. Collaborate on improvement PRD based on findings
3. Create tags for different improvement areas (refactor-components, improve-state-management, etc.)
4. Keep only major improvement initiatives in master
```

---

## Primary Interaction: MCP Server vs. CLI

Taskmaster offers two primary ways to interact:

1.  **MCP Server (Recommended for Integrated Tools)**:
    - For AI agents and integrated development environments (like <AGENT>), interacting via the **MCP server is the preferred method**.
    - The MCP server exposes Taskmaster functionality through a set of tools (e.g., `get_tasks`, `add_subtask`).
    - This method offers better performance, structured data exchange, and richer error handling compared to CLI parsing.
    - Refer to @`mcp.md` for details on the MCP architecture and available tools.
    - A comprehensive list and description of MCP tools and their corresponding CLI commands can be found in @`taskmaster.md`.
    - **Restart the MCP server** if core logic in `scripts/modules` or MCP tool/direct function definitions change.
    - **Note**: MCP tools fully support tagged task lists with complete tag management capabilities.

2.  **`task-master` CLI (For Users & Fallback)**:
    - The global `task-master` command provides a user-friendly interface for direct terminal interaction.
    - It can also serve as a fallback if the MCP server is inaccessible or a specific function isn't exposed via MCP.
    - Install globally with `npm install -g task-master-ai` or use locally via `npx task-master-ai ...`.
    - The CLI commands often mirror the MCP tools (e.g., `task-master list` corresponds to `get_tasks`).
    - Refer to @`taskmaster.md` for a detailed command reference.
    - **Tagged Task Lists**: CLI fully supports the new tagged system with seamless migration.

## How the Tag System Works (For Your Reference)

- **Data Structure**: Tasks are organized into separate contexts (tags) like "master", "feature-branch", or "v2.0".
- **Silent Migration**: Existing projects automatically migrate to use a "master" tag with zero disruption.
- **Context Isolation**: Tasks in different tags are completely separate. Changes in one tag do not affect any other tag.
- **Manual Control**: The user is always in control. There is no automatic switching. You facilitate switching by using `use-tag <name>`.
- **Full CLI & MCP Support**: All tag management commands are available through both the CLI and MCP tools for you to use. Refer to @`taskmaster.md` for a full command list.

---

## Task Complexity Analysis

-   Run `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) for comprehensive analysis
-   Review complexity report via `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`) for a formatted, readable version.
-   Focus on tasks with highest complexity scores (8-10) for detailed breakdown
-   Use analysis results to determine appropriate subtask allocation
-   Note that reports are automatically used by the `expand_task` tool/command

## Task Breakdown Process

-   Use `expand_task` / `task-master expand --id=<id>`. It automatically uses the complexity report if found, otherwise generates default number of subtasks.
-   Use `--num=<number>` to specify an explicit number of subtasks, overriding defaults or complexity report recommendations.
-   Add `--research` flag to leverage Perplexity AI for research-backed expansion.
-   Add `--force` flag to clear existing subtasks before generating new ones (default is to append).
-   Use `--prompt="<context>"` to provide additional context when needed.
-   Review and adjust generated subtasks as necessary.
-   Use `expand_all` tool or `task-master expand --all` to expand multiple pending tasks at once, respecting flags like `--force` and `--research`.
-   If subtasks need complete replacement (regardless of the `--force` flag on `expand`), clear them first with `clear_subtasks` / `task-master clear-subtasks --id=<id>`.

## Implementation Drift Handling

-   When implementation differs significantly from planned approach
-   When future tasks need modification due to current implementation choices
-   When new dependencies or requirements emerge
-   Use `update` / `task-master update --from=<futureTaskId> --prompt='<explanation>\nUpdate context...' --research` to update multiple future tasks.
-   Use `update_task` / `task-master update-task --id=<taskId> --prompt='<explanation>\nUpdate context...' --research` to update a single specific task.

## Task Status Management

-   Use 'pending' for tasks ready to be worked on
-   Use 'done' for completed and verified tasks
-   Use 'deferred' for postponed tasks
-   Add custom status values as needed for project-specific workflows

## Task Structure Fields

- **id**: Unique identifier for the task (Example: `1`, `1.1`)
- **title**: Brief, descriptive title (Example: `"Initialize Repo"`)
- **description**: Concise summary of what the task involves (Example: `"Create a new repository, set up initial structure."`)
- **status**: Current state of the task (Example: `"pending"`, `"done"`, `"deferred"`)
- **dependencies**: IDs of prerequisite tasks (Example: `[1, 2.1]`)
    - Dependencies are displayed with status indicators (✅ for completed, ⏱️ for pending)
    - This helps quickly identify which prerequisite tasks are blocking work
- **priority**: Importance level (Example: `"high"`, `"medium"`, `"low"`)
- **details**: In-depth implementation instructions (Example: `"Use GitHub client ID/secret, handle callback, set session token."`)
- **testStrategy**: Verification approach (Example: `"Deploy and call endpoint to confirm 'Hello World' response."`)
- **subtasks**: List of smaller, more specific tasks (Example: `[{"id": 1, "title": "Configure OAuth", ...}]`)
- Refer to task structure details (previously linked to `tasks.md`).

## Configuration Management (Updated)

Taskmaster configuration is managed through two main mechanisms:

1.  **`.taskmaster/config.json` File (Primary):**
    *   Located in the project root directory.
    *   Stores most configuration settings: AI model selections (main, research, fallback), parameters (max tokens, temperature), logging level, default subtasks/priority, project name, etc.
    *   **Tagged System Settings**: Includes `global.defaultTag` (defaults to "master") and `tags` section for tag management configuration.
    *   **Managed via `task-master models --setup` command.** Do not edit manually unless you know what you are doing.
    *   **View/Set specific models via `task-master models` command or `models` MCP tool.**
    *   Created automatically when you run `task-master models --setup` for the first time or during tagged system migration.

2.  **Environment Variables (`.env` / `mcp.json`):**
    *   Used **only** for sensitive API keys and specific endpoint URLs.
    *   Place API keys (one per provider) in a `.env` file in the project root for CLI usage.
    *   For MCP/<AGENT> integration, configure these keys in the `env` section of `.<AGENT>/mcp.json`.
    *   Available keys/variables: See `assets/env.example` or the Configuration section in the command reference (previously linked to `taskmaster.md`).

[TRUNCATED]
```

.rules/rules.md
```
---
description: Guidelines for creating and maintaining AGENT rules to ensure consistency and effectiveness.
---

- **Required Rule Structure:**
  ```markdown
  ---
  description: Clear, one-line description of what the rule enforces
  ---

  - **Main Points in Bold**
    - Sub-points with details
    - Examples and explanations
  ```

- **File References:**
  - Use `[filename](md:path/to/file)` ([filename](md:filename)) to reference files
  - Example: [prisma.md](.ruler/prisma.md) for rule references
  - Example: [schema.prisma](md:prisma/schema.prisma) for code references

- **Code Examples:**
  - Use language-specific code blocks
  ```typescript
  // ✅ DO: Show good examples
  const goodExample = true;

  // ❌ DON'T: Show anti-patterns
  const badExample = false;
  ```

- **Rule Content Guidelines:**
  - Start with high-level overview
  - Include specific, actionable requirements
  - Show examples of correct implementation
  - Reference existing code when possible
  - Keep rules DRY by referencing other rules

- **Rule Maintenance:**
  - Update rules when new patterns emerge
  - Add examples from actual codebase
  - Remove outdated patterns
  - Cross-reference related rules

- **Best Practices:**
  - Use bullet points for clarity
  - Keep descriptions concise
  - Include both DO and DON'T examples
  - Reference actual code over theoretical examples
  - Use consistent formatting across rules
```

.rules/self_improve.md
```
---
description: Guidelines for continuously improving  rules based on emerging code patterns and best practices.
---

- **Rule Improvement Triggers:**
  - New code patterns not covered by existing rules
  - Repeated similar implementations across files
  - Common error patterns that could be prevented
  - New libraries or tools being used consistently
  - Emerging best practices in the codebase

- **Analysis Process:**
  - Compare new code with existing rules
  - Identify patterns that should be standardized
  - Look for references to external documentation
  - Check for consistent error handling patterns
  - Monitor test patterns and coverage

- **Rule Updates:**
  - **Add New Rules When:**
    - A new technology/pattern is used in 3+ files
    - Common bugs could be prevented by a rule
    - Code reviews repeatedly mention the same feedback
    - New security or performance patterns emerge

  - **Modify Existing Rules When:**
    - Better examples exist in the codebase
    - Additional edge cases are discovered
    - Related rules have been updated
    - Implementation details have changed

- **Example Pattern Recognition:**
  ```typescript
  // If you see repeated patterns like:
  const data = await prisma.user.findMany({
    select: { id: true, email: true },
    where: { status: 'ACTIVE' }
  });

  // Consider adding to [prisma.md](.ruler/prisma.md):
  // - Standard select fields
  // - Common where conditions
  // - Performance optimization patterns
  ```

- **Rule Quality Checks:**
  - Rules should be actionable and specific
  - Examples should come from actual code
  - References should be up to date
  - Patterns should be consistently enforced

- **Continuous Improvement:**
  - Monitor code review comments
  - Track common development questions
  - Update rules after major refactors
  - Add links to relevant documentation
  - Cross-reference related rules

- **Rule Deprecation:**
  - Mark outdated patterns as deprecated
  - Remove rules that no longer apply
  - Update references to deprecated rules
  - Document migration paths for old patterns

- **Documentation Updates:**
  - Keep examples synchronized with code
  - Update references to external docs
  - Maintain links between related rules
  - Document breaking changes
Follow [.ruler.md](.ruler/rules.md) for proper rule formatting and structure.
```

.rules/taskmaster.md
```
---
description: Comprehensive reference for Taskmaster MCP tools and CLI commands.
---

# Taskmaster Tool & Command Reference

This document provides a detailed reference for interacting with Taskmaster, covering both the recommended MCP tools, suitable for integrations like <AGENT>, and the corresponding `task-master` CLI commands, designed for direct user interaction or fallback.

**Note:** For interacting with Taskmaster programmatically or via integrated tools, using the **MCP tools is strongly recommended** due to better performance, structured data, and error handling. The CLI commands serve as a user-friendly alternative and fallback.

**Important:** Several MCP tools involve AI processing... The AI-powered tools include `parse_prd`, `analyze_project_complexity`, `update_subtask`, `update_task`, `update`, `expand_all`, `expand_task`, and `add_task`.

**🏷️ Tagged Task Lists System:** Task Master now supports **tagged task lists** for multi-context task management. This allows you to maintain separate, isolated lists of tasks for different features, branches, or experiments. Existing projects are seamlessly migrated to use a default "master" tag. Most commands now support a `--tag <name>` flag to specify which context to operate on. If omitted, commands use the currently active tag.

---

## Initialization & Setup

### 1. Initialize Project (`init`)

*   **MCP Tool:** `initialize_project`
*   **CLI Command:** `task-master init [options]`
*   **Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project.`
*   **Key CLI Options:**
    *   `--name <name>`: `Set the name for your project in Taskmaster's configuration.`
    *   `--description <text>`: `Provide a brief description for your project.`
    *   `--version <version>`: `Set the initial version for your project, e.g., '0.1.0'.`
    *   `-y, --yes`: `Initialize Taskmaster quickly using default settings without interactive prompts.`
*   **Usage:** Run this once at the beginning of a new project.
*   **MCP Variant Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project by running the 'task-master init' command.`
*   **Key MCP Parameters/Options:**
    *   `projectName`: `Set the name for your project.` (CLI: `--name <name>`)
    *   `projectDescription`: `Provide a brief description for your project.` (CLI: `--description <text>`)
    *   `projectVersion`: `Set the initial version for your project, e.g., '0.1.0'.` (CLI: `--version <version>`)
    *   `authorName`: `Author name.` (CLI: `--author <author>`)
    *   `skipInstall`: `Skip installing dependencies. Default is false.` (CLI: `--skip-install`)
    *   `addAliases`: `Add shell aliases tm, taskmaster, hamster, and ham. Default is false.` (CLI: `--aliases`)
    *   `yes`: `Skip prompts and use defaults/provided arguments. Default is false.` (CLI: `-y, --yes`)
*   **Usage:** Run this once at the beginning of a new project, typically via an integrated tool like <AGENT>. Operates on the current working directory of the MCP server.
*   **Important:** Once complete, you *MUST* parse a prd in order to generate tasks. There will be no tasks files until then. The next step after initializing should be to create a PRD using the example PRD in .taskmaster/templates/example_prd.txt.
*   **Tagging:** Use the `--tag` option to parse the PRD into a specific, non-default tag context. If the tag doesn't exist, it will be created automatically. Example: `task-master parse-prd spec.txt --tag=new-feature`.

### 2. Parse PRD (`parse_prd`)

*   **MCP Tool:** `parse_prd`
*   **CLI Command:** `task-master parse-prd [file] [options]`
*   **Description:** `Parse a Product Requirements Document, PRD, or text file with Taskmaster to automatically generate an initial set of tasks in tasks.json.`
*   **Key Parameters/Options:**
    *   `input`: `Path to your PRD or requirements text file that Taskmaster should parse for tasks.` (CLI: `[file]` positional or `-i, --input <file>`)
    *   `output`: `Specify where Taskmaster should save the generated 'tasks.json' file. Defaults to '.taskmaster/tasks/tasks.json'.` (CLI: `-o, --output <file>`)
    *   `numTasks`: `Approximate number of top-level tasks Taskmaster should aim to generate from the document.` (CLI: `-n, --num-tasks <number>`)
    *   `force`: `Use this to allow Taskmaster to overwrite an existing 'tasks.json' without asking for confirmation.` (CLI: `-f, --force`)
*   **Usage:** Useful for bootstrapping a project from an existing requirements document.
*   **Notes:** Task Master will strictly adhere to any specific requirements mentioned in the PRD, such as libraries, database schemas, frameworks, tech stacks, etc., while filling in any gaps where the PRD isn't fully specified. Tasks are designed to provide the most direct implementation path while avoiding over-engineering.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress. If the user does not have a PRD, suggest discussing their idea and then use the example PRD in `.taskmaster/templates/example_prd.txt` as a template for creating the PRD based on their idea, for use with `parse-prd`.

---

## AI Model Configuration

### 2. Manage Models (`models`)
*   **MCP Tool:** `models`
*   **CLI Command:** `task-master models [options]`
*   **Description:** `View the current AI model configuration or set specific models for different roles (main, research, fallback). Allows setting custom model IDs for Ollama and OpenRouter.`
*   **Key MCP Parameters/Options:**
    *   `setMain <model_id>`: `Set the primary model ID for task generation/updates.` (CLI: `--set-main <model_id>`)
    *   `setResearch <model_id>`: `Set the model ID for research-backed operations.` (CLI: `--set-research <model_id>`)
    *   `setFallback <model_id>`: `Set the model ID to use if the primary fails.` (CLI: `--set-fallback <model_id>`)
    *   `ollama <boolean>`: `Indicates the set model ID is a custom Ollama model.` (CLI: `--ollama`)
    *   `openrouter <boolean>`: `Indicates the set model ID is a custom OpenRouter model.` (CLI: `--openrouter`)
    *   `listAvailableModels <boolean>`: `If true, lists available models not currently assigned to a role.` (CLI: No direct equivalent; CLI lists available automatically)
    *   `projectRoot <string>`: `Optional. Absolute path to the project root directory.` (CLI: Determined automatically)
*   **Key CLI Options:**
    *   `--set-main <model_id>`: `Set the primary model.`
    *   `--set-research <model_id>`: `Set the research model.`
    *   `--set-fallback <model_id>`: `Set the fallback model.`
    *   `--ollama`: `Specify that the provided model ID is for Ollama (use with --set-*).`
    *   `--openrouter`: `Specify that the provided model ID is for OpenRouter (use with --set-*). Validates against OpenRouter API.`
    *   `--bedrock`: `Specify that the provided model ID is for AWS Bedrock (use with --set-*).`
    *   `--setup`: `Run interactive setup to configure models, including custom Ollama/OpenRouter IDs.`
*   **Usage (MCP):** Call without set flags to get current config. Use `setMain`, `setResearch`, or `setFallback` with a valid model ID to update the configuration. Use `listAvailableModels: true` to get a list of unassigned models. To set a custom model, provide the model ID and set `ollama: true` or `openrouter: true`.
*   **Usage (CLI):** Run without flags to view current configuration and available models. Use set flags to update specific roles. Use `--setup` for guided configuration, including custom models. To set a custom model via flags, use `--set-<role>=<model_id>` along with either `--ollama` or `--openrouter`.
*   **Notes:** Configuration is stored in `.taskmaster/config.json` in the project root. This command/tool modifies that file. Use `listAvailableModels` or `task-master models` to see internally supported models. OpenRouter custom models are validated against their live API. Ollama custom models are not validated live.
*   **API note:** API keys for selected AI providers (based on their model) need to exist in the mcp.json file to be accessible in MCP context. The API keys must be present in the local .env file for the CLI to be able to read them.
*   **Model costs:** The costs in supported models are expressed in dollars. An input/output value of 3 is $3.00. A value of 0.8 is $0.80.
*   **Warning:** DO NOT MANUALLY EDIT THE .taskmaster/config.json FILE. Use the included commands either in the MCP or CLI format as needed. Always prioritize MCP tools when available and use the CLI as a fallback.

---

## Task Listing & Viewing

### 3. Get Tasks (`get_tasks`)

*   **MCP Tool:** `get_tasks`
*   **CLI Command:** `task-master list [options]`
*   **Description:** `List your Taskmaster tasks, optionally filtering by status and showing subtasks.`
*   **Key Parameters/Options:**
    *   `status`: `Show only Taskmaster tasks matching this status (or multiple statuses, comma-separated), e.g., 'pending' or 'done,in-progress'.` (CLI: `-s, --status <status>`)
    *   `withSubtasks`: `Include subtasks indented under their parent tasks in the list.` (CLI: `--with-subtasks`)
    *   `tag`: `Specify which tag context to list tasks from. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
    *   `watch`: `Watch for changes and auto-refresh the list in real-time. Works with file storage (fs.watch) and API storage (Supabase Realtime).` (CLI: `-w, --watch`)
*   **Usage:** Get an overview of the project status, often used at the start of a work session. Use `--watch` to keep the list live-updating as tasks change.

### 4. Get Next Task (`next_task`)

*   **MCP Tool:** `next_task`
*   **CLI Command:** `task-master next [options]`
*   **Description:** `Ask Taskmaster to show the next available task you can work on, based on status and completed dependencies.`
*   **Key Parameters/Options:**
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
    *   `tag`: `Specify which tag context to use. Defaults to the current active tag.` (CLI: `--tag <name>`)
*   **Usage:** Identify what to work on next according to the plan.

### 5. Get Task Details (`get_task`)

*   **MCP Tool:** `get_task`
*   **CLI Command:** `task-master show [id] [options]`
*   **Description:** `Display detailed information for one or more specific Taskmaster tasks or subtasks by ID.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID of the Taskmaster task (e.g., '15'), subtask (e.g., '15.2'), or a comma-separated list of IDs ('1,5,10.2') you want to view.` (CLI: `[id]` positional or `-i, --id <id>`)
    *   `tag`: `Specify which tag context to get the task(s) from. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Understand the full details for a specific task. When multiple IDs are provided, a summary table is shown.
*   **CRITICAL INFORMATION** If you need to collect information from multiple tasks, use comma-separated IDs (i.e. 1,2,3) to receive an array of tasks. Do not needlessly get tasks one at a time if you need to get many as that is wasteful.

---

## Task Creation & Modification

### 6. Add Task (`add_task`)

*   **MCP Tool:** `add_task`
*   **CLI Command:** `task-master add-task [options]`
*   **Description:** `Add a new task to Taskmaster by describing it; AI will structure it.`
*   **Key Parameters/Options:**
    *   `prompt`: `Required. Describe the new task you want Taskmaster to create, e.g., "Implement user authentication using JWT".` (CLI: `-p, --prompt <text>`)
    *   `dependencies`: `Specify the IDs of any Taskmaster tasks that must be completed before this new one can start, e.g., '12,14'.` (CLI: `-d, --dependencies <ids>`)
    *   `priority`: `Set the priority for the new task: 'high', 'medium', or 'low'. Default is 'medium'.` (CLI: `--priority <priority>`)
    *   `research`: `Enable Taskmaster to use the research role for potentially more informed task creation.` (CLI: `-r, --research`)
    *   `tag`: `Specify which tag context to add the task to. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Quickly add newly identified tasks during development.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 7. Add Subtask (`add_subtask`)

*   **MCP Tool:** `add_subtask`
*   **CLI Command:** `task-master add-subtask [options]`
*   **Description:** `Add a new subtask to a Taskmaster parent task, or convert an existing task into a subtask.`
*   **Key Parameters/Options:**
    *   `id` / `parent`: `Required. The ID of the Taskmaster task that will be the parent.` (MCP: `id`, CLI: `-p, --parent <id>`)
    *   `taskId`: `Use this if you want to convert an existing top-level Taskmaster task into a subtask of the specified parent.` (CLI: `-i, --task-id <id>`)
    *   `title`: `Required if not using taskId. The title for the new subtask Taskmaster should create.` (CLI: `-t, --title <title>`)
    *   `description`: `A brief description for the new subtask.` (CLI: `-d, --description <text>`)
    *   `details`: `Provide implementation notes or details for the new subtask.` (CLI: `--details <text>`)
    *   `dependencies`: `Specify IDs of other tasks or subtasks, e.g., '15' or '16.1', that must be done before this new subtask.` (CLI: `--dependencies <ids>`)
    *   `status`: `Set the initial status for the new subtask. Default is 'pending'.` (CLI: `-s, --status <status>`)
    *   `generate`: `Enable Taskmaster to regenerate markdown task files after adding the subtask.` (CLI: `--generate`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Break down tasks manually or reorganize existing tasks.

### 8. Update Tasks (`update`)

*   **MCP Tool:** `update`
*   **CLI Command:** `task-master update [options]`
*   **Description:** `Update multiple upcoming tasks in Taskmaster based on new context or changes, starting from a specific task ID.`
*   **Key Parameters/Options:**
    *   `from`: `Required. The ID of the first task Taskmaster should update. All tasks with this ID or higher that are not 'done' will be considered.` (CLI: `--from <id>`)
    *   `prompt`: `Required. Explain the change or new context for Taskmaster to apply to the tasks, e.g., "We are now using React Query instead of Redux Toolkit for data fetching".` (CLI: `-p, --prompt <text>`)
    *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Handle significant implementation changes or pivots that affect multiple future tasks. Example CLI: `task-master update --from='18' --prompt='Switching to React Query.\nNeed to refactor data fetching...'`
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 9. Update Task (`update_task`)

*   **MCP Tool:** `update_task`
*   **CLI Command:** `task-master update-task [options]`
*   **Description:** `Modify a specific Taskmaster task by ID, incorporating new information or changes. By default, this replaces the existing task details.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The specific ID of the Taskmaster task, e.g., '15', you want to update.` (CLI: `-i, --id <id>`)
    *   `prompt`: `Required. Explain the specific changes or provide the new information Taskmaster should incorporate into this task.` (CLI: `-p, --prompt <text>`)
    *   `append`: `If true, appends the prompt content to the task's details with a timestamp, rather than replacing them. Behaves like update-subtask.` (CLI: `--append`)
    *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
    *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Refine a specific task based on new understanding. Use `--append` to log progress without creating subtasks.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 10. Update Subtask (`update_subtask`)

*   **MCP Tool:** `update_subtask`
*   **CLI Command:** `task-master update-subtask [options]`
*   **Description:** `Append timestamped notes or details to a specific Taskmaster subtask without overwriting existing content. Intended for iterative implementation logging.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID of the Taskmaster subtask, e.g., '5.2', to update with new information.` (CLI: `-i, --id <id>`)
    *   `prompt`: `Required. The information, findings, or progress notes to append to the subtask's details with a timestamp.` (CLI: `-p, --prompt <text>`)
    *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
    *   `tag`: `Specify which tag context the subtask belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Log implementation progress, findings, and discoveries during subtask development. Each update is timestamped and appended to preserve the implementation journey.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 11. Set Task Status (`set_task_status`)

*   **MCP Tool:** `set_task_status`
*   **CLI Command:** `task-master set-status [options]`
*   **Description:** `Update the status of one or more Taskmaster tasks or subtasks, e.g., 'pending', 'in-progress', 'done'.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID(s) of the Taskmaster task(s) or subtask(s), e.g., '15', '15.2', or '16,17.1', to update.` (CLI: `-i, --id <id>`)
    *   `status`: `Required. The new status to set, e.g., 'done', 'pending', 'in-progress', 'review', 'cancelled'.` (CLI: `-s, --status <status>`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Mark progress as tasks move through the development cycle.

### 12. Remove Task (`remove_task`)

*   **MCP Tool:** `remove_task`
*   **CLI Command:** `task-master remove-task [options]`
*   **Description:** `Permanently remove a task or subtask from the Taskmaster tasks list.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID of the Taskmaster task, e.g., '5', or subtask, e.g., '5.2', to permanently remove.` (CLI: `-i, --id <id>`)
    *   `yes`: `Skip the confirmation prompt and immediately delete the task.` (CLI: `-y, --yes`)
[TRUNCATED]
```

.tickets/Oraclepack File Storage.md
```
Parent Ticket:

* Title: Stop oraclepack from writing run state/config JSON files into the project working directory
* Summary: oraclepack currently writes per-pack `*.state.json`, `*.report.json`, and `*.chatgpt-urls.json` files into the repo/working directory. The requested change is to store these as config/state/cache outside the repo root (prefer XDG base dirs) and/or under a dedicated project-local `.oraclepack/` directory to avoid clutter.
* Source:

  * Link/ID: Not provided
  * Original ticket excerpt (≤25 words) capturing the overall theme: “Move state/report outputs out of CWD by default… Stop producing per-pack `*.chatgpt-urls.json` by default.”
* Global Constraints:

  * Treat outputs as **config/state/cache** and store outside repo root using XDG base dirs (per ticket text).
  * Use Go `os.UserConfigDir()` / `os.UserCacheDir()` for cross-platform defaults (per ticket text).
  * No `UserStateDir()` in Go stdlib; implement `$XDG_STATE_HOME` fallback (per ticket text).
* Global Environment:

  * Unknown
* Global Evidence:

  * Current filenames mentioned: `<packBase>.state.json`, `<packBase>.report.json`, `<sameBase>.chatgpt-urls.json`.
  * XDG Base Directory spec reference (background).
  * Go `os.UserConfigDir` / `os.UserCacheDir` reference (background).

Split Plan:

* Coverage Map:

  * Original item: “`oraclepack run` … derives filenames from the pack basename and writes them to the current working directory: `statePath := <packBase>.state.json`, `reportPath := <packBase>.report.json`”

    * Assigned Ticket ID: T2
  * Original item: “The TUI ‘ChatGPT URL picker’ then creates `<sameBase>.chatgpt-urls.json` next to the state file (or next to the pack file if statePath is empty).”

    * Assigned Ticket ID: T3
  * Original item: “It also defaults edits to **project scope**, so it will keep generating project-scoped stores unless the user explicitly switches to global.”

    * Assigned Ticket ID: T3
  * Original item: “Treat these as **config/state/cache** and store them outside the repo root using standard base dirs: … `$XDG_CONFIG_HOME` … `$XDG_STATE_HOME` … `$XDG_CACHE_HOME`…”

    * Assigned Ticket ID: T1
  * Original item: “In Go, you should use `os.UserConfigDir()` / `os.UserCacheDir()`… (There’s no `UserStateDir()`… implement XDG_STATE_HOME fallback…)”

    * Assigned Ticket ID: T1
  * Original item: “Move state/report outputs out of CWD by default… Update `internal/cli/run.go`… Make the directory overridable with a flag/env (e.g., `--state-dir` / `ORACLEPACK_STATE_DIR`).”

    * Assigned Ticket ID: T2
  * Original item: “Stop producing per-pack `*.chatgpt-urls.json` by default… Best UX default: change … default save scope to **global**…”

    * Assigned Ticket ID: T3
  * Original item: “Keep ‘project scope’ as an opt-in mode, but write it to a single per-project location (e.g., `<repo>/.oraclepack/chatgpt-urls.json`), not `<packName>.chatgpt-urls.json`.”

    * Assigned Ticket ID: T3
  * Original item: “Acceptable alternative (project-local…): `<repo>/.oraclepack/state/*.state.json` … `<repo>/.oraclepack/chatgpt-urls.json` … add `.oraclepack/` to `.gitignore`.”

    * Assigned Ticket ID: T4
  * Original item: “Immediate workaround (no code changes): Add these to `.gitignore`: `*.state.json`, `*.report.json`, `*.chatgpt-urls.json`.”

    * Assigned Ticket ID: T4
* Dependencies:

  * T2 depends on T1 because T2 needs an agreed/default “oraclepack state dir” location strategy (XDG-based) to write into.
  * T3 depends on T1 because T3 needs a global config location strategy (XDG-based) for URL persistence.
* Split Tickets:

```ticket T1
T# Title: Define XDG-based directory strategy for oraclepack config/state/cache
Type: chore
Target Area: Config/state path resolution (shared utility / helpers)
Summary:
- Define the standard locations where oraclepack stores user config, run state, and cache so outputs stop polluting the repo root.
- The ticket requires using XDG base dirs and Go’s cross-platform helpers where applicable, with an explicit fallback for state.
In Scope:
- Adopt XDG directory categories as the guiding model:
  - Config: `$XDG_CONFIG_HOME` (default `~/.config`)
  - State: `$XDG_STATE_HOME` (default `~/.local/state`)
  - Cache: `$XDG_CACHE_HOME` (default `~/.cache`)
- Use Go `os.UserConfigDir()` / `os.UserCacheDir()` for cross-platform defaults (per ticket text).
- Implement a state-dir resolver that honors `$XDG_STATE_HOME` and falls back when not set (since Go stdlib has no `UserStateDir()`).
Out of Scope:
- Not provided
Current Behavior (Actual):
- Not provided
Expected Behavior:
- oraclepack has a single, consistent mechanism to determine:
  - “oraclepack config dir” (for user prefs like URL lists)
  - “oraclepack state dir” (for resume/run state)
  - “oraclepack cache dir” (for non-essential cached data)
Reproduction Steps:
- Not provided
Requirements / Constraints:
- Treat outputs as config/state/cache; store outside repo root using standard base dirs (per ticket text).
- Use `os.UserConfigDir()` / `os.UserCacheDir()` where applicable (per ticket text).
- Implement `$XDG_STATE_HOME` fallback logic (per ticket text).
Evidence:
- “Treat these as config/state/cache and store them outside the repo root using standard base dirs…” (parent ticket)
- “In Go, you should use os.UserConfigDir() / os.UserCacheDir()… There’s no UserStateDir()…” (parent ticket)
Open Items / Unknowns:
- Exact package/file locations for where to place the shared directory-resolution logic: Unknown
Risks / Dependencies:
- Not provided
Acceptance Criteria:
- A single directory-resolution mechanism exists for config/state/cache categories as described in scope.
- The state-dir resolution honors `$XDG_STATE_HOME` when set and has a documented fallback when unset.
- The config/cache resolution uses Go’s `os.UserConfigDir()` / `os.UserCacheDir()` (or equivalent wrapper) per ticket text.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Treat these as config/state/cache and store them outside the repo root using standard base dirs…”
- “In Go, you should use os.UserConfigDir() / os.UserCacheDir()… There’s no UserStateDir()…”
```

```ticket T2
T# Title: Move run-generated state/report JSON outputs out of CWD and add state-dir override
Type: enhancement
Target Area: Run command output paths (`internal/cli/run.go`)
Summary:
- oraclepack currently writes `<packBase>.state.json` and `<packBase>.report.json` into the current working directory.
- Update the run pathing so these files are written under a dedicated “oraclepack state dir” by default, with an override via flag/env.
In Scope:
- Change default output location for:
  - `<packBase>.state.json`
  - `<packBase>.report.json`
  from current working directory to a dedicated “oraclepack state dir”.
- Update `internal/cli/run.go` to compute state/report paths under that state dir (per ticket text).
- Add override via flag and env:
  - `--state-dir`
  - `ORACLEPACK_STATE_DIR`
Out of Scope:
- Not provided
Current Behavior (Actual):
- `<packBase>.state.json` and `<packBase>.report.json` are written to the current working directory.
Expected Behavior:
- By default, running oraclepack does not create `*.state.json` / `*.report.json` in the repo root / CWD.
- By default, state/report files are written under the dedicated oraclepack state dir.
- Setting `--state-dir` or `ORACLEPACK_STATE_DIR` writes state/report files under the specified directory.
Reproduction Steps:
1) Run `oraclepack run` from a repo root (or any working directory).
2) Observe creation of `<packBase>.state.json` and `<packBase>.report.json` in the working directory.
Requirements / Constraints:
- Must be overridable by `--state-dir` / `ORACLEPACK_STATE_DIR` (per ticket text).
- Should use the state-dir strategy defined in T1 for the default state dir.
Evidence:
- “`oraclepack run` … writes them to the current working directory: `statePath := <packBase>.state.json`, `reportPath := <packBase>.report.json`”
- “Update `internal/cli/run.go` … Make the directory overridable with a flag/env (e.g., `--state-dir` / `ORACLEPACK_STATE_DIR`).”
Open Items / Unknowns:
- Whether state/report filenames must remain exactly `<packBase>.state.json` / `<packBase>.report.json` or can change: Not provided
Risks / Dependencies:
- Depends on T1 for default state-dir resolution strategy.
Acceptance Criteria:
- Running oraclepack with no overrides does not create `*.state.json` or `*.report.json` in the current working directory.
- With no overrides, state/report files are written under the resolved oraclepack state dir.
- With `--state-dir=<dir>`, state/report files are written under `<dir>`.
- With `ORACLEPACK_STATE_DIR=<dir>`, state/report files are written under `<dir>`.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “`oraclepack run` … writes … `<packBase>.state.json` … `<packBase>.report.json` … to the current working directory”
- “Move state/report outputs out of CWD by default… Update internal/cli/run.go… `--state-dir` / `ORACLEPACK_STATE_DIR`”
```

```ticket T3
T# Title: Stop generating per-pack `*.chatgpt-urls.json`; default URL picker persistence to global store
Type: enhancement
Target Area: TUI “ChatGPT URL picker” persistence
Summary:
- The TUI URL picker currently creates `<sameBase>.chatgpt-urls.json` near the pack/state file and defaults edits to project scope.
- Change it so the default save scope is global (one file), while keeping project scope as an opt-in that writes to a single stable per-project path.
In Scope:
- Remove/avoid creating `<sameBase>.chatgpt-urls.json` “next to the state file (or next to the pack file…)” (per ticket text).
- Change the URL picker default save scope to **global** (per ticket text).
- Keep “project scope” as opt-in, but store at a single stable path:
  - `<repo>/.oraclepack/chatgpt-urls.json`
  rather than `<packName>.chatgpt-urls.json` (per ticket text).
- Persist the global URL store to a single global location:
  - Per ticket text, an existing global store path is referenced: `~/.oraclepack/chatgpt-urls.json`.
Out of Scope:
- Not provided
Current Behavior (Actual):
- URL picker creates `<sameBase>.chatgpt-urls.json` next to the state file (or pack file).
- URL picker defaults edits to project scope.
Expected Behavior:
- Using the URL picker does not create `<packBase>.chatgpt-urls.json` files.
- Default persistence is global (one stable file).
- Project scope, if selected, writes only to `<repo>/.oraclepack/chatgpt-urls.json`.
Reproduction Steps:
1) Use the TUI “ChatGPT URL picker” during a run.
2) Observe `<sameBase>.chatgpt-urls.json` being created near pack/state file.
Requirements / Constraints:
- Default save scope should be global (per ticket text).
- Project scope must be opt-in and must not create per-pack URL json files (per ticket text).
- Global persistence location:
  - Conflicting guidance exists: ticket recommends XDG config dir generally, but also references existing `~/.oraclepack/chatgpt-urls.json` path.
Evidence:
- “The TUI ‘ChatGPT URL picker’ then creates `<sameBase>.chatgpt-urls.json`…”
- “It also defaults edits to project scope…”
- “Stop producing per-pack `*.chatgpt-urls.json` by default… change … default save scope to global…”
- “Keep ‘project scope’ as an opt-in… write it to `<repo>/.oraclepack/chatgpt-urls.json`… not `<packName>.chatgpt-urls.json`.”
Open Items / Unknowns:
- Whether to keep `~/.oraclepack/chatgpt-urls.json` as the global path or migrate to `$XDG_CONFIG_HOME/...` (both appear in the parent ticket guidance).
- Exact file/path of the “URL picker” implementation: Not provided
Risks / Dependencies:
- Depends on T1 if migrating global storage to XDG config dir.
Acceptance Criteria:
- After using the URL picker, no `<packBase>.chatgpt-urls.json` is created near the pack/state/CWD.
- Default behavior persists URLs to exactly one global store (stable path; not per-pack).
- When “project scope” is selected, URLs persist to `<repo>/.oraclepack/chatgpt-urls.json` (single per-project file).
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “The TUI ‘ChatGPT URL picker’ then creates `<sameBase>.chatgpt-urls.json`…”
- “Best UX default: change … default save scope to global…”
- “Keep ‘project scope’ … `<repo>/.oraclepack/chatgpt-urls.json`, not `<packName>.chatgpt-urls.json`.”
```

```ticket T4
T# Title: Add project-local `.oraclepack/` layout guidance and `.gitignore` patterns to prevent repo pollution
Type: docs
Target Area: Repo hygiene (docs / templates / ignore rules)
Summary:
- The parent ticket proposes an acceptable project-local layout under `<repo>/.oraclepack/` and an immediate workaround via `.gitignore`.
- Capture these as documented guidance (and/or provide default ignore patterns) so repos remain clean even before code changes land.
In Scope:
- Document (or provide recommended structure for) project-local layout:
  - `<repo>/.oraclepack/state/*.state.json`
  - `<repo>/.oraclepack/state/*.report.json`
  - `<repo>/.oraclepack/chatgpt-urls.json`
- Add guidance to add `.oraclepack/` to `.gitignore` when adopting that structure.
- Add the immediate workaround ignore patterns:
  - `*.state.json`
  - `*.report.json`
  - `*.chatgpt-urls.json`
Out of Scope:
- Not provided
Current Behavior (Actual):
- Not provided
Expected Behavior:
- Repos can adopt a single project-local `.oraclepack/` directory and ignore it.
- Repos can immediately ignore current output filenames to avoid noise.
Reproduction Steps:
- Not provided
Requirements / Constraints:
- Must preserve the exact patterns and structure described in the parent ticket text.
Evidence:
- “Acceptable alternative (project-local…): `<repo>/.oraclepack/state/*.state.json` … add `.oraclepack/` to `.gitignore`.”
- “Immediate workaround (no code changes): Add these to `.gitignore`: `*.state.json`, `*.report.json`, `*.chatgpt-urls.json`.”
Open Items / Unknowns:
- Where this guidance should live (README, docs page, template): Not provided
Risks / Dependencies:
- Not provided
Acceptance Criteria:
- Documentation includes the described `.oraclepack/` directory layout and explicitly recommends ignoring `.oraclepack/` when using it.
- Documentation includes the three immediate-workaround `.gitignore` patterns exactly as specified.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Acceptable alternative (project-local…): `<repo>/.oraclepack/state/*.state.json`… add `.oraclepack/` to `.gitignore`.”
- “Immediate workaround… Add these to `.gitignore`: `*.state.json`…”
```
```

.tickets/Oraclepack Schema Approach.md
```
Parent Ticket:

* Title: Adopt a schema-driven approach to prevent oraclepack run failures
* Summary:

  * Current runs fail because structure is inferred from Markdown heuristics (e.g., exactly one ```bash fence, sequential step headers, exactly 20 steps).
  * Proposal: generate a machine-validated **manifest** (JSON Schema) and **deterministically render** the Markdown pack; optionally add stricter linting for Markdown-only packs.
* Source:

  * Link/ID (if present) or “Not provided”
  * Original ticket excerpt (≤25 words) capturing the overall theme

    * “separate ‘machine-validated structure’ from ‘human-readable Markdown’ … generate only a JSON manifest … then a deterministic renderer produces the Markdown pack.”
* Global Constraints:

  * Keep existing oraclepack Markdown contract / backward-compatible (“keep the existing Markdown contract for oraclepack execution”).
  * Steps must be exactly 20; step IDs must be sequential 01..20.
* Global Environment:

  * Unknown
* Global Evidence:

  * Error text: “invalid pack structure: no bash code block found”.
  * Pack constraints referenced: “Exactly one ```bash fence”, “Exactly 20 steps”, “sequential step numbers”.

Split Plan:

* Coverage Map:

  * Original item: “separate ‘machine-validated structure’ from ‘human-readable Markdown.’”

    * Assigned Ticket ID: T1
  * Original item: “AI generates only a JSON manifest that must validate against a JSON Schema; renderer produces Markdown pack.”

    * Assigned Ticket ID: T1
  * Original item: “Prevent missing/multiple ```bash fences (root cause of ‘invalid pack structure: no bash code block found’).”

    * Assigned Ticket ID: T3
  * Original item: “Prevent non-sequential steps (Go validator requires sequential step numbers).”

    * Assigned Ticket ID: T1
  * Original item: “Prevent wrong step count (enforce exactly 20 in schema).”

    * Assigned Ticket ID: T1
  * Original item: “Minimal ‘Pack Manifest v1’ JSON Schema (Draft 2020-12) with schema_version/kind/out_dir/write_output/steps; step fields id/title/bash plus roi/impact/confidence/effort/horizon/category/reference.”

    * Assigned Ticket ID: T1
  * Original item: “Rendering rule (deterministic): one ```bash fence; prelude out_dir=…; optional --write-output; each step ‘# 01) …’ with body.”

    * Assigned Ticket ID: T2
  * Original item: “If Markdown-only: add explicit schema/lint mode (exactly one ```bash fence; exactly 20 steps; sequential 01..20; optional header tokens).”

    * Assigned Ticket ID: T3
  * Original item: “Stage-2 directory contract: exactly one file per prefix 01-*.md … 20-*.md.”

    * Assigned Ticket ID: T3
  * Original item: “Action pack lint (Stage 3): one ```bash fence; enforce 01..20 exact count.”

    * Assigned Ticket ID: T3
  * Original item: “CI checks: validate(manifest.json) → render(pack.md) → oraclepack validate pack.md → (optional) dry-run checks.”

    * Assigned Ticket ID: T4
* Dependencies:

  * T2 depends on T1 because the renderer needs the validated “Pack Manifest v1” structure as input.
  * T4 depends on T1 and T2 because CI runs “validate(manifest.json) → render(pack.md)”.
* Split Tickets:

```ticket T1
T# Title: Define and validate “Pack Manifest v1” schema (manifest-first)
Type: chore
Target Area: Pack authoring contract (manifest JSON + JSON Schema validation)
Summary:
- Introduce a manifest-first source of truth: the AI produces a JSON manifest that must validate against a JSON Schema.
- The schema enforces step count (exactly 20) and step IDs (01..20) to prevent structural runner failures.
- This separates machine-validated structure from the Markdown pack to reduce malformed packs.
In Scope:
- Define “Pack Manifest v1” JSON Schema (Draft 2020-12) with required fields: schema_version (const 1), kind (enum), out_dir, steps (min/max 20).
- Define step object constraints: required id/title/bash; id pattern for 01..20; optional roi/impact/confidence/effort/horizon/category/reference.
- Validate manifests against the schema before rendering/using them.
Out of Scope:
- Not provided
Current Behavior (Actual):
- Runner infers structure from Markdown heuristics; malformed structure can cause run-time validation errors.
- Step count and sequential numbering can be violated if not enforced early.
Expected Behavior:
- A manifest that does not conform (wrong count, wrong IDs, missing required fields) is rejected by schema validation.
- Manifests accepted by validation always contain exactly 20 steps with valid IDs and required fields.
Reproduction Steps:
1) Provide a manifest with fewer than 20 steps.
2) Provide a manifest with a non-matching step id (e.g., "21" or "1").
3) Validate manifest and confirm it fails schema validation.
Requirements / Constraints:
- schema_version must be 1.
- steps must be exactly 20 (minItems=20, maxItems=20).
- step id must match 01..20 via pattern.
Evidence:
- “the AI generates only a JSON manifest that must validate against a JSON Schema” (ticket text)
- “Wrong step count (you can enforce exactly 20 in schema rather than ‘hoping’ the model did it).”
Open Items / Unknowns:
- Exact location/path conventions for storing manifest.json are not provided.
- How/where validation is invoked (CLI, CI, library) is not provided.
Risks / Dependencies:
- Risk: keeping backward compatibility requires rendering to the existing Markdown pack contract (handled in T2).
Acceptance Criteria:
- [ ] A JSON Schema exists for “Pack Manifest v1” with required fields and constraints as described.
- [ ] A manifest with != 20 steps fails validation.
- [ ] A manifest with an invalid step id fails validation.
- [ ] A manifest missing required fields (schema_version/kind/out_dir/steps) fails validation.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Manifest-first + JSON Schema (then render Markdown)”
- “minItems: 20, maxItems: 20”
- “id … pattern: ^(0[1-9]|1[0-9]|20)$”
```

````ticket T2
T# Title: Implement deterministic renderer from manifest → oraclepack Markdown pack
Type: enhancement
Target Area: Pack rendering (manifest → Markdown pack)
Summary:
- Add a deterministic rendering rule that converts a validated manifest into a Markdown pack that always satisfies oraclepack’s structural expectations.
- This prevents issues like missing/multiple bash fences and malformed step formatting by making Markdown a compiled artifact.
In Scope:
- Render exactly one fenced code block labeled `bash` in the entire document.
- Render prelude lines including: `out_dir="..."` and optional `--write-output` as described.
- Render each step with header `# NN) ...` and step body from `bash` content.
Out of Scope:
- Not provided
Current Behavior (Actual):
- Markdown is the primary artifact; structure can be malformed by generation, causing downstream failures.
Expected Behavior:
- Renderer output always includes exactly one `bash` fence and emits all 20 steps in order.
- Pack contains the required prelude line(s) described in the ticket text.
Reproduction Steps:
1) Validate a manifest (per T1).
2) Render to Markdown.
3) Confirm output contains exactly one `bash` fence and step headers for 01..20 in sequence.
Requirements / Constraints:
- Output must be runner-ingestible per the described structural rules (single bash fence, 20 steps, sequential).
Evidence:
- “Rendering rule (deterministic) … emits exactly: one ```bash fence … prelude lines … then each step: # 01) … Step body = bash”
Open Items / Unknowns:
- Exact step title formatting beyond “# NN) …” is not provided.
- Whether additional header tokens (ROI=…) are required at render time is not provided.
Risks / Dependencies:
- Depends on T1 (renderer assumes manifest structure/constraints).
Acceptance Criteria:
- [ ] Given a valid manifest, renderer produces a Markdown pack with exactly one ```bash fenced block.
- [ ] Output contains 20 step headers numbered 01..20 in order.
- [ ] Output includes the `out_dir="..."` prelude line.
- [ ] Renderer can conditionally include the optional `--write-output` line when present in the manifest.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “From this manifest, your renderer emits exactly: One ```bash fence”
- “Prelude lines: out_dir="..." … optional --write-output”
- “Then each step: # 01) … Step body = bash”
````

````ticket T3
T# Title: Add stricter lint/validation for Markdown-only packs and Stage-2/Stage-3 outputs
Type: chore
Target Area: Pack linting/validation (Markdown packs + output directory contract)
Summary:
- If the project keeps Markdown-only as a supported input path, add an explicit lint/validation mode that enforces the same structural contract.
- Extend checks to Stage-2 output directory naming expectations and Stage-3 action pack constraints to reduce “runner infers structure” failures.
In Scope:
- Pack-level lint (Stage 1) enforcing:
  - Exactly one ```bash fence.
  - Exactly 20 steps.
  - Step IDs exactly 01..20 and sequential.
  - Optional enforcement of required header tokens (ROI= impact= confidence= … reference=) as described.
- Stage-2 directory contract lint:
  - Exactly one file per prefix 01-*.md … 20-*.md.
- Stage-3 action pack lint:
  - Exactly one ```bash fence.
  - Enforce 01..20 and exact count.
Out of Scope:
- Not provided
Current Behavior (Actual):
- Common failure mode noted: “invalid pack structure: no bash code block found.”
- Existing checks may be incomplete (“your current check only ensures ‘some’ step headers exist” per ticket text).
Expected Behavior:
- Markdown packs that violate the contract are rejected early with lint errors before execution.
- Stage-2 outputs and Stage-3 action packs are validated against exact-count and naming/structure rules.
Reproduction Steps:
1) Create a Markdown pack with no `bash` fenced block → lint should fail.
2) Create a Markdown pack with 19 steps or non-sequential IDs → lint should fail.
3) Create an output directory missing `07-*.md` or containing duplicates for a prefix → lint should fail.
Requirements / Constraints:
- Enforce: one ```bash fence, exactly 20 steps, sequential 01..20.
Evidence:
- “Missing / multiple ```bash fences (common root cause of ‘invalid pack structure: no bash code block found’).”
- “Add an explicit schema/lint mode … Exactly one ```bash fence … Exactly 20 steps … Step IDs exactly 01..20”
- “Stage-2 directory contract … Exactly one file per prefix 01-*.md … 20-*.md”
- “Action pack lint (Stage 3) … Enforce 01..20 and exact count”
Open Items / Unknowns:
- Exact current validator behaviors and what already exists vs missing are not provided.
Risks / Dependencies:
- Risk: enforcing optional header tokens could break existing packs if not already standardized.
Acceptance Criteria:
- [ ] Lint fails when no `bash` fence exists and surfaces a clear error.
- [ ] Lint fails when step count != 20.
- [ ] Lint fails when step IDs are not exactly 01..20 sequential.
- [ ] Stage-2 lint fails when any step output prefix 01..20 is missing or duplicated.
- [ ] Stage-3 lint fails when action pack does not have exactly one `bash` fence or correct 01..20 steps.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “invalid pack structure: no bash code block found”
- “Pack-level lint (Stage 1) … Exactly one ```bash fence … Exactly 20 steps”
- “Stage-2 directory contract … Exactly one file per prefix 01-*.md … 20-*.md”
````

```ticket T4
T# Title: Add CI validation pipeline for manifest-first workflow (validate → render → oraclepack validate → optional dry-run)
Type: chore
Target Area: CI checks / pipeline gating
Summary:
- Add CI checks that gate merges/runs on structural correctness by validating the manifest, rendering Markdown deterministically, and validating the rendered pack with oraclepack tooling.
- This formalizes the “Markdown is compiled artifact” approach and reduces runtime surprises.
In Scope:
- CI sequence as described:
  - validate(manifest.json)
  - render(pack.md)
  - oraclepack validate pack.md
  - optional dry-run checks
Out of Scope:
- Not provided
Current Behavior (Actual):
- Pack structural issues can slip into execution time if not validated earlier.
Expected Behavior:
- CI fails fast when manifest validation fails or rendered pack fails oraclepack validation.
Reproduction Steps:
1) Commit a manifest with 19 steps; CI should fail at validate(manifest.json).
2) Commit a manifest that renders an invalid pack (if possible); CI should fail at oraclepack validate.
Requirements / Constraints:
- CI must preserve existing oraclepack Markdown contract (rendered pack is what oraclepack consumes).
Evidence:
- “Add CI checks: validate(manifest.json) → render(pack.md) → oraclepack validate pack.md → (optional) dry-run checks”
Open Items / Unknowns:
- Where CI runs (provider/tooling) is not provided.
- Whether “dry-run checks” exist and what they check is not provided.
Risks / Dependencies:
- Depends on T1 and T2 to provide validate+render steps.
Acceptance Criteria:
- [ ] CI runs schema validation on manifest.json and fails on invalid manifests.
- [ ] CI renders pack.md deterministically from the manifest.
- [ ] CI runs oraclepack validation on pack.md and fails if invalid.
- [ ] Optional dry-run step is present if supported; otherwise omitted without breaking the sequence intent.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Add CI checks: validate(manifest.json) → render(pack.md) → oraclepack validate pack.md → (optional) dry-run checks”
- “Treat Markdown packs as a compiled artifact, not the source of truth.”
```
```

.tickets/Oraclepack bash fix.md
```
Parent Ticket:

* Title: Prevent oraclepack pack failures caused by orphaned `-p/--prompt` lines in generated bash steps
* Summary: Generated oraclepack markdown packs can emit a multiline `oracle ...` command where `-p "$(cat <<'PROMPT' ...)"` starts on a new line without a continuation, causing Bash to treat `-p` as a standalone command and fail (`exit status 127`). The fix requires making pack generation structurally safe and adding validator guardrails that fail fast on regressions.
* Source:

  * Link/ID: Bash command syntax fix.md
  * Original ticket excerpt (≤25 words) capturing the overall theme: “make the generator/template structurally unable to emit orphaned flags… and make oraclepack validate fail fast”
* Global Constraints:

  * “never put `-p/--prompt` (or any flag) on its own line”
  * “no inline comments at end of an `oracle ...` line”
* Global Environment:

  * Unknown
* Global Evidence:

  * Error: `bash: line 59: -p: command not found` + `exit status 127`
  * Reference pack: `oracle-pack-2026-01-08-tickets-direct.md` (pattern repeated across steps)

Split Plan:

* Coverage Map:

  * “`bash: line 59: -p: command not found` + `exit status 127`” → T1
  * “`-p "$(cat <<'PROMPT' ...)"` is on the next line without `\` … repeated in others” → T1
  * “Minimal fix: add a continuation backslash, or put `-p` on the same line” → T1
  * “Optional comment goes ABOVE the command, not inline” → T1
  * “Wherever you render `oracle ... "${ticket_args[@]}" # extra_files ...` then newline then `-p ...` … change it” → T1
  * “Permanent template rule: never put `-p/--prompt` on its own line; build prompt first, then call oracle on a single command line” → T1
  * “Enforce: no inline comments at end of an `oracle ...` line” → T1
  * “If you must wrap long lines, require explicit `\` continuations and disallow comments on continued lines” → T1
  * “Add checks to `oraclepack validate` after extracting the single `bash` fence” → T2
  * “Add `bash -n` syntax check” → T2
  * “Add `shellcheck` static analysis” → T2
  * “Custom ‘orphaned flag line’ detector (regex + continuation exceptions)” → T2
  * “Ensure `oraclepack run` always calls `validate` first (or at minimum in TUI Run/Rerun paths)” → T3
  * “Add CI/pre-commit: run `oraclepack validate` on any generated/modified pack” → T3
  * “Offer: point at exact rendering pattern + canonical snippet” → Non-actionable / Info-only
* Dependencies:

  * T3 depends on T2 because “Make validate unavoidable” is intended to enforce the added validator checks that catch regressions.
* Split Tickets:

```ticket T1
T# Title: Make pack generation structurally safe (no orphaned `-p/--prompt` lines)
Type: bug
Target Area: Pack generator/template that emits oraclepack Markdown steps (tickets-direct pack generation)
Summary:
- Generated packs can split an `oracle ...` invocation across lines such that `-p "$(cat <<'PROMPT' ...)"` starts on a new line without a continuation.
- Bash then executes `-p` as a standalone command, causing `command not found` and `exit status 127`.
- Update generation patterns so prompts are built safely and the `oracle` command remains a single logical command (or uses correct continuations without inline comment footguns).
In Scope:
- Eliminate multiline `oracle` invocations that place `-p/--prompt` on its own line.
- Apply the “minimal fix” pattern where multiline is unavoidable: add a line-continuation `\` (and ensure comments do not break continuation).
- Enforce generator rule: no inline trailing comments on `oracle ...` lines (comments/newlines can terminate the command unexpectedly).
- Adopt canonical “build prompt first, then call oracle” step shape as the standard emission pattern.
Out of Scope:
- Not provided
Current Behavior (Actual):
- `oracle ...` command is terminated by a newline, then `-p "$(cat <<'PROMPT' ...)"` appears on the next line without `\`, so Bash treats `-p` as a command and fails.
Expected Behavior:
- Generated bash steps never emit orphaned flag lines (e.g., `-p`, `-f`, `--prompt`) that can be interpreted as standalone shell commands.
- Generated `oracle` invocations are either a single logical line or correctly continued (without inline comments breaking continuation).
Reproduction Steps:
1. Run the generated pack `oracle-pack-2026-01-08-tickets-direct.md`.
2. Observe the step where `-p` begins a new line without a continuation and the shell errors.
Requirements / Constraints:
- “never put `-p/--prompt` (or any flag) on its own line”
- “no inline comments at end of an `oracle ...` line”
- If wrapping is necessary: require explicit `\` continuations and disallow comments on continued lines.
Evidence:
- Error: `bash: line 59: -p: command not found` + `exit status 127`
- Pattern described: `-p "$(cat <<'PROMPT' ...)"` on next line without `\` in `oracle-pack-2026-01-08-tickets-direct.md`
Open Items / Unknowns:
- Exact location(s) of the emitting template(s): Unknown / Not provided
- Whether multiple generators/templates emit the pattern beyond tickets-direct: Unknown / Not provided
Risks / Dependencies:
- Risk: Partial fixes (only adding `\`) may regress if inline comments or formatting are reintroduced.
Acceptance Criteria:
- Generated packs do not contain any step where a line begins with `-p` / `--prompt` intended as a continuation of `oracle` without an explicit safe structure.
- Running the regenerated tickets-direct pack no longer produces `-p: command not found` / `exit status 127` for the previously failing steps.
- Generator output follows one of:
  - prompt built first + `oracle ... --prompt "$prompt"` as a single logical command, OR
  - explicit `\` continuation with no inline trailing comments on continued lines.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “`bash: line 59: -p: command not found` + `exit status 127`”
- “the `-p "$(cat <<'PROMPT' ...)"` part is on the next line without a line-continuation (`\`)”
- “Permanent template rule: never put `-p/--prompt` (or any flag) on its own line”
```

```ticket T2
T# Title: Add validator guardrails (bash-lint + orphaned-flag detection) to fail fast
Type: enhancement
Target Area: `oraclepack validate` (after extracting the single `bash` fence)
Summary:
- Even with a safer generator, regressions can reintroduce orphaned flag lines that only fail at runtime.
- Add validation checks that detect bash syntax issues and the specific “orphaned flag line” class before execution.
- Validation should clearly fail on suspicious standalone flag lines unless safely continued.
In Scope:
- Run `bash -n` against the extracted bash step script(s) as a syntax sanity check.
- Run `shellcheck` static analysis on the extracted bash script(s).
- Implement the custom “orphaned flag line” detector:
  - Fail if a non-heredoc line matches `^\s*-(p|f)\b` or `^\s*--(prompt|file|write-output)\b`
  - Unless the previous non-empty line ends with a legal continuation (`\`, `|`, `&&`, `||`, `(`, etc.)
Out of Scope:
- Making `validate` mandatory in all run paths (handled separately)
Current Behavior (Actual):
- Not provided
Expected Behavior:
- `oraclepack validate` fails fast with a clear error when a pack contains likely orphaned flag lines (e.g., `-p ...`) outside permitted continuation contexts.
- `oraclepack validate` reports bash syntax issues before execution.
Reproduction Steps:
1. Create/modify a pack step where `-p` is on its own line without a valid continuation.
2. Run `oraclepack validate`.
Requirements / Constraints:
- Checks are added “after extracting the single `bash` fence”.
- Orphaned-flag detector must ignore heredoc bodies (“non-heredoc line”).
Evidence:
- “Add these checks to `oraclepack validate` after extracting the single `bash` fence”
- Detector specification (regex + continuation exceptions) provided in ticket text.
Open Items / Unknowns:
- Availability/installation method for `shellcheck` in the execution environment: Unknown / Not provided
- Exact current structure of `oraclepack validate` and how it extracts bash fence: Unknown / Not provided
Risks / Dependencies:
- Risk: False positives if continuation heuristics are too strict; must match the specified allowed continuations.
Acceptance Criteria:
- `oraclepack validate` includes `bash -n` and fails on invalid bash syntax in the extracted script(s).
- `oraclepack validate` runs `shellcheck` and surfaces failures per project policy (pass/fail behavior not specified in ticket text).
- `oraclepack validate` fails when a non-heredoc line begins with `-p`, `-f`, `--prompt`, `--file`, or `--write-output` and the previous non-empty line does not end with an allowed continuation token.
- `oraclepack validate` does not falsely flag valid heredoc prompt bodies.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Add these checks to `oraclepack validate` after extracting the single `bash` fence”
- “`bash -n` syntax check (cheap sanity)”
- “Custom ‘orphaned flag line’ detector… `^\s*-(p|f)\b` … unless… ends with… (`\`, `|`, `&&`, `||`, `(`, etc.)”
```

```ticket T3
T# Title: Make validation unavoidable in normal use (run/TUI) and add CI/pre-commit gate
Type: chore
Target Area: `oraclepack run` execution flow, TUI “Run/Rerun” paths, and repo automation (CI/pre-commit)
Summary:
- Validation guardrails are only effective if they run consistently before pack execution.
- Ensure `oraclepack run` calls `validate` first (or at minimum in TUI Run/Rerun paths).
- Add automated gating so modified/generated packs are validated before being executed/merged.
In Scope:
- Ensure `oraclepack run` always calls `validate` first.
- Ensure TUI “Run/Rerun” paths invoke `validate` first (at minimum).
- Add CI/pre-commit step to run `oraclepack validate` on generated/modified packs.
Out of Scope:
- Implementing the validator checks themselves (handled separately)
Current Behavior (Actual):
- Not provided
Expected Behavior:
- Running a pack via CLI or TUI triggers validation first, preventing execution of invalid packs.
- CI/pre-commit blocks changes that introduce invalid pack structure detectable by `oraclepack validate`.
Reproduction Steps:
1. Introduce a known-invalid pattern (e.g., orphaned `-p` line) into a pack.
2. Attempt to run via `oraclepack run` and via TUI Run/Rerun.
3. Attempt to commit/CI-run with the invalid pack present.
Requirements / Constraints:
- “Ensure `oraclepack run` always calls `validate` first (or at minimum in TUI ‘Run/Rerun’ paths).”
- “Add CI/pre-commit: run `oraclepack validate` on any generated/modified pack.”
Evidence:
- The ticket text specifies making validation unavoidable and adding CI/pre-commit gating.
Open Items / Unknowns:
- Existing CI/pre-commit tooling and where to hook validation: Unknown / Not provided
- Exact TUI entrypoints for Run/Rerun: Unknown / Not provided
Risks / Dependencies:
- Depends on `oraclepack validate` providing the intended guardrails to justify making it mandatory.
Acceptance Criteria:
- `oraclepack run` invokes `validate` before executing pack steps.
- TUI Run/Rerun paths invoke `validate` before execution (at minimum).
- CI/pre-commit configuration exists to run `oraclepack validate` on generated/modified packs and fails on validation errors.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Make validate unavoidable in normal use”
- “Ensure `oraclepack run` always calls `validate` first (or at minimum in TUI ‘Run/Rerun’ paths).”
- “Add CI/pre-commit: run `oraclepack validate` on any generated/modified pack.”
```
```

.tickets/Publish OraclePack MCP.md
```
Parent Ticket:

* Title: Publish/distribute `oraclepack-mcp-server` to avoid long-form MCP client configuration
* Summary: Replace the hardcoded venv interpreter path in MCP client configs with a portable, short config, and optionally enable one-click installation for supported clients.
* Source:

  * Link/ID (if present) or “Not provided”: `oraclepack-op-mcp.md`
  * Original ticket excerpt (≤25 words) capturing the overall theme: “publish this so we do not have to use the long form configuration for configuring mcp clients”
* Global Constraints:

  * Eliminate reliance on an absolute venv interpreter path in MCP client configuration.
  * Preserve required env variables (`ORACLEPACK_BIN`, `ORACLEPACK_ALLOWED_ROOTS`, `ORACLEPACK_ENABLE_EXEC`) in examples.
* Global Environment:

  * Unknown
* Global Evidence:

  * Current MCP client config example (shows venv path + args + env).

Split Plan:

* Coverage Map:

  * Original item: “how do I publish this so we do not have to use the long form configuration for configuring mcp clients?”

    * Assigned Ticket ID: T1
  * Original item: Current config uses venv interpreter path: `"command": "/home/user/.../venv/bin/python"`

    * Assigned Ticket ID: T1
  * Original item: Current args: `["-m", "oraclepack_mcp_server", "--transport", "stdio"]`

    * Assigned Ticket ID: T1
  * Original item: Current env vars: `ORACLEPACK_BIN`, `ORACLEPACK_ALLOWED_ROOTS`, `ORACLEPACK_ENABLE_EXEC`

    * Assigned Ticket ID: T1
  * Original item: Option 1: “Publish a Python package so the MCP command is just a PATH executable” + `uv build`, `uv publish`, `uv tool install ...`

    * Assigned Ticket ID: T1
  * Original item: Option 1 config snippet (command becomes `oraclepack-mcp-server`, args `--transport stdio`, env preserved)

    * Assigned Ticket ID: T1
  * Original item: Note: “If you want to reduce env too, prefer absolute paths…”

    * Assigned Ticket ID: T1
  * Original item: Option 2: “No install short config: run via uvx” + config snippet using `"command": "uvx"`

    * Assigned Ticket ID: T2
  * Original item: Option 2 note: aligns with `server.json` PyPI example using `runtimeHint: "uvx"`

    * Assigned Ticket ID: T4
  * Original item: Option 3a: “Claude Desktop: ship a .mcpb bundle” + `mcpb init`, `mcpb pack` + distribute `.mcpb`

    * Assigned Ticket ID: T3
  * Original item: Option 3b: “publish to Official MCP Registry (and GitHub MCP Registry)” via `server.json` and `mcp-publisher` steps

    * Assigned Ticket ID: T4
  * Original item: Recommendation section (choose Option 1 for no venv path; Option 3 for no manual config)

    * Assigned Ticket ID: Info-only
  * Original item: Note: “standardize the executable name to match the PyPI identifier”

    * Assigned Ticket ID: T1
* Dependencies:

  * T2 depends on T1 because the `uvx` approach runs the published package name (`oraclepack-mcp-server`).
  * T4 depends on T1 because the described registry publishing path references a PyPI stdio server example.
* Split Tickets:

```ticket T1
T# Title: Publish `oraclepack-mcp-server` as a PATH executable (PyPI + uv tools) and update config example
Type: enhancement
Target Area: Distribution/packaging for MCP server (`oraclepack-mcp-server`) + MCP client config examples
Summary:
- Publish the MCP server as a Python package so MCP clients can invoke it via a normal command on PATH instead of a venv interpreter path.
- Provide the shorter MCP client configuration example that uses `command: "oraclepack-mcp-server"` and preserves required env vars.
In Scope:
- Publish steps using uv:
  - `uv build`
  - `uv publish`
- Install guidance via uv tools:
  - `uv tool install oraclepack-mcp-server`
- Update the MCP client config example to:
  - `"command": "oraclepack-mcp-server"`
  - `"args": ["--transport", "stdio"]`
  - Keep env: `ORACLEPACK_BIN`, `ORACLEPACK_ALLOWED_ROOTS`, `ORACLEPACK_ENABLE_EXEC`
- Naming guidance: standardize executable name to match the PyPI identifier (e.g., `oraclepack-mcp-server`).
- Guidance note: prefer absolute paths for env values if trying to reduce/env-stabilize in hosts with undefined working directory.
Out of Scope:
- “One-click install” packaging and registry publishing (handled in other tickets).
Current Behavior (Actual):
- MCP client config points at a venv interpreter path and runs `-m oraclepack_mcp_server`:
  - `"command": "/home/user/.../venv/bin/python"`
Expected Behavior:
- MCP client config can run a PATH command directly:
  - `"command": "oraclepack-mcp-server"`
  - No venv absolute path required.
Reproduction Steps:
- Not provided
Requirements / Constraints:
- Preserve required env variables in examples:
  - `ORACLEPACK_BIN`
  - `ORACLEPACK_ALLOWED_ROOTS`
  - `ORACLEPACK_ENABLE_EXEC`
Evidence:
- Current config snippet includes venv interpreter path and env vars:
  - `"command": "/home/user/projects/temp/oraclepack/oraclepack-mcp-server/venv/bin/python"`
  - `"args": ["-m", "oraclepack_mcp_server", "--transport", "stdio"]`
  - `ORACLEPACK_BIN`, `ORACLEPACK_ALLOWED_ROOTS`, `ORACLEPACK_ENABLE_EXEC`
Open Items / Unknowns:
- Package metadata and repository details for publishing (Unknown / Not provided).
- Desired final executable name if it differs from `oraclepack-mcp-server` (Unknown / Not provided).
Risks / Dependencies:
- Not provided
Acceptance Criteria:
- A published distribution path exists that does not require MCP clients to reference a venv interpreter path.
- Documentation/config example shows:
  - `"command": "oraclepack-mcp-server"`
  - `"args": ["--transport", "stdio"]`
  - env variables preserved as shown in the source text.
- Executable naming guidance is documented (“match the PyPI identifier”).
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “publish/distribute paths that eliminate the venv absolute path”
- “Publish a Python package so the MCP `command` is just a PATH executable”
- “uv build / uv publish … uv tool install oraclepack-mcp-server”
```

```ticket T2
T# Title: Add “no install” MCP config option using `uvx`
Type: docs
Target Area: MCP client configuration documentation/examples
Summary:
- Provide a short MCP client configuration that runs the server via `uvx` so users don’t need a pre-created local venv path in config.
- Keep required environment variables in the example config.
In Scope:
- Document the `uvx`-based MCP client config example:
  - `"command": "uvx"`
  - `"args": ["oraclepack-mcp-server", "--transport", "stdio"]`
  - env: `ORACLEPACK_BIN`, `ORACLEPACK_ALLOWED_ROOTS`, `ORACLEPACK_ENABLE_EXEC`
Out of Scope:
- Publishing to PyPI (handled in T1).
- Registry publishing via `server.json`/`mcp-publisher` (handled in T4).
Current Behavior (Actual):
- Config is “long-form” due to a venv interpreter path.
Expected Behavior:
- Users can use a short config that invokes `uvx` with the package name and stdio transport args.
Reproduction Steps:
- Not provided
Requirements / Constraints:
- Preserve required env variables in the example config.
Evidence:
- Option 2 config snippet:
  - `"command": "uvx"`
  - `"args": ["oraclepack-mcp-server", "--transport", "stdio"]`
Open Items / Unknowns:
- Whether target MCP clients/hosts support `uvx` invocation in their MCP server configuration (Unknown / Not provided).
Risks / Dependencies:
- Depends on T1 (published package name referenced by `uvx`).
Acceptance Criteria:
- Documentation includes the `uvx` config snippet exactly as described in the source text.
- Documentation explicitly retains the required env variable keys used in the source text.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “No install short config: run via `uvx`”
- `"command": "uvx", "args": ["oraclepack-mcp-server", "--transport", "stdio"]`
```

```ticket T3
T# Title: Create and distribute a `.mcpb` bundle for Claude Desktop installation
Type: enhancement
Target Area: MCP Bundle packaging for Claude Desktop distribution
Summary:
- Package the local MCP server as a `.mcpb` bundle so users can install via a UI flow in supported clients (Claude Desktop mentioned).
- Document the bundle creation commands and distribution approach.
In Scope:
- Use MCPB tooling steps as described:
  - `npm install -g @anthropic-ai/mcpb`
  - `mcpb init`
  - `mcpb pack`
- Distribute the resulting `.mcpb` (example given: GitHub Releases).
- Document that users install via Claude Desktop Extensions UI flow (per source text).
Out of Scope:
- PyPI publishing and `uv` tooling approach (handled in T1).
- Official/GitHub MCP registry publishing (handled in T4).
Current Behavior (Actual):
- Users must configure MCP clients manually with JSON.
Expected Behavior:
- Users can install the server via a `.mcpb` bundle in clients that support MCP bundles (Claude Desktop mentioned).
Reproduction Steps:
- Not provided
Requirements / Constraints:
- Follow the described `.mcpb` workflow (init + pack).
Evidence:
- “Claude Desktop: ship a `.mcpb` bundle … mcpb init … mcpb pack … Distribute the resulting `.mcpb`”
Open Items / Unknowns:
- Bundle manifest contents and exact server entrypoints required by MCPB for this server (Unknown / Not provided).
Risks / Dependencies:
- Not provided
Acceptance Criteria:
- A `.mcpb` bundle can be produced using the documented CLI steps.
- Documentation explains how to obtain the `.mcpb` (distribution channel mentioned) and install it in Claude Desktop (Extensions UI flow mentioned).
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Claude Desktop: ship a `.mcpb` bundle”
- “mcpb init … mcpb pack”
- “Distribute the resulting `.mcpb` (e.g., GitHub Releases)”
```

```ticket T4
T# Title: Publish `server.json` via `mcp-publisher` for MCP Registry / GitHub MCP Registry discovery
Type: enhancement
Target Area: Registry publishing metadata (`server.json`) + publishing workflow (`mcp-publisher`)
Summary:
- Enable “one-click install” in supported clients by publishing a `server.json` descriptor via `mcp-publisher`, targeting the Official MCP Registry and GitHub MCP Registry (as described).
- Document the high-level publishing steps and ownership proof requirement as stated.
In Scope:
- Generate `server.json` using `mcp-publisher init`.
- Follow the publishing sequence as described:
  1) Install `mcp-publisher`
  2) `mcp-publisher init` to generate `server.json`
  3) Prove package ownership (PyPI: add `mcp-name: ...` to README)
  4) `mcp-publisher login github`
  5) `mcp-publisher publish`
- Ensure `server.json` aligns with the described PyPI stdio example capabilities (mentions `environmentVariables` and `runtimeHint: "uvx"`).
Out of Scope:
- `.mcpb` bundling (handled in T3).
- Core PyPI package publishing steps (handled in T1).
Current Behavior (Actual):
- Users must manually configure MCP clients using JSON and local paths.
Expected Behavior:
- Server is discoverable/installable via registry mechanisms described (VS Code / ecosystem via registry).
Reproduction Steps:
- Not provided
Requirements / Constraints:
- Include the described package ownership proof metadata for PyPI (README `mcp-name: ...`).
Evidence:
- “publish a `server.json` via `mcp-publisher`”
- Step list including `mcp-publisher init`, README `mcp-name: ...`, `login github`, `publish`
- Note about PyPI example supporting `environmentVariables` and `runtimeHint: "uvx"`
Open Items / Unknowns:
- Final server identifier/name to use for `mcp-name: ...` (Unknown / Not provided).
- Which registries/clients are in scope beyond “VS Code / ecosystem” phrasing (Unknown / Not provided).
Risks / Dependencies:
- Depends on T1 if the published registry entry targets a PyPI package distribution (as described).
Acceptance Criteria:
- A `server.json` exists generated/maintained via `mcp-publisher init` per the described workflow.
- Documentation includes the stated publishing steps and the PyPI ownership proof requirement (`mcp-name: ...` in README).
- Documentation notes the described `runtimeHint: "uvx"` alignment for the PyPI stdio example.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “publish to the Official MCP Registry (and GitHub MCP Registry)”
- “publish a `server.json` via `mcp-publisher`”
- “Prove package ownership … add `mcp-name: ...` to your README”
```
```

oraclepack-mcp-server/inspector.config.json
```
{
  "mcpServers": {
    "oraclepack": {
      "command": "/home/user/projects/temp/oraclepack/oraclepack-mcp-server/venv/bin/python",
      "args": ["-m", "oraclepack_mcp_server", "--transport", "stdio"],
      "env": {
        "ORACLEPACK_BIN": "oraclepack",
        "ORACLEPACK_ALLOWED_ROOTS": "/home/user/projects/temp/oraclepack",
        "ORACLEPACK_ENABLE_EXEC": "1"
      }
    }
  }
}
```

oraclepack-mcp-server/pyproject.toml
```
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "oraclepack-mcp-server"
version = "0.1.0"
description = "MCP wrapper for oraclepack CLI"
authors = [
    { name = "Oraclepack Contributor" }
]
dependencies = [
    "mcp[cli]>=0.1.0",
    "pydantic-settings>=2.0.0",
    "pydantic>=2.0.0",
]
requires-python = ">=3.10"

[project.scripts]
oraclepack-mcp = "oraclepack_mcp_server.__main__:main"
```

oraclepack-mcp-server/requirements.txt
```
mcp[cli]
pydantic-settings
pydantic>=2.0
```

scripts/build_install_oraclepack.md
```
```bash
# path: scripts/build_install_oraclepack.sh
#!/usr/bin/env bash
set -euo pipefail

# Builds oraclepack for:
# - WSL/Linux (oraclepack)
# - Windows amd64 (oraclepack.exe)
# Then installs:
# - WSL binary -> ~/.local/bin/
# - Windows exe -> /mnt/c/Users/<winuser>/.local/bin/
# And writes a Git Bash wrapper:
# - /mnt/c/Users/<winuser>/bin/oraclepack  (calls WSL binary via wsl.exe)

usage() {
  cat <<'USAGE'
Usage:
  scripts/build_install_oraclepack.sh [options]

Options:
  --repo-root <path>      Repo root (default: git toplevel, else current dir)
  --win-user <name>       Windows username (default: auto-detect, else "user")
  --wsl-distro <name>     WSL distro name for wsl.exe -d (default: $WSL_DISTRO_NAME or "Ubuntu-24.04")
  --wsl-user <name>       WSL username for wsl.exe -u (default: current user)
  --no-linux              Skip building/installing Linux binary
  --no-windows            Skip building/installing Windows .exe
  --no-wrapper            Skip writing the Git Bash wrapper script
  --cgo <0|1>             Set CGO_ENABLED (default: leave unchanged)

Examples:
  scripts/build_install_oraclepack.sh
  scripts/build_install_oraclepack.sh --win-user Alice --wsl-distro Ubuntu-24.04
USAGE
}

die() { echo "error: $*" >&2; exit 1; }

have() { command -v "$1" >/dev/null 2>&1; }

detect_repo_root() {
  if have git && git rev-parse --show-toplevel >/dev/null 2>&1; then
    git rev-parse --show-toplevel
  else
    pwd
  fi
}

detect_win_user() {
  # Best-effort: ask Windows for %USERNAME% via cmd.exe (works in most WSL setups).
  if have cmd.exe; then
    local u
    u="$(cmd.exe /c "echo %USERNAME%" 2>/dev/null | tr -d '\r' | tail -n 1 || true)"
    if [[ -n "${u:-}" && "${u:-}" != "%USERNAME%" ]]; then
      echo "$u"
      return
    fi
  fi
  echo "user"
}

REPO_ROOT=""
WIN_USER=""
WSL_DISTRO="${WSL_DISTRO_NAME:-Ubuntu-24.04}"
WSL_USER="$(whoami)"
DO_LINUX=1
DO_WINDOWS=1
DO_WRAPPER=1
CGO=""

while [[ $# -gt 0 ]]; do
  case "$1" in
    --repo-root)  REPO_ROOT="${2:-}"; shift 2;;
    --win-user)   WIN_USER="${2:-}"; shift 2;;
    --wsl-distro) WSL_DISTRO="${2:-}"; shift 2;;
    --wsl-user)   WSL_USER="${2:-}"; shift 2;;
    --no-linux)   DO_LINUX=0; shift;;
    --no-windows) DO_WINDOWS=0; shift;;
    --no-wrapper) DO_WRAPPER=0; shift;;
    --cgo)        CGO="${2:-}"; shift 2;;
    -h|--help)    usage; exit 0;;
    *)            die "unknown option: $1 (use --help)";;
  esac
done

[[ -n "$REPO_ROOT" ]] || REPO_ROOT="$(detect_repo_root)"
[[ -d "$REPO_ROOT" ]] || die "repo root not found: $REPO_ROOT"

[[ -n "$WIN_USER" ]] || WIN_USER="$(detect_win_user)"

have go || die "go not found in PATH"

# Paths
LINUX_OUT="$REPO_ROOT/oraclepack"
WIN_OUT="$REPO_ROOT/oraclepack.exe"

LINUX_INSTALL_DIR="$HOME/.local/bin"
LINUX_INSTALL_PATH="$LINUX_INSTALL_DIR/oraclepack"

WIN_HOME="/mnt/c/Users/$WIN_USER"
WIN_LOCAL_BIN_DIR="$WIN_HOME/.local/bin"
WIN_LOCAL_BIN_PATH="$WIN_LOCAL_BIN_DIR/oraclepack.exe"

WIN_GITBASH_BIN_DIR="$WIN_HOME/bin"
WIN_GITBASH_WRAPPER_PATH="$WIN_GITBASH_BIN_DIR/oraclepack"

# Optional CGO toggle
if [[ -n "$CGO" ]]; then
  [[ "$CGO" == "0" || "$CGO" == "1" ]] || die "--cgo must be 0 or 1"
  export CGO_ENABLED="$CGO"
fi

cd "$REPO_ROOT"

# Build binaries
if [[ "$DO_LINUX" -eq 1 ]]; then
  echo "==> Building Linux (WSL) binary: $LINUX_OUT"
  go build -o "$LINUX_OUT" ./cmd/oraclepack
fi

if [[ "$DO_WINDOWS" -eq 1 ]]; then
  echo "==> Building Windows amd64 exe: $WIN_OUT"
  GOOS=windows GOARCH=amd64 go build -o "$WIN_OUT" ./cmd/oraclepack
fi

# Install binaries
if [[ "$DO_LINUX" -eq 1 ]]; then
  echo "==> Installing Linux binary -> $LINUX_INSTALL_PATH"
  mkdir -p "$LINUX_INSTALL_DIR"
  cp -f "$LINUX_OUT" "$LINUX_INSTALL_PATH"
fi

if [[ "$DO_WINDOWS" -eq 1 ]]; then
  echo "==> Installing Windows exe -> $WIN_LOCAL_BIN_PATH"
  mkdir -p "$WIN_LOCAL_BIN_DIR"
  cp -f "$WIN_OUT" "$WIN_LOCAL_BIN_PATH"
fi

# Write Git Bash wrapper (stored on Windows filesystem)
if [[ "$DO_WRAPPER" -eq 1 ]]; then
  echo "==> Writing Git Bash wrapper -> $WIN_GITBASH_WRAPPER_PATH"
  mkdir -p "$WIN_GITBASH_BIN_DIR"

  cat > "$WIN_GITBASH_WRAPPER_PATH" <<EOF
#!/usr/bin/env bash
set -euo pipefail

# Git for Windows (Git Bash) path-conversion off for this exec call.
# Required so /home/... is not rewritten into C:/Program Files/Git/...
MSYS_NO_PATHCONV=1 exec wsl.exe -d ${WSL_DISTRO@Q} -u ${WSL_USER@Q} -- ${LINUX_INSTALL_PATH@Q} "\$@"
EOF

  # Ensure LF line endings (in case editor/tool wrote CRLF) and best-effort executable bit.
  sed -i 's/\r$//' "$WIN_GITBASH_WRAPPER_PATH" || true
  chmod +x "$WIN_GITBASH_WRAPPER_PATH" 2>/dev/null || true

  echo "==> Note: In Git Bash, ensure ~/bin is in PATH (so 'oraclepack' resolves to this wrapper)."
fi

echo "==> Done."
echo "    WSL binary:     $LINUX_INSTALL_PATH"
echo "    Windows exe:    $WIN_LOCAL_BIN_PATH"
echo "    Git Bash wrap:  $WIN_GITBASH_WRAPPER_PATH"
```

Run (from repo root in WSL):

```bash
chmod +x scripts/build_install_oraclepack.sh
scripts/build_install_oraclepack.sh
```

Optional example:

```bash
scripts/build_install_oraclepack.sh --win-user user --wsl-distro Ubuntu-24.04 --wsl-user user
```
```

scripts/build_install_oraclepack.sh
```
# path: scripts/build_install_oraclepack.sh
#!/usr/bin/env bash
set -euo pipefail

# Builds oraclepack for:
# - WSL/Linux (oraclepack)
# - Windows amd64 (oraclepack.exe)
# Then installs:
# - WSL binary -> ~/.local/bin/
# - Windows exe -> /mnt/c/Users/<winuser>/.local/bin/
# And writes a Git Bash wrapper:
# - /mnt/c/Users/<winuser>/bin/oraclepack  (calls WSL binary via wsl.exe)

usage() {
  cat <<'USAGE'
Usage:
  scripts/build_install_oraclepack.sh [options]

Options:
  --repo-root <path>      Repo root (default: git toplevel, else current dir)
  --win-user <name>       Windows username (default: auto-detect, else "user")
  --wsl-distro <name>     WSL distro name for wsl.exe -d (default: $WSL_DISTRO_NAME or "Ubuntu-24.04")
  --wsl-user <name>       WSL username for wsl.exe -u (default: current user)
  --no-linux              Skip building/installing Linux binary
  --no-windows            Skip building/installing Windows .exe
  --no-wrapper            Skip writing the Git Bash wrapper script
  --cgo <0|1>             Set CGO_ENABLED (default: leave unchanged)

Examples:
  scripts/build_install_oraclepack.sh
  scripts/build_install_oraclepack.sh --win-user Alice --wsl-distro Ubuntu-24.04
USAGE
}

die() { echo "error: $*" >&2; exit 1; }

have() { command -v "$1" >/dev/null 2>&1; }

detect_repo_root() {
  if have git && git rev-parse --show-toplevel >/dev/null 2>&1; then
    git rev-parse --show-toplevel
  else
    pwd
  fi
}

detect_win_user() {
  # Best-effort: ask Windows for %USERNAME% via cmd.exe (works in most WSL setups).
  if have cmd.exe; then
    local u
    u="$(cmd.exe /c "echo %USERNAME%" 2>/dev/null | tr -d '\r' | tail -n 1 || true)"
    if [[ -n "${u:-}" && "${u:-}" != "%USERNAME%" ]]; then
      echo "$u"
      return
    fi
  fi
  echo "user"
}

REPO_ROOT=""
WIN_USER=""
WSL_DISTRO="${WSL_DISTRO_NAME:-Ubuntu-24.04}"
WSL_USER="$(whoami)"
DO_LINUX=1
DO_WINDOWS=1
DO_WRAPPER=1
CGO=""

while [[ $# -gt 0 ]]; do
  case "$1" in
    --repo-root)  REPO_ROOT="${2:-}"; shift 2;;
    --win-user)   WIN_USER="${2:-}"; shift 2;;
    --wsl-distro) WSL_DISTRO="${2:-}"; shift 2;;
    --wsl-user)   WSL_USER="${2:-}"; shift 2;;
    --no-linux)   DO_LINUX=0; shift;;
    --no-windows) DO_WINDOWS=0; shift;;
    --no-wrapper) DO_WRAPPER=0; shift;;
    --cgo)        CGO="${2:-}"; shift 2;;
    -h|--help)    usage; exit 0;;
    *)            die "unknown option: $1 (use --help)";;
  esac
done

[[ -n "$REPO_ROOT" ]] || REPO_ROOT="$(detect_repo_root)"
[[ -d "$REPO_ROOT" ]] || die "repo root not found: $REPO_ROOT"

[[ -n "$WIN_USER" ]] || WIN_USER="$(detect_win_user)"

have go || die "go not found in PATH"

# Paths
LINUX_OUT="$REPO_ROOT/oraclepack"
WIN_OUT="$REPO_ROOT/oraclepack.exe"

LINUX_INSTALL_DIR="$HOME/.local/bin"
LINUX_INSTALL_PATH="$LINUX_INSTALL_DIR/oraclepack"

WIN_HOME="/mnt/c/Users/$WIN_USER"
WIN_LOCAL_BIN_DIR="$WIN_HOME/.local/bin"
WIN_LOCAL_BIN_PATH="$WIN_LOCAL_BIN_DIR/oraclepack.exe"

WIN_GITBASH_BIN_DIR="$WIN_HOME/bin"
WIN_GITBASH_WRAPPER_PATH="$WIN_GITBASH_BIN_DIR/oraclepack"

# Optional CGO toggle
if [[ -n "$CGO" ]]; then
  [[ "$CGO" == "0" || "$CGO" == "1" ]] || die "--cgo must be 0 or 1"
  export CGO_ENABLED="$CGO"
fi

cd "$REPO_ROOT"

# Build binaries
if [[ "$DO_LINUX" -eq 1 ]]; then
  echo "==> Building Linux (WSL) binary: $LINUX_OUT"
  go build -o "$LINUX_OUT" ./cmd/oraclepack
fi

if [[ "$DO_WINDOWS" -eq 1 ]]; then
  echo "==> Building Windows amd64 exe: $WIN_OUT"
  GOOS=windows GOARCH=amd64 go build -o "$WIN_OUT" ./cmd/oraclepack
fi

# Install binaries
if [[ "$DO_LINUX" -eq 1 ]]; then
  echo "==> Installing Linux binary -> $LINUX_INSTALL_PATH"
  mkdir -p "$LINUX_INSTALL_DIR"
  cp -f "$LINUX_OUT" "$LINUX_INSTALL_PATH"
fi

if [[ "$DO_WINDOWS" -eq 1 ]]; then
  echo "==> Installing Windows exe -> $WIN_LOCAL_BIN_PATH"
  mkdir -p "$WIN_LOCAL_BIN_DIR"
  cp -f "$WIN_OUT" "$WIN_LOCAL_BIN_PATH"
fi

# Write Git Bash wrapper (stored on Windows filesystem)
if [[ "$DO_WRAPPER" -eq 1 ]]; then
  echo "==> Writing Git Bash wrapper -> $WIN_GITBASH_WRAPPER_PATH"
  mkdir -p "$WIN_GITBASH_BIN_DIR"

  cat > "$WIN_GITBASH_WRAPPER_PATH" <<EOF
#!/usr/bin/env bash
set -euo pipefail

# Git for Windows (Git Bash) path-conversion off for this exec call.
# Required so /home/... is not rewritten into C:/Program Files/Git/...
MSYS_NO_PATHCONV=1 exec wsl.exe -d ${WSL_DISTRO@Q} -u ${WSL_USER@Q} -- ${LINUX_INSTALL_PATH@Q} "\$@"
EOF

  # Ensure LF line endings (in case editor/tool wrote CRLF) and best-effort executable bit.
  sed -i 's/\r$//' "$WIN_GITBASH_WRAPPER_PATH" || true
  chmod +x "$WIN_GITBASH_WRAPPER_PATH" 2>/dev/null || true

  echo "==> Note: In Git Bash, ensure ~/bin is in PATH (so 'oraclepack' resolves to this wrapper)."
fi

echo "==> Done."
echo "    WSL binary:     $LINUX_INSTALL_PATH"
echo "    Windows exe:    $WIN_LOCAL_BIN_PATH"
echo "    Git Bash wrap:  $WIN_GITBASH_WRAPPER_PATH"
```

scripts/codefetch_skill.sh
```
# path: scripts/codefetch_skill.sh
#!/usr/bin/env bash
set -euo pipefail

usage() {
  cat <<'USAGE'
Usage:
  bash scripts/codefetch_skill.sh <skill-name> [output-file]

The argument must be the skill directory name under ./skills (no prefix assumptions),
e.g.:
  bash scripts/codefetch_skill.sh oraclepack-tickets-pack
  bash scripts/codefetch_skill.sh tickets-pack
  bash scripts/codefetch_skill.sh my-skill-name ./out.md

Env overrides:
  CODEFETCH_THREADS   (default: 5)
  CODEFETCH_MAXTOKENS (default: 75000)
USAGE
}

if [[ "${1:-}" == "" || "${1:-}" == "-h" || "${1:-}" == "--help" ]]; then
  usage
  exit 0
fi

skill_name="$1"
threads="${CODEFETCH_THREADS:-5}"
max_tokens="${CODEFETCH_MAXTOKENS:-75000}"

skill_dir="skills/${skill_name%/}"

if [[ ! -d "$skill_dir" ]]; then
  echo "Error: skill directory not found: $skill_dir" >&2
  echo "Expected a folder under ./skills/ named exactly: '$skill_name'" >&2
  exit 1
fi

out="${2:-${skill_name}_skill.md}"

include_files=(
  "${skill_dir}/SKILL.md"
  "${skill_dir}/assets/**/*"
  "${skill_dir}/references/**/*"
  "${skill_dir}/scripts/**/*"
)

include_files_csv=""
for pat in "${include_files[@]}"; do
  if [[ -z "$include_files_csv" ]]; then
    include_files_csv="$pat"
  else
    include_files_csv="${include_files_csv},$pat"
  fi
done

codefetch -t "$threads" \
  --include-dir "$skill_dir" \
  --include-files "$include_files_csv" \
  -o "$out" \
  --max-tokens "$max_tokens"

echo "Wrote: $out"
```

scripts/install-global.ps1
```
# path: scripts/install-global.ps1
[CmdletBinding()]
param(
  [string]$InstallDir = "C:\Tools",
  [switch]$AddToPath,
  [switch]$SkipTests
)

$ErrorActionPreference = "Stop"

function Get-RepoRoot {
  try {
    return (git rev-parse --show-toplevel).Trim()
  } catch {
    throw "Not inside a git repo (expected oraclepack repo)."
  }
}

$RepoRoot = Get-RepoRoot
Set-Location $RepoRoot

if (-not (Get-Command go -ErrorAction SilentlyContinue)) {
  throw "Go not found in PATH."
}

Write-Host "==> Repo: $RepoRoot"
Write-Host "==> InstallDir: $InstallDir"

if (-not $SkipTests) {
  Write-Host "==> go test ./..."
  go test ./...
}

# Match README build target: ./cmd/oraclepack
Write-Host "==> go build -o oraclepack.exe ./cmd/oraclepack"
go build -o oraclepack.exe ./cmd/oraclepack

New-Item -ItemType Directory -Force -Path $InstallDir | Out-Null
Copy-Item -Force -Path (Join-Path $RepoRoot "oraclepack.exe") -Destination (Join-Path $InstallDir "oraclepack.exe")

if ($AddToPath) {
  $userPath = [Environment]::GetEnvironmentVariable("Path", "User")
  if ($userPath -notmatch [Regex]::Escape($InstallDir)) {
    $newPath = if ([string]::IsNullOrWhiteSpace($userPath)) { $InstallDir } else { "$userPath;$InstallDir" }
    [Environment]::SetEnvironmentVariable("Path", $newPath, "User")
    Write-Host "==> Added to User PATH: $InstallDir (restart terminal to pick up PATH changes)"
  } else {
    Write-Host "==> InstallDir already in User PATH"
  }
}

Write-Host "==> Installed: $InstallDir\oraclepack.exe"
& (Join-Path $InstallDir "oraclepack.exe") --version 2>$null
```

scripts/install-global.sh
```
# path: scripts/install-global.sh
#!/usr/bin/env bash
set -euo pipefail

usage() {
  cat <<'USAGE'
install-global.sh — rebuild oraclepack and install it to a PATH directory.

Usage:
  ./scripts/install-global.sh [--prefix DIR] [--sudo] [--skip-tests]

Options:
  --prefix DIR     Install directory (default: ~/.local/bin; macOS prefers /usr/local/bin if writable)
  --sudo           Use sudo when copying into --prefix (for system dirs like /usr/local/bin)
  --skip-tests     Skip `go test ./...`

Examples:
  ./scripts/install-global.sh
  ./scripts/install-global.sh --prefix "$HOME/.local/bin"
  ./scripts/install-global.sh --prefix /usr/local/bin --sudo
USAGE
}

PREFIX=""
USE_SUDO=0
SKIP_TESTS=0

while [[ $# -gt 0 ]]; do
  case "$1" in
    --prefix) PREFIX="${2:-}"; shift 2 ;;
    --sudo) USE_SUDO=1; shift ;;
    --skip-tests) SKIP_TESTS=1; shift ;;
    -h|--help) usage; exit 0 ;;
    *) echo "Unknown arg: $1" >&2; usage; exit 2 ;;
  esac
done

# Repo root (so script works from anywhere)
REPO_ROOT="$(git rev-parse --show-toplevel 2>/dev/null || true)"
if [[ -z "${REPO_ROOT}" ]]; then
  echo "Error: not inside a git repo (expected oraclepack repo)." >&2
  exit 1
fi
cd "$REPO_ROOT"

# Build output
BUILD_DIR="$REPO_ROOT/.build"
mkdir -p "$BUILD_DIR"
OUT_BIN="$BUILD_DIR/oraclepack"

# Default install prefix
if [[ -z "${PREFIX}" ]]; then
  case "$(uname -s)" in
    Darwin)
      if [[ -w "/usr/local/bin" ]]; then
        PREFIX="/usr/local/bin"
      else
        PREFIX="$HOME/.local/bin"
      fi
      ;;
    *)
      PREFIX="$HOME/.local/bin"
      ;;
  esac
fi

echo "==> Repo: $REPO_ROOT"
echo "==> Building: $OUT_BIN"
echo "==> Installing to: $PREFIX"

command -v go >/dev/null 2>&1 || { echo "Error: go not found in PATH." >&2; exit 1; }

if [[ "$SKIP_TESTS" -eq 0 ]]; then
  echo "==> go test ./..."
  go test ./...
fi

# Match README build target: ./cmd/oraclepack :contentReference[oaicite:0]{index=0}
go build -o "$OUT_BIN" ./cmd/oraclepack

mkdir -p "$PREFIX"

# Install (overwrite existing)
if [[ "$USE_SUDO" -eq 1 ]]; then
  sudo install -m 0755 "$OUT_BIN" "$PREFIX/oraclepack"
else
  install -m 0755 "$OUT_BIN" "$PREFIX/oraclepack"
fi

echo "==> Installed: $PREFIX/oraclepack"
echo "==> Version (if supported):"
"$PREFIX/oraclepack" --version 2>/dev/null || true

# Best-effort: refresh shell hash table (won't error if unsupported)
hash -r 2>/dev/null || true
```

scripts/tag-release.sh
```
# path: scripts/tag-release.sh
#!/usr/bin/env bash
set -euo pipefail

read -r -p "Input tag version (e.g., 0.2.0): " version
version="${version//[[:space:]]/}"
[[ -n "${version}" ]] || { echo "Error: version cannot be empty." >&2; exit 1; }

tag="v${version}"

git rev-parse -q --verify "refs/tags/${tag}" >/dev/null && {
  echo "Error: tag ${tag} already exists locally." >&2
  exit 1
}

git ls-remote --tags origin "refs/tags/${tag}" | grep -q . && {
  echo "Error: tag ${tag} already exists on origin." >&2
  exit 1
}

git tag "${tag}"
git push origin "${tag}"
```

.config/commands/oracle-pack_v2.toml
```
# path: commands/oraclepack/oracle-pack_v2.toml
# invoked via: /oraclepack:oracle-pack_v2 {{args}}

description = "Generate a strategist-questions Oracle pack that validates/runs under oraclepack (```bash fence + # NN) headers), writes oracle outputs under docs/, and preserves the Codex-style template (parsed args + ROI ordering + coverage check)."

prompt = """
You are generating output for a STRICT downstream CLI parser (oraclepack).
Your output MUST be parseable by oraclepack’s Markdown parser:
- The commands MUST be inside a ```bash fenced code block (triple backticks), not ~~~.
- Step headers MUST be exactly: # NN) ... (e.g., # 01) ...). Do NOT use em dashes (—) in place of the ')'.

User args (raw): {{args}}

------------------------------------------------------------
A) ARG PARSING (no follow-ups; apply defaults)
Extract from {{args}} if present (key=value or similar), else default:

- codebase_name: Unknown
- constraints: None
- non_goals: None
- team_size: Unknown
- deadline: Unknown

Oracle pack controls:
- out_dir: docs/oracle/strategist-questions/$(date +%F)
- oracle_cmd: oracle
- oracle_flags: --browser-attachments always --files-report
- extra_files: (empty; if present, treat as comma-separated file paths/globs to include as additional -f entries in EVERY command)

You MUST render these values into the final output under the “parsed args” section.

------------------------------------------------------------
B) INFERENCE-FIRST DISCOVERY (adaptive; evidence-driven; deterministic)
Goal: infer what exists before searching broadly.

1) Prefer cheap “index” artifacts first:
   - README / docs index (if present)
   - primary manifests (package.json, pyproject.toml, go.mod, Cargo.toml, etc.)
   - obvious entrypoints referenced by scripts/manifests

2) Derive a search plan from evidence:
   - follow imports/registrations from entrypoints into:
     routing/handlers, auth/permissions, jobs/queues, data layer/migrations,
     feature flags, observability/logging, caching/state, failure modes.

3) Harvest >= 20 candidate anchors, each as ONE of:
   - {path}:{symbol} (preferred)
   - {endpoint}
   - {event}
If a category cannot be evidenced, keep its anchor as Unknown AND record the missing artifact pattern.

Required coverage categories (must appear across your 20 questions):
- contracts/interfaces
- invariants
- caching/state
- background jobs
- observability
- permissions
- migrations
- UX flows
- failure modes
- feature flags

------------------------------------------------------------
C) QUESTION GENERATION (exactly 20; 12 Immediate + 8 Strategic)
For each question, produce:
- Reference: {path}:{symbol} OR {endpoint} OR {event} OR Unknown
- Category: one of the required categories (or a sensible subcategory that still maps to them)
- Horizon: Immediate or Strategic
- Question: focused, feasibility-first
- Rationale: EXACTLY one sentence
- Smallest experiment today: EXACTLY one concrete action

No duplicates by intent or reference.

------------------------------------------------------------
D) ROI SCORING + ORDERING (required)
For each question, choose:
- impact, confidence, effort ∈ {0.1..1.0} with one decimal
Compute:
- ROI = (impact * confidence) / effort

Sort ALL 20 commands by:
1) ROI descending
2) tie-breaker: lower effort first

Numbering remains 01..20 in this final sorted order.

------------------------------------------------------------
E) ORACLE COMMAND EMISSION + ATTACHMENTS (minimal; evidence-driven)
For each command:
- Use exactly:
  <oracle_cmd> \
    <oracle_flags> \
    --write-output "<out_dir>/<nn>-<slug>.md" \
    -p "<prompt>" \
    -f "<file 1>" \
    -f "<file 2>" \
    ... \
    <extra_files...>

Attachment minimization:
- Prefer 1–3 attachments per command.
- If Reference is {path}:{symbol}: attach that file; optionally ONE more upstream entrypoint/router/config if needed.
- If Reference is {endpoint}: attach route map + handler file (if different).
- If Reference is {event}: attach job registration + worker implementation (if different).
- If Reference is Unknown: attach only “index” files (README + primary manifest + 1 best-guess entrypoint if found).
- NEVER attach files you did not discover or cannot justify.

extra_files behavior:
- If extra_files was provided, append those as additional -f entries at the end of EVERY command (after the minimal evidence attachments).

Slug rules:
- <slug> lowercase a-z0-9 and hyphens only.
- Derive from category + a hint of reference (fallback: category only).

------------------------------------------------------------
F) SAVE / WRITE SEMANTICS (required; docs/)
- The oracle outputs are written by oracle itself via --write-output "<out_dir>/...".
  Because out_dir defaults under docs/, oracle outputs will land under docs/.
- This slash-command response (the pack Markdown) is printed to stdout.
  The caller MUST save it to the path printed on the first line:
  Output file: docs/strategist-questions-oracle-pack-YYYY-MM-DD.md
  (If you cannot determine date, use: docs/strategist-questions-oracle-pack.md)

------------------------------------------------------------
G) OUTPUT FORMAT (STRICT; MUST MATCH THIS SHAPE)
1) First line of the assistant response MUST be:
   Output file: docs/strategist-questions-oracle-pack-YYYY-MM-DD.md
   (Use today’s date if known; otherwise: docs/strategist-questions-oracle-pack.md)

2) After that line, output EXACTLY ONE Markdown document matching the template below.
3) Do NOT add any extra prose, headings, or fences beyond what the template requires.
4) The ```bash code fence MUST be triple-backtick fenced, and MUST close with triple-backticks.
5) Step headers inside the bash fence MUST be: # NN) ... (to satisfy oraclepack).

TEMPLATE (MUST MATCH):
<!-- begin template -->
# oracle strategist question pack

---

## parsed args

- codebase_name: <Unknown|value>
- constraints: <None|value>
- non_goals: <None|value>
- team_size: <Unknown|value>
- deadline: <Unknown|value>
- out_dir: <docs/oracle/strategist-questions/$(date +%F)|value>
- oracle_cmd: <oracle|value>
- oracle_flags: <--browser-attachments always --files-report|value>
- extra_files: <empty|value>

---

## commands (exactly 20; sorted by ROI desc; ties by lower effort)

```bash
out_dir="<out_dir>"
mkdir -p "$out_dir"

# 01) ROI=<..> impact=<..> confidence=<..> effort=<..> horizon=<Immediate|Strategic> category=<...> reference=<...>
<oracle_cmd> \
  <oracle_flags> \
  --write-output "<out_dir>/01-<slug>.md" \
  -p "Strategist question #01
Reference: <{path}:{symbol} OR {endpoint} OR {event} OR Unknown>
Category: <one of required categories>
Horizon: <Immediate|Strategic>
ROI: <roi> (impact=<i>, confidence=<c>, effort=<e>)
Question: <question text>
Rationale: <exactly one sentence>
Smallest experiment today: <exactly one action>
Constraints: <constraints or None>
Non-goals: <non_goals or None>

Answer format:
1) Direct answer (1–4 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (1 action) — may differ from the suggested one if you justify it
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next." \
  -f "<minimal evidence file 1>" \
  -f "<optional supporting file 2>" \
  <optional extra_files entries...>

# 02) ...
# ...
# 20) ...
````

---

## coverage check (must be satisfied)

* contracts/interfaces: <OK|Missing (state missing artifact pattern)>

* invariants: <OK|Missing (...)>

* caching/state: <OK|Missing (...)>

* background jobs: <OK|Missing (...)>

* observability: <OK|Missing (...)>

* permissions: <OK|Missing (...)>

* migrations: <OK|Missing (...)>

* UX flows: <OK|Missing (...)>

* failure modes: <OK|Missing (...)>

* feature flags: <OK|Missing (...)>

<!-- end template -->

Now generate the final output that matches the template exactly.
"""

```

.config/completion/oraclepack.completion.sh
```
# bash completion V2 for oraclepack                           -*- shell-script -*-

__oraclepack_debug()
{
    if [[ -n ${BASH_COMP_DEBUG_FILE-} ]]; then
        echo "$*" >> "${BASH_COMP_DEBUG_FILE}"
    fi
}

# Macs have bash3 for which the bash-completion package doesn't include
# _init_completion. This is a minimal version of that function.
__oraclepack_init_completion()
{
    COMPREPLY=()
    _get_comp_words_by_ref "$@" cur prev words cword
}

# This function calls the oraclepack program to obtain the completion
# results and the directive.  It fills the 'out' and 'directive' vars.
__oraclepack_get_completion_results() {
    local requestComp lastParam lastChar args

    # Prepare the command to request completions for the program.
    # Calling ${words[0]} instead of directly oraclepack allows handling aliases
    args=("${words[@]:1}")
    requestComp="${words[0]} __complete ${args[*]}"

    lastParam=${words[$((${#words[@]}-1))]}
    lastChar=${lastParam:$((${#lastParam}-1)):1}
    __oraclepack_debug "lastParam ${lastParam}, lastChar ${lastChar}"

    if [[ -z ${cur} && ${lastChar} != = ]]; then
        # If the last parameter is complete (there is a space following it)
        # We add an extra empty parameter so we can indicate this to the go method.
        __oraclepack_debug "Adding extra empty parameter"
        requestComp="${requestComp} ''"
    fi

    # When completing a flag with an = (e.g., oraclepack -n=<TAB>)
    # bash focuses on the part after the =, so we need to remove
    # the flag part from $cur
    if [[ ${cur} == -*=* ]]; then
        cur="${cur#*=}"
    fi

    __oraclepack_debug "Calling ${requestComp}"
    # Use eval to handle any environment variables and such
    out=$(eval "${requestComp}" 2>/dev/null)

    # Extract the directive integer at the very end of the output following a colon (:)
    directive=${out##*:}
    # Remove the directive
    out=${out%:*}
    if [[ ${directive} == "${out}" ]]; then
        # There is not directive specified
        directive=0
    fi
    __oraclepack_debug "The completion directive is: ${directive}"
    __oraclepack_debug "The completions are: ${out}"
}

__oraclepack_process_completion_results() {
    local shellCompDirectiveError=1
    local shellCompDirectiveNoSpace=2
    local shellCompDirectiveNoFileComp=4
    local shellCompDirectiveFilterFileExt=8
    local shellCompDirectiveFilterDirs=16
    local shellCompDirectiveKeepOrder=32

    if (((directive & shellCompDirectiveError) != 0)); then
        # Error code.  No completion.
        __oraclepack_debug "Received error from custom completion go code"
        return
    else
        if (((directive & shellCompDirectiveNoSpace) != 0)); then
            if [[ $(type -t compopt) == builtin ]]; then
                __oraclepack_debug "Activating no space"
                compopt -o nospace
            else
                __oraclepack_debug "No space directive not supported in this version of bash"
            fi
        fi
        if (((directive & shellCompDirectiveKeepOrder) != 0)); then
            if [[ $(type -t compopt) == builtin ]]; then
                # no sort isn't supported for bash less than < 4.4
                if [[ ${BASH_VERSINFO[0]} -lt 4 || ( ${BASH_VERSINFO[0]} -eq 4 && ${BASH_VERSINFO[1]} -lt 4 ) ]]; then
                    __oraclepack_debug "No sort directive not supported in this version of bash"
                else
                    __oraclepack_debug "Activating keep order"
                    compopt -o nosort
                fi
            else
                __oraclepack_debug "No sort directive not supported in this version of bash"
            fi
        fi
        if (((directive & shellCompDirectiveNoFileComp) != 0)); then
            if [[ $(type -t compopt) == builtin ]]; then
                __oraclepack_debug "Activating no file completion"
                compopt +o default
            else
                __oraclepack_debug "No file completion directive not supported in this version of bash"
            fi
        fi
    fi

    # Separate activeHelp from normal completions
    local completions=()
    local activeHelp=()
    __oraclepack_extract_activeHelp

    if (((directive & shellCompDirectiveFilterFileExt) != 0)); then
        # File extension filtering
        local fullFilter="" filter filteringCmd

        # Do not use quotes around the $completions variable or else newline
        # characters will be kept.
        for filter in ${completions[*]}; do
            fullFilter+="$filter|"
        done

        filteringCmd="_filedir $fullFilter"
        __oraclepack_debug "File filtering command: $filteringCmd"
        $filteringCmd
    elif (((directive & shellCompDirectiveFilterDirs) != 0)); then
        # File completion for directories only

        local subdir
        subdir=${completions[0]}
        if [[ -n $subdir ]]; then
            __oraclepack_debug "Listing directories in $subdir"
            pushd "$subdir" >/dev/null 2>&1 && _filedir -d && popd >/dev/null 2>&1 || return
        else
            __oraclepack_debug "Listing directories in ."
            _filedir -d
        fi
    else
        __oraclepack_handle_completion_types
    fi

    __oraclepack_handle_special_char "$cur" :
    __oraclepack_handle_special_char "$cur" =

    # Print the activeHelp statements before we finish
    __oraclepack_handle_activeHelp
}

__oraclepack_handle_activeHelp() {
    # Print the activeHelp statements
    if ((${#activeHelp[*]} != 0)); then
        if [ -z $COMP_TYPE ]; then
            # Bash v3 does not set the COMP_TYPE variable.
            printf "\n";
            printf "%s\n" "${activeHelp[@]}"
            printf "\n"
            __oraclepack_reprint_commandLine
            return
        fi

        # Only print ActiveHelp on the second TAB press
        if [ $COMP_TYPE -eq 63 ]; then
            printf "\n"
            printf "%s\n" "${activeHelp[@]}"

            if ((${#COMPREPLY[*]} == 0)); then
                # When there are no completion choices from the program, file completion
                # may kick in if the program has not disabled it; in such a case, we want
                # to know if any files will match what the user typed, so that we know if
                # there will be completions presented, so that we know how to handle ActiveHelp.
                # To find out, we actually trigger the file completion ourselves;
                # the call to _filedir will fill COMPREPLY if files match.
                if (((directive & shellCompDirectiveNoFileComp) == 0)); then
                    __oraclepack_debug "Listing files"
                    _filedir
                fi
            fi

            if ((${#COMPREPLY[*]} != 0)); then
                # If there are completion choices to be shown, print a delimiter.
                # Re-printing the command-line will automatically be done
                # by the shell when it prints the completion choices.
                printf -- "--"
            else
                # When there are no completion choices at all, we need
                # to re-print the command-line since the shell will
                # not be doing it itself.
                __oraclepack_reprint_commandLine
            fi
        elif [ $COMP_TYPE -eq 37 ] || [ $COMP_TYPE -eq 42 ]; then
            # For completion type: menu-complete/menu-complete-backward and insert-completions
            # the completions are immediately inserted into the command-line, so we first
            # print the activeHelp message and reprint the command-line since the shell won't.
            printf "\n"
            printf "%s\n" "${activeHelp[@]}"

            __oraclepack_reprint_commandLine
        fi
    fi
}

__oraclepack_reprint_commandLine() {
    # The prompt format is only available from bash 4.4.
    # We test if it is available before using it.
    if (x=${PS1@P}) 2> /dev/null; then
        printf "%s" "${PS1@P}${COMP_LINE[@]}"
    else
        # Can't print the prompt.  Just print the
        # text the user had typed, it is workable enough.
        printf "%s" "${COMP_LINE[@]}"
    fi
}

# Separate activeHelp lines from real completions.
# Fills the $activeHelp and $completions arrays.
__oraclepack_extract_activeHelp() {
    local activeHelpMarker="_activeHelp_ "
    local endIndex=${#activeHelpMarker}

    while IFS='' read -r comp; do
        [[ -z $comp ]] && continue

        if [[ ${comp:0:endIndex} == $activeHelpMarker ]]; then
            comp=${comp:endIndex}
            __oraclepack_debug "ActiveHelp found: $comp"
            if [[ -n $comp ]]; then
                activeHelp+=("$comp")
            fi
        else
            # Not an activeHelp line but a normal completion
            completions+=("$comp")
        fi
    done <<<"${out}"
}

__oraclepack_handle_completion_types() {
    __oraclepack_debug "__oraclepack_handle_completion_types: COMP_TYPE is $COMP_TYPE"

    case $COMP_TYPE in
    37|42)
        # Type: menu-complete/menu-complete-backward and insert-completions
        # If the user requested inserting one completion at a time, or all
        # completions at once on the command-line we must remove the descriptions.
        # https://github.com/spf13/cobra/issues/1508

        # If there are no completions, we don't need to do anything
        (( ${#completions[@]} == 0 )) && return 0

        local tab=$'\t'

        # Strip any description and escape the completion to handled special characters
        IFS=$'\n' read -ra completions -d '' < <(printf "%q\n" "${completions[@]%%$tab*}")

        # Only consider the completions that match
        IFS=$'\n' read -ra COMPREPLY -d '' < <(IFS=$'\n'; compgen -W "${completions[*]}" -- "${cur}")

        # compgen looses the escaping so we need to escape all completions again since they will
        # all be inserted on the command-line.
        IFS=$'\n' read -ra COMPREPLY -d '' < <(printf "%q\n" "${COMPREPLY[@]}")
        ;;

    *)
        # Type: complete (normal completion)
        __oraclepack_handle_standard_completion_case
        ;;
    esac
}

__oraclepack_handle_standard_completion_case() {
    local tab=$'\t'

    # If there are no completions, we don't need to do anything
    (( ${#completions[@]} == 0 )) && return 0

    # Short circuit to optimize if we don't have descriptions
    if [[ "${completions[*]}" != *$tab* ]]; then
        # First, escape the completions to handle special characters
        IFS=$'\n' read -ra completions -d '' < <(printf "%q\n" "${completions[@]}")
        # Only consider the completions that match what the user typed
        IFS=$'\n' read -ra COMPREPLY -d '' < <(IFS=$'\n'; compgen -W "${completions[*]}" -- "${cur}")

        # compgen looses the escaping so, if there is only a single completion, we need to
        # escape it again because it will be inserted on the command-line.  If there are multiple
        # completions, we don't want to escape them because they will be printed in a list
        # and we don't want to show escape characters in that list.
        if (( ${#COMPREPLY[@]} == 1 )); then
            COMPREPLY[0]=$(printf "%q" "${COMPREPLY[0]}")
        fi
        return 0
    fi

    local longest=0
    local compline
    # Look for the longest completion so that we can format things nicely
    while IFS='' read -r compline; do
        [[ -z $compline ]] && continue

        # Before checking if the completion matches what the user typed,
        # we need to strip any description and escape the completion to handle special
        # characters because those escape characters are part of what the user typed.
        # Don't call "printf" in a sub-shell because it will be much slower
        # since we are in a loop.
        printf -v comp "%q" "${compline%%$tab*}" &>/dev/null || comp=$(printf "%q" "${compline%%$tab*}")

        # Only consider the completions that match
        [[ $comp == "$cur"* ]] || continue

        # The completions matches.  Add it to the list of full completions including
        # its description.  We don't escape the completion because it may get printed
        # in a list if there are more than one and we don't want show escape characters
        # in that list.
        COMPREPLY+=("$compline")

        # Strip any description before checking the length, and again, don't escape
        # the completion because this length is only used when printing the completions
        # in a list and we don't want show escape characters in that list.
        comp=${compline%%$tab*}
        if ((${#comp}>longest)); then
            longest=${#comp}
        fi
    done < <(printf "%s\n" "${completions[@]}")

    # If there is a single completion left, remove the description text and escape any special characters
    if ((${#COMPREPLY[*]} == 1)); then
        __oraclepack_debug "COMPREPLY[0]: ${COMPREPLY[0]}"
        COMPREPLY[0]=$(printf "%q" "${COMPREPLY[0]%%$tab*}")
        __oraclepack_debug "Removed description from single completion, which is now: ${COMPREPLY[0]}"
    else
        # Format the descriptions
        __oraclepack_format_comp_descriptions $longest
    fi
}

__oraclepack_handle_special_char()
{
    local comp="$1"
    local char=$2
    if [[ "$comp" == *${char}* && "$COMP_WORDBREAKS" == *${char}* ]]; then
        local word=${comp%"${comp##*${char}}"}
        local idx=${#COMPREPLY[*]}
        while ((--idx >= 0)); do
            COMPREPLY[idx]=${COMPREPLY[idx]#"$word"}
        done
    fi
}

__oraclepack_format_comp_descriptions()
{
    local tab=$'\t'
    local comp desc maxdesclength
    local longest=$1

    local i ci
    for ci in ${!COMPREPLY[*]}; do
        comp=${COMPREPLY[ci]}
        # Properly format the description string which follows a tab character if there is one
        if [[ "$comp" == *$tab* ]]; then
            __oraclepack_debug "Original comp: $comp"
            desc=${comp#*$tab}
            comp=${comp%%$tab*}

            # $COLUMNS stores the current shell width.
            # Remove an extra 4 because we add 2 spaces and 2 parentheses.
            maxdesclength=$(( COLUMNS - longest - 4 ))

            # Make sure we can fit a description of at least 8 characters
            # if we are to align the descriptions.
            if ((maxdesclength > 8)); then
                # Add the proper number of spaces to align the descriptions
                for ((i = ${#comp} ; i < longest ; i++)); do
                    comp+=" "
                done
            else
                # Don't pad the descriptions so we can fit more text after the completion
                maxdesclength=$(( COLUMNS - ${#comp} - 4 ))
            fi

            # If there is enough space for any description text,
            # truncate the descriptions that are too long for the shell width
            if ((maxdesclength > 0)); then
                if ((${#desc} > maxdesclength)); then
                    desc=${desc:0:$(( maxdesclength - 1 ))}
                    desc+="…"
                fi
                comp+="  ($desc)"
            fi
            COMPREPLY[ci]=$comp
            __oraclepack_debug "Final comp: $comp"
        fi
    done
}

__start_oraclepack()
{
    local cur prev words cword split

    COMPREPLY=()

    # Call _init_completion from the bash-completion package
    # to prepare the arguments properly
    if declare -F _init_completion >/dev/null 2>&1; then
        _init_completion -n =: || return
    else
        __oraclepack_init_completion -n =: || return
    fi

    __oraclepack_debug
    __oraclepack_debug "========= starting completion logic =========="
    __oraclepack_debug "cur is ${cur}, words[*] is ${words[*]}, #words[@] is ${#words[@]}, cword is $cword"

    # The user could have moved the cursor backwards on the command-line.
    # We need to trigger completion from the $cword location, so we need
    # to truncate the command-line ($words) up to the $cword location.
    words=("${words[@]:0:$cword+1}")
    __oraclepack_debug "Truncated words[*]: ${words[*]},"

    local out directive
    __oraclepack_get_completion_results
    __oraclepack_process_completion_results
}

if [[ $(type -t compopt) = "builtin" ]]; then
    complete -o default -F __start_oraclepack oraclepack
else
    complete -o default -o nospace -F __start_oraclepack oraclepack
fi

# ex: ts=4 sw=4 et filetype=sh
```

.config/scripts/build_install_oraclepack.md
```
```bash
# path: scripts/build_install_oraclepack.sh
#!/usr/bin/env bash
set -euo pipefail

# Builds oraclepack for:
# - WSL/Linux (oraclepack)
# - Windows amd64 (oraclepack.exe)
# Then installs:
# - WSL binary -> ~/.local/bin/
# - Windows exe -> /mnt/c/Users/<winuser>/.local/bin/
# And writes a Git Bash wrapper:
# - /mnt/c/Users/<winuser>/bin/oraclepack  (calls WSL binary via wsl.exe)

usage() {
  cat <<'USAGE'
Usage:
  scripts/build_install_oraclepack.sh [options]

Options:
  --repo-root <path>      Repo root (default: git toplevel, else current dir)
  --win-user <name>       Windows username (default: auto-detect, else "user")
  --wsl-distro <name>     WSL distro name for wsl.exe -d (default: $WSL_DISTRO_NAME or "Ubuntu-24.04")
  --wsl-user <name>       WSL username for wsl.exe -u (default: current user)
  --no-linux              Skip building/installing Linux binary
  --no-windows            Skip building/installing Windows .exe
  --no-wrapper            Skip writing the Git Bash wrapper script
  --cgo <0|1>             Set CGO_ENABLED (default: leave unchanged)

Examples:
  scripts/build_install_oraclepack.sh
  scripts/build_install_oraclepack.sh --win-user Alice --wsl-distro Ubuntu-24.04
USAGE
}

die() { echo "error: $*" >&2; exit 1; }

have() { command -v "$1" >/dev/null 2>&1; }

detect_repo_root() {
  if have git && git rev-parse --show-toplevel >/dev/null 2>&1; then
    git rev-parse --show-toplevel
  else
    pwd
  fi
}

detect_win_user() {
  # Best-effort: ask Windows for %USERNAME% via cmd.exe (works in most WSL setups).
  if have cmd.exe; then
    local u
    u="$(cmd.exe /c "echo %USERNAME%" 2>/dev/null | tr -d '\r' | tail -n 1 || true)"
    if [[ -n "${u:-}" && "${u:-}" != "%USERNAME%" ]]; then
      echo "$u"
      return
    fi
  fi
  echo "user"
}

REPO_ROOT=""
WIN_USER=""
WSL_DISTRO="${WSL_DISTRO_NAME:-Ubuntu-24.04}"
WSL_USER="$(whoami)"
DO_LINUX=1
DO_WINDOWS=1
DO_WRAPPER=1
CGO=""

while [[ $# -gt 0 ]]; do
  case "$1" in
    --repo-root)  REPO_ROOT="${2:-}"; shift 2;;
    --win-user)   WIN_USER="${2:-}"; shift 2;;
    --wsl-distro) WSL_DISTRO="${2:-}"; shift 2;;
    --wsl-user)   WSL_USER="${2:-}"; shift 2;;
    --no-linux)   DO_LINUX=0; shift;;
    --no-windows) DO_WINDOWS=0; shift;;
    --no-wrapper) DO_WRAPPER=0; shift;;
    --cgo)        CGO="${2:-}"; shift 2;;
    -h|--help)    usage; exit 0;;
    *)            die "unknown option: $1 (use --help)";;
  esac
done

[[ -n "$REPO_ROOT" ]] || REPO_ROOT="$(detect_repo_root)"
[[ -d "$REPO_ROOT" ]] || die "repo root not found: $REPO_ROOT"

[[ -n "$WIN_USER" ]] || WIN_USER="$(detect_win_user)"

have go || die "go not found in PATH"

# Paths
LINUX_OUT="$REPO_ROOT/oraclepack"
WIN_OUT="$REPO_ROOT/oraclepack.exe"

LINUX_INSTALL_DIR="$HOME/.local/bin"
LINUX_INSTALL_PATH="$LINUX_INSTALL_DIR/oraclepack"

WIN_HOME="/mnt/c/Users/$WIN_USER"
WIN_LOCAL_BIN_DIR="$WIN_HOME/.local/bin"
WIN_LOCAL_BIN_PATH="$WIN_LOCAL_BIN_DIR/oraclepack.exe"

WIN_GITBASH_BIN_DIR="$WIN_HOME/bin"
WIN_GITBASH_WRAPPER_PATH="$WIN_GITBASH_BIN_DIR/oraclepack"

# Optional CGO toggle
if [[ -n "$CGO" ]]; then
  [[ "$CGO" == "0" || "$CGO" == "1" ]] || die "--cgo must be 0 or 1"
  export CGO_ENABLED="$CGO"
fi

cd "$REPO_ROOT"

# Build binaries
if [[ "$DO_LINUX" -eq 1 ]]; then
  echo "==> Building Linux (WSL) binary: $LINUX_OUT"
  go build -o "$LINUX_OUT" ./cmd/oraclepack
fi

if [[ "$DO_WINDOWS" -eq 1 ]]; then
  echo "==> Building Windows amd64 exe: $WIN_OUT"
  GOOS=windows GOARCH=amd64 go build -o "$WIN_OUT" ./cmd/oraclepack
fi

# Install binaries
if [[ "$DO_LINUX" -eq 1 ]]; then
  echo "==> Installing Linux binary -> $LINUX_INSTALL_PATH"
  mkdir -p "$LINUX_INSTALL_DIR"
  cp -f "$LINUX_OUT" "$LINUX_INSTALL_PATH"
fi

if [[ "$DO_WINDOWS" -eq 1 ]]; then
  echo "==> Installing Windows exe -> $WIN_LOCAL_BIN_PATH"
  mkdir -p "$WIN_LOCAL_BIN_DIR"
  cp -f "$WIN_OUT" "$WIN_LOCAL_BIN_PATH"
fi

# Write Git Bash wrapper (stored on Windows filesystem)
if [[ "$DO_WRAPPER" -eq 1 ]]; then
  echo "==> Writing Git Bash wrapper -> $WIN_GITBASH_WRAPPER_PATH"
  mkdir -p "$WIN_GITBASH_BIN_DIR"

  cat > "$WIN_GITBASH_WRAPPER_PATH" <<EOF
#!/usr/bin/env bash
set -euo pipefail

# Git for Windows (Git Bash) path-conversion off for this exec call.
# Required so /home/... is not rewritten into C:/Program Files/Git/...
MSYS_NO_PATHCONV=1 exec wsl.exe -d ${WSL_DISTRO@Q} -u ${WSL_USER@Q} -- ${LINUX_INSTALL_PATH@Q} "\$@"
EOF

  # Ensure LF line endings (in case editor/tool wrote CRLF) and best-effort executable bit.
  sed -i 's/\r$//' "$WIN_GITBASH_WRAPPER_PATH" || true
  chmod +x "$WIN_GITBASH_WRAPPER_PATH" 2>/dev/null || true

  echo "==> Note: In Git Bash, ensure ~/bin is in PATH (so 'oraclepack' resolves to this wrapper)."
fi

echo "==> Done."
echo "    WSL binary:     $LINUX_INSTALL_PATH"
echo "    Windows exe:    $WIN_LOCAL_BIN_PATH"
echo "    Git Bash wrap:  $WIN_GITBASH_WRAPPER_PATH"
```

Run (from repo root in WSL):

```bash
chmod +x scripts/build_install_oraclepack.sh
scripts/build_install_oraclepack.sh
```

Optional example:

```bash
scripts/build_install_oraclepack.sh --win-user user --wsl-distro Ubuntu-24.04 --wsl-user user
```
```

.config/scripts/build_install_oraclepack.sh
```
# path: scripts/build_install_oraclepack.sh
#!/usr/bin/env bash
set -euo pipefail

# Builds oraclepack for:
# - WSL/Linux (oraclepack)
# - Windows amd64 (oraclepack.exe)
# Then installs:
# - WSL binary -> ~/.local/bin/
# - Windows exe -> /mnt/c/Users/<winuser>/.local/bin/
# And writes a Git Bash wrapper:
# - /mnt/c/Users/<winuser>/bin/oraclepack  (calls WSL binary via wsl.exe)

usage() {
  cat <<'USAGE'
Usage:
  scripts/build_install_oraclepack.sh [options]

Options:
  --repo-root <path>      Repo root (default: git toplevel, else current dir)
  --win-user <name>       Windows username (default: auto-detect, else "user")
  --wsl-distro <name>     WSL distro name for wsl.exe -d (default: $WSL_DISTRO_NAME or "Ubuntu-24.04")
  --wsl-user <name>       WSL username for wsl.exe -u (default: current user)
  --no-linux              Skip building/installing Linux binary
  --no-windows            Skip building/installing Windows .exe
  --no-wrapper            Skip writing the Git Bash wrapper script
  --cgo <0|1>             Set CGO_ENABLED (default: leave unchanged)

Examples:
  scripts/build_install_oraclepack.sh
  scripts/build_install_oraclepack.sh --win-user Alice --wsl-distro Ubuntu-24.04
USAGE
}

die() { echo "error: $*" >&2; exit 1; }

have() { command -v "$1" >/dev/null 2>&1; }

detect_repo_root() {
  if have git && git rev-parse --show-toplevel >/dev/null 2>&1; then
    git rev-parse --show-toplevel
  else
    pwd
  fi
}

detect_win_user() {
  # Best-effort: ask Windows for %USERNAME% via cmd.exe (works in most WSL setups).
  if have cmd.exe; then
    local u
    u="$(cmd.exe /c "echo %USERNAME%" 2>/dev/null | tr -d '\r' | tail -n 1 || true)"
    if [[ -n "${u:-}" && "${u:-}" != "%USERNAME%" ]]; then
      echo "$u"
      return
    fi
  fi
  echo "user"
}

REPO_ROOT=""
WIN_USER=""
WSL_DISTRO="${WSL_DISTRO_NAME:-Ubuntu-24.04}"
WSL_USER="$(whoami)"
DO_LINUX=1
DO_WINDOWS=1
DO_WRAPPER=1
CGO=""

while [[ $# -gt 0 ]]; do
  case "$1" in
    --repo-root)  REPO_ROOT="${2:-}"; shift 2;;
    --win-user)   WIN_USER="${2:-}"; shift 2;;
    --wsl-distro) WSL_DISTRO="${2:-}"; shift 2;;
    --wsl-user)   WSL_USER="${2:-}"; shift 2;;
    --no-linux)   DO_LINUX=0; shift;;
    --no-windows) DO_WINDOWS=0; shift;;
    --no-wrapper) DO_WRAPPER=0; shift;;
    --cgo)        CGO="${2:-}"; shift 2;;
    -h|--help)    usage; exit 0;;
    *)            die "unknown option: $1 (use --help)";;
  esac
done

[[ -n "$REPO_ROOT" ]] || REPO_ROOT="$(detect_repo_root)"
[[ -d "$REPO_ROOT" ]] || die "repo root not found: $REPO_ROOT"

[[ -n "$WIN_USER" ]] || WIN_USER="$(detect_win_user)"

have go || die "go not found in PATH"

# Paths
LINUX_OUT="$REPO_ROOT/oraclepack"
WIN_OUT="$REPO_ROOT/oraclepack.exe"

LINUX_INSTALL_DIR="$HOME/.local/bin"
LINUX_INSTALL_PATH="$LINUX_INSTALL_DIR/oraclepack"

WIN_HOME="/mnt/c/Users/$WIN_USER"
WIN_LOCAL_BIN_DIR="$WIN_HOME/.local/bin"
WIN_LOCAL_BIN_PATH="$WIN_LOCAL_BIN_DIR/oraclepack.exe"

WIN_GITBASH_BIN_DIR="$WIN_HOME/bin"
WIN_GITBASH_WRAPPER_PATH="$WIN_GITBASH_BIN_DIR/oraclepack"

# Optional CGO toggle
if [[ -n "$CGO" ]]; then
  [[ "$CGO" == "0" || "$CGO" == "1" ]] || die "--cgo must be 0 or 1"
  export CGO_ENABLED="$CGO"
fi

cd "$REPO_ROOT"

# Build binaries
if [[ "$DO_LINUX" -eq 1 ]]; then
  echo "==> Building Linux (WSL) binary: $LINUX_OUT"
  go build -o "$LINUX_OUT" ./cmd/oraclepack
fi

if [[ "$DO_WINDOWS" -eq 1 ]]; then
  echo "==> Building Windows amd64 exe: $WIN_OUT"
  GOOS=windows GOARCH=amd64 go build -o "$WIN_OUT" ./cmd/oraclepack
fi

# Install binaries
if [[ "$DO_LINUX" -eq 1 ]]; then
  echo "==> Installing Linux binary -> $LINUX_INSTALL_PATH"
  mkdir -p "$LINUX_INSTALL_DIR"
  cp -f "$LINUX_OUT" "$LINUX_INSTALL_PATH"
fi

if [[ "$DO_WINDOWS" -eq 1 ]]; then
  echo "==> Installing Windows exe -> $WIN_LOCAL_BIN_PATH"
  mkdir -p "$WIN_LOCAL_BIN_DIR"
  cp -f "$WIN_OUT" "$WIN_LOCAL_BIN_PATH"
fi

# Write Git Bash wrapper (stored on Windows filesystem)
if [[ "$DO_WRAPPER" -eq 1 ]]; then
  echo "==> Writing Git Bash wrapper -> $WIN_GITBASH_WRAPPER_PATH"
  mkdir -p "$WIN_GITBASH_BIN_DIR"

  cat > "$WIN_GITBASH_WRAPPER_PATH" <<EOF
#!/usr/bin/env bash
set -euo pipefail

# Git for Windows (Git Bash) path-conversion off for this exec call.
# Required so /home/... is not rewritten into C:/Program Files/Git/...
MSYS_NO_PATHCONV=1 exec wsl.exe -d ${WSL_DISTRO@Q} -u ${WSL_USER@Q} -- ${LINUX_INSTALL_PATH@Q} "\$@"
EOF

  # Ensure LF line endings (in case editor/tool wrote CRLF) and best-effort executable bit.
  sed -i 's/\r$//' "$WIN_GITBASH_WRAPPER_PATH" || true
  chmod +x "$WIN_GITBASH_WRAPPER_PATH" 2>/dev/null || true

  echo "==> Note: In Git Bash, ensure ~/bin is in PATH (so 'oraclepack' resolves to this wrapper)."
fi

echo "==> Done."
echo "    WSL binary:     $LINUX_INSTALL_PATH"
echo "    Windows exe:    $WIN_LOCAL_BIN_PATH"
echo "    Git Bash wrap:  $WIN_GITBASH_WRAPPER_PATH"
```

.config/scripts/codefetch_skill.sh
```
# path: scripts/codefetch_skill.sh
#!/usr/bin/env bash
set -euo pipefail

usage() {
  cat <<'USAGE'
Usage:
  bash scripts/codefetch_skill.sh <skill-name> [output-file]

The argument must be the skill directory name under ./skills (no prefix assumptions),
e.g.:
  bash scripts/codefetch_skill.sh oraclepack-tickets-pack
  bash scripts/codefetch_skill.sh tickets-pack
  bash scripts/codefetch_skill.sh my-skill-name ./out.md

Env overrides:
  CODEFETCH_THREADS   (default: 5)
  CODEFETCH_MAXTOKENS (default: 75000)
USAGE
}

if [[ "${1:-}" == "" || "${1:-}" == "-h" || "${1:-}" == "--help" ]]; then
  usage
  exit 0
fi

skill_name="$1"
threads="${CODEFETCH_THREADS:-5}"
max_tokens="${CODEFETCH_MAXTOKENS:-75000}"

skill_dir="skills/${skill_name%/}"

if [[ ! -d "$skill_dir" ]]; then
  echo "Error: skill directory not found: $skill_dir" >&2
  echo "Expected a folder under ./skills/ named exactly: '$skill_name'" >&2
  exit 1
fi

out="${2:-${skill_name}_skill.md}"

include_files=(
  "${skill_dir}/SKILL.md"
  "${skill_dir}/assets/**/*"
  "${skill_dir}/references/**/*"
  "${skill_dir}/scripts/**/*"
)

include_files_csv=""
for pat in "${include_files[@]}"; do
  if [[ -z "$include_files_csv" ]]; then
    include_files_csv="$pat"
  else
    include_files_csv="${include_files_csv},$pat"
  fi
done

codefetch -t "$threads" \
  --include-dir "$skill_dir" \
  --include-files "$include_files_csv" \
  -o "$out" \
  --max-tokens "$max_tokens"

echo "Wrote: $out"
```

.config/scripts/install-global.ps1
```
# path: scripts/install-global.ps1
[CmdletBinding()]
param(
  [string]$InstallDir = "C:\Tools",
  [switch]$AddToPath,
  [switch]$SkipTests
)

$ErrorActionPreference = "Stop"

function Get-RepoRoot {
  try {
    return (git rev-parse --show-toplevel).Trim()
  } catch {
    throw "Not inside a git repo (expected oraclepack repo)."
  }
}

$RepoRoot = Get-RepoRoot
Set-Location $RepoRoot

if (-not (Get-Command go -ErrorAction SilentlyContinue)) {
  throw "Go not found in PATH."
}

Write-Host "==> Repo: $RepoRoot"
Write-Host "==> InstallDir: $InstallDir"

if (-not $SkipTests) {
  Write-Host "==> go test ./..."
  go test ./...
}

# Match README build target: ./cmd/oraclepack
Write-Host "==> go build -o oraclepack.exe ./cmd/oraclepack"
go build -o oraclepack.exe ./cmd/oraclepack

New-Item -ItemType Directory -Force -Path $InstallDir | Out-Null
Copy-Item -Force -Path (Join-Path $RepoRoot "oraclepack.exe") -Destination (Join-Path $InstallDir "oraclepack.exe")

if ($AddToPath) {
  $userPath = [Environment]::GetEnvironmentVariable("Path", "User")
  if ($userPath -notmatch [Regex]::Escape($InstallDir)) {
    $newPath = if ([string]::IsNullOrWhiteSpace($userPath)) { $InstallDir } else { "$userPath;$InstallDir" }
    [Environment]::SetEnvironmentVariable("Path", $newPath, "User")
    Write-Host "==> Added to User PATH: $InstallDir (restart terminal to pick up PATH changes)"
  } else {
    Write-Host "==> InstallDir already in User PATH"
  }
}

Write-Host "==> Installed: $InstallDir\oraclepack.exe"
& (Join-Path $InstallDir "oraclepack.exe") --version 2>$null
```

.config/scripts/install-global.sh
```
# path: scripts/install-global.sh
#!/usr/bin/env bash
set -euo pipefail

usage() {
  cat <<'USAGE'
install-global.sh — rebuild oraclepack and install it to a PATH directory.

Usage:
  ./scripts/install-global.sh [--prefix DIR] [--sudo] [--skip-tests]

Options:
  --prefix DIR     Install directory (default: ~/.local/bin; macOS prefers /usr/local/bin if writable)
  --sudo           Use sudo when copying into --prefix (for system dirs like /usr/local/bin)
  --skip-tests     Skip `go test ./...`

Examples:
  ./scripts/install-global.sh
  ./scripts/install-global.sh --prefix "$HOME/.local/bin"
  ./scripts/install-global.sh --prefix /usr/local/bin --sudo
USAGE
}

PREFIX=""
USE_SUDO=0
SKIP_TESTS=0

while [[ $# -gt 0 ]]; do
  case "$1" in
    --prefix) PREFIX="${2:-}"; shift 2 ;;
    --sudo) USE_SUDO=1; shift ;;
    --skip-tests) SKIP_TESTS=1; shift ;;
    -h|--help) usage; exit 0 ;;
    *) echo "Unknown arg: $1" >&2; usage; exit 2 ;;
  esac
done

# Repo root (so script works from anywhere)
REPO_ROOT="$(git rev-parse --show-toplevel 2>/dev/null || true)"
if [[ -z "${REPO_ROOT}" ]]; then
  echo "Error: not inside a git repo (expected oraclepack repo)." >&2
  exit 1
fi
cd "$REPO_ROOT"

# Build output
BUILD_DIR="$REPO_ROOT/.build"
mkdir -p "$BUILD_DIR"
OUT_BIN="$BUILD_DIR/oraclepack"

# Default install prefix
if [[ -z "${PREFIX}" ]]; then
  case "$(uname -s)" in
    Darwin)
      if [[ -w "/usr/local/bin" ]]; then
        PREFIX="/usr/local/bin"
      else
        PREFIX="$HOME/.local/bin"
      fi
      ;;
    *)
      PREFIX="$HOME/.local/bin"
      ;;
  esac
fi

echo "==> Repo: $REPO_ROOT"
echo "==> Building: $OUT_BIN"
echo "==> Installing to: $PREFIX"

command -v go >/dev/null 2>&1 || { echo "Error: go not found in PATH." >&2; exit 1; }

if [[ "$SKIP_TESTS" -eq 0 ]]; then
  echo "==> go test ./..."
  go test ./...
fi

# Match README build target: ./cmd/oraclepack :contentReference[oaicite:0]{index=0}
go build -o "$OUT_BIN" ./cmd/oraclepack

mkdir -p "$PREFIX"

# Install (overwrite existing)
if [[ "$USE_SUDO" -eq 1 ]]; then
  sudo install -m 0755 "$OUT_BIN" "$PREFIX/oraclepack"
else
  install -m 0755 "$OUT_BIN" "$PREFIX/oraclepack"
fi

echo "==> Installed: $PREFIX/oraclepack"
echo "==> Version (if supported):"
"$PREFIX/oraclepack" --version 2>/dev/null || true

# Best-effort: refresh shell hash table (won't error if unsupported)
hash -r 2>/dev/null || true
```

.config/scripts/tag-release.sh
```
# path: scripts/tag-release.sh
#!/usr/bin/env bash
set -euo pipefail

read -r -p "Input tag version (e.g., 0.2.0): " version
version="${version//[[:space:]]/}"
[[ -n "${version}" ]] || { echo "Error: version cannot be empty." >&2; exit 1; }

tag="v${version}"

git rev-parse -q --verify "refs/tags/${tag}" >/dev/null && {
  echo "Error: tag ${tag} already exists locally." >&2
  exit 1
}

git ls-remote --tags origin "refs/tags/${tag}" | grep -q . && {
  echo "Error: tag ${tag} already exists on origin." >&2
  exit 1
}

git tag "${tag}"
git push origin "${tag}"
```

.github/workflows/ci.yml
```
# path: .github/workflows/ci.yml
name: ci

on:
  pull_request:
  push:
    branches:
      - main

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Set up Go
        uses: actions/setup-go@v6
        with:
          go-version-file: go.mod
          cache: true

      # oraclepack tests expect `oracle` to be available on PATH
      - name: Set up Node (for oracle CLI)
        uses: actions/setup-node@v4
        with:
          node-version: "22"

      - name: Install oracle CLI
        run: npm install -g @steipete/oracle

      - name: Smoke test oracle CLI
        run: oracle --help

      - name: Test
        run: go test ./...

      - name: Vet
        run: go vet ./...
```

.github/workflows/release.yml
```
# path: .github/workflows/release.yml
name: release

on:
  push:
    tags:
      - "v*"

permissions:
  contents: write

jobs:
  goreleaser:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Set up Go
        uses: actions/setup-go@v6
        with:
          # Reads the Go version from go.mod ("go 1.xx")
          go-version-file: go.mod
          cache: true

      - name: Run GoReleaser
        uses: goreleaser/goreleaser-action@v6
        with:
          distribution: goreleaser
          version: "~> v2"
          args: release --clean
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

internal/cli/cmds.go
```
package cli

import (
	"fmt"

	"github.com/spf13/cobra"
	"github.com/user/oraclepack/internal/app"
)

var validateCmd = &cobra.Command{
	Use:   "validate [pack.md]",
	Short: "Validate an oracle pack",
	Args:  cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		cfg := app.Config{PackPath: args[0]}
		a := app.New(cfg)
		if err := a.LoadPack(); err != nil {
			return err
		}
		fmt.Println("Pack is valid.")
		return nil
	},
}

var listCmd = &cobra.Command{
	Use:   "list [pack.md]",
	Short: "List steps in an oracle pack",
	Args:  cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		cfg := app.Config{PackPath: args[0]}
		a := app.New(cfg)
		if err := a.LoadPack(); err != nil {
			return err
		}
		for _, s := range a.Pack.Steps {
			fmt.Printf("%s: %s\n", s.ID, s.OriginalLine)
		}
		return nil
	},
}

func init() {
	rootCmd.AddCommand(validateCmd)
	rootCmd.AddCommand(listCmd)
}
```

internal/cli/root.go
```
package cli

import (
	"fmt"
	"os"

	"github.com/spf13/cobra"
	"github.com/user/oraclepack/internal/errors"
)

var (
	noTUI     bool
	oracleBin string
	outDir    string
)

var rootCmd = &cobra.Command{
	Use:   "oraclepack",
	Short: "Oracle Pack Runner",
	Long:  `A polished TUI-driven runner for oracle-based interactive bash steps.`,
}

// Execute adds all child commands to the root command and sets flags appropriately.
func Execute() {
	if err := rootCmd.Execute(); err != nil {
		fmt.Fprintln(os.Stderr, err)
		os.Exit(errors.ExitCode(err))
	}
}

func init() {
	rootCmd.PersistentFlags().BoolVar(&noTUI, "no-tui", false, "Disable the TUI and run in plain terminal mode")
	rootCmd.PersistentFlags().StringVar(&oracleBin, "oracle-bin", "oracle", "Path to the oracle binary")
	rootCmd.PersistentFlags().StringVarP(&outDir, "out-dir", "o", "", "Output directory for step execution")
}
```

internal/cli/run.go
```
package cli

import (
	"context"
	"os"
	"path/filepath"
	"strings"

	"github.com/spf13/cobra"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/user/oraclepack/internal/app"
	"github.com/user/oraclepack/internal/tui"
)

var (
	yes          bool
	resume       bool
	stopOnFail   bool
	roiThreshold float64
	roiMode      string
	runAll       bool
)

var runCmd = &cobra.Command{
	Use:   "run [pack.md]",
	Short: "Run an oracle pack",
	Args:  cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		packPath := args[0]
		
		// Setup paths
		base := strings.TrimSuffix(filepath.Base(packPath), filepath.Ext(packPath))
		statePath := base + ".state.json"
		reportPath := base + ".report.json"

		cfg := app.Config{
			PackPath:     packPath,
			StatePath:    statePath,
			ReportPath:   reportPath,
			Resume:       resume,
			StopOnFail:   stopOnFail,
			WorkDir:      ".",
			OutDir:       outDir,
			ROIThreshold: roiThreshold,
			ROIMode:      roiMode,
		}

		a := app.New(cfg)
		// Prepare the application (loads pack, resolves out_dir, provisions env)
		if err := a.Prepare(); err != nil {
			return err
		}
		
		if err := a.LoadState(); err != nil {
			return err
		}

		if noTUI {
			return a.RunPlain(context.Background(), os.Stdout)
		}

		m := tui.NewModel(a.Pack, a.Runner, a.State, cfg.StatePath, cfg.ROIThreshold, cfg.ROIMode, runAll)
		p := tea.NewProgram(m, tea.WithAltScreen())
		_, err := p.Run()
		return err
	},
}

func init() {
	runCmd.Flags().BoolVarP(&yes, "yes", "y", false, "Auto-approve all steps")
	runCmd.Flags().BoolVar(&resume, "resume", false, "Resume from last successful step")
	runCmd.Flags().BoolVar(&stopOnFail, "stop-on-fail", true, "Stop execution if a step fails")
	runCmd.Flags().Float64Var(&roiThreshold, "roi-threshold", 0.0, "Filter steps by ROI threshold")
	runCmd.Flags().StringVar(&roiMode, "roi-mode", "over", "ROI filter mode ('over' or 'under')")
	runCmd.Flags().BoolVar(&runAll, "run-all", false, "Automatically run all steps sequentially on start")
	rootCmd.AddCommand(runCmd)
}
```

internal/errors/errors.go
```
package errors

import (
	"errors"
)

var (
	// ErrInvalidPack is returned when the Markdown pack is malformed.
	ErrInvalidPack = errors.New("invalid pack structure")
	// ErrExecutionFailed is returned when a shell command fails.
	ErrExecutionFailed = errors.New("execution failed")
	// ErrConfigInvalid is returned when CLI flags or environment variables are incorrect.
	ErrConfigInvalid = errors.New("invalid configuration")
)

// ExitCode returns the appropriate exit code for a given error.
func ExitCode(err error) int {
	if err == nil {
		return 0
	}

	if errors.Is(err, ErrConfigInvalid) {
		return 2
	}

	if errors.Is(err, ErrInvalidPack) {
		return 3
	}

	if errors.Is(err, ErrExecutionFailed) {
		return 4
	}

	return 1 // Generic error
}
```

internal/errors/errors_test.go
```
package errors

import (
	"errors"
	"fmt"
	"testing"
)

func TestExitCode(t *testing.T) {
	tests := []struct {
		name     string
		err      error
		expected int
	}{
		{"nil error", nil, 0},
		{"generic error", errors.New("generic"), 1},
		{"invalid pack", ErrInvalidPack, 3},
		{"execution failed", ErrExecutionFailed, 4},
		{"config invalid", ErrConfigInvalid, 2},
		{"wrapped invalid pack", fmt.Errorf("wrap: %w", ErrInvalidPack), 3},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			if got := ExitCode(tt.err); got != tt.expected {
				t.Errorf("ExitCode() = %v, want %v", got, tt.expected)
			}
		})
	}
}
```

internal/app/app.go
```
package app

import (
	"fmt"
	"os"

	"github.com/user/oraclepack/internal/exec"
	"github.com/user/oraclepack/internal/pack"
	"github.com/user/oraclepack/internal/state"
)

// Config holds application-wide configuration.
type Config struct {
	PackPath     string
	StatePath    string
	ReportPath   string
	StopOnFail   bool
	Resume       bool
	Verbose      bool
	DryRun       bool
	OracleFlags  []string
	WorkDir      string
	OutDir       string // CLI override for output directory
	ROIThreshold float64
	ROIMode      string // "over" or "under"
}

// App orchestrates the execution flow.
type App struct {
	Config Config
	Pack   *pack.Pack
	State  *state.RunState
	Runner *exec.Runner
}

// New creates a new application instance.
func New(cfg Config) *App {
	return &App{
		Config: cfg,
		Runner: exec.NewRunner(exec.RunnerOptions{
			WorkDir:     cfg.WorkDir,
			OracleFlags: cfg.OracleFlags,
		}),
	}
}

// LoadPack loads and validates the pack.
func (a *App) LoadPack() error {
	data, err := os.ReadFile(a.Config.PackPath)
	if err != nil {
		return err
	}

	p, err := pack.Parse(data)
	if err != nil {
		return err
	}

	if err := p.Validate(); err != nil {
		return err
	}

	a.Pack = p
	a.Pack.Source = a.Config.PackPath
	return nil
}

// LoadState loads or initializes the state.
func (a *App) LoadState() error {
	if a.Config.Resume {
		s, err := state.LoadState(a.Config.StatePath)
		if err == nil {
			a.State = s
			return nil
		}
	}

	a.State = &state.RunState{
		SchemaVersion: 1,
		StepStatuses:  make(map[string]state.StepStatus),
	}
	return nil
}

// Prepare resolves configuration and prepares the runtime environment.
func (a *App) Prepare() error {
	if a.Pack == nil {
		if err := a.LoadPack(); err != nil {
			return err
		}
	}

	// Resolve Output Directory
	// Precedence: CLI > Pack > Default (.)
	outDir := a.Config.OutDir
	if outDir == "" && a.Pack.OutDir != "" {
		outDir = a.Pack.OutDir
	}
	if outDir == "" {
		outDir = "."
	}

	// Provision Directory
	if err := os.MkdirAll(outDir, 0755); err != nil {
		return fmt.Errorf("failed to create output directory %s: %w", outDir, err)
	}

	// Update Runner
	// We do NOT set WorkDir to outDir, so execution happens in the project root.
	// This preserves relative path resolution for -f flags.
	// a.Runner.WorkDir = outDir 
	
	// Add out_dir to Env so scripts can reference it
	a.Runner.Env = append(a.Runner.Env, fmt.Sprintf("out_dir=%s", outDir))

	return nil
}
```

internal/app/app_test.go
```
package app

import (
	"bytes"
	"context"
	"os"
	"testing"
)

func TestApp_RunPlain(t *testing.T) {
	packContent := `
# Test Pack
` + "```" + `bash
# 01)
echo "step 1"
# 02)
echo "step 2"
` + "```" + `
`
	packFile := "test.md"
	stateFile := "test_state.json"
	reportFile := "test_report.json"
	defer os.Remove(packFile)
	defer os.Remove(stateFile)
	defer os.Remove(reportFile)

	os.WriteFile(packFile, []byte(packContent), 0644)

	cfg := Config{
		PackPath:   packFile,
		StatePath:  stateFile,
		ReportPath: reportFile,
	}

	a := New(cfg)
	if err := a.Prepare(); err != nil {
		t.Fatalf("Prepare failed: %v", err)
	}
	if err := a.LoadState(); err != nil {
		t.Fatalf("LoadState failed: %v", err)
	}
	
	var out bytes.Buffer
	err := a.RunPlain(context.Background(), &out)
	if err != nil {
		t.Fatalf("RunPlain failed: %v", err)
	}

	output := out.String()
	if !contains(output, "step 1") || !contains(output, "step 2") {
		t.Errorf("output missing steps: %s", output)
	}

	if _, err := os.Stat(stateFile); os.IsNotExist(err) {
		t.Error("state file was not created")
	}

	if _, err := os.Stat(reportFile); os.IsNotExist(err) {
		t.Error("report file was not created")
	}
}

func contains(s, substr string) bool {
	return len(s) >= len(substr) && (s == substr || (len(substr) > 0 && (s[:len(substr)] == substr || contains(s[1:], substr))))
}
```

internal/app/run.go
```
package app

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"time"

	"github.com/user/oraclepack/internal/report"
	"github.com/user/oraclepack/internal/state"
)

func (a *App) RunPlain(ctx context.Context, out io.Writer) error {
	// Assumes a.Prepare() and a.LoadState() have been called by the CLI entrypoint.
	if a.Pack == nil {
		return fmt.Errorf("pack not loaded")
	}
	if a.State == nil {
		return fmt.Errorf("state not loaded")
	}

	if a.State.StartTime.IsZero() {
		a.State.StartTime = time.Now()
	}

	fmt.Fprintf(out, "Running pack: %s\n", a.Config.PackPath)
	fmt.Fprintf(out, "Output directory: %s\n", a.Runner.WorkDir)

	// Prelude
	if a.Pack.Prelude.Code != "" {
		fmt.Fprintln(out, "Executing prelude...")
		err := a.Runner.RunPrelude(ctx, &a.Pack.Prelude, out)
		a.recordWarnings()
		if err != nil {
			return fmt.Errorf("prelude failed: %w", err)
		}
	}

	for _, step := range a.Pack.Steps {
		// Filter by ROI
		if a.Config.ROIThreshold > 0 {
			if a.Config.ROIMode == "under" {
				// "under" is strictly less than
				if step.ROI >= a.Config.ROIThreshold {
					fmt.Fprintf(out, "Skipping step %s (ROI %.2f >= %.2f)\n", step.ID, step.ROI, a.Config.ROIThreshold)
					continue
				}
			} else {
				// "over" is greater than or equal to (3.3 or higher)
				if step.ROI < a.Config.ROIThreshold {
					fmt.Fprintf(out, "Skipping step %s (ROI %.2f < %.2f)\n", step.ID, step.ROI, a.Config.ROIThreshold)
					continue
				}
			}
		}

		// Check resume
		if s, ok := a.State.StepStatuses[step.ID]; ok && s.Status == state.StatusSuccess {
			fmt.Fprintf(out, "Skipping step %s (already succeeded)\n", step.ID)
			continue
		}

		fmt.Fprintf(out, "\n>>> Step %s: %s\n", step.ID, step.OriginalLine)

		status := state.StepStatus{
			Status:    state.StatusRunning,
			StartedAt: time.Now(),
		}
		a.State.StepStatuses[step.ID] = status
		a.saveState()

		// Execute
		err := a.Runner.RunStep(ctx, &step, out)
		a.recordWarnings()

		status.EndedAt = time.Now()
		if err != nil {
			status.Status = state.StatusFailed
			status.Error = err.Error()
			a.State.StepStatuses[step.ID] = status
			a.saveState()

			if a.Config.StopOnFail {
				a.finalize(out)
				return err
			}
			continue
		}

		status.Status = state.StatusSuccess
		status.ExitCode = 0
		a.State.StepStatuses[step.ID] = status
		a.saveState()
	}

	a.finalize(out)
	return nil
}

func (a *App) recordWarnings() {
	if a.State == nil || a.Runner == nil {
		return
	}
	warnings := a.Runner.DrainWarnings()
	if len(warnings) == 0 {
		return
	}
	for _, w := range warnings {
		a.State.Warnings = append(a.State.Warnings, state.Warning{
			Scope:   w.Scope,
			StepID:  w.StepID,
			Line:    w.Line,
			Token:   w.Token,
			Message: w.Message,
		})
	}
	a.saveState()
}

func (a *App) saveState() {
	if a.Config.StatePath != "" {
		_ = state.SaveStateAtomic(a.Config.StatePath, a.State)
	}
}

func (a *App) finalize(out io.Writer) {
	if a.Config.ReportPath != "" {
		rep := report.GenerateReport(a.State, filepath.Base(a.Config.PackPath))
		data, _ := json.MarshalIndent(rep, "", "  ")
		_ = os.WriteFile(a.Config.ReportPath, data, 0644)
		fmt.Fprintf(out, "\nReport written to %s\n", a.Config.ReportPath)
	}
}
```

internal/app/run_test.go
```
package app

import (
	"bytes"
	"context"
	"os"
	"strings"
	"testing"
)

func TestApp_RunPlain_ROI(t *testing.T) {
	packContent := `
# ROI Test Pack
` + "```" + `bash
# 01) ROI=5.0
echo "high"
# 02) ROI=3.3
echo "threshold"
# 03) ROI=1.0
echo "low"
` + "```" + `
`
	packFile := "roi_test.md"
	defer os.Remove(packFile)
	os.WriteFile(packFile, []byte(packContent), 0644)

	// Test Case 1: Filter OVER 3.3 (Should run 5.0 and 3.3)
	t.Run("Filter Over 3.3", func(t *testing.T) {
		var out bytes.Buffer
		cfg := Config{
			PackPath:     packFile,
			ROIThreshold: 3.3,
			ROIMode:      "over",
		}
		app := New(cfg)
		if err := app.Prepare(); err != nil {
			t.Fatalf("Prepare failed: %v", err)
		}
		if err := app.LoadState(); err != nil {
			t.Fatalf("LoadState failed: %v", err)
		}
		if err := app.RunPlain(context.Background(), &out); err != nil {
			t.Fatalf("RunPlain failed: %v", err)
		}
		output := out.String()
		if !strings.Contains(output, "Step 01") {
			t.Error("expected Step 01 (5.0) to run")
		}
		if !strings.Contains(output, "Step 02") {
			t.Error("expected Step 02 (3.3) to run (inclusive)")
		}
		if strings.Contains(output, "Step 03") && !strings.Contains(output, "Skipping step 03") {
			t.Error("expected Step 03 (1.0) to be skipped")
		}
	})

	// Test Case 2: Filter UNDER 3.3 (Should run 1.0 only)
	t.Run("Filter Under 3.3", func(t *testing.T) {
		var out bytes.Buffer
		cfg := Config{
			PackPath:     packFile,
			ROIThreshold: 3.3,
			ROIMode:      "under",
		}
		app := New(cfg)
		if err := app.Prepare(); err != nil {
			t.Fatalf("Prepare failed: %v", err)
		}
		if err := app.LoadState(); err != nil {
			t.Fatalf("LoadState failed: %v", err)
		}
		if err := app.RunPlain(context.Background(), &out); err != nil {
			t.Fatalf("RunPlain failed: %v", err)
		}
		output := out.String()
		if strings.Contains(output, "Step 01") && !strings.Contains(output, "Skipping step 01") {
			t.Error("expected Step 01 (5.0) to be skipped")
		}
		if strings.Contains(output, "Step 02") && !strings.Contains(output, "Skipping step 02") {
			t.Error("expected Step 02 (3.3) to be skipped (exclusive)")
		}
		if !strings.Contains(output, "Step 03") {
			t.Error("expected Step 03 (1.0) to run")
		}
	})
}
```

.mypy_cache/3.12/@plugins_snapshot.json
```
{}
```

.mypy_cache/3.12/_ast.data.json
```
{".class":"MypyFile","_fullname":"_ast","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","AST":{".class":"SymbolTableNode","cross_ref":"ast.AST","kind":"Gdef"},"Add":{".class":"SymbolTableNode","cross_ref":"ast.Add","kind":"Gdef"},"And":{".class":"SymbolTableNode","cross_ref":"ast.And","kind":"Gdef"},"AnnAssign":{".class":"SymbolTableNode","cross_ref":"ast.AnnAssign","kind":"Gdef"},"Assert":{".class":"SymbolTableNode","cross_ref":"ast.Assert","kind":"Gdef"},"Assign":{".class":"SymbolTableNode","cross_ref":"ast.Assign","kind":"Gdef"},"AsyncFor":{".class":"SymbolTableNode","cross_ref":"ast.AsyncFor","kind":"Gdef"},"AsyncFunctionDef":{".class":"SymbolTableNode","cross_ref":"ast.AsyncFunctionDef","kind":"Gdef"},"AsyncWith":{".class":"SymbolTableNode","cross_ref":"ast.AsyncWith","kind":"Gdef"},"Attribute":{".class":"SymbolTableNode","cross_ref":"ast.Attribute","kind":"Gdef"},"AugAssign":{".class":"SymbolTableNode","cross_ref":"ast.AugAssign","kind":"Gdef"},"Await":{".class":"SymbolTableNode","cross_ref":"ast.Await","kind":"Gdef"},"BinOp":{".class":"SymbolTableNode","cross_ref":"ast.BinOp","kind":"Gdef"},"BitAnd":{".class":"SymbolTableNode","cross_ref":"ast.BitAnd","kind":"Gdef"},"BitOr":{".class":"SymbolTableNode","cross_ref":"ast.BitOr","kind":"Gdef"},"BitXor":{".class":"SymbolTableNode","cross_ref":"ast.BitXor","kind":"Gdef"},"BoolOp":{".class":"SymbolTableNode","cross_ref":"ast.BoolOp","kind":"Gdef"},"Break":{".class":"SymbolTableNode","cross_ref":"ast.Break","kind":"Gdef"},"Call":{".class":"SymbolTableNode","cross_ref":"ast.Call","kind":"Gdef"},"ClassDef":{".class":"SymbolTableNode","cross_ref":"ast.ClassDef","kind":"Gdef"},"Compare":{".class":"SymbolTableNode","cross_ref":"ast.Compare","kind":"Gdef"},"Constant":{".class":"SymbolTableNode","cross_ref":"ast.Constant","kind":"Gdef"},"Continue":{".class":"SymbolTableNode","cross_ref":"ast.Continue","kind":"Gdef"},"Del":{".class":"SymbolTableNode","cross_ref":"ast.Del","kind":"Gdef"},"Delete":{".class":"SymbolTableNode","cross_ref":"ast.Delete","kind":"Gdef"},"Dict":{".class":"SymbolTableNode","cross_ref":"ast.Dict","kind":"Gdef"},"DictComp":{".class":"SymbolTableNode","cross_ref":"ast.DictComp","kind":"Gdef"},"Div":{".class":"SymbolTableNode","cross_ref":"ast.Div","kind":"Gdef"},"Eq":{".class":"SymbolTableNode","cross_ref":"ast.Eq","kind":"Gdef"},"ExceptHandler":{".class":"SymbolTableNode","cross_ref":"ast.ExceptHandler","kind":"Gdef"},"Expr":{".class":"SymbolTableNode","cross_ref":"ast.Expr","kind":"Gdef"},"Expression":{".class":"SymbolTableNode","cross_ref":"ast.Expression","kind":"Gdef"},"FloorDiv":{".class":"SymbolTableNode","cross_ref":"ast.FloorDiv","kind":"Gdef"},"For":{".class":"SymbolTableNode","cross_ref":"ast.For","kind":"Gdef"},"FormattedValue":{".class":"SymbolTableNode","cross_ref":"ast.FormattedValue","kind":"Gdef"},"FunctionDef":{".class":"SymbolTableNode","cross_ref":"ast.FunctionDef","kind":"Gdef"},"FunctionType":{".class":"SymbolTableNode","cross_ref":"ast.FunctionType","kind":"Gdef"},"GeneratorExp":{".class":"SymbolTableNode","cross_ref":"ast.GeneratorExp","kind":"Gdef"},"Global":{".class":"SymbolTableNode","cross_ref":"ast.Global","kind":"Gdef"},"Gt":{".class":"SymbolTableNode","cross_ref":"ast.Gt","kind":"Gdef"},"GtE":{".class":"SymbolTableNode","cross_ref":"ast.GtE","kind":"Gdef"},"If":{".class":"SymbolTableNode","cross_ref":"ast.If","kind":"Gdef"},"IfExp":{".class":"SymbolTableNode","cross_ref":"ast.IfExp","kind":"Gdef"},"Import":{".class":"SymbolTableNode","cross_ref":"ast.Import","kind":"Gdef"},"ImportFrom":{".class":"SymbolTableNode","cross_ref":"ast.ImportFrom","kind":"Gdef"},"In":{".class":"SymbolTableNode","cross_ref":"ast.In","kind":"Gdef"},"Interactive":{".class":"SymbolTableNode","cross_ref":"ast.Interactive","kind":"Gdef"},"Invert":{".class":"SymbolTableNode","cross_ref":"ast.Invert","kind":"Gdef"},"Is":{".class":"SymbolTableNode","cross_ref":"ast.Is","kind":"Gdef"},"IsNot":{".class":"SymbolTableNode","cross_ref":"ast.IsNot","kind":"Gdef"},"JoinedStr":{".class":"SymbolTableNode","cross_ref":"ast.JoinedStr","kind":"Gdef"},"LShift":{".class":"SymbolTableNode","cross_ref":"ast.LShift","kind":"Gdef"},"Lambda":{".class":"SymbolTableNode","cross_ref":"ast.Lambda","kind":"Gdef"},"List":{".class":"SymbolTableNode","cross_ref":"ast.List","kind":"Gdef"},"ListComp":{".class":"SymbolTableNode","cross_ref":"ast.ListComp","kind":"Gdef"},"Literal":{".class":"SymbolTableNode","cross_ref":"typing.Literal","kind":"Gdef","module_hidden":true,"module_public":false},"Load":{".class":"SymbolTableNode","cross_ref":"ast.Load","kind":"Gdef"},"Lt":{".class":"SymbolTableNode","cross_ref":"ast.Lt","kind":"Gdef"},"LtE":{".class":"SymbolTableNode","cross_ref":"ast.LtE","kind":"Gdef"},"MatMult":{".class":"SymbolTableNode","cross_ref":"ast.MatMult","kind":"Gdef"},"MatchAs":{".class":"SymbolTableNode","cross_ref":"ast.MatchAs","kind":"Gdef"},"MatchClass":{".class":"SymbolTableNode","cross_ref":"ast.MatchClass","kind":"Gdef"},"MatchMapping":{".class":"SymbolTableNode","cross_ref":"ast.MatchMapping","kind":"Gdef"},"MatchOr":{".class":"SymbolTableNode","cross_ref":"ast.MatchOr","kind":"Gdef"},"MatchSequence":{".class":"SymbolTableNode","cross_ref":"ast.MatchSequence","kind":"Gdef"},"MatchSingleton":{".class":"SymbolTableNode","cross_ref":"ast.MatchSingleton","kind":"Gdef"},"MatchStar":{".class":"SymbolTableNode","cross_ref":"ast.MatchStar","kind":"Gdef"},"MatchValue":{".class":"SymbolTableNode","cross_ref":"ast.MatchValue","kind":"Gdef"},"Mod":{".class":"SymbolTableNode","cross_ref":"ast.Mod","kind":"Gdef"},"Module":{".class":"SymbolTableNode","cross_ref":"ast.Module","kind":"Gdef"},"Mult":{".class":"SymbolTableNode","cross_ref":"ast.Mult","kind":"Gdef"},"Name":{".class":"SymbolTableNode","cross_ref":"ast.Name","kind":"Gdef"},"NamedExpr":{".class":"SymbolTableNode","cross_ref":"ast.NamedExpr","kind":"Gdef"},"Nonlocal":{".class":"SymbolTableNode","cross_ref":"ast.Nonlocal","kind":"Gdef"},"Not":{".class":"SymbolTableNode","cross_ref":"ast.Not","kind":"Gdef"},"NotEq":{".class":"SymbolTableNode","cross_ref":"ast.NotEq","kind":"Gdef"},"NotIn":{".class":"SymbolTableNode","cross_ref":"ast.NotIn","kind":"Gdef"},"Or":{".class":"SymbolTableNode","cross_ref":"ast.Or","kind":"Gdef"},"ParamSpec":{".class":"SymbolTableNode","cross_ref":"ast.ParamSpec","kind":"Gdef"},"Pass":{".class":"SymbolTableNode","cross_ref":"ast.Pass","kind":"Gdef"},"Pow":{".class":"SymbolTableNode","cross_ref":"ast.Pow","kind":"Gdef"},"PyCF_ALLOW_TOP_LEVEL_AWAIT":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_ast.PyCF_ALLOW_TOP_LEVEL_AWAIT","name":"PyCF_ALLOW_TOP_LEVEL_AWAIT","type":{".class":"LiteralType","fallback":"builtins.int","value":8192}}},"PyCF_ONLY_AST":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_ast.PyCF_ONLY_AST","name":"PyCF_ONLY_AST","type":{".class":"LiteralType","fallback":"builtins.int","value":1024}}},"PyCF_TYPE_COMMENTS":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_ast.PyCF_TYPE_COMMENTS","name":"PyCF_TYPE_COMMENTS","type":{".class":"LiteralType","fallback":"builtins.int","value":4096}}},"RShift":{".class":"SymbolTableNode","cross_ref":"ast.RShift","kind":"Gdef"},"Raise":{".class":"SymbolTableNode","cross_ref":"ast.Raise","kind":"Gdef"},"Return":{".class":"SymbolTableNode","cross_ref":"ast.Return","kind":"Gdef"},"Set":{".class":"SymbolTableNode","cross_ref":"ast.Set","kind":"Gdef"},"SetComp":{".class":"SymbolTableNode","cross_ref":"ast.SetComp","kind":"Gdef"},"Slice":{".class":"SymbolTableNode","cross_ref":"ast.Slice","kind":"Gdef"},"Starred":{".class":"SymbolTableNode","cross_ref":"ast.Starred","kind":"Gdef"},"Store":{".class":"SymbolTableNode","cross_ref":"ast.Store","kind":"Gdef"},"Sub":{".class":"SymbolTableNode","cross_ref":"ast.Sub","kind":"Gdef"},"Subscript":{".class":"SymbolTableNode","cross_ref":"ast.Subscript","kind":"Gdef"},"Try":{".class":"SymbolTableNode","cross_ref":"ast.Try","kind":"Gdef"},"TryStar":{".class":"SymbolTableNode","cross_ref":"ast.TryStar","kind":"Gdef"},"Tuple":{".class":"SymbolTableNode","cross_ref":"ast.Tuple","kind":"Gdef"},"TypeIgnore":{".class":"SymbolTableNode","cross_ref":"ast.TypeIgnore","kind":"Gdef"},"TypeVar":{".class":"SymbolTableNode","cross_ref":"ast.TypeVar","kind":"Gdef"},"TypeVarTuple":{".class":"SymbolTableNode","cross_ref":"ast.TypeVarTuple","kind":"Gdef"},"UAdd":{".class":"SymbolTableNode","cross_ref":"ast.UAdd","kind":"Gdef"},"USub":{".class":"SymbolTableNode","cross_ref":"ast.USub","kind":"Gdef"},"UnaryOp":{".class":"SymbolTableNode","cross_ref":"ast.UnaryOp","kind":"Gdef"},"While":{".class":"SymbolTableNode","cross_ref":"ast.While","kind":"Gdef"},"With":{".class":"SymbolTableNode","cross_ref":"ast.With","kind":"Gdef"},"Yield":{".class":"SymbolTableNode","cross_ref":"ast.Yield","kind":"Gdef"},"YieldFrom":{".class":"SymbolTableNode","cross_ref":"ast.YieldFrom","kind":"Gdef"},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_ast.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_ast.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_ast.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_ast.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_ast.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_ast.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"alias":{".class":"SymbolTableNode","cross_ref":"ast.alias","kind":"Gdef"},"arg":{".class":"SymbolTableNode","cross_ref":"ast.arg","kind":"Gdef"},"arguments":{".class":"SymbolTableNode","cross_ref":"ast.arguments","kind":"Gdef"},"boolop":{".class":"SymbolTableNode","cross_ref":"ast.boolop","kind":"Gdef"},"cmpop":{".class":"SymbolTableNode","cross_ref":"ast.cmpop","kind":"Gdef"},"comprehension":{".class":"SymbolTableNode","cross_ref":"ast.comprehension","kind":"Gdef"},"excepthandler":{".class":"SymbolTableNode","cross_ref":"ast.excepthandler","kind":"Gdef"},"expr":{".class":"SymbolTableNode","cross_ref":"ast.expr","kind":"Gdef"},"expr_context":{".class":"SymbolTableNode","cross_ref":"ast.expr_context","kind":"Gdef"},"keyword":{".class":"SymbolTableNode","cross_ref":"ast.keyword","kind":"Gdef"},"match_case":{".class":"SymbolTableNode","cross_ref":"ast.match_case","kind":"Gdef"},"mod":{".class":"SymbolTableNode","cross_ref":"ast.mod","kind":"Gdef"},"operator":{".class":"SymbolTableNode","cross_ref":"ast.operator","kind":"Gdef"},"pattern":{".class":"SymbolTableNode","cross_ref":"ast.pattern","kind":"Gdef"},"stmt":{".class":"SymbolTableNode","cross_ref":"ast.stmt","kind":"Gdef"},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false},"type_ignore":{".class":"SymbolTableNode","cross_ref":"ast.type_ignore","kind":"Gdef"},"type_param":{".class":"SymbolTableNode","cross_ref":"ast.type_param","kind":"Gdef"},"unaryop":{".class":"SymbolTableNode","cross_ref":"ast.unaryop","kind":"Gdef"},"withitem":{".class":"SymbolTableNode","cross_ref":"ast.withitem","kind":"Gdef"}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_ast.pyi"}
```

.mypy_cache/3.12/_ast.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,111,1,1,1,1],"dep_prios":[10,5,5,5,30,30,30],"dependencies":["sys","ast","typing","builtins","_frozen_importlib","_typeshed","abc"],"hash":"506bc583306f4b94d727fb61708c1873cb3b3fdf","id":"_ast","ignore_all":true,"interface_hash":"e1e0fe79f0f27e0c8fe3cce0224f1b06f28f4737","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_ast.pyi","plugin_data":null,"size":3496,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/_codecs.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/_codecs.meta.json
```
{"data_mtime":1767891128,"dep_lines":[4,1,2,3,5,6,1,1,1,1,1],"dep_prios":[5,10,10,5,5,5,5,30,30,30,30],"dependencies":["collections.abc","codecs","sys","_typeshed","typing","typing_extensions","builtins","_collections_abc","_frozen_importlib","abc","types"],"hash":"9c92db538a425ec561b85a564f567dc0c6ba2074","id":"_codecs","ignore_all":true,"interface_hash":"eecf14067db0d10d08b11ef98975cab0fdfde1de","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_codecs.pyi","plugin_data":null,"size":7059,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/_collections_abc.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/_collections_abc.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,3,4,1,1,1],"dep_prios":[10,5,5,5,5,30,30],"dependencies":["sys","abc","types","typing","builtins","_frozen_importlib","_typeshed"],"hash":"a526dac2ef1f80d9e0a33f11f80df105cf4939ab","id":"_collections_abc","ignore_all":true,"interface_hash":"39730ebfe5eab9ed5f32e8c85361048d6cdc1db0","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_collections_abc.pyi","plugin_data":null,"size":3077,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/_frozen_importlib.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/_frozen_importlib.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,5,6,1,3,4,8,1,1,1,1],"dep_prios":[10,10,5,5,20,10,5,5,5,30,30,30],"dependencies":["importlib.abc","importlib.machinery","_typeshed.importlib","collections.abc","importlib","sys","types","typing","builtins","_typeshed","abc","importlib._abc"],"hash":"d9e040a3e2921454ce5f15891fc32cf3fa65a284","id":"_frozen_importlib","ignore_all":true,"interface_hash":"9023a3591eca6a160f77eba0bf2745eb17b308d7","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_frozen_importlib.pyi","plugin_data":null,"size":4041,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/_frozen_importlib_external.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/_frozen_importlib_external.meta.json
```
{"data_mtime":1767891128,"dep_lines":[3,4,8,9,11,16,1,2,3,5,6,7,12,13,1,1,1,1,1,1,1],"dep_prios":[10,5,5,5,5,10,10,10,20,10,10,5,5,5,5,30,30,30,30,30,30],"dependencies":["importlib.abc","importlib.machinery","_typeshed.importlib","collections.abc","importlib.metadata","importlib.readers","_ast","_io","importlib","sys","types","_typeshed","typing","typing_extensions","builtins","_collections_abc","_frozen_importlib","abc","ast","importlib._abc","os"],"hash":"f10b55cab201631dcc95f81f2303997322e740c8","id":"_frozen_importlib_external","ignore_all":true,"interface_hash":"bba2c39f9641e4859e9aca9f5628b5d84163ed24","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_frozen_importlib_external.pyi","plugin_data":null,"size":8117,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/_io.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/_io.meta.json
```
{"data_mtime":1767891128,"dep_lines":[5,1,2,3,4,6,7,8,9,10,1,1,1],"dep_prios":[5,10,10,10,5,5,5,5,5,5,30,30,30],"dependencies":["collections.abc","builtins","codecs","sys","_typeshed","io","os","types","typing","typing_extensions","_collections_abc","_frozen_importlib","abc"],"hash":"6ea7c4de7cc0a01b4b38f647b5ea7b18b7569797","id":"_io","ignore_all":true,"interface_hash":"364b66e416a6d98ac8a274d52120dbe013adf38b","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_io.pyi","plugin_data":null,"size":9807,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/_sitebuiltins.data.json
```
{".class":"MypyFile","_fullname":"_sitebuiltins","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","ClassVar":{".class":"SymbolTableNode","cross_ref":"typing.ClassVar","kind":"Gdef","module_hidden":true,"module_public":false},"Iterable":{".class":"SymbolTableNode","cross_ref":"typing.Iterable","kind":"Gdef","module_hidden":true,"module_public":false},"Literal":{".class":"SymbolTableNode","cross_ref":"typing.Literal","kind":"Gdef","module_hidden":true,"module_public":false},"NoReturn":{".class":"SymbolTableNode","cross_ref":"typing.NoReturn","kind":"Gdef","module_hidden":true,"module_public":false},"Quitter":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"_sitebuiltins.Quitter","name":"Quitter","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"_sitebuiltins.Quitter","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"_sitebuiltins","mro":["_sitebuiltins.Quitter","builtins.object"],"names":{".class":"SymbolTable","__call__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1],"arg_names":["self","code"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"_sitebuiltins.Quitter.__call__","name":"__call__","type":{".class":"CallableType","arg_kinds":[0,1],"arg_names":["self","code"],"arg_types":["_sitebuiltins.Quitter",{".class":"TypeAliasType","args":[],"type_ref":"sys._ExitCode"}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__call__ of Quitter","ret_type":{".class":"UninhabitedType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0],"arg_names":["self","name","eof"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"_sitebuiltins.Quitter.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,0,0],"arg_names":["self","name","eof"],"arg_types":["_sitebuiltins.Quitter","builtins.str","builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of Quitter","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"eof":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"_sitebuiltins.Quitter.eof","name":"eof","type":"builtins.str"}},"name":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"_sitebuiltins.Quitter.name","name":"name","type":"builtins.str"}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"_Helper":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"_sitebuiltins._Helper","name":"_Helper","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"_sitebuiltins._Helper","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"_sitebuiltins","mro":["_sitebuiltins._Helper","builtins.object"],"names":{".class":"SymbolTable","__call__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1],"arg_names":["self","request"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"_sitebuiltins._Helper.__call__","name":"__call__","type":{".class":"CallableType","arg_kinds":[0,1],"arg_names":["self","request"],"arg_types":["_sitebuiltins._Helper","builtins.object"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__call__ of _Helper","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"_Printer":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"_sitebuiltins._Printer","name":"_Printer","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"_sitebuiltins._Printer","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"_sitebuiltins","mro":["_sitebuiltins._Printer","builtins.object"],"names":{".class":"SymbolTable","MAXLINES":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_classvar","is_ready"],"fullname":"_sitebuiltins._Printer.MAXLINES","name":"MAXLINES","type":{".class":"LiteralType","fallback":"builtins.int","value":23}}},"__call__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"_sitebuiltins._Printer.__call__","name":"__call__","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["_sitebuiltins._Printer"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__call__ of _Printer","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0,1,1],"arg_names":["self","name","data","files","dirs"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"_sitebuiltins._Printer.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,0,0,1,1],"arg_names":["self","name","data","files","dirs"],"arg_types":["_sitebuiltins._Printer","builtins.str","builtins.str",{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"typing.Iterable"},{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"typing.Iterable"}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of _Printer","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_sitebuiltins.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_sitebuiltins.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_sitebuiltins.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_sitebuiltins.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_sitebuiltins.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"_sitebuiltins.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_sitebuiltins.pyi"}
```

.mypy_cache/3.12/_sitebuiltins.meta.json
```
{"data_mtime":1767891128,"dep_lines":[2,1,3,1,1,1,1],"dep_prios":[5,10,5,5,30,30,30],"dependencies":["collections.abc","sys","typing","builtins","_frozen_importlib","abc","types"],"hash":"e6e5c5ce8260e3c2b7a40d1e32263187611481a2","id":"_sitebuiltins","ignore_all":true,"interface_hash":"6f82dacd8544441dbe6130eb979252b332573206","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_sitebuiltins.pyi","plugin_data":null,"size":538,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/abc.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/abc.meta.json
```
{"data_mtime":1767891128,"dep_lines":[4,1,2,5,6,1,1,1],"dep_prios":[5,5,10,5,5,5,30,30],"dependencies":["collections.abc","_typeshed","sys","typing","typing_extensions","builtins","_frozen_importlib","types"],"hash":"14708309acc87f4adb93786d9401ce31406810f8","id":"abc","ignore_all":true,"interface_hash":"867bd30f794b447a6c20ef9d7f921c15e747c9d0","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/abc.pyi","plugin_data":null,"size":1987,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/ast.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/ast.meta.json
```
{"data_mtime":1767891128,"dep_lines":[10,1,2,3,4,9,11,1,1,1,1,1],"dep_prios":[5,10,10,5,5,5,5,5,30,30,30,30],"dependencies":["collections.abc","os","sys","typing_extensions","_ast","_typeshed","typing","builtins","_collections_abc","_frozen_importlib","abc","types"],"hash":"dfa11a65941431bf51cf670e28eb10030e60ddd8","id":"ast","ignore_all":true,"interface_hash":"5ef5962d6692a37b72588527bbc7266083f8dcbf","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/ast.pyi","plugin_data":null,"size":76400,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/builtins.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/builtins.meta.json
```
{"data_mtime":1767891128,"dep_lines":[35,2,3,4,5,6,7,36,41,64,1,1,1,1,1],"dep_prios":[5,10,10,5,10,5,5,5,5,5,30,30,30,30,30],"dependencies":["collections.abc","_ast","_sitebuiltins","_typeshed","sys","types","_collections_abc","io","typing","typing_extensions","_frozen_importlib","_io","abc","ast","os"],"hash":"a2bc8bd0e6b5c7dc17c677a2b83dbeeea086e711","id":"builtins","ignore_all":true,"interface_hash":"8a0846ad1633f1735e0ab66ad823f8b3093b2d1e","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/builtins.pyi","plugin_data":null,"size":84991,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/codecs.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/codecs.meta.json
```
{"data_mtime":1767891128,"dep_lines":[5,1,2,3,4,6,7,1,1,1],"dep_prios":[5,10,5,5,5,5,5,5,30,30],"dependencies":["collections.abc","types","_codecs","_typeshed","abc","typing","typing_extensions","builtins","_collections_abc","_frozen_importlib"],"hash":"fc1bb845512e1d3e65dd68d3a4118b64c63c3a6e","id":"codecs","ignore_all":true,"interface_hash":"fdbbd2e445a3aca2dff4411135a927790b89d1a0","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/codecs.pyi","plugin_data":null,"size":12145,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/contextlib.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/contextlib.meta.json
```
{"data_mtime":1767891128,"dep_lines":[5,1,2,3,6,7,8,1,1,1],"dep_prios":[5,5,10,5,5,5,5,5,30,30],"dependencies":["collections.abc","abc","sys","_typeshed","types","typing","typing_extensions","builtins","_frozen_importlib","os"],"hash":"9ee0e3fda1c79c605a49fe44a06ac62a0cf6c555","id":"contextlib","ignore_all":true,"interface_hash":"418e3b5354f1b311b3a105168879662984ee8847","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/contextlib.pyi","plugin_data":null,"size":9313,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/dataclasses.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/dataclasses.meta.json
```
{"data_mtime":1767891128,"dep_lines":[6,1,2,3,4,5,7,8,1,1],"dep_prios":[5,10,10,5,5,5,5,5,30,30],"dependencies":["collections.abc","enum","sys","types","_typeshed","builtins","typing","typing_extensions","_frozen_importlib","abc"],"hash":"1e1bf1eb2d24f667845171b68771b4abda159e53","id":"dataclasses","ignore_all":true,"interface_hash":"91b86cae1b4522d53824fad463e29460c03cf85a","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/dataclasses.pyi","plugin_data":null,"size":10126,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/enum.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/enum.meta.json
```
{"data_mtime":1767891128,"dep_lines":[6,1,2,3,5,7,8,1,1],"dep_prios":[5,5,10,10,5,5,5,30,30],"dependencies":["collections.abc","_typeshed","sys","types","builtins","typing","typing_extensions","_frozen_importlib","abc"],"hash":"8d5c0cd8657b5fa3d633d49b0b7b2ea3df2083b0","id":"enum","ignore_all":true,"interface_hash":"1dd29b048e0b67ef917d1c353f69af8fe844107c","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/enum.pyi","plugin_data":null,"size":12074,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/genericpath.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/genericpath.meta.json
```
{"data_mtime":1767891128,"dep_lines":[4,1,2,3,5,6,1,1,1],"dep_prios":[5,10,10,5,5,5,5,30,30],"dependencies":["collections.abc","os","sys","_typeshed","typing","typing_extensions","builtins","_frozen_importlib","abc"],"hash":"a8607d6c88e26a860182960264fbb6690ff9ee58","id":"genericpath","ignore_all":true,"interface_hash":"110e39a376f73c60da654b31a36d318ea56a3f2e","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/genericpath.pyi","plugin_data":null,"size":2203,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/io.data.json
```
{".class":"MypyFile","_fullname":"io","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","BlockingIOError":{".class":"SymbolTableNode","cross_ref":"_io.BlockingIOError","kind":"Gdef"},"BufferedIOBase":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["_io._BufferedIOBase","io.IOBase"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"io.BufferedIOBase","name":"BufferedIOBase","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"io.BufferedIOBase","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"io","mro":["io.BufferedIOBase","_io._BufferedIOBase","io.IOBase","_io._IOBase","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"BufferedRWPair":{".class":"SymbolTableNode","cross_ref":"_io.BufferedRWPair","kind":"Gdef"},"BufferedRandom":{".class":"SymbolTableNode","cross_ref":"_io.BufferedRandom","kind":"Gdef"},"BufferedReader":{".class":"SymbolTableNode","cross_ref":"_io.BufferedReader","kind":"Gdef"},"BufferedWriter":{".class":"SymbolTableNode","cross_ref":"_io.BufferedWriter","kind":"Gdef"},"BytesIO":{".class":"SymbolTableNode","cross_ref":"_io.BytesIO","kind":"Gdef"},"DEFAULT_BUFFER_SIZE":{".class":"SymbolTableNode","cross_ref":"_io.DEFAULT_BUFFER_SIZE","kind":"Gdef"},"FileIO":{".class":"SymbolTableNode","cross_ref":"_io.FileIO","kind":"Gdef"},"Final":{".class":"SymbolTableNode","cross_ref":"typing.Final","kind":"Gdef","module_hidden":true,"module_public":false},"IOBase":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["_io._IOBase"],"dataclass_transform_spec":null,"declared_metaclass":"abc.ABCMeta","defn":{".class":"ClassDef","fullname":"io.IOBase","name":"IOBase","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"io.IOBase","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"io","mro":["io.IOBase","_io._IOBase","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"IncrementalNewlineDecoder":{".class":"SymbolTableNode","cross_ref":"_io.IncrementalNewlineDecoder","kind":"Gdef"},"RawIOBase":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["_io._RawIOBase","io.IOBase"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"io.RawIOBase","name":"RawIOBase","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"io.RawIOBase","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"io","mro":["io.RawIOBase","_io._RawIOBase","io.IOBase","_io._IOBase","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"SEEK_CUR":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","final_value":1,"flags":["is_final","is_ready","is_inferred","has_explicit_value"],"fullname":"io.SEEK_CUR","name":"SEEK_CUR","type":{".class":"Instance","args":[],"extra_attrs":null,"last_known_value":{".class":"LiteralType","fallback":"builtins.int","value":1},"type_ref":"builtins.int"}}},"SEEK_END":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","final_value":2,"flags":["is_final","is_ready","is_inferred","has_explicit_value"],"fullname":"io.SEEK_END","name":"SEEK_END","type":{".class":"Instance","args":[],"extra_attrs":null,"last_known_value":{".class":"LiteralType","fallback":"builtins.int","value":2},"type_ref":"builtins.int"}}},"SEEK_SET":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","final_value":0,"flags":["is_final","is_ready","is_inferred","has_explicit_value"],"fullname":"io.SEEK_SET","name":"SEEK_SET","type":{".class":"Instance","args":[],"extra_attrs":null,"last_known_value":{".class":"LiteralType","fallback":"builtins.int","value":0},"type_ref":"builtins.int"}}},"StringIO":{".class":"SymbolTableNode","cross_ref":"_io.StringIO","kind":"Gdef"},"TextIOBase":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["_io._TextIOBase","io.IOBase"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"io.TextIOBase","name":"TextIOBase","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"io.TextIOBase","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"io","mro":["io.TextIOBase","_io._TextIOBase","io.IOBase","_io._IOBase","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"TextIOWrapper":{".class":"SymbolTableNode","cross_ref":"_io.TextIOWrapper","kind":"Gdef"},"UnsupportedOperation":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.OSError","builtins.ValueError"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"io.UnsupportedOperation","name":"UnsupportedOperation","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"io.UnsupportedOperation","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"io","mro":["io.UnsupportedOperation","builtins.OSError","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"_BufferedIOBase":{".class":"SymbolTableNode","cross_ref":"_io._BufferedIOBase","kind":"Gdef","module_hidden":true,"module_public":false},"_IOBase":{".class":"SymbolTableNode","cross_ref":"_io._IOBase","kind":"Gdef","module_hidden":true,"module_public":false},"_RawIOBase":{".class":"SymbolTableNode","cross_ref":"_io._RawIOBase","kind":"Gdef","module_hidden":true,"module_public":false},"_TextIOBase":{".class":"SymbolTableNode","cross_ref":"_io._TextIOBase","kind":"Gdef","module_hidden":true,"module_public":false},"_WrappedBuffer":{".class":"SymbolTableNode","cross_ref":"_io._WrappedBuffer","kind":"Gdef","module_public":false},"__all__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"io.__all__","name":"__all__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"io.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"io.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"io.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"io.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"io.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"io.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"abc":{".class":"SymbolTableNode","cross_ref":"abc","kind":"Gdef","module_hidden":true,"module_public":false},"open":{".class":"SymbolTableNode","cross_ref":"_io.open","kind":"Gdef"},"open_code":{".class":"SymbolTableNode","cross_ref":"_io.open_code","kind":"Gdef"},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false},"text_encoding":{".class":"SymbolTableNode","cross_ref":"_io.text_encoding","kind":"Gdef"}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/io.pyi"}
```

.mypy_cache/3.12/io.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,3,23,1,1,1,1],"dep_prios":[10,10,5,5,5,30,30,30],"dependencies":["abc","sys","_io","typing","builtins","_frozen_importlib","_typeshed","types"],"hash":"ab68068e8f03aa8f1a21951a150e926cbb8af3c4","id":"io","ignore_all":true,"interface_hash":"f2a4ed95a7355fee22968cabb3fd4e92358c357a","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/io.pyi","plugin_data":null,"size":1494,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/pathlib.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/pathlib.meta.json
```
{"data_mtime":1767891128,"dep_lines":[14,1,2,3,15,16,18,19,1,1,1,1,1],"dep_prios":[5,10,5,5,5,5,5,5,5,30,30,30,30],"dependencies":["collections.abc","sys","types","_typeshed","io","os","typing","typing_extensions","builtins","_collections_abc","_frozen_importlib","_io","abc"],"hash":"b850216cb60fc148412e847e53b6a7c1cecf7698","id":"pathlib","ignore_all":true,"interface_hash":"6fd40b8be1ff483efb9e92d046685d146efbedb7","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/pathlib.pyi","plugin_data":null,"size":11886,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/posixpath.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/posixpath.meta.json
```
{"data_mtime":1767891128,"dep_lines":[3,1,2,4,20,21,22,1,1,1],"dep_prios":[5,10,5,5,5,5,5,5,30,30],"dependencies":["collections.abc","sys","_typeshed","genericpath","os","typing","typing_extensions","builtins","_frozen_importlib","abc"],"hash":"e8a6f0db23a10ee4e66ec15b39654e4de26d03e8","id":"posixpath","ignore_all":true,"interface_hash":"29fabbd38e99dbbce5d499b7a3fff98d1be13406","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/posixpath.pyi","plugin_data":null,"size":4811,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/re.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/re.meta.json
```
{"data_mtime":1767891128,"dep_lines":[6,1,2,3,4,5,7,8,11,1,1,1,1],"dep_prios":[5,10,10,10,10,5,5,5,5,5,30,30,30],"dependencies":["collections.abc","enum","sre_compile","sre_constants","sys","_typeshed","typing","typing_extensions","types","builtins","_collections_abc","_frozen_importlib","abc"],"hash":"0c2dfe7fe0c5030932745ea7e19113ab6ad5cd6a","id":"re","ignore_all":true,"interface_hash":"b3937fc378491b0dcc6c0fa4ac578b3d06a6aa46","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/re.pyi","plugin_data":null,"size":11818,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/resource.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/resource.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,3,1,1,1,1],"dep_prios":[10,5,5,5,30,30,30],"dependencies":["sys","_typeshed","typing","builtins","_frozen_importlib","abc","types"],"hash":"f1c5466c4351866284685531b61198656dc3906b","id":"resource","ignore_all":true,"interface_hash":"680163ba76a34705652fbd59a057fcc2e43f86be","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/resource.pyi","plugin_data":null,"size":2804,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/sre_compile.data.json
```
{".class":"MypyFile","_fullname":"sre_compile","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","ANY":{".class":"SymbolTableNode","cross_ref":"sre_constants.ANY","kind":"Gdef"},"ANY_ALL":{".class":"SymbolTableNode","cross_ref":"sre_constants.ANY_ALL","kind":"Gdef"},"ASSERT":{".class":"SymbolTableNode","cross_ref":"sre_constants.ASSERT","kind":"Gdef"},"ASSERT_NOT":{".class":"SymbolTableNode","cross_ref":"sre_constants.ASSERT_NOT","kind":"Gdef"},"AT":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT","kind":"Gdef"},"ATCODES":{".class":"SymbolTableNode","cross_ref":"sre_constants.ATCODES","kind":"Gdef"},"ATOMIC_GROUP":{".class":"SymbolTableNode","cross_ref":"sre_constants.ATOMIC_GROUP","kind":"Gdef"},"AT_BEGINNING":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_BEGINNING","kind":"Gdef"},"AT_BEGINNING_LINE":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_BEGINNING_LINE","kind":"Gdef"},"AT_BEGINNING_STRING":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_BEGINNING_STRING","kind":"Gdef"},"AT_BOUNDARY":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_BOUNDARY","kind":"Gdef"},"AT_END":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_END","kind":"Gdef"},"AT_END_LINE":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_END_LINE","kind":"Gdef"},"AT_END_STRING":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_END_STRING","kind":"Gdef"},"AT_LOCALE":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_LOCALE","kind":"Gdef"},"AT_LOC_BOUNDARY":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_LOC_BOUNDARY","kind":"Gdef"},"AT_LOC_NON_BOUNDARY":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_LOC_NON_BOUNDARY","kind":"Gdef"},"AT_MULTILINE":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_MULTILINE","kind":"Gdef"},"AT_NON_BOUNDARY":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_NON_BOUNDARY","kind":"Gdef"},"AT_UNICODE":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_UNICODE","kind":"Gdef"},"AT_UNI_BOUNDARY":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_UNI_BOUNDARY","kind":"Gdef"},"AT_UNI_NON_BOUNDARY":{".class":"SymbolTableNode","cross_ref":"sre_constants.AT_UNI_NON_BOUNDARY","kind":"Gdef"},"Any":{".class":"SymbolTableNode","cross_ref":"typing.Any","kind":"Gdef","module_hidden":true,"module_public":false},"BIGCHARSET":{".class":"SymbolTableNode","cross_ref":"sre_constants.BIGCHARSET","kind":"Gdef"},"BRANCH":{".class":"SymbolTableNode","cross_ref":"sre_constants.BRANCH","kind":"Gdef"},"CATEGORY":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY","kind":"Gdef"},"CATEGORY_DIGIT":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_DIGIT","kind":"Gdef"},"CATEGORY_LINEBREAK":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_LINEBREAK","kind":"Gdef"},"CATEGORY_LOC_NOT_WORD":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_LOC_NOT_WORD","kind":"Gdef"},"CATEGORY_LOC_WORD":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_LOC_WORD","kind":"Gdef"},"CATEGORY_NOT_DIGIT":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_NOT_DIGIT","kind":"Gdef"},"CATEGORY_NOT_LINEBREAK":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_NOT_LINEBREAK","kind":"Gdef"},"CATEGORY_NOT_SPACE":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_NOT_SPACE","kind":"Gdef"},"CATEGORY_NOT_WORD":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_NOT_WORD","kind":"Gdef"},"CATEGORY_SPACE":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_SPACE","kind":"Gdef"},"CATEGORY_UNI_DIGIT":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_UNI_DIGIT","kind":"Gdef"},"CATEGORY_UNI_LINEBREAK":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_UNI_LINEBREAK","kind":"Gdef"},"CATEGORY_UNI_NOT_DIGIT":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_UNI_NOT_DIGIT","kind":"Gdef"},"CATEGORY_UNI_NOT_LINEBREAK":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_UNI_NOT_LINEBREAK","kind":"Gdef"},"CATEGORY_UNI_NOT_SPACE":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_UNI_NOT_SPACE","kind":"Gdef"},"CATEGORY_UNI_NOT_WORD":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_UNI_NOT_WORD","kind":"Gdef"},"CATEGORY_UNI_SPACE":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_UNI_SPACE","kind":"Gdef"},"CATEGORY_UNI_WORD":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_UNI_WORD","kind":"Gdef"},"CATEGORY_WORD":{".class":"SymbolTableNode","cross_ref":"sre_constants.CATEGORY_WORD","kind":"Gdef"},"CHARSET":{".class":"SymbolTableNode","cross_ref":"sre_constants.CHARSET","kind":"Gdef"},"CHCODES":{".class":"SymbolTableNode","cross_ref":"sre_constants.CHCODES","kind":"Gdef"},"CH_LOCALE":{".class":"SymbolTableNode","cross_ref":"sre_constants.CH_LOCALE","kind":"Gdef"},"CH_UNICODE":{".class":"SymbolTableNode","cross_ref":"sre_constants.CH_UNICODE","kind":"Gdef"},"FAILURE":{".class":"SymbolTableNode","cross_ref":"sre_constants.FAILURE","kind":"Gdef"},"GROUPREF":{".class":"SymbolTableNode","cross_ref":"sre_constants.GROUPREF","kind":"Gdef"},"GROUPREF_EXISTS":{".class":"SymbolTableNode","cross_ref":"sre_constants.GROUPREF_EXISTS","kind":"Gdef"},"GROUPREF_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.GROUPREF_IGNORE","kind":"Gdef"},"GROUPREF_LOC_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.GROUPREF_LOC_IGNORE","kind":"Gdef"},"GROUPREF_UNI_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.GROUPREF_UNI_IGNORE","kind":"Gdef"},"IN":{".class":"SymbolTableNode","cross_ref":"sre_constants.IN","kind":"Gdef"},"INFO":{".class":"SymbolTableNode","cross_ref":"sre_constants.INFO","kind":"Gdef"},"IN_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.IN_IGNORE","kind":"Gdef"},"IN_LOC_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.IN_LOC_IGNORE","kind":"Gdef"},"IN_UNI_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.IN_UNI_IGNORE","kind":"Gdef"},"JUMP":{".class":"SymbolTableNode","cross_ref":"sre_constants.JUMP","kind":"Gdef"},"LITERAL":{".class":"SymbolTableNode","cross_ref":"sre_constants.LITERAL","kind":"Gdef"},"LITERAL_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.LITERAL_IGNORE","kind":"Gdef"},"LITERAL_LOC_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.LITERAL_LOC_IGNORE","kind":"Gdef"},"LITERAL_UNI_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.LITERAL_UNI_IGNORE","kind":"Gdef"},"MAGIC":{".class":"SymbolTableNode","cross_ref":"sre_constants.MAGIC","kind":"Gdef"},"MARK":{".class":"SymbolTableNode","cross_ref":"sre_constants.MARK","kind":"Gdef"},"MAXCODE":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sre_compile.MAXCODE","name":"MAXCODE","type":"builtins.int"}},"MAXGROUPS":{".class":"SymbolTableNode","cross_ref":"sre_constants.MAXGROUPS","kind":"Gdef"},"MAXREPEAT":{".class":"SymbolTableNode","cross_ref":"sre_constants.MAXREPEAT","kind":"Gdef"},"MAX_REPEAT":{".class":"SymbolTableNode","cross_ref":"sre_constants.MAX_REPEAT","kind":"Gdef"},"MAX_UNTIL":{".class":"SymbolTableNode","cross_ref":"sre_constants.MAX_UNTIL","kind":"Gdef"},"MIN_REPEAT":{".class":"SymbolTableNode","cross_ref":"sre_constants.MIN_REPEAT","kind":"Gdef"},"MIN_REPEAT_ONE":{".class":"SymbolTableNode","cross_ref":"sre_constants.MIN_REPEAT_ONE","kind":"Gdef"},"MIN_UNTIL":{".class":"SymbolTableNode","cross_ref":"sre_constants.MIN_UNTIL","kind":"Gdef"},"NEGATE":{".class":"SymbolTableNode","cross_ref":"sre_constants.NEGATE","kind":"Gdef"},"NOT_LITERAL":{".class":"SymbolTableNode","cross_ref":"sre_constants.NOT_LITERAL","kind":"Gdef"},"NOT_LITERAL_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.NOT_LITERAL_IGNORE","kind":"Gdef"},"NOT_LITERAL_LOC_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.NOT_LITERAL_LOC_IGNORE","kind":"Gdef"},"NOT_LITERAL_UNI_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.NOT_LITERAL_UNI_IGNORE","kind":"Gdef"},"OPCODES":{".class":"SymbolTableNode","cross_ref":"sre_constants.OPCODES","kind":"Gdef"},"OP_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.OP_IGNORE","kind":"Gdef"},"OP_LOCALE_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.OP_LOCALE_IGNORE","kind":"Gdef"},"OP_UNICODE_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.OP_UNICODE_IGNORE","kind":"Gdef"},"POSSESSIVE_REPEAT":{".class":"SymbolTableNode","cross_ref":"sre_constants.POSSESSIVE_REPEAT","kind":"Gdef"},"POSSESSIVE_REPEAT_ONE":{".class":"SymbolTableNode","cross_ref":"sre_constants.POSSESSIVE_REPEAT_ONE","kind":"Gdef"},"Pattern":{".class":"SymbolTableNode","cross_ref":"re.Pattern","kind":"Gdef","module_hidden":true,"module_public":false},"RANGE":{".class":"SymbolTableNode","cross_ref":"sre_constants.RANGE","kind":"Gdef"},"RANGE_UNI_IGNORE":{".class":"SymbolTableNode","cross_ref":"sre_constants.RANGE_UNI_IGNORE","kind":"Gdef"},"REPEAT":{".class":"SymbolTableNode","cross_ref":"sre_constants.REPEAT","kind":"Gdef"},"REPEAT_ONE":{".class":"SymbolTableNode","cross_ref":"sre_constants.REPEAT_ONE","kind":"Gdef"},"SRE_FLAG_ASCII":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_FLAG_ASCII","kind":"Gdef"},"SRE_FLAG_DEBUG":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_FLAG_DEBUG","kind":"Gdef"},"SRE_FLAG_DOTALL":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_FLAG_DOTALL","kind":"Gdef"},"SRE_FLAG_IGNORECASE":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_FLAG_IGNORECASE","kind":"Gdef"},"SRE_FLAG_LOCALE":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_FLAG_LOCALE","kind":"Gdef"},"SRE_FLAG_MULTILINE":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_FLAG_MULTILINE","kind":"Gdef"},"SRE_FLAG_TEMPLATE":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_FLAG_TEMPLATE","kind":"Gdef"},"SRE_FLAG_UNICODE":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_FLAG_UNICODE","kind":"Gdef"},"SRE_FLAG_VERBOSE":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_FLAG_VERBOSE","kind":"Gdef"},"SRE_INFO_CHARSET":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_INFO_CHARSET","kind":"Gdef"},"SRE_INFO_LITERAL":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_INFO_LITERAL","kind":"Gdef"},"SRE_INFO_PREFIX":{".class":"SymbolTableNode","cross_ref":"sre_constants.SRE_INFO_PREFIX","kind":"Gdef"},"SUBPATTERN":{".class":"SymbolTableNode","cross_ref":"sre_constants.SUBPATTERN","kind":"Gdef"},"SUCCESS":{".class":"SymbolTableNode","cross_ref":"sre_constants.SUCCESS","kind":"Gdef"},"SubPattern":{".class":"SymbolTableNode","cross_ref":"sre_parse.SubPattern","kind":"Gdef","module_hidden":true,"module_public":false},"_NamedIntConstant":{".class":"SymbolTableNode","cross_ref":"sre_constants._NamedIntConstant","kind":"Gdef","module_hidden":true,"module_public":false},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sre_compile.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sre_compile.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sre_compile.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sre_compile.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sre_compile.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sre_compile.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"compile":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1],"arg_names":["p","flags"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sre_compile.compile","name":"compile","type":{".class":"CallableType","arg_kinds":[0,1],"arg_names":["p","flags"],"arg_types":[{".class":"UnionType","items":["builtins.str","builtins.bytes","sre_parse.SubPattern"],"uses_pep604_syntax":true},"builtins.int"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"compile","ret_type":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2}],"extra_attrs":null,"type_ref":"re.Pattern"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"dis":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["code"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sre_compile.dis","name":"dis","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["code"],"arg_types":[{".class":"Instance","args":["sre_constants._NamedIntConstant"],"extra_attrs":null,"type_ref":"builtins.list"}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"dis","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"error":{".class":"SymbolTableNode","cross_ref":"re.error","kind":"Gdef"},"isstring":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["obj"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sre_compile.isstring","name":"isstring","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["obj"],"arg_types":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"isstring","ret_type":"builtins.bool","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/sre_compile.pyi"}
```

.mypy_cache/3.12/sre_compile.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,4,5,1,1,1],"dep_prios":[5,5,5,5,5,30,30],"dependencies":["re","sre_constants","sre_parse","typing","builtins","_frozen_importlib","abc"],"hash":"314498570402673c11acd537a3e6edacc0ed0b05","id":"sre_compile","ignore_all":true,"interface_hash":"6ae360fcfc473ad49a5acf1f29f700e6d9221a8a","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/sre_compile.pyi","plugin_data":null,"size":332,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/sre_constants.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/sre_constants.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,3,4,1,1,1,1,1],"dep_prios":[10,5,5,5,5,30,30,30,30],"dependencies":["sys","re","typing","typing_extensions","builtins","_frozen_importlib","_typeshed","abc","types"],"hash":"102fc8e029497208490afa8b349e1096ae3d13f0","id":"sre_constants","ignore_all":true,"interface_hash":"a85862109251d51e0df99641eb952760d89521f8","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/sre_constants.pyi","plugin_data":null,"size":3824,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/sre_parse.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/sre_parse.meta.json
```
{"data_mtime":1767891128,"dep_lines":[2,1,3,4,6,7,1,1,1,1,1],"dep_prios":[5,10,5,5,5,5,5,30,30,30,30],"dependencies":["collections.abc","sys","re","sre_constants","typing","typing_extensions","builtins","_frozen_importlib","_typeshed","abc","types"],"hash":"7e80d862e8bb8db9c0d0cde7d14c059a4dadf512","id":"sre_parse","ignore_all":true,"interface_hash":"24903b0328fdfde56a4ebd33d55ebd340e774eb9","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/sre_parse.pyi","plugin_data":null,"size":3790,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/subprocess.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/subprocess.meta.json
```
{"data_mtime":1767891128,"dep_lines":[3,1,2,4,5,6,1,1,1,1,1],"dep_prios":[5,10,5,5,5,5,5,30,30,30,30],"dependencies":["collections.abc","sys","_typeshed","types","typing","typing_extensions","builtins","_collections_abc","_frozen_importlib","abc","os"],"hash":"356127252f67b15f1bff9c9620ce387765741335","id":"subprocess","ignore_all":true,"interface_hash":"4b088b9c4c7b54b4e22dca1854303a8e8d361419","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/subprocess.pyi","plugin_data":null,"size":91357,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/test.data.json
```
{".class":"MypyFile","_fullname":"test","future_import_flags":[],"is_partial_stub_package":false,"is_stub":false,"names":{".class":"SymbolTable","__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"test.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"test.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"test.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"test.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"test.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"test.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}}},"path":"/home/user/projects/temp/oraclepack/docs/test.py"}
```

.mypy_cache/3.12/test.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,1,1,1],"dep_prios":[5,30,30,30],"dependencies":["builtins","_frozen_importlib","abc","typing"],"hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","id":"test","ignore_all":false,"interface_hash":"d7a601d9828617323d61d3f9ed3e690fe2152856","mtime":1767891124,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/projects/temp/oraclepack/docs/test.py","plugin_data":null,"size":0,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/types.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/types.meta.json
```
{"data_mtime":1767891128,"dep_lines":[3,4,17,1,2,20,21,663,1,1],"dep_prios":[5,5,5,10,5,5,5,5,30,30],"dependencies":["_typeshed.importlib","collections.abc","importlib.machinery","sys","_typeshed","typing","typing_extensions","builtins","_frozen_importlib","abc"],"hash":"ee4ded2c420ddf7b9278d6721987e28f3bd5c89d","id":"types","ignore_all":true,"interface_hash":"da681320cbef8ef523aaaf72c94025b17f6521e9","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/types.pyi","plugin_data":null,"size":22884,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/typing.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/typing.meta.json
```
{"data_mtime":1767891128,"dep_lines":[5,6,7,8,9,10,11,12,499,1,1],"dep_prios":[10,10,5,5,5,5,5,5,5,5,30],"dependencies":["collections","sys","typing_extensions","_collections_abc","_typeshed","abc","re","types","contextlib","builtins","_frozen_importlib"],"hash":"1850e3dd2e43ae76f25c8c4ac58581fb9f659a15","id":"typing","ignore_all":true,"interface_hash":"51f7ddd6d73e871d8cd779dad688f9deac6d02f5","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/typing.pyi","plugin_data":null,"size":37819,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/typing_extensions.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/typing_extensions.meta.json
```
{"data_mtime":1767891128,"dep_lines":[376,3,4,5,6,7,8,69,1,1],"dep_prios":[5,10,10,5,5,5,5,5,5,30],"dependencies":["collections.abc","abc","sys","typing","_collections_abc","_typeshed","contextlib","types","builtins","_frozen_importlib"],"hash":"8b004565f89c760413260f9c21b7d4add31f1bb7","id":"typing_extensions","ignore_all":true,"interface_hash":"313ba102aea969904af9ee75975fe896e1526675","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/typing_extensions.pyi","plugin_data":null,"size":17919,"suppressed":[],"version_id":"1.15.0"}
```

internal/pack/parser.go
```
package pack

import (
	"bufio"
	"fmt"
	"regexp"
	"strconv"
	"strings"

	"github.com/user/oraclepack/internal/errors"
)

var (
	bashFenceRegex = regexp.MustCompile("(?s)```bash\n(.*?)\n```")
	// Updated regex to support ")", " —", and " -" separators
	stepHeaderRegex = regexp.MustCompile(`^#\s*(\d{2})(?:\)|[\s]+[—-])`)
	roiRegex        = regexp.MustCompile(`ROI=(\d+(\.\d+)?)`)
	outDirRegex    = regexp.MustCompile(`(?m)^out_dir=["']?([^"'\s]+)["']?`)
	writeOutputRegex = regexp.MustCompile(`(?m)--write-output`)
)

// Parse reads a Markdown content and returns a Pack.
func Parse(content []byte) (*Pack, error) {
	match := bashFenceRegex.FindSubmatch(content)
	if match == nil || len(match) < 2 {
		return nil, fmt.Errorf("%w: no bash code block found", errors.ErrInvalidPack)
	}

	bashCode := string(match[1])
	pack := &Pack{}
	
	scanner := bufio.NewScanner(strings.NewReader(bashCode))
	var currentStep *Step
	var preludeLines []string
	var inSteps bool

	for scanner.Scan() {
		line := scanner.Text()
		headerMatch := stepHeaderRegex.FindStringSubmatch(strings.TrimSpace(line))

		if len(headerMatch) > 1 {
			inSteps = true
			if currentStep != nil {
				pack.Steps = append(pack.Steps, *currentStep)
			}
			num, _ := strconv.Atoi(headerMatch[1])
			
			// Extract ROI if present
			var roi float64
			cleanedLine := line
			roiMatch := roiRegex.FindStringSubmatch(line)
			if len(roiMatch) > 1 {
				val, err := strconv.ParseFloat(roiMatch[1], 64)
				if err == nil {
					roi = val
					// Remove ROI tag from display title, but keep original line intact?
					// The task says "strip from Step.Title". Step struct currently has `OriginalLine`.
					// I'll assume OriginalLine is what is displayed, or I should add a Title field.
					// Looking at Step struct: ID, Number, Code, OriginalLine.
					// I'll remove it from OriginalLine for now or add a Title field.
					// The existing TUI uses OriginalLine as description. 
					// Let's clean OriginalLine for display purposes or add a dedicated Title field.
					// Adding a dedicated Title field seems cleaner but requires struct change.
					// For now, I'll strip it from OriginalLine to match the prompt requirement "cleaner UI display".
					cleanedLine = strings.Replace(cleanedLine, roiMatch[0], "", 1)
					cleanedLine = strings.TrimSpace(cleanedLine)
					// Fix any double spaces or trailing separators if needed, but simple replace is a good start.
				}
			}

			currentStep = &Step{
				ID:           headerMatch[1],
				Number:       num,
				OriginalLine: cleanedLine,
				ROI:          roi,
			}
			continue
		}

		if inSteps {
			currentStep.Code += line + "\n"
		} else {
			preludeLines = append(preludeLines, line)
		}
	}

	if currentStep != nil {
		pack.Steps = append(pack.Steps, *currentStep)
	}

	pack.Prelude.Code = strings.Join(preludeLines, "\n")
	pack.DeriveMetadata()

	return pack, nil
}

// DeriveMetadata extracts configuration from the prelude.
func (p *Pack) DeriveMetadata() {
	outDirMatch := outDirRegex.FindStringSubmatch(p.Prelude.Code)
	if len(outDirMatch) > 1 {
		p.OutDir = outDirMatch[1]
	}

	if writeOutputRegex.MatchString(p.Prelude.Code) {
		p.WriteOutput = true
	}
}

// Validate checks if the pack follows all rules.
func (p *Pack) Validate() error {
	if len(p.Steps) == 0 {
		return fmt.Errorf("%w: at least one step is required", errors.ErrInvalidPack)
	}

	seen := make(map[int]bool)
	for i, step := range p.Steps {
		if step.Number <= 0 {
			return fmt.Errorf("%w: invalid step number %d", errors.ErrInvalidPack, step.Number)
		}
		if seen[step.Number] {
			return fmt.Errorf("%w: duplicate step number %d", errors.ErrInvalidPack, step.Number)
		}
		seen[step.Number] = true

		// Optional: Ensure sequential starting from 1
		if step.Number != i+1 {
			return fmt.Errorf("%w: steps must be sequential starting from 1 (expected %d, got %d)", errors.ErrInvalidPack, i+1, step.Number)
		}
	}

	return nil
}
```

internal/pack/parser_test.go
```
package pack

import (
	"strings"
	"testing"
)

func TestParse(t *testing.T) {
	content := []byte(`
# My Pack
Some description.

` + "```" + `bash
out_dir="dist"
--write-output

# 01)
echo "hello"

# 02)
echo "world"
` + "```" + `
`)

	p, err := Parse(content)
	if err != nil {
		t.Fatalf("Parse failed: %v", err)
	}

	if p.OutDir != "dist" {
		t.Errorf("expected OutDir dist, got %s", p.OutDir)
	}

	if !p.WriteOutput {
		t.Errorf("expected WriteOutput true, got false")
	}

	if len(p.Steps) != 2 {
		t.Errorf("expected 2 steps, got %d", len(p.Steps))
	}

	if p.Steps[0].ID != "01" || p.Steps[0].Number != 1 {
		t.Errorf("step 1 mismatch: %+v", p.Steps[0])
	}

	if err := p.Validate(); err != nil {
		t.Errorf("Validate failed: %v", err)
	}
}

func TestParseVariants(t *testing.T) {
	tests := []struct {
		name    string
		content string
	}{
		{
			"em dash",
			`
` + "```" + `bash
# 01 — ROI=...
echo "step 1"
` + "```" + `
`,
		},
		{
			"hyphen",
			`
` + "```" + `bash
# 01 - ROI=...
echo "step 1"
` + "```" + `
`,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			p, err := Parse([]byte(tt.content))
			if err != nil {
				t.Fatalf("Parse failed: %v", err)
			}
			if len(p.Steps) != 1 {
				t.Errorf("expected 1 step, got %d", len(p.Steps))
			}
		})
	}
}

func TestParseROI(t *testing.T) {
	content := []byte(`
` + "```" + `bash
# 01) ROI=4.5 clean me
echo "high value"

# 02) ROI=0.5
echo "low value"

# 03) No ROI
echo "default"
` + "```" + `
`)

	p, err := Parse(content)
	if err != nil {
		t.Fatalf("Parse failed: %v", err)
	}

	if len(p.Steps) != 3 {
		t.Fatalf("expected 3 steps, got %d", len(p.Steps))
	}

	if p.Steps[0].ROI != 4.5 {
		t.Errorf("step 1 ROI mismatch: expected 4.5, got %f", p.Steps[0].ROI)
	}
	if strings.Contains(p.Steps[0].OriginalLine, "ROI=4.5") {
		t.Errorf("step 1 title was not cleaned: %q", p.Steps[0].OriginalLine)
	}

	if p.Steps[1].ROI != 0.5 {
		t.Errorf("step 2 ROI mismatch: expected 0.5, got %f", p.Steps[1].ROI)
	}

	if p.Steps[2].ROI != 0.0 {
		t.Errorf("step 3 ROI mismatch: expected 0.0, got %f", p.Steps[2].ROI)
	}
}

func TestValidateErrors(t *testing.T) {
	tests := []struct {
		name    string
		pack    *Pack
		wantErr string
	}{
		{
			"no steps",
			&Pack{},
			"at least one step is required",
		},
		{
			"duplicate steps",
			&Pack{
				Steps: []Step{
					{Number: 1, ID: "01"},
					{Number: 1, ID: "01"},
				},
			},
			"duplicate step number 1",
		},
		{
			"non-sequential",
			&Pack{
				Steps: []Step{
					{Number: 1, ID: "01"},
					{Number: 3, ID: "03"},
				},
			},
			"steps must be sequential starting from 1",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			err := tt.pack.Validate()
			if err == nil {
				t.Error("expected error, got nil")
			} else if !contains(err.Error(), tt.wantErr) {
				t.Errorf("expected error containing %q, got %q", tt.wantErr, err.Error())
			}
		})
	}
}

func contains(s, substr string) bool {
	return len(s) >= len(substr) && (s == substr || (len(substr) > 0 && (s[:len(substr)] == substr || contains(s[1:], substr))))
}
```

internal/pack/types.go
```
package pack

// Pack represents a parsed oracle pack.
type Pack struct {
	Prelude     Prelude
	Steps       []Step
	Source      string
	OutDir      string
	WriteOutput bool
}

// Prelude contains the shell code that runs before any steps.
type Prelude struct {
	Code string
}

// Step represents an individual executable step within the pack.
type Step struct {
	ID           string  // e.g., "01"
	Number       int     // e.g., 1
	Code         string  // The bash code
	OriginalLine string  // The header line, e.g., "# 01)"
	ROI          float64 // Return on Investment value extracted from header
}
```

internal/render/render.go
```
package render

import (
	"sync"

	"github.com/charmbracelet/glamour"
	"github.com/user/oraclepack/internal/pack"
)

const (
	DefaultStyle = "dark"
	DefaultWidth = 80
)

type rendererKey struct {
	width int
	style string
}

var (
	rendererMu    sync.Mutex
	rendererCache = map[rendererKey]*glamour.TermRenderer{}
)

// RenderMarkdown renders markdown text as ANSI-styled text.
func RenderMarkdown(text string, width int, style string) (string, error) {
	if width <= 0 {
		width = DefaultWidth
	}
	if style == "" {
		style = DefaultStyle
	}

	r, err := rendererFor(width, style)
	if err != nil {
		return "", err
	}

	return r.Render(text)
}

// RenderStepCode renders a step's code block for preview.
func RenderStepCode(s pack.Step, width int, style string) (string, error) {
	md := "```bash\n" + s.Code + "\n```"
	return RenderMarkdown(md, width, style)
}

func rendererFor(width int, style string) (*glamour.TermRenderer, error) {
	key := rendererKey{width: width, style: style}

	rendererMu.Lock()
	r := rendererCache[key]
	rendererMu.Unlock()
	if r != nil {
		return r, nil
	}

	opts := []glamour.TermRendererOption{glamour.WithWordWrap(width)}
	if style == "auto" {
		opts = append(opts, glamour.WithAutoStyle())
	} else {
		opts = append(opts, glamour.WithStandardStyle(style))
	}

	r, err := glamour.NewTermRenderer(opts...)
	if err != nil {
		return nil, err
	}

	rendererMu.Lock()
	rendererCache[key] = r
	rendererMu.Unlock()
	return r, nil
}
```

internal/render/render_test.go
```
package render

import (
	"strings"
	"testing"
)

func TestRenderMarkdown(t *testing.T) {
	text := "# Hello\n**bold**"
	got, err := RenderMarkdown(text, 40, DefaultStyle)
	if err != nil {
		t.Fatalf("RenderMarkdown failed: %v", err)
	}

	// ANSI escape codes start with \x1b[
	if !strings.Contains(got, "\x1b[") {
		t.Errorf("expected ANSI codes in output, got: %q", got)
	}
}
```

internal/report/generate.go
```
package report

import (
	"time"

	"github.com/user/oraclepack/internal/state"
)

// GenerateReport creates a ReportV1 from a RunState.
func GenerateReport(s *state.RunState, packName string) *ReportV1 {
	report := &ReportV1{
		PackInfo: PackInfo{
			Name: packName,
			Hash: s.PackHash,
		},
		GeneratedAt: time.Now(),
		Steps:       []StepReport{},
	}

	var totalDuration time.Duration
	success, failure, skipped := 0, 0, 0

	for id, status := range s.StepStatuses {
		duration := status.EndedAt.Sub(status.StartedAt)
		if status.EndedAt.IsZero() || status.StartedAt.IsZero() {
			duration = 0
		}

		totalDuration += duration

		sr := StepReport{
			ID:         id,
			Status:     string(status.Status),
			ExitCode:   status.ExitCode,
			Duration:   duration,
			DurationMs: duration.Milliseconds(),
			Error:      status.Error,
		}
		report.Steps = append(report.Steps, sr)

		switch status.Status {
		case state.StatusSuccess:
			success++
		case state.StatusFailed:
			failure++
		case state.StatusSkipped:
			skipped++
		}
	}

	report.Summary = Summary{
		TotalSteps:      len(s.StepStatuses),
		SuccessCount:    success,
		FailureCount:    failure,
		SkippedCount:    skipped,
		TotalDuration:   totalDuration,
		TotalDurationMs: totalDuration.Milliseconds(),
	}

	if len(s.Warnings) > 0 {
		report.Warnings = make([]Warning, 0, len(s.Warnings))
		for _, w := range s.Warnings {
			report.Warnings = append(report.Warnings, Warning{
				Scope:   w.Scope,
				StepID:  w.StepID,
				Line:    w.Line,
				Token:   w.Token,
				Message: w.Message,
			})
		}
	}

	return report
}
```

internal/report/report_test.go
```
package report

import (
	"testing"
	"time"

	"github.com/user/oraclepack/internal/state"
)

func TestGenerateReport(t *testing.T) {
	s := &state.RunState{
		PackHash: "hash123",
		StepStatuses: map[string]state.StepStatus{
			"01": {
				Status:    state.StatusSuccess,
				StartedAt: time.Now().Add(-1 * time.Second),
				EndedAt:   time.Now(),
			},
		},
	}

	rep := GenerateReport(s, "my-pack")

	if rep.PackInfo.Name != "my-pack" {
		t.Errorf("expected name my-pack, got %s", rep.PackInfo.Name)
	}

	if rep.Summary.TotalSteps != 1 {
		t.Errorf("expected 1 total step, got %d", rep.Summary.TotalSteps)
	}

	if rep.Summary.SuccessCount != 1 {
		t.Errorf("expected 1 success, got %d", rep.Summary.SuccessCount)
	}
}
```

internal/report/types.go
```
package report

import (
	"time"
)

// ReportV1 represents the final machine-readable summary.
type ReportV1 struct {
	Summary     Summary      `json:"summary"`
	PackInfo    PackInfo     `json:"pack_info"`
	Steps       []StepReport `json:"steps"`
	Warnings    []Warning    `json:"warnings,omitempty"`
	GeneratedAt time.Time    `json:"generated_at"`
}

type Summary struct {
	TotalSteps      int           `json:"total_steps"`
	SuccessCount    int           `json:"success_count"`
	FailureCount    int           `json:"failure_count"`
	SkippedCount    int           `json:"skipped_count"`
	TotalDuration   time.Duration `json:"total_duration"`
	TotalDurationMs int64         `json:"total_duration_ms"`
}

type PackInfo struct {
	Name string `json:"name"`
	Hash string `json:"hash"`
}

type StepReport struct {
	ID         string        `json:"id"`
	Status     string        `json:"status"`
	ExitCode   int           `json:"exit_code"`
	Duration   time.Duration `json:"duration"`
	DurationMs int64         `json:"duration_ms"`
	Error      string        `json:"error,omitempty"`
}

// Warning captures non-fatal execution notes surfaced during a run.
type Warning struct {
	Scope   string `json:"scope"`
	StepID  string `json:"step_id,omitempty"`
	Line    int    `json:"line"`
	Token   string `json:"token"`
	Message string `json:"message"`
}
```

internal/state/persist.go
```
package state

import (
	"encoding/json"
	"fmt"
	"os"
)

// SaveStateAtomic saves the state to a file atomically.
func SaveStateAtomic(path string, state *RunState) error {
	data, err := json.MarshalIndent(state, "", "  ")
	if err != nil {
		return fmt.Errorf("marshal state: %w", err)
	}

	tempPath := path + ".tmp"
	if err := os.WriteFile(tempPath, data, 0644); err != nil {
		return fmt.Errorf("write temp file: %w", err)
	}

	if err := os.Rename(tempPath, path); err != nil {
		os.Remove(tempPath)
		return fmt.Errorf("rename temp file: %w", err)
	}

	return nil
}

// LoadState loads the state from a file.
func LoadState(path string) (*RunState, error) {
	data, err := os.ReadFile(path)
	if err != nil {
		if os.IsNotExist(err) {
			return nil, fmt.Errorf("state file not found: %w", err)
		}
		return nil, fmt.Errorf("read state file: %w", err)
	}

	var state RunState
	if err := json.Unmarshal(data, &state); err != nil {
		return nil, fmt.Errorf("unmarshal state: %w", err)
	}

	return &state, nil
}
```

internal/state/state_test.go
```
package state

import (
	"os"
	"testing"
)

func TestStatePersistence(t *testing.T) {
	tmpFile := "test_state.json"
	defer os.Remove(tmpFile)

	s := &RunState{
		SchemaVersion: 1,
		PackHash:      "abc",
		StepStatuses: map[string]StepStatus{
			"01": {Status: StatusSuccess, ExitCode: 0},
		},
	}

	if err := SaveStateAtomic(tmpFile, s); err != nil {
		t.Fatalf("SaveStateAtomic failed: %v", err)
	}

	loaded, err := LoadState(tmpFile)
	if err != nil {
		t.Fatalf("LoadState failed: %v", err)
	}

	if loaded.PackHash != s.PackHash {
		t.Errorf("expected hash %s, got %s", s.PackHash, loaded.PackHash)
	}

	if loaded.StepStatuses["01"].Status != StatusSuccess {
		t.Errorf("expected status success, got %s", loaded.StepStatuses["01"].Status)
	}
}
```

internal/state/types.go
```
package state

import (
	"time"
)

type Status string

const (
	StatusPending Status = "pending"
	StatusRunning Status = "running"
	StatusSuccess Status = "success"
	StatusFailed  Status = "failed"
	StatusSkipped Status = "skipped"
)

// RunState tracks the execution progress of an oracle pack.
type RunState struct {
	SchemaVersion int                   `json:"schema_version"`
	PackHash      string                `json:"pack_hash"`
	StartTime     time.Time             `json:"start_time"`
	StepStatuses  map[string]StepStatus `json:"step_statuses"`
	ROIThreshold  float64               `json:"roi_threshold,omitempty"`
	ROIMode       string                `json:"roi_mode,omitempty"`
	Warnings      []Warning             `json:"warnings,omitempty"`
}

// StepStatus holds the outcome of an individual step.
type StepStatus struct {
	Status    Status    `json:"status"`
	ExitCode  int       `json:"exit_code"`
	StartedAt time.Time `json:"started_at"`
	EndedAt   time.Time `json:"ended_at"`
	Error     string    `json:"error,omitempty"`
}

// Warning captures a non-fatal execution note (e.g., sanitized labels).
type Warning struct {
	Scope   string `json:"scope"`
	StepID  string `json:"step_id,omitempty"`
	Line    int    `json:"line"`
	Token   string `json:"token"`
	Message string `json:"message"`
}
```

internal/tui/clipboard.go
```
package tui

import (
	"fmt"
	"os"
	"os/exec"
	"runtime"
	"strings"
)

func copyToClipboard(content string) error {
	var cmd *exec.Cmd
	switch runtime.GOOS {
	case "darwin":
		cmd = exec.Command("pbcopy")
	case "linux":
		if _, err := exec.LookPath("wl-copy"); err == nil {
			cmd = exec.Command("wl-copy")
		} else if _, err := exec.LookPath("xclip"); err == nil {
			cmd = exec.Command("xclip", "-selection", "clipboard")
		} else if _, err := exec.LookPath("xsel"); err == nil {
			cmd = exec.Command("xsel", "--clipboard", "--input")
		} else {
			return err
		}
	case "windows":
		cmd = exec.Command("cmd", "/c", "clip")
	default:
		return exec.ErrNotFound
	}

	cmd.Stdin = strings.NewReader(content)
	return cmd.Run()
}

func writeClipboardFallback(content string) (string, error) {
	file, err := os.CreateTemp("", "oraclepack-step-*.txt")
	if err != nil {
		return "", fmt.Errorf("create temp file: %w", err)
	}
	defer file.Close()
	if _, err := file.WriteString(content); err != nil {
		return "", fmt.Errorf("write temp file: %w", err)
	}
	return file.Name(), nil
}
```

internal/tui/filter_test.go
```
package tui

import (
	"os"
	"path/filepath"
	"testing"

	tea "github.com/charmbracelet/bubbletea"
	"github.com/user/oraclepack/internal/exec"
	"github.com/user/oraclepack/internal/pack"
	"github.com/user/oraclepack/internal/state"
)

func TestFilterLogic(t *testing.T) {
	// Setup pack with steps having different ROI
	p := &pack.Pack{
		Steps: []pack.Step{
			{ID: "01", ROI: 1.0, OriginalLine: "Step 1"},
			{ID: "02", ROI: 5.0, OriginalLine: "Step 2"},
			{ID: "03", ROI: 10.0, OriginalLine: "Step 3"},
		},
	}
	r := exec.NewRunner(exec.RunnerOptions{})
	s := &state.RunState{}

	// Initialize model with no filter (threshold 0)
	m := NewModel(p, r, s, "", 0, "over", false)

	if len(m.list.Items()) != 3 {
		t.Fatalf("expected 3 items initially, got %d", len(m.list.Items()))
	}

	// Apply filter: ROI >= 5.0
	m.roiThreshold = 5.0
	m.roiMode = "over"
	m = m.refreshList()

	if len(m.list.Items()) != 2 {
		t.Errorf("expected 2 items after filtering >= 5.0, got %d", len(m.list.Items()))
	}

	// Verify items are 02 and 03
	items := m.list.Items()
	if items[0].(item).id != "02" {
		t.Errorf("expected first item to be 02, got %s", items[0].(item).id)
	}
	if items[1].(item).id != "03" {
		t.Errorf("expected second item to be 03, got %s", items[1].(item).id)
	}

	// Apply filter: ROI < 5.0 ("under")
	m.roiThreshold = 5.0
	m.roiMode = "under"
	m = m.refreshList()

	if len(m.list.Items()) != 1 {
		t.Errorf("expected 1 item after filtering < 5.0, got %d", len(m.list.Items()))
	}
	if m.list.Items()[0].(item).id != "01" {
		t.Errorf("expected item to be 01, got %s", m.list.Items()[0].(item).id)
	}
}

func TestROIModeTogglePersists(t *testing.T) {
	dir := t.TempDir()
	statePath := filepath.Join(dir, "state.json")
	p := &pack.Pack{
		Steps: []pack.Step{
			{ID: "01", ROI: 1.0, OriginalLine: "Step 1"},
		},
	}
	r := exec.NewRunner(exec.RunnerOptions{})
	s := &state.RunState{SchemaVersion: 1}

	m := NewModel(p, r, s, statePath, 0, "over", false)

	updated, _ := m.Update(tea.KeyMsg{Type: tea.KeyRunes, Runes: []rune("m")})
	m2 := updated.(Model)
	if m2.roiMode != "under" {
		t.Fatalf("expected roiMode to toggle to under, got %s", m2.roiMode)
	}

	loaded, err := state.LoadState(statePath)
	if err != nil {
		t.Fatalf("failed to load state: %v", err)
	}
	if loaded.ROIMode != "under" {
		t.Fatalf("expected persisted roiMode under, got %s", loaded.ROIMode)
	}

	if err := os.Remove(statePath); err != nil {
		t.Fatalf("failed to cleanup state file: %v", err)
	}
}
```

internal/tui/overrides_confirm.go
```
package tui

import (
	"fmt"
	"sort"
	"strings"

	"github.com/user/oraclepack/internal/exec"
	"github.com/user/oraclepack/internal/overrides"
)

type ValidationResultMsg struct {
	Errors []exec.ValidationError
	Err    error
}

type OverridesConfirmModel struct {
	validating bool
	errMsg     string
	errors     []exec.ValidationError
}

func (m OverridesConfirmModel) View(over overrides.RuntimeOverrides, baseline []string) string {
	added := strings.Join(over.AddedFlags, ", ")
	if added == "" {
		added = "(none)"
	}
	removed := strings.Join(over.RemovedFlags, ", ")
	if removed == "" {
		removed = "(none)"
	}
	targeted := len(over.ApplyToSteps)
	targetList := formatTargetList(over.ApplyToSteps, 5)
	effective := effectiveFlagsSummary(over, baseline)
	lines := []string{
		"Summary:",
		fmt.Sprintf("Added flags: %s", added),
		fmt.Sprintf("Removed flags: %s", removed),
		fmt.Sprintf("Targeted steps: %d%s", targeted, targetList),
		fmt.Sprintf("Effective flags: %s", effective),
		"",
		"[Enter] Validate  [Esc] Cancel",
	}

	if m.validating {
		lines = append(lines, "", "Validating overrides...")
	}
	if m.errMsg != "" {
		lines = append(lines, "", "Validation failed:", m.errMsg)
	}
	if len(m.errors) > 0 {
		lines = append(lines, "", fmt.Sprintf("Validation errors (%d):", len(m.errors)))
		lines = append(lines, formatValidationErrors(m.errors, 6)...)
	}

	return strings.Join(lines, "\n")
}

func formatTargetList(targets map[string]bool, limit int) string {
	if len(targets) == 0 || limit <= 0 {
		return ""
	}
	ids := make([]string, 0, len(targets))
	for id := range targets {
		ids = append(ids, id)
	}
	sort.Strings(ids)
	if len(ids) <= limit {
		return fmt.Sprintf(" (%s)", strings.Join(ids, ", "))
	}
	return fmt.Sprintf(" (%s, +%d more)", strings.Join(ids[:limit], ", "), len(ids)-limit)
}

func effectiveFlagsSummary(over overrides.RuntimeOverrides, baseline []string) string {
	if len(over.ApplyToSteps) == 0 {
		return "(no steps targeted)"
	}
	var first string
	for id := range over.ApplyToSteps {
		first = id
		break
	}
	flags := over.EffectiveFlags(first, baseline)
	if len(flags) == 0 {
		return "(none)"
	}
	return strings.Join(flags, " ")
}

func formatValidationErrors(errors []exec.ValidationError, limit int) []string {
	if limit <= 0 {
		return nil
	}
	lines := []string{}
	for i, err := range errors {
		if i >= limit {
			lines = append(lines, fmt.Sprintf("- (+%d more)", len(errors)-limit))
			break
		}
		msg := strings.TrimSpace(err.ErrorMessage)
		if msg == "" {
			msg = "(no error message)"
		}
		lines = append(lines, fmt.Sprintf("- Step %s: %s", err.StepID, firstLine(msg)))
	}
	return lines
}

func firstLine(msg string) string {
	if idx := strings.IndexByte(msg, '\n'); idx != -1 {
		return msg[:idx]
	}
	return msg
}
```

internal/tui/overrides_flags.go
```
package tui

import (
	"fmt"
	"io"

	"github.com/charmbracelet/bubbles/list"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
)

type FlagItem struct {
	Flag       string
	Desc       string
	IsBaseline bool
	Selected   bool
}

func (i FlagItem) Title() string       { return i.Flag }
func (i FlagItem) Description() string { return i.Desc }
func (i FlagItem) FilterValue() string { return i.Flag }

type FlagsPickerModel struct {
	list list.Model
}

func NewFlagsPickerModel(baseline []string) FlagsPickerModel {
	baselineSet := make(map[string]bool, len(baseline))
	for _, f := range baseline {
		baselineSet[f] = true
	}

	curated := []FlagItem{
		{Flag: "--files-report", Desc: "Show per-file token usage"},
		{Flag: "--render", Desc: "Print assembled markdown bundle"},
		{Flag: "--render-plain", Desc: "Render markdown without ANSI"},
		{Flag: "--copy", Desc: "Copy assembled markdown bundle"},
		{Flag: "--wait", Desc: "Wait for background API runs"},
	}

	items := make([]list.Item, 0, len(curated))
	for _, c := range curated {
		c.IsBaseline = baselineSet[c.Flag]
		if c.IsBaseline {
			c.Selected = true
		}
		items = append(items, c)
	}

	delegate := newFlagsDelegate()
	l := list.New(items, delegate, 0, 0)
	l.Title = "Oracle Flags"
	l.SetFilteringEnabled(true)

	return FlagsPickerModel{list: l}
}

func (m FlagsPickerModel) Init() tea.Cmd {
	return nil
}

func (m FlagsPickerModel) Update(msg tea.Msg) (FlagsPickerModel, tea.Cmd) {
	switch msg := msg.(type) {
	case tea.KeyMsg:
		if msg.String() == " " {
			idx := m.list.Index()
			item, ok := m.list.SelectedItem().(FlagItem)
			if ok && !item.IsBaseline {
				item.Selected = !item.Selected
				_ = m.list.SetItem(idx, item)
			}
		}
	}

	var cmd tea.Cmd
	m.list, cmd = m.list.Update(msg)
	return m, cmd
}

func (m *FlagsPickerModel) SetSize(width, height int) {
	m.list.SetSize(width, height)
}

func (m FlagsPickerModel) View() string {
	return m.list.View()
}

func (m FlagsPickerModel) SelectedFlags() []string {
	var flags []string
	for _, item := range m.list.Items() {
		if fi, ok := item.(FlagItem); ok && fi.Selected && !fi.IsBaseline {
			flags = append(flags, fi.Flag)
		}
	}
	return flags
}

type flagsDelegate struct {
	list.DefaultDelegate
}

func newFlagsDelegate() flagsDelegate {
	d := list.NewDefaultDelegate()
	return flagsDelegate{DefaultDelegate: d}
}

func (d flagsDelegate) Render(w io.Writer, m list.Model, index int, item list.Item) {
	fi, ok := item.(FlagItem)
	if !ok {
		d.DefaultDelegate.Render(w, m, index, item)
		return
	}

	checked := fi.Selected || fi.IsBaseline
	marker := "[ ]"
	if checked {
		marker = "[x]"
	}
	if fi.IsBaseline {
		marker = "[*]"
	}

	label := fi.Flag
	if fi.Desc != "" {
		label = fmt.Sprintf("%s - %s", fi.Flag, fi.Desc)
	}
	if fi.IsBaseline {
		label = label + " (base)"
	}

	line := fmt.Sprintf("%s %s", marker, label)
	if index == m.Index() {
		line = d.Styles.SelectedTitle.Render(line)
	} else {
		line = d.Styles.NormalTitle.Render(line)
	}
	if fi.IsBaseline {
		line = lipgloss.NewStyle().Faint(true).Render(line)
	}

	fmt.Fprintln(w, line)
}
```

internal/tui/overrides_flow.go
```
package tui

import (
	"context"
	"fmt"

	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/user/oraclepack/internal/exec"
	"github.com/user/oraclepack/internal/overrides"
	"github.com/user/oraclepack/internal/pack"
)

type OverridesStep int

const (
	OverridesFlags OverridesStep = iota
	OverridesSteps
	OverridesConfirm
)

type OverridesStartedMsg struct{}

type OverridesAppliedMsg struct {
	Overrides overrides.RuntimeOverrides
}

type OverridesCancelledMsg struct{}

type OverridesFlowModel struct {
	step    OverridesStep
	flags   FlagsPickerModel
	steps   StepsPickerModel
	confirm OverridesConfirmModel

	packSteps        []pack.Step
	baseline         []string
	runnerOpts       exec.RunnerOptions
	pendingOverrides overrides.RuntimeOverrides
}

func NewOverridesFlowModel(steps []pack.Step, baseline []string, opts exec.RunnerOptions) OverridesFlowModel {
	return OverridesFlowModel{
		step:       OverridesFlags,
		flags:      NewFlagsPickerModel(nil),
		steps:      NewStepsPickerModel(steps),
		confirm:    OverridesConfirmModel{},
		packSteps:  steps,
		baseline:   exec.ApplyChatGPTURL(baseline, opts.ChatGPTURL),
		runnerOpts: opts,
	}
}

func (m OverridesFlowModel) Init() tea.Cmd {
	return nil
}

func (m OverridesFlowModel) Update(msg tea.Msg) (OverridesFlowModel, tea.Cmd) {
	var cmd tea.Cmd
	if m.step == OverridesFlags {
		m.flags, cmd = m.flags.Update(msg)
	}
	if m.step == OverridesSteps {
		m.steps, cmd = m.steps.Update(msg)
	}
	if m.step == OverridesConfirm {
		switch v := msg.(type) {
		case ValidationResultMsg:
			m.confirm.validating = false
			m.confirm.errors = v.Errors
			if v.Err != nil {
				m.confirm.errMsg = v.Err.Error()
				return m, nil
			}
			if len(v.Errors) > 0 {
				m.confirm.errMsg = fmt.Sprintf("%d validation errors detected.", len(v.Errors))
				return m, nil
			}
			return m, func() tea.Msg { return OverridesAppliedMsg{Overrides: m.pendingOverrides} }
		}
	}

	switch msg := msg.(type) {
	case tea.KeyMsg:
		switch msg.String() {
		case "esc":
			return m, func() tea.Msg { return OverridesCancelledMsg{} }
		case "shift+tab", "backspace":
			if m.step > OverridesFlags {
				m.step--
			}
		case "enter", "tab":
			if m.step == OverridesConfirm {
				if m.confirm.validating {
					return m, nil
				}
				m.pendingOverrides = m.currentOverrides()
				m.confirm.validating = true
				m.confirm.errMsg = ""
				m.confirm.errors = nil
				return m, m.validateCmd(m.pendingOverrides)
			}
			m.step++
		}
	}

	return m, cmd
}

func (m OverridesFlowModel) View(width, height int) string {
	title := lipgloss.NewStyle().Bold(true).Render("Overrides Wizard")
	step := fmt.Sprintf("Step %d/3", int(m.step)+1)
	body := fmt.Sprintf("Current step: %s\n\n[Enter] Next  [Esc] Cancel", overridesStepName(m.step))

	var content string
	if m.step == OverridesFlags {
		m.flags.SetSize(width-4, height-8)
		content = lipgloss.JoinVertical(lipgloss.Left,
			title,
			step,
			"",
			m.flags.View(),
			"",
			body,
		)
	} else if m.step == OverridesSteps {
		m.steps.SetSize(width-4, height-8)
		content = lipgloss.JoinVertical(lipgloss.Left,
			title,
			step,
			"",
			m.steps.View(),
			"",
			body,
		)
	} else if m.step == OverridesConfirm {
		content = lipgloss.JoinVertical(lipgloss.Left,
			title,
			step,
			"",
			m.confirm.View(m.currentOverrides(), m.baseline),
		)
	} else {
		content = lipgloss.JoinVertical(lipgloss.Left,
			title,
			step,
			"",
			body,
		)
	}

	return lipgloss.Place(width, height, lipgloss.Center, lipgloss.Center, content)
}

func (m OverridesFlowModel) currentOverrides() overrides.RuntimeOverrides {
	return overrides.RuntimeOverrides{
		AddedFlags:   m.flags.SelectedFlags(),
		RemovedFlags: nil,
		ApplyToSteps: m.steps.SelectedSteps(),
	}
}

func (m OverridesFlowModel) validateCmd(over overrides.RuntimeOverrides) tea.Cmd {
	return func() tea.Msg {
		errs, err := exec.ValidateOverrides(context.Background(), m.packSteps, &over, m.baseline, m.runnerOpts)
		return ValidationResultMsg{Errors: errs, Err: err}
	}
}

func overridesStepName(step OverridesStep) string {
	switch step {
	case OverridesFlags:
		return "Flags"
	case OverridesSteps:
		return "Target Steps"
	case OverridesConfirm:
		return "Confirm"
	default:
		return "Unknown"
	}
}
```

internal/tui/overrides_steps.go
```
package tui

import (
	"fmt"
	"io"

	"github.com/charmbracelet/bubbles/list"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/user/oraclepack/internal/pack"
)

type StepItem struct {
	ID       string
	TitleTxt string
	DescTxt  string
	Selected bool
}

func (i StepItem) Title() string       { return i.TitleTxt }
func (i StepItem) Description() string { return i.DescTxt }
func (i StepItem) FilterValue() string { return i.TitleTxt }

type StepsPickerModel struct {
	list list.Model
}

func NewStepsPickerModel(steps []pack.Step) StepsPickerModel {
	items := make([]list.Item, 0, len(steps))
	for _, s := range steps {
		items = append(items, StepItem{
			ID:       s.ID,
			TitleTxt: fmt.Sprintf("Step %s", s.ID),
			DescTxt:  s.OriginalLine,
			Selected: true,
		})
	}

	delegate := newStepsDelegate()
	l := list.New(items, delegate, 0, 0)
	l.Title = "Target Steps"
	l.SetFilteringEnabled(true)

	return StepsPickerModel{list: l}
}

func (m StepsPickerModel) Init() tea.Cmd {
	return nil
}

func (m StepsPickerModel) Update(msg tea.Msg) (StepsPickerModel, tea.Cmd) {
	switch msg := msg.(type) {
	case tea.KeyMsg:
		switch msg.String() {
		case "a", "A":
			m = m.setAll(true)
			return m, nil
		case "i":
			m = m.invert()
			return m, nil
		case "n":
			m = m.setAll(false)
			return m, nil
		case " ":
			idx := m.list.Index()
			item, ok := m.list.SelectedItem().(StepItem)
			if ok {
				item.Selected = !item.Selected
				_ = m.list.SetItem(idx, item)
			}
		}
	}

	var cmd tea.Cmd
	m.list, cmd = m.list.Update(msg)
	return m, cmd
}

func (m *StepsPickerModel) SetSize(width, height int) {
	m.list.SetSize(width, height)
}

func (m StepsPickerModel) View() string {
	help := lipgloss.NewStyle().Faint(true).Render("[space] toggle  [a] all  [i] invert  [n] none")
	return m.list.View() + "\n" + help
}

func (m StepsPickerModel) SelectedSteps() map[string]bool {
	selected := make(map[string]bool)
	for _, item := range m.list.Items() {
		if si, ok := item.(StepItem); ok && si.Selected {
			selected[si.ID] = true
		}
	}
	return selected
}

func (m StepsPickerModel) setAll(value bool) StepsPickerModel {
	for idx, item := range m.list.Items() {
		si, ok := item.(StepItem)
		if !ok {
			continue
		}
		si.Selected = value
		_ = m.list.SetItem(idx, si)
	}
	return m
}

func (m StepsPickerModel) invert() StepsPickerModel {
	for idx, item := range m.list.Items() {
		si, ok := item.(StepItem)
		if !ok {
			continue
		}
		si.Selected = !si.Selected
		_ = m.list.SetItem(idx, si)
	}
	return m
}

type stepsDelegate struct {
	list.DefaultDelegate
}

func newStepsDelegate() stepsDelegate {
	d := list.NewDefaultDelegate()
	return stepsDelegate{DefaultDelegate: d}
}

func (d stepsDelegate) Render(w io.Writer, m list.Model, index int, item list.Item) {
	si, ok := item.(StepItem)
	if !ok {
		d.DefaultDelegate.Render(w, m, index, item)
		return
	}

	marker := "[ ]"
	if si.Selected {
		marker = "[x]"
	}

	label := si.TitleTxt
	if si.DescTxt != "" {
		label = fmt.Sprintf("%s - %s", si.TitleTxt, si.DescTxt)
	}

	line := fmt.Sprintf("%s %s", marker, label)
	if index == m.Index() {
		line = d.Styles.SelectedTitle.Render(line)
	} else {
		line = d.Styles.NormalTitle.Render(line)
	}

	fmt.Fprintln(w, line)
}
```

internal/tui/overrides_url.go
```
package tui

import (
	"strings"

	"github.com/charmbracelet/bubbles/textinput"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
)

type URLInputModel struct {
	input textinput.Model
	err   string
}

func NewURLInputModel() URLInputModel {
	ti := textinput.New()
	ti.Placeholder = "https://chat.openai.com/project/..."
	ti.CharLimit = 200
	ti.Width = 50

	return URLInputModel{input: ti}
}

func (m URLInputModel) Init() tea.Cmd {
	return textinput.Blink
}

func (m URLInputModel) Update(msg tea.Msg) (URLInputModel, tea.Cmd) {
	var cmd tea.Cmd
	m.input, cmd = m.input.Update(msg)
	m.err = ""
	if !m.IsValid() {
		m.err = "Invalid URL (must start with http:// or https://)"
	}
	return m, cmd
}

func (m URLInputModel) Value() string {
	return strings.TrimSpace(m.input.Value())
}

func (m URLInputModel) IsValid() bool {
	v := m.Value()
	if v == "" {
		return true
	}
	return strings.HasPrefix(v, "http://") || strings.HasPrefix(v, "https://")
}

func (m URLInputModel) View() string {
	body := m.input.View()
	if m.err != "" {
		body = body + "\n" + lipgloss.NewStyle().Foreground(lipgloss.Color("196")).Render(m.err)
	}
	return body
}

func (m *URLInputModel) SetValue(v string) {
	m.input.SetValue(v)
}

func (m *URLInputModel) Focus() {
	m.input.Focus()
}

func (m *URLInputModel) Blur() {
	m.input.Blur()
}
```

internal/tui/preview_test.go
```
package tui

import (
	"strings"
	"testing"

	"github.com/user/oraclepack/internal/exec"
	"github.com/user/oraclepack/internal/pack"
	"github.com/user/oraclepack/internal/state"
)

func TestStepPreviewContentUnwrapped(t *testing.T) {
	p := &pack.Pack{
		Steps: []pack.Step{
			{ID: "01", OriginalLine: "Step 1", Code: "echo hello"},
		},
	}
	r := exec.NewRunner(exec.RunnerOptions{})
	s := &state.RunState{}
	m := NewModel(p, r, s, "", 0, "over", false)
	m.width = 80
	m.previewID = "01"
	m.previewWrap = false

	content := m.stepPreviewContent()
	if !strings.Contains(content, "Step 01") {
		t.Fatalf("expected header to include step id, got %q", content)
	}
	if !strings.Contains(content, "echo hello") {
		t.Fatalf("expected content to include code, got %q", content)
	}
}
```

internal/tui/tui.go
```
package tui

import (
	"context"
	"fmt"
	"strings"
	"time"

	"github.com/charmbracelet/bubbles/list"
	"github.com/charmbracelet/bubbles/spinner"
	"github.com/charmbracelet/bubbles/textinput"
	"github.com/charmbracelet/bubbles/viewport"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/user/oraclepack/internal/exec"
	"github.com/user/oraclepack/internal/overrides"
	"github.com/user/oraclepack/internal/pack"
	"github.com/user/oraclepack/internal/render"
	"github.com/user/oraclepack/internal/state"
)

type ViewState int

const (
	ViewSteps ViewState = iota
	ViewRunning
	ViewDone
	ViewOverrides
	ViewStepPreview
)

type item struct {
	id     string
	title  string
	desc   string
	status state.Status
}

func (i item) Title() string       { return i.title }
func (i item) Description() string { return i.desc }
func (i item) FilterValue() string { return i.title }

type Model struct {
	list        list.Model
	viewport    viewport.Model
	spinner     spinner.Model
	filterInput textinput.Model
	urlInput    URLInputModel
	urlPicker   URLPickerModel
	pack        *pack.Pack
	runner      *exec.Runner
	state       *state.RunState
	statePath   string

	width  int
	height int

	viewState     ViewState
	running       bool
	runAll        bool // State for sequential execution
	currentIdx    int
	autoRun       bool // Config to auto-start on init
	previewID     string
	previewWrap   bool
	previewNotice string

	// Filtering state
	allSteps     []item // Store all items to support dynamic filtering
	roiThreshold float64
	roiMode      string
	isFiltering  bool
	isEditingURL bool
	isPickingURL bool

	overridesFlow    OverridesFlowModel
	appliedOverrides *overrides.RuntimeOverrides
	chatGPTURL       string

	err      error
	logLines []string
	logChan  chan string
}

func NewModel(p *pack.Pack, r *exec.Runner, s *state.RunState, statePath string, roiThreshold float64, roiMode string, autoRun bool) Model {
	if s != nil {
		if s.ROIThreshold > 0 {
			roiThreshold = s.ROIThreshold
		}
		if s.ROIMode != "" {
			roiMode = s.ROIMode
		}
	}
	var allItems []item
	for _, step := range p.Steps {
		allItems = append(allItems, item{
			id:    step.ID,
			title: fmt.Sprintf("Step %s", step.ID),
			desc:  step.OriginalLine,
		})
	}

	ti := textinput.New()
	ti.Placeholder = "Enter ROI threshold (e.g. 2.5)"
	ti.CharLimit = 10
	ti.Width = 20

	l := list.New([]list.Item{}, list.NewDefaultDelegate(), 0, 0)
	l.Title = "Oracle Pack Steps"

	sp := spinner.New()
	sp.Spinner = spinner.Dot
	sp.Style = lipgloss.NewStyle().Foreground(lipgloss.Color("205"))

	vp := viewport.New(0, 0)
	vp.SetContent("Press Enter to run selected, 'a' to run all filtered steps, 'f' to set ROI threshold, 'm' to toggle ROI mode, 'v' to view step, 'o' to configure overrides, 'u' for ChatGPT URL, 'U' to pick a saved URL.")

	projectPath := ProjectURLStorePath(statePath, p.Source)
	globalPath := GlobalURLStorePath()
	urlPicker := NewURLPickerModel(projectPath, globalPath)
	resolvedURL := r.ChatGPTURL
	if resolvedURL == "" {
		resolvedURL = urlPicker.DefaultURL()
	}
	if resolvedURL != "" {
		r.ChatGPTURL = resolvedURL
	}

	m := Model{
		list:          l,
		viewport:      vp,
		spinner:       sp,
		filterInput:   ti,
		urlInput:      NewURLInputModel(),
		urlPicker:     urlPicker,
		pack:          p,
		runner:        r,
		state:         s,
		statePath:     statePath,
		autoRun:       autoRun,
		allSteps:      allItems,
		roiThreshold:  roiThreshold,
		roiMode:       roiMode,
		logChan:       make(chan string, 100),
		viewState:     ViewSteps,
		overridesFlow: NewOverridesFlowModel(p.Steps, r.OracleFlags, RunnerOptionsFromRunner(r)),
		chatGPTURL:    resolvedURL,
		previewWrap:   true,
	}
	m.urlInput.SetValue(resolvedURL)
	m.urlInput.Blur()

	// Apply initial filter
	return m.refreshList()
}

func (m Model) refreshList() Model {
	var filtered []list.Item
	for _, it := range m.allSteps {
		// Find the original step to check ROI
		var step *pack.Step
		for _, s := range m.pack.Steps {
			if s.ID == it.id {
				step = &s
				break
			}
		}
		if step == nil {
			continue
		}

		if m.roiThreshold > 0 {
			if m.roiMode == "under" {
				if step.ROI >= m.roiThreshold {
					continue
				}
			} else {
				if step.ROI < m.roiThreshold {
					continue
				}
			}
		}
		filtered = append(filtered, it)
	}
	m.list.SetItems(filtered)
	return m
}

type StartAutoRunMsg struct{}

func (m Model) Init() tea.Cmd {
	var cmds []tea.Cmd
	if m.autoRun {
		cmds = append(cmds, func() tea.Msg { return StartAutoRunMsg{} })
	}
	cmds = append(cmds, textinput.Blink)
	return tea.Batch(cmds...)
}

type LogMsg string
type FinishedMsg struct {
	Err error
	ID  string
}

func (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
	var cmds []tea.Cmd

	// Global keys (Quit)
	if msg, ok := msg.(tea.KeyMsg); ok {
		switch msg.String() {
		case "ctrl+c":
			return m, tea.Quit
		}
	}

	if msg, ok := msg.(OverridesStartedMsg); ok {
		_ = msg
		m.viewState = ViewOverrides
		m.overridesFlow = NewOverridesFlowModel(m.pack.Steps, m.runner.OracleFlags, RunnerOptionsFromRunner(m.runner))
		return m, nil
	}
	if msg, ok := msg.(OverridesAppliedMsg); ok {
		over := msg.Overrides
		m.appliedOverrides = &over
		if m.runner != nil {
			m.runner.Overrides = &over
		}
		m.viewState = ViewSteps
		return m, nil
	}
	if msg, ok := msg.(OverridesCancelledMsg); ok {
		_ = msg
		m.appliedOverrides = nil
		if m.runner != nil {
			m.runner.Overrides = nil
		}
		m.viewState = ViewSteps
		return m, nil
	}
	if msg, ok := msg.(URLPickedMsg); ok {
		m.chatGPTURL = msg.URL
		if m.runner != nil {
			m.runner.ChatGPTURL = m.chatGPTURL
		}
		m.urlInput.SetValue(m.chatGPTURL)
		m.isPickingURL = false
		return m, nil
	}
	if _, ok := msg.(URLPickerCancelledMsg); ok {
		m.isPickingURL = false
		return m, nil
	}

	if m.viewState == ViewOverrides {
		var cmd tea.Cmd
		m.overridesFlow, cmd = m.overridesFlow.Update(msg)
		return m, cmd
	}

	if m.viewState == ViewStepPreview {
		switch msg := msg.(type) {
		case clearPreviewNoticeMsg:
			m.previewNotice = ""
			return m, nil
		case tea.KeyMsg:
			switch msg.String() {
			case "q":
				return m, tea.Quit
			case "b", "esc":
				m.previewID = ""
				m.previewNotice = ""
				m.viewState = ViewSteps
				m.setListPreviewContent(m.selectedItemID())
				return m, nil
			case "t":
				m.previewWrap = !m.previewWrap
				m.viewport.SetContent(m.stepPreviewContent())
				return m, nil
			case "c":
				content := m.stepPlainTextFor(m.previewID)
				if err := copyToClipboard(content); err != nil {
					path, fallbackErr := writeClipboardFallback(content)
					if fallbackErr != nil {
						m.previewNotice = "Copy failed: " + err.Error()
					} else {
						m.previewNotice = "Copy failed; saved to " + path
					}
				} else {
					m.previewNotice = "Copied to clipboard"
				}
				return m, tea.Tick(2*time.Second, func(time.Time) tea.Msg {
					return clearPreviewNoticeMsg{}
				})
			}
		}
		var cmd tea.Cmd
		m.viewport, cmd = m.viewport.Update(msg)
		return m, cmd
	}

	switch m.viewState {
	case ViewDone:
		if msg, ok := msg.(tea.KeyMsg); ok {
			switch msg.String() {
			case "q":
				return m, tea.Quit
			case "b":
				m.viewState = ViewSteps
				m.setListPreviewContent(m.selectedItemID())
				return m, nil
			case "n":
				m.resetState()
				return m, nil
			case "r":
				// Rerun selected step (if we have one selected in list)
				// Or rerun the whole sequence if that was the context?
				// Requirement says "rerun a step ('r')". Assuming selected step.
				// We need to transition to ViewSteps logic or trigger run directly.
				m.viewState = ViewSteps // Go back to steps view? Or Running?
				// To trigger run, we can fall through or simulate Enter.
				// Let's just switch to steps and let user press Enter, or trigger run immediately?
				// "trigger the execution logic for the specific failed step"
				i, ok := m.list.SelectedItem().(item)
				if ok {
					m.running = true
					m.viewState = ViewRunning
					m.logLines = nil
					m.viewport.SetContent("Re-running execution...")
					return m, tea.Batch(m.runStep(i.id), m.waitForLogs(), m.spinner.Tick)
				}
			}
		}
		// In Done view, we might still want to handle window size?
		if msg, ok := msg.(tea.WindowSizeMsg); ok {
			m.handleWindowSize(msg)
		}
		return m, nil
	}

	// Filter Input Mode
	if m.isFiltering {
		switch msg := msg.(type) {
		case tea.KeyMsg:
			switch msg.String() {
			case "enter":
				var val float64
				_, err := fmt.Sscanf(m.filterInput.Value(), "%f", &val)
				if err == nil {
					m.roiThreshold = val
					m = m.refreshList()
					m.persistFilterState()
				}
				m.isFiltering = false
				m.filterInput.Blur()
				return m, nil
			case "esc":
				m.isFiltering = false
				m.filterInput.Blur()
				return m, nil
			}
		}
		var cmd tea.Cmd
		m.filterInput, cmd = m.filterInput.Update(msg)
		cmds = append(cmds, cmd)
		return m, tea.Batch(cmds...)
	}

	// ChatGPT URL Input Mode
	if m.isEditingURL {
		switch msg := msg.(type) {
		case tea.KeyMsg:
			switch msg.String() {
			case "enter":
				if m.urlInput.IsValid() {
					m.chatGPTURL = m.urlInput.Value()
					if m.runner != nil {
						m.runner.ChatGPTURL = m.chatGPTURL
					}
					m.isEditingURL = false
					m.urlInput.Blur()
					return m, nil
				}
			case "esc":
				m.isEditingURL = false
				m.urlInput.Blur()
				return m, nil
			}
		}
		var cmd tea.Cmd
		m.urlInput, cmd = m.urlInput.Update(msg)
		cmds = append(cmds, cmd)
		return m, tea.Batch(cmds...)
	}

	// URL Picker Mode
	if m.isPickingURL {
		var cmd tea.Cmd
		m.urlPicker, cmd = m.urlPicker.Update(msg)
		return m, cmd
	}

	// Normal Steps View / Running
	switch msg := msg.(type) {
	case tea.KeyMsg:
		switch msg.String() {
		case "q":
			if !m.running {
				return m, tea.Quit
			}
		case "enter":
			if !m.running {
				i, ok := m.list.SelectedItem().(item)
				if ok {
					m.running = true
					m.viewState = ViewRunning
					m.runAll = false
					m.logLines = nil
					m.viewport.SetContent("Starting execution...")
					return m, tea.Batch(m.runStep(i.id), m.waitForLogs(), m.spinner.Tick)
				}
			}
		case "a":
			if !m.running && len(m.list.Items()) > 0 {
				m.running = true
				m.viewState = ViewRunning
				m.runAll = true
				m.currentIdx = 0
				m.logLines = nil
				m.list.Select(0)
				i := m.list.Items()[0].(item)
				m.viewport.SetContent(fmt.Sprintf("Starting sequential run (Step 1/%d)...", len(m.list.Items())))
				return m, tea.Batch(m.runStep(i.id), m.waitForLogs(), m.spinner.Tick)
			}
		case "f":
			if !m.running {
				m.isFiltering = true
				m.filterInput.Focus()
				m.filterInput.SetValue(fmt.Sprintf("%.1f", m.roiThreshold))
				return m, textinput.Blink
			}
		case "m":
			if !m.running {
				if m.roiMode == "under" {
					m.roiMode = "over"
				} else {
					m.roiMode = "under"
				}
				m = m.refreshList()
				m.persistFilterState()
				return m, nil
			}
		case "v":
			if !m.running {
				i, ok := m.list.SelectedItem().(item)
				if ok {
					m.previewID = i.id
					m.viewState = ViewStepPreview
					m.viewport.YOffset = 0
					m.viewport.SetContent(m.stepPreviewContent())
					return m, nil
				}
			}
		case "u":
			if !m.running {
				m.isEditingURL = true
				m.urlInput.SetValue(m.chatGPTURL)
				m.urlInput.Focus()
				return m, textinput.Blink
			}
		case "U":
			if !m.running {
				m.isPickingURL = true
				return m, nil
			}
		case "o":
			if !m.running {
				return m, func() tea.Msg { return OverridesStartedMsg{} }
			}
		}

	case StartAutoRunMsg:
		if !m.running && len(m.list.Items()) > 0 {
			m.running = true
			m.viewState = ViewRunning
			m.runAll = true
			m.currentIdx = 0
			m.logLines = nil
			m.list.Select(0)
			i := m.list.Items()[0].(item)
			m.viewport.SetContent(fmt.Sprintf("Auto-running all steps (Step 1/%d)...", len(m.list.Items())))
			return m, tea.Batch(m.runStep(i.id), m.waitForLogs(), m.spinner.Tick)
		}

	case tea.WindowSizeMsg:
		m.handleWindowSize(msg)

	case LogMsg:
		m.logLines = append(m.logLines, string(msg))
		m.viewport.SetContent(strings.Join(m.logLines, "\n"))
		m.viewport.GotoBottom()
		return m, m.waitForLogs()

	case FinishedMsg:
		m.recordWarnings()
		if msg.Err != nil {
			m.err = msg.Err
			m.logLines = append(m.logLines, fmt.Sprintf("\n❌ ERROR: %v", msg.Err))
			m.running = false
			m.runAll = false
			m.viewState = ViewDone // Or stay in steps? Requirement says ViewDone on completion?
			// If error, maybe stay on steps or go to done with error?
			// "Failed at step X" is a summary state.
			m.viewState = ViewDone
		} else {
			m.logLines = append(m.logLines, "\n✅ SUCCESS")

			if m.runAll {
				m.currentIdx++
				if m.currentIdx < len(m.list.Items()) {
					m.list.Select(m.currentIdx)
					i := m.list.Items()[m.currentIdx].(item)
					m.logLines = append(m.logLines, fmt.Sprintf("\n--- Starting Step %d/%d ---\n", m.currentIdx+1, len(m.list.Items())))
					return m, m.runStep(i.id)
				} else {
					m.logLines = append(m.logLines, "\n🏁 ALL STEPS COMPLETED")
					m.running = false
					m.runAll = false
					m.viewState = ViewDone
				}
			} else {
				m.running = false
				m.viewState = ViewDone // Single step done
			}
		}
		m.viewport.SetContent(strings.Join(m.logLines, "\n"))
		m.viewport.GotoBottom()

	case spinner.TickMsg:
		var cmd tea.Cmd
		m.spinner, cmd = m.spinner.Update(msg)
		return m, cmd
	}

	if !m.running && !m.isFiltering && m.viewState == ViewSteps {
		prevID := m.selectedItemID()
		var cmd tea.Cmd
		m.list, cmd = m.list.Update(msg)
		cmds = append(cmds, cmd)
		newID := m.selectedItemID()
		if newID != "" && newID != prevID {
			m.viewport.YOffset = 0
			m.setListPreviewContent(newID)
		}
	}

	return m, tea.Batch(cmds...)
}

func (m *Model) handleWindowSize(msg tea.WindowSizeMsg) {
	m.width = msg.Width
	m.height = msg.Height
	if m.viewState == ViewStepPreview {
		m.viewport.Width = msg.Width - 4
		m.viewport.Height = msg.Height - 6
		if m.viewport.Height < 1 {
			m.viewport.Height = 1
		}
		m.viewport.SetContent(m.stepPreviewContent())
		m.viewport.GotoTop()
		return
	}
	contentHeight := msg.Height - 5
	if contentHeight < 1 {
		contentHeight = 1
	}
	m.list.SetSize(msg.Width/3, contentHeight)
	m.viewport.Width = msg.Width - (msg.Width / 3) - 6
	m.viewport.Height = contentHeight
	if !m.running && m.viewState == ViewSteps {
		m.setListPreviewContent(m.selectedItemID())
	}
}

func (m *Model) resetState() {
	// Reset RunState
	m.state.StartTime = time.Now()
	m.state.StepStatuses = make(map[string]state.StepStatus)

	// Save cleared state to disk
	if m.statePath != "" {
		_ = state.SaveStateAtomic(m.statePath, m.state)
	}

	// Reset UI
	m.logLines = nil
	m.viewport.SetContent("State reset. Ready for new run.")
	m.list.Select(0)
	m.viewState = ViewSteps
	m.running = false
	m.runAll = false
	m.appliedOverrides = nil
	if m.runner != nil {
		m.runner.Overrides = nil
	}
}

func (m *Model) persistFilterState() {
	if m.state == nil || m.statePath == "" {
		return
	}
	m.state.ROIThreshold = m.roiThreshold
	m.state.ROIMode = m.roiMode
	_ = state.SaveStateAtomic(m.statePath, m.state)
}

func (m *Model) recordWarnings() {
	if m.state == nil || m.statePath == "" || m.runner == nil {
		return
	}
	warnings := m.runner.DrainWarnings()
	if len(warnings) == 0 {
		return
	}
	for _, w := range warnings {
		m.state.Warnings = append(m.state.Warnings, state.Warning{
			Scope:   w.Scope,
			StepID:  w.StepID,
			Line:    w.Line,
			Token:   w.Token,
			Message: w.Message,
		})
	}
	_ = state.SaveStateAtomic(m.statePath, m.state)
}

func (m *Model) setLogContent() {
	if len(m.logLines) == 0 {
		return
	}
	m.viewport.SetContent(strings.Join(m.logLines, "\n"))
	m.viewport.GotoBottom()
}

func (m *Model) stepPreviewContent() string {
	return m.stepPreviewContentFor(m.previewID)
}

func (m *Model) stepPreviewContentFor(id string) string {
	md, ok := m.stepMarkdownFor(id)
	if !ok {
		return md
	}
	width := m.previewRenderWidth()
	rendered, err := render.RenderMarkdown(md, width, "auto")
	if err != nil {
		return m.stepPlainTextFor(id)
	}
	return rendered
}

func (m *Model) stepMarkdownFor(id string) (string, bool) {
	if id == "" {
		return "No step selected.", false
	}
	step := m.stepForID(id)
	if step == nil {
		return "Step not found.", false
	}
	header := fmt.Sprintf("## Step %s\n%s\n\n", step.ID, step.OriginalLine)
	md := header + "```bash\n" + step.Code + "\n```\n"
	return md, true
}

func (m *Model) stepPlainTextFor(id string) string {
	if id == "" {
		return "No step selected."
	}
	step := m.stepForID(id)
	if step == nil {
		return "Step not found."
	}
	header := fmt.Sprintf("Step %s\n%s\n", step.ID, step.OriginalLine)
	return header + "\n" + step.Code
}

func (m *Model) stepForID(id string) *pack.Step {
	for i := range m.pack.Steps {
		if m.pack.Steps[i].ID == id {
			return &m.pack.Steps[i]
		}
	}
	return nil
}

func (m *Model) previewRenderWidth() int {
	width := m.viewport.Width
	if width <= 0 {
		width = render.DefaultWidth
	}
	if !m.previewWrap {
		if width < render.DefaultWidth {
			width = render.DefaultWidth
		}
		width = width * 4
	}
	return width
}

func (m *Model) selectedItemID() string {
	it, ok := m.list.SelectedItem().(item)
	if !ok {
		return ""
	}
	return it.id
}

func (m *Model) setListPreviewContent(id string) {
	if id == "" {
		m.viewport.SetContent("No step selected.")
		return
	}
	m.viewport.SetContent(m.stepPreviewContentFor(id))
	m.viewport.GotoTop()
}

type clearPreviewNoticeMsg struct{}

func (m Model) View() string {
	if m.width == 0 {
		return "Initializing..."
	}

	if m.viewState == ViewDone {
		return m.viewDone()
	}

	if m.viewState == ViewOverrides {
		return m.overridesFlow.View(m.width, m.height)
	}

	if m.isFiltering {
		return lipgloss.Place(m.width, m.height,
			lipgloss.Center, lipgloss.Center,
			lipgloss.JoinVertical(lipgloss.Center,
				"Enter ROI Threshold:",
				m.filterInput.View(),
				"(Enter to apply, Esc to cancel)",
			),
		)
	}

	if m.isEditingURL {
		return lipgloss.Place(m.width, m.height,
			lipgloss.Center, lipgloss.Center,
			lipgloss.JoinVertical(lipgloss.Center,
				"ChatGPT URL (browser mode):",
				m.urlInput.View(),
				"(Enter to apply, Esc to cancel)",
			),
		)
	}

	if m.isPickingURL {
		m.urlPicker.SetSize(m.width-4, m.height-4)
		return lipgloss.Place(m.width, m.height,
			lipgloss.Center, lipgloss.Center,
			m.urlPicker.View(),
		)
	}

	if m.viewState == ViewStepPreview {
		m.viewport.Width = m.width - 4
		m.viewport.Height = m.height - 6
		title := lipgloss.NewStyle().Bold(true).Render("Step Preview")
		help := "[b] Back  [q] Quit  [t] Wrap  [c] Copy  (scroll with ↑↓ / PgUp/PgDn)"
		notice := ""
		if m.previewNotice != "" {
			notice = lipgloss.NewStyle().Foreground(lipgloss.Color("82")).Render(m.previewNotice)
		}
		content := lipgloss.JoinVertical(lipgloss.Left,
			title,
			help,
			notice,
			"",
			m.viewport.View(),
		)
		return lipgloss.Place(m.width, m.height, lipgloss.Center, lipgloss.Center, content)
	}

	left := m.list.View()
	right := m.viewport.View()

	if m.running {
		status := "Running..."
		if m.runAll {
			status = fmt.Sprintf("Running All (%d/%d)...", m.currentIdx+1, len(m.list.Items()))
		}
		right = m.spinner.View() + " " + status + "\n" + right
	} else {
		filterStatus := ""
		if m.roiThreshold > 0 {
			modeSym := ">="
			if m.roiMode == "under" {
				modeSym = "<"
			}
			filterStatus = fmt.Sprintf(" [Filter: ROI %s %.1f]", modeSym, m.roiThreshold)
		}
		if filterStatus == "" {
			modeSym := ">="
			if m.roiMode == "under" {
				modeSym = "<"
			}
			filterStatus = fmt.Sprintf(" [Filter: ROI %s ∞]", modeSym)
		}
		overrideStatus := ""
		if m.appliedOverrides != nil {
			added := len(m.appliedOverrides.AddedFlags)
			removed := len(m.appliedOverrides.RemovedFlags)
			targeted := len(m.appliedOverrides.ApplyToSteps)
			overrideStatus = fmt.Sprintf(" [Overrides: +%d -%d steps:%d]", added, removed, targeted)
		}
		urlStatus := ""
		if m.chatGPTURL != "" {
			urlStatus = " [ChatGPT URL: set]"
		} else {
			urlStatus = " [ChatGPT URL: none]"
		}
		statusLine := strings.TrimSpace(filterStatus + overrideStatus + urlStatus)
		if statusLine != "" {
			right = lipgloss.NewStyle().Foreground(lipgloss.Color("63")).Render(statusLine) + "\n" + right
		}
	}

	help := m.stepsHelpBar(m.width)
	rightWidth := m.viewport.Width
	if rightWidth < 1 {
		rightWidth = 1
	}
	right = lipgloss.NewStyle().Width(rightWidth).Render(right)
	main := lipgloss.JoinHorizontal(lipgloss.Top, left, " | ", right)
	return lipgloss.JoinVertical(lipgloss.Left, main, help)
}

func (m Model) viewDone() string {
	title := lipgloss.NewStyle().Bold(true).Foreground(lipgloss.Color("42")).Render("Execution Complete")
	if m.err != nil {
		title = lipgloss.NewStyle().Bold(true).Foreground(lipgloss.Color("196")).Render("Execution Failed")
	}

	help := "[n] New Run  [r] Rerun  [b] Back to List  [q] Quit  [m] ROI Mode"

	// Show the log viewport in the done screen too? Or just a summary?
	// Requirement says "displays a summary".
	// But viewing the logs is useful.
	// I'll show the viewport in the center/bottom.

	content := lipgloss.JoinVertical(lipgloss.Center,
		title,
		"",
		m.viewport.View(),
		"",
		help,
	)

[TRUNCATED]
```

internal/tui/tui_test.go
```
package tui

import (
	"testing"

	"github.com/user/oraclepack/internal/exec"
	"github.com/user/oraclepack/internal/pack"
	"github.com/user/oraclepack/internal/state"
)

func TestInitAutoRun(t *testing.T) {
	p := &pack.Pack{
		Steps: []pack.Step{
			{ID: "01", Number: 1, Code: "echo hello"},
		},
	}
	r := exec.NewRunner(exec.RunnerOptions{})
	s := &state.RunState{}

	// Test case 1: autoRun = true
	modelAuto := NewModel(p, r, s, "", 0, "over", true)
	cmdAuto := modelAuto.Init()
	
	if cmdAuto == nil {
		t.Fatal("expected Init cmd to be non-nil when autoRun is true")
	}
	// Note: We can't easily assert the content of a Batch command in a unit test.

	// Test case 2: autoRun = false
	modelManual := NewModel(p, r, s, "", 0, "over", false)
	// Even with autoRun false, we have textinput.Blink, so Init is not nil.
	cmdManual := modelManual.Init()
	if cmdManual == nil {
		t.Fatal("expected Init cmd to be non-nil due to textinput.Blink")
	}
}
```

internal/tui/url_picker.go
```
package tui

import (
	"fmt"
	"strings"

	"github.com/charmbracelet/bubbles/list"
	"github.com/charmbracelet/bubbles/textinput"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
)

type URLPickedMsg struct {
	URL string
}

type URLPickerCancelledMsg struct{}

type urlItem struct {
	name  string
	url   string
	scope string
}

func (i urlItem) Title() string       { return i.name }
func (i urlItem) Description() string { return fmt.Sprintf("%s • %s", i.scope, i.url) }
func (i urlItem) FilterValue() string { return i.name }

type URLPickerModel struct {
	list list.Model

	projectPath string
	globalPath  string
	project     URLStore
	global      URLStore

	editing   bool
	editName  textinput.Model
	editURL   textinput.Model
	editScope string
	editIdx   int
	editIsNew bool

	errMsg string
}

func NewURLPickerModel(projectPath, globalPath string) URLPickerModel {
	project, _ := LoadURLStore(projectPath)
	global, _ := LoadURLStore(globalPath)

	items := makeURLItems(project, global)
	l := list.New(items, list.NewDefaultDelegate(), 0, 0)
	l.Title = "ChatGPT Project URLs"
	l.SetFilteringEnabled(true)
	selectDefault(&l, project, global)

	name := textinput.New()
	name.Placeholder = "Name (e.g., Core Project)"
	name.CharLimit = 60
	name.Width = 40

	url := textinput.New()
	url.Placeholder = "https://chatgpt.com/g/.../project"
	url.CharLimit = 200
	url.Width = 60

	return URLPickerModel{
		list:        l,
		projectPath: projectPath,
		globalPath:  globalPath,
		project:     project,
		global:      global,
		editName:    name,
		editURL:     url,
	}
}

func (m URLPickerModel) Init() tea.Cmd {
	return nil
}

func (m URLPickerModel) Update(msg tea.Msg) (URLPickerModel, tea.Cmd) {
	if m.editing {
		return m.updateEdit(msg)
	}

	switch msg := msg.(type) {
	case tea.KeyMsg:
		switch msg.String() {
		case "esc":
			return m, func() tea.Msg { return URLPickerCancelledMsg{} }
		case "enter":
			item, ok := m.list.SelectedItem().(urlItem)
			if !ok {
				return m, nil
			}
			m.touch(item)
			return m, func() tea.Msg { return URLPickedMsg{URL: item.url} }
		case "a":
			m.startEdit(urlScopeProject, "", "", true)
			return m, nil
		case "e":
			item, ok := m.list.SelectedItem().(urlItem)
			if !ok {
				return m, nil
			}
			m.startEdit(item.scope, item.name, item.url, false)
			return m, nil
		case "d":
			item, ok := m.list.SelectedItem().(urlItem)
			if !ok {
				return m, nil
			}
			m.delete(item)
			return m, nil
		case "s":
			item, ok := m.list.SelectedItem().(urlItem)
			if !ok {
				return m, nil
			}
			m.setDefault(item)
			return m, nil
		}
	}

	var cmd tea.Cmd
	m.list, cmd = m.list.Update(msg)
	return m, cmd
}

func (m *URLPickerModel) SetSize(width, height int) {
	m.list.SetSize(width, height-4)
}

func (m URLPickerModel) View() string {
	if m.editing {
		return m.editView()
	}

	help := lipgloss.NewStyle().Faint(true).Render("[enter] use  [a] add  [e] edit  [d] delete  [s] default  [esc] cancel")
	return m.list.View() + "\n" + help
}

func makeURLItems(project URLStore, global URLStore) []list.Item {
	var items []list.Item
	for _, it := range project.Items {
		items = append(items, urlItem{name: it.Name, url: it.URL, scope: urlScopeProject})
	}
	for _, it := range global.Items {
		items = append(items, urlItem{name: it.Name, url: it.URL, scope: urlScopeGlobal})
	}
	return items
}

func selectDefault(l *list.Model, project URLStore, global URLStore) {
	if l == nil {
		return
	}
	name, scope := defaultNameScope(project, global)
	if name == "" {
		return
	}
	for idx, item := range l.Items() {
		if it, ok := item.(urlItem); ok && it.name == name && it.scope == scope {
			l.Select(idx)
			return
		}
	}
}

func defaultNameScope(project URLStore, global URLStore) (string, string) {
	if project.Default != "" {
		return project.Default, urlScopeProject
	}
	if global.Default != "" {
		return global.Default, urlScopeGlobal
	}
	return "", ""
}

func (m URLPickerModel) DefaultURL() string {
	name, scope := defaultNameScope(m.project, m.global)
	if name == "" {
		return ""
	}
	store := m.storeFor(scope)
	if store == nil {
		return ""
	}
	for _, it := range store.Items {
		if it.Name == name {
			return it.URL
		}
	}
	return ""
}

func (m *URLPickerModel) refresh() {
	m.list.SetItems(makeURLItems(m.project, m.global))
	selectDefault(&m.list, m.project, m.global)
}

func (m *URLPickerModel) touch(item urlItem) {
	store := m.storeFor(item.scope)
	if store == nil {
		return
	}
	for i := range store.Items {
		if store.Items[i].Name == item.name {
			store.Items[i].LastUsed = nowRFC3339()
			break
		}
	}
	_ = m.saveStores()
}

func (m *URLPickerModel) delete(item urlItem) {
	store := m.storeFor(item.scope)
	if store == nil {
		return
	}
	var out []URLItem
	for _, it := range store.Items {
		if it.Name == item.name {
			continue
		}
		out = append(out, it)
	}
	store.Items = out
	if store.Default == item.name {
		store.Default = ""
	}
	_ = m.saveStores()
	m.refresh()
}

func (m *URLPickerModel) setDefault(item urlItem) {
	store := m.storeFor(item.scope)
	if store == nil {
		return
	}
	store.Default = item.name
	_ = m.saveStores()
}

func (m *URLPickerModel) startEdit(scope, name, url string, isNew bool) {
	m.editing = true
	m.editScope = scope
	m.editIsNew = isNew
	m.editName.SetValue(name)
	m.editURL.SetValue(url)
	m.editName.Focus()
	m.editURL.Blur()
	m.errMsg = ""
}

func (m URLPickerModel) editView() string {
	scopeLabel := fmt.Sprintf("Scope: %s (g=global, p=project)", m.editScope)
	if m.globalPath == "" && m.projectPath != "" {
		scopeLabel = "Scope: project"
		m.editScope = urlScopeProject
	}
	if m.projectPath == "" && m.globalPath != "" {
		scopeLabel = "Scope: global"
		m.editScope = urlScopeGlobal
	}
	lines := []string{
		"Add / Edit ChatGPT URL",
		scopeLabel,
		"",
		"Name:",
		m.editName.View(),
		"",
		"URL:",
		m.editURL.View(),
		"",
		"[tab] switch field  [enter] save  [esc] cancel",
	}
	if m.errMsg != "" {
		lines = append(lines, "", lipgloss.NewStyle().Foreground(lipgloss.Color("196")).Render(m.errMsg))
	}
	return lipgloss.JoinVertical(lipgloss.Left, lines...)
}

func (m URLPickerModel) updateEdit(msg tea.Msg) (URLPickerModel, tea.Cmd) {
	switch msg := msg.(type) {
	case tea.KeyMsg:
		switch msg.String() {
		case "esc":
			m.editing = false
			return m, nil
		case "tab":
			if m.editName.Focused() {
				m.editName.Blur()
				m.editURL.Focus()
			} else {
				m.editURL.Blur()
				m.editName.Focus()
			}
			return m, nil
		case "g":
			if m.globalPath != "" {
				m.editScope = urlScopeGlobal
			}
		case "p":
			if m.projectPath != "" {
				m.editScope = urlScopeProject
			}
		case "enter":
			name := strings.TrimSpace(m.editName.Value())
			url := strings.TrimSpace(m.editURL.Value())
			if name == "" || !isValidURL(url) {
				m.errMsg = "Name and a valid URL are required."
				return m, nil
			}
			m.saveEdit(name, url)
			m.editing = false
			m.refresh()
			return m, nil
		}
	}

	var cmd tea.Cmd
	if m.editName.Focused() {
		m.editName, cmd = m.editName.Update(msg)
	} else {
		m.editURL, cmd = m.editURL.Update(msg)
	}
	return m, cmd
}

func (m *URLPickerModel) saveEdit(name, url string) {
	scope := m.editScope
	if scope == "" {
		scope = urlScopeProject
	}

	// remove from other store if scope changed
	m.removeByName(name, urlScopeProject)
	m.removeByName(name, urlScopeGlobal)

	store := m.storeFor(scope)
	if store == nil {
		return
	}
	updated := false
	for i := range store.Items {
		if store.Items[i].Name == name {
			store.Items[i].URL = url
			store.Items[i].LastUsed = nowRFC3339()
			updated = true
			break
		}
	}
	if !updated {
		store.Items = append(store.Items, URLItem{Name: name, URL: url, LastUsed: nowRFC3339()})
	}
	_ = m.saveStores()
}

func (m *URLPickerModel) removeByName(name, scope string) {
	store := m.storeFor(scope)
	if store == nil {
		return
	}
	var out []URLItem
	for _, it := range store.Items {
		if it.Name == name {
			continue
		}
		out = append(out, it)
	}
	store.Items = out
}

func (m *URLPickerModel) storeFor(scope string) *URLStore {
	switch scope {
	case urlScopeProject:
		if m.projectPath == "" {
			return nil
		}
		return &m.project
	case urlScopeGlobal:
		if m.globalPath == "" {
			return nil
		}
		return &m.global
	default:
		return nil
	}
}

func (m *URLPickerModel) saveStores() error {
	if err := SaveURLStore(m.projectPath, m.project); err != nil {
		return err
	}
	if err := SaveURLStore(m.globalPath, m.global); err != nil {
		return err
	}
	return nil
}
```

internal/tui/url_store.go
```
package tui

import (
	"encoding/json"
	"errors"
	"os"
	"path/filepath"
	"strings"
	"time"
)

const (
	urlScopeProject = "project"
	urlScopeGlobal  = "global"
)

type URLItem struct {
	Name     string `json:"name"`
	URL      string `json:"url"`
	LastUsed string `json:"lastUsed,omitempty"`
}

type URLStore struct {
	Default string    `json:"default"`
	Items   []URLItem `json:"items"`
}

func LoadURLStore(path string) (URLStore, error) {
	if path == "" {
		return URLStore{}, nil
	}
	data, err := os.ReadFile(path)
	if err != nil {
		if errors.Is(err, os.ErrNotExist) {
			return URLStore{}, nil
		}
		return URLStore{}, err
	}
	var store URLStore
	if err := json.Unmarshal(data, &store); err != nil {
		return URLStore{}, err
	}
	return store, nil
}

func SaveURLStore(path string, store URLStore) error {
	if path == "" {
		return nil
	}
	if err := os.MkdirAll(filepath.Dir(path), 0o755); err != nil {
		return err
	}
	data, err := json.MarshalIndent(store, "", "  ")
	if err != nil {
		return err
	}
	return os.WriteFile(path, data, 0o644)
}

func ProjectURLStorePath(statePath, packSource string) string {
	if statePath != "" {
		base := strings.TrimSuffix(statePath, ".state.json")
		return base + ".chatgpt-urls.json"
	}
	if packSource == "" {
		return ""
	}
	return packSource + ".chatgpt-urls.json"
}

func GlobalURLStorePath() string {
	home, err := os.UserHomeDir()
	if err != nil || home == "" {
		return ""
	}
	return filepath.Join(home, ".oraclepack", "chatgpt-urls.json")
}

func nowRFC3339() string {
	return time.Now().UTC().Format(time.RFC3339)
}

func isValidURL(value string) bool {
	v := strings.TrimSpace(value)
	if v == "" {
		return false
	}
	return strings.HasPrefix(v, "http://") || strings.HasPrefix(v, "https://")
}
```

internal/tui/url_store_test.go
```
package tui

import (
	"path/filepath"
	"testing"
)

func TestURLStoreSaveLoad(t *testing.T) {
	dir := t.TempDir()
	path := filepath.Join(dir, "urls.json")

	store := URLStore{
		Default: "Primary",
		Items: []URLItem{{
			Name: "Primary",
			URL:  "https://chatgpt.com/g/primary",
		}},
	}

	if err := SaveURLStore(path, store); err != nil {
		t.Fatalf("failed to save store: %v", err)
	}

	loaded, err := LoadURLStore(path)
	if err != nil {
		t.Fatalf("failed to load store: %v", err)
	}

	if loaded.Default != store.Default {
		t.Fatalf("expected default %q, got %q", store.Default, loaded.Default)
	}
	if len(loaded.Items) != 1 || loaded.Items[0].URL != store.Items[0].URL {
		t.Fatalf("loaded items mismatch: %+v", loaded.Items)
	}
}

func TestURLPickerDefaultURLPrefersProject(t *testing.T) {
	dir := t.TempDir()
	projectPath := filepath.Join(dir, "project.json")
	globalPath := filepath.Join(dir, "global.json")

	project := URLStore{
		Default: "Project",
		Items: []URLItem{{
			Name: "Project",
			URL:  "https://chatgpt.com/g/project",
		}},
	}
	global := URLStore{
		Default: "Global",
		Items: []URLItem{{
			Name: "Global",
			URL:  "https://chatgpt.com/g/global",
		}},
	}

	if err := SaveURLStore(projectPath, project); err != nil {
		t.Fatalf("failed to save project store: %v", err)
	}
	if err := SaveURLStore(globalPath, global); err != nil {
		t.Fatalf("failed to save global store: %v", err)
	}

	picker := NewURLPickerModel(projectPath, globalPath)
	if got := picker.DefaultURL(); got != project.Items[0].URL {
		t.Fatalf("expected project default URL %q, got %q", project.Items[0].URL, got)
	}
}
```

internal/exec/flags.go
```
package exec

import "strings"

// ApplyChatGPTURL ensures a single --chatgpt-url flag is present when url is set.
// It removes any existing --chatgpt-url/--browser-url flags and their values.
func ApplyChatGPTURL(flags []string, url string) []string {
	var out []string
	skipNext := false
	for _, f := range flags {
		if skipNext {
			skipNext = false
			continue
		}
		if f == "--chatgpt-url" || f == "--browser-url" {
			skipNext = true
			continue
		}
		if strings.HasPrefix(f, "--chatgpt-url=") || strings.HasPrefix(f, "--browser-url=") {
			continue
		}
		out = append(out, f)
	}
	if url != "" {
		out = append(out, "--chatgpt-url", url)
	}
	return out
}
```

internal/exec/inject.go
```
package exec

import "strings"

// InjectFlags scans a script and appends flags to any 'oracle' command invocation.
func InjectFlags(script string, flags []string) string {
	if len(flags) == 0 {
		return script
	}

	flagStr := strings.Join(flags, " ")

	lines := strings.Split(script, "\n")
	for i, line := range lines {
		trimmed := strings.TrimSpace(line)
		if strings.HasPrefix(trimmed, "#") {
			continue
		}

		insertIdx := oracleInsertIndex(line)
		if insertIdx == -1 {
			continue
		}

		lines[i] = insertFlagsInLine(line, insertIdx, flagStr)
	}

	return strings.Join(lines, "\n")
}

func oracleInsertIndex(line string) int {
	i := 0
	for i < len(line) && (line[i] == ' ' || line[i] == '\t') {
		i++
	}

	if !strings.HasPrefix(line[i:], "oracle") {
		return -1
	}

	end := i + len("oracle")
	if end < len(line) {
		next := line[end]
		if next != ' ' && next != '\t' {
			return -1
		}
	}

	return end
}

func insertFlagsInLine(line string, insertIdx int, flags string) string {
	prefix := line[:insertIdx]
	rest := line[insertIdx:]
	if rest == "" {
		return prefix + " " + flags
	}
	if rest[0] == ' ' || rest[0] == '\t' {
		return prefix + " " + flags + rest
	}
	return prefix + " " + flags + " " + rest
}
```

internal/exec/inject_test.go
```
package exec

import (
	"testing"
)

func TestInjectFlags(t *testing.T) {
	tests := []struct {
		name     string
		script   string
		flags    []string
		expected string
	}{
		{
			"simple injection",
			"oracle query 'hello'",
			[]string{"--verbose"},
			"oracle --verbose query 'hello'",
		},
		{
			"indented injection",
			"  oracle query 'hello'",
			[]string{"--verbose"},
			"  oracle --verbose query 'hello'",
		},
		{
			"no injection needed",
			"echo 'hello'",
			[]string{"--verbose"},
			"echo 'hello'",
		},
		{
			"multiple lines",
			"echo 'start'\noracle query\necho 'end'",
			[]string{"--debug"},
			"echo 'start'\noracle --debug query\necho 'end'",
		},
		{
			"multiline with continuation",
			"oracle \\\n  --json \\\n  --files",
			[]string{"--flag"},
			"oracle --flag \\\n  --json \\\n  --files",
		},
		{
			"multiline with args and continuation",
			"  oracle arg \\\n  --json",
			[]string{"--flag"},
			"  oracle --flag arg \\\n  --json",
		},
		{
			"commented command",
			"# oracle --json",
			[]string{"--verbose"},
			"# oracle --json",
		},
		{
			"oracle as part of word",
			"coracle query",
			[]string{"--verbose"},
			"coracle query",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			got := InjectFlags(tt.script, tt.flags)
			if got != tt.expected {
				t.Errorf("InjectFlags() = %q, want %q", got, tt.expected)
			}
		})
	}
}
```

internal/exec/oracle_scan.go
```
package exec

import (
	"regexp"
	"strings"
)

var oracleCmdRegex = regexp.MustCompile(`^(\s*)(oracle)\b`)

// OracleInvocation represents a detected oracle command in a script.
type OracleInvocation struct {
	StartLine   int    // 0-based start line index
	EndLine     int    // 0-based end line index (inclusive)
	Raw         string // The full command string (joined if multi-line)
	Display     string // A trimmed version for UI display
	Indentation string // The leading whitespace
}

// ExtractOracleInvocations extracts oracle invocations from a script.
func ExtractOracleInvocations(script string) []OracleInvocation {
	var invocations []OracleInvocation
	lines := strings.Split(script, "\n")

	for i := 0; i < len(lines); i++ {
		line := lines[i]
		trimmed := strings.TrimSpace(line)

		// Skip comments
		if strings.HasPrefix(trimmed, "#") {
			continue
		}

		// Check for oracle command
		loc := oracleCmdRegex.FindStringSubmatchIndex(line)
		if loc != nil {
			startLine := i
			// Group 1 is the indentation
			indentation := line[loc[2]:loc[3]]

			var cmdBuilder strings.Builder
			cmdBuilder.WriteString(line)

			endLine := i
			// Handle line continuations
			// Check if line ends with backslash (ignoring trailing whitespace)
			for {
				if endLine+1 >= len(lines) {
					break
				}

				// Check current line for continuation
				currTrimmed := strings.TrimRight(lines[endLine], " \t")
				if !strings.HasSuffix(currTrimmed, "\\") {
					break
				}

				endLine++
				cmdBuilder.WriteString("\n")
				cmdBuilder.WriteString(lines[endLine])
			}

			raw := cmdBuilder.String()
			invocations = append(invocations, OracleInvocation{
				StartLine:   startLine,
				EndLine:     endLine,
				Raw:         raw,
				Display:     strings.TrimSpace(raw),
				Indentation: indentation,
			})

			i = endLine // Advance loop
		}
	}
	return invocations
}
```

internal/exec/oracle_scan_test.go
```
package exec

import (
	"reflect"
	"testing"
)

func TestExtractOracleInvocations(t *testing.T) {
	tests := []struct {
		name   string
		script string
		want   []OracleInvocation
	}{
		{
			name:   "Simple command",
			script: "oracle --json",
			want: []OracleInvocation{
				{StartLine: 0, EndLine: 0, Raw: "oracle --json", Display: "oracle --json", Indentation: ""},
			},
		},
		{
			name:   "Indented command",
			script: "  oracle --json",
			want: []OracleInvocation{
				{StartLine: 0, EndLine: 0, Raw: "  oracle --json", Display: "oracle --json", Indentation: "  "},
			},
		},
		{
			name: "Multiline command",
			script: `oracle \
  --json \
  --files`,
			want: []OracleInvocation{
				{StartLine: 0, EndLine: 2, Raw: `oracle \
  --json \
  --files`, Display: `oracle \
  --json \
  --files`, Indentation: ""},
			},
		},
		{
			name: "Commented command",
			script: `# oracle --json
oracle --real`,
			want: []OracleInvocation{
				{StartLine: 1, EndLine: 1, Raw: "oracle --real", Display: "oracle --real", Indentation: ""},
			},
		},
		{
			name: "Multiple commands",
			script: `
echo start
oracle --one
echo mid
oracle --two
echo end
`,
			want: []OracleInvocation{
				{StartLine: 2, EndLine: 2, Raw: "oracle --one", Display: "oracle --one", Indentation: ""},
				{StartLine: 4, EndLine: 4, Raw: "oracle --two", Display: "oracle --two", Indentation: ""},
			},
		},
		{
			name:   "Oraclepack prefix (should not match)",
			script: "oraclepack run",
			want:   nil,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			got := ExtractOracleInvocations(tt.script)
			if !reflect.DeepEqual(got, tt.want) {
				t.Errorf("ExtractOracleInvocations() = %+v, want %+v", got, tt.want)
			}
		})
	}
}
```

internal/exec/oracle_validate.go
```
package exec

import (
	"bytes"
	"context"
	"os"
	"os/exec"
	"strings"

	"github.com/user/oraclepack/internal/overrides"
	"github.com/user/oraclepack/internal/pack"
)

// ValidationError captures a failed oracle validation for a step.
type ValidationError struct {
	StepID       string
	Command      string
	ErrorMessage string
}

// ValidateOverrides runs oracle --dry-run summary for targeted steps.
func ValidateOverrides(
	ctx context.Context,
	steps []pack.Step,
	over *overrides.RuntimeOverrides,
	baseline []string,
	opts RunnerOptions,
) ([]ValidationError, error) {
	if over == nil || over.ApplyToSteps == nil {
		return nil, nil
	}

	shell := opts.Shell
	if shell == "" {
		shell = "/bin/bash"
	}
	env := append(os.Environ(), opts.Env...)

	var results []ValidationError
	for _, step := range steps {
		if !over.ApplyToSteps[step.ID] {
			continue
		}

		invocations := ExtractOracleInvocations(step.Code)
		if len(invocations) == 0 {
			continue
		}

		flags := over.EffectiveFlags(step.ID, baseline)
		flags = append(flags, "--dry-run", "summary")

		for _, inv := range invocations {
			cmdStr := InjectFlags(inv.Raw, flags)
			msg, err := execDryRun(ctx, shell, opts.WorkDir, env, cmdStr)
			if err == nil {
				continue
			}

			results = append(results, ValidationError{
				StepID:       step.ID,
				Command:      cmdStr,
				ErrorMessage: msg,
			})
		}
	}

	return results, nil
}

func execDryRun(ctx context.Context, shell, workDir string, env []string, command string) (string, error) {
	if pathVal := findEnvValue(env, "PATH"); pathVal != "" {
		command = "export PATH=" + shellQuote(pathVal) + "; " + command
	}

	cmd := exec.CommandContext(ctx, shell, "-lc", command)
	if workDir != "" {
		cmd.Dir = workDir
	}
	cmd.Env = env

	var stdout, stderr bytes.Buffer
	cmd.Stdout = &stdout
	cmd.Stderr = &stderr

	err := cmd.Run()
	if err == nil {
		return stdout.String(), nil
	}
	if stderr.Len() > 0 {
		return strings.TrimSpace(stderr.String()), err
	}
	if stdout.Len() > 0 {
		return strings.TrimSpace(stdout.String()), err
	}
	return err.Error(), err
}

func findEnvValue(env []string, key string) string {
	prefix := key + "="
	for _, entry := range env {
		if strings.HasPrefix(entry, prefix) {
			return strings.TrimPrefix(entry, prefix)
		}
	}
	return ""
}

func shellQuote(value string) string {
	if value == "" {
		return "''"
	}
	return "'" + strings.ReplaceAll(value, "'", "'\\''") + "'"
}
```

internal/exec/oracle_validate_test.go
```
package exec

import (
	"context"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/user/oraclepack/internal/overrides"
	"github.com/user/oraclepack/internal/pack"
)

func TestValidateOverrides_Success(t *testing.T) {
	dir := t.TempDir()
	writeOracleStub(t, dir)

	steps := []pack.Step{
		{ID: "01", Code: "oracle --ok"},
	}
	over := &overrides.RuntimeOverrides{
		ApplyToSteps: map[string]bool{"01": true},
	}

	_, err := ValidateOverrides(
		context.Background(),
		steps,
		over,
		[]string{"--base"},
		RunnerOptions{
			WorkDir: dir,
			Env:     []string{"PATH=" + dir + string(os.PathListSeparator) + os.Getenv("PATH")},
		},
	)
	if err != nil {
		t.Fatalf("ValidateOverrides failed: %v", err)
	}
}

func TestValidateOverrides_Error(t *testing.T) {
	dir := t.TempDir()
	writeOracleStub(t, dir)

	steps := []pack.Step{
		{ID: "01", Code: "oracle --bad"},
	}
	over := &overrides.RuntimeOverrides{
		ApplyToSteps: map[string]bool{"01": true},
	}

	errs, err := ValidateOverrides(
		context.Background(),
		steps,
		over,
		nil,
		RunnerOptions{
			WorkDir: dir,
			Env:     []string{"PATH=" + dir + string(os.PathListSeparator) + os.Getenv("PATH")},
		},
	)
	if err != nil {
		t.Fatalf("ValidateOverrides failed: %v", err)
	}
	if len(errs) != 1 {
		t.Fatalf("expected 1 validation error, got %d", len(errs))
	}
	msg := errs[0].ErrorMessage
	if !strings.Contains(msg, "invalid flag") && !strings.Contains(msg, "unknown option") {
		t.Fatalf("unexpected error message: %q", msg)
	}
	if !strings.Contains(errs[0].Command, "--dry-run summary") {
		t.Fatalf("expected command to include --dry-run summary, got %q", errs[0].Command)
	}
}

func writeOracleStub(t *testing.T, dir string) {
	t.Helper()
	stub := `#!/bin/sh
has_dry=0
has_summary=0
for arg in "$@"; do
  if [ "$arg" = "--dry-run" ]; then has_dry=1; fi
  if [ "$arg" = "summary" ]; then has_summary=1; fi
  if [ "$arg" = "--bad" ]; then echo "invalid flag" 1>&2; exit 1; fi
done
if [ $has_dry -eq 0 ] || [ $has_summary -eq 0 ]; then
  echo "missing dry run" 1>&2
  exit 1
fi
exit 0
`
	path := filepath.Join(dir, "oracle")
	if err := os.WriteFile(path, []byte(stub), 0o755); err != nil {
		t.Fatalf("write oracle stub: %v", err)
	}
}
```

internal/exec/runner.go
```
package exec

import (
	"context"
	"fmt"
	"io"
	"os"
	"os/exec"

	"github.com/user/oraclepack/internal/errors"
	"github.com/user/oraclepack/internal/overrides"
	"github.com/user/oraclepack/internal/pack"
)

// Runner handles the execution of shell scripts.
type Runner struct {
	Shell       string
	WorkDir     string
	Env         []string
	OracleFlags []string
	Overrides   *overrides.RuntimeOverrides
	ChatGPTURL  string
	warnings    []SanitizeWarning
}

// RunnerOptions configures a Runner.
type RunnerOptions struct {
	Shell       string
	WorkDir     string
	Env         []string
	OracleFlags []string
	Overrides   *overrides.RuntimeOverrides
	ChatGPTURL  string
}

// NewRunner creates a new Runner with options.
func NewRunner(opts RunnerOptions) *Runner {
	shell := opts.Shell
	if shell == "" {
		shell = "/bin/bash"
	}

	return &Runner{
		Shell:       shell,
		WorkDir:     opts.WorkDir,
		Env:         append(os.Environ(), opts.Env...),
		OracleFlags: opts.OracleFlags,
		Overrides:   opts.Overrides,
		ChatGPTURL:  opts.ChatGPTURL,
	}
}

// RunPrelude executes the prelude code.
func (r *Runner) RunPrelude(ctx context.Context, p *pack.Prelude, logWriter io.Writer) error {
	script, warnings := SanitizeScript(p.Code, "prelude", "")
	r.recordWarnings(warnings, logWriter)
	return r.run(ctx, script, logWriter)
}

// RunStep executes a single step's code.
func (r *Runner) RunStep(ctx context.Context, s *pack.Step, logWriter io.Writer) error {
	flags := ApplyChatGPTURL(r.OracleFlags, r.ChatGPTURL)
	if r.Overrides != nil {
		flags = r.Overrides.EffectiveFlags(s.ID, r.OracleFlags)
		flags = ApplyChatGPTURL(flags, r.ChatGPTURL)
	}
	code := InjectFlags(s.Code, flags)
	script, warnings := SanitizeScript(code, "step", s.ID)
	r.recordWarnings(warnings, logWriter)
	return r.run(ctx, script, logWriter)
}

func (r *Runner) recordWarnings(warnings []SanitizeWarning, logWriter io.Writer) {
	if len(warnings) == 0 {
		return
	}
	for _, w := range warnings {
		r.warnings = append(r.warnings, w)
		if logWriter != nil {
			scope := w.Scope
			if scope == "" {
				scope = "script"
			}
			step := ""
			if w.StepID != "" {
				step = " step " + w.StepID
			}
			_, _ = fmt.Fprintf(logWriter, "⚠ oraclepack: sanitized label in %s%s line %d: %s\n", scope, step, w.Line, w.Token)
		}
	}
}

// DrainWarnings returns any sanitizer warnings collected since the last call.
func (r *Runner) DrainWarnings() []SanitizeWarning {
	if len(r.warnings) == 0 {
		return nil
	}
	out := make([]SanitizeWarning, len(r.warnings))
	copy(out, r.warnings)
	r.warnings = nil
	return out
}

func (r *Runner) run(ctx context.Context, script string, logWriter io.Writer) error {
	// We use bash -lc to ensure login shell (paths, aliases, etc)
	cmd := exec.CommandContext(ctx, r.Shell, "-lc", script)
	cmd.Dir = r.WorkDir
	cmd.Env = r.Env

	// Standardize stdout and stderr to the logWriter
	cmd.Stdout = logWriter
	cmd.Stderr = logWriter

	err := cmd.Run()
	if err != nil {
		if ctx.Err() != nil {
			return ctx.Err()
		}
		return fmt.Errorf("%w: %v", errors.ErrExecutionFailed, err)
	}

	return nil
}
```

internal/exec/runner_test.go
```
package exec

import (
	"context"
	"strings"
	"testing"

	"github.com/user/oraclepack/internal/pack"
)

func TestRunner_RunStep(t *testing.T) {
	r := NewRunner(RunnerOptions{})
	
	var lines []string
	lw := &LineWriter{
		Callback: func(line string) {
			lines = append(lines, line)
		},
	}

	step := &pack.Step{
		Code: "echo 'hello world'",
	}

	err := r.RunStep(context.Background(), step, lw)
	if err != nil {
		t.Fatalf("RunStep failed: %v", err)
	}
	lw.Close()

	found := false
	for _, l := range lines {
		if strings.TrimSpace(l) == "hello world" {
			found = true
			break
		}
	}

	if !found {
		t.Errorf("expected 'hello world' in output, got: %v", lines)
	}
}

func TestRunner_ContextCancellation(t *testing.T) {
	r := NewRunner(RunnerOptions{})
	
	ctx, cancel := context.WithCancel(context.Background())
	cancel() // Cancel immediately

	step := &pack.Step{
		Code: "sleep 10",
	}

	err := r.RunStep(ctx, step, nil)
	if err != context.Canceled {
		t.Errorf("expected context.Canceled, got %v", err)
	}
}
```

internal/exec/sanitize.go
```
package exec

import (
	osexec "os/exec"
	"regexp"
	"strings"
)

// SanitizeWarning captures a label line that was converted to a safe echo.
type SanitizeWarning struct {
	Scope   string
	StepID  string
	Line    int
	Token   string
	Message string
}

var (
	labelTokenRegex   = regexp.MustCompile(`^[A-Za-z][A-Za-z0-9_-]*$`)
	heredocStartRegex = regexp.MustCompile(`<<-?\s*['"]?([A-Za-z0-9_]+)['"]?`)
)

var shellBuiltins = map[string]bool{
	"alias":    true,
	"bg":       true,
	"break":    true,
	"cd":       true,
	"command":  true,
	"continue": true,
	"declare":  true,
	"dirs":     true,
	"echo":     true,
	"eval":     true,
	"exec":     true,
	"exit":     true,
	"export":   true,
	"fg":       true,
	"getopts":  true,
	"hash":     true,
	"help":     true,
	"jobs":     true,
	"local":    true,
	"popd":     true,
	"printf":   true,
	"pushd":    true,
	"pwd":      true,
	"readonly": true,
	"return":   true,
	"set":      true,
	"shift":    true,
	"source":   true,
	"test":     true,
	"trap":     true,
	"true":     true,
	"type":     true,
	"ulimit":   true,
	"umask":    true,
	"unalias":  true,
	"unset":    true,
	"wait":     true,
	"false":    true,
}

var shellKeywords = map[string]bool{
	"case":     true,
	"do":       true,
	"done":     true,
	"elif":     true,
	"else":     true,
	"esac":     true,
	"fi":       true,
	"for":      true,
	"function": true,
	"if":       true,
	"in":       true,
	"select":   true,
	"then":     true,
	"time":     true,
	"until":    true,
	"while":    true,
}

// SanitizeScript converts bare label-like lines into safe echo statements.
func SanitizeScript(script, scope, stepID string) (string, []SanitizeWarning) {
	if script == "" {
		return script, nil
	}

	lines := strings.Split(script, "\n")
	var warnings []SanitizeWarning
	var heredocEnd string

	for i, line := range lines {
		trimmed := strings.TrimSpace(line)
		if heredocEnd != "" {
			if trimmed == heredocEnd {
				heredocEnd = ""
			}
			continue
		}
		if trimmed == "" || strings.HasPrefix(trimmed, "#") {
			continue
		}

		if end := heredocStartToken(trimmed); end != "" {
			heredocEnd = end
			continue
		}

		fields := strings.Fields(trimmed)
		if len(fields) != 1 {
			continue
		}
		token := fields[0]
		if !labelTokenRegex.MatchString(token) {
			continue
		}
		lower := strings.ToLower(token)
		if shellBuiltins[lower] || shellKeywords[lower] {
			continue
		}
		if _, err := osexec.LookPath(token); err == nil {
			continue
		}

		indent := line[:len(line)-len(strings.TrimLeft(line, " \t"))]
		lines[i] = indent + "echo \"" + token + "\""
		warnings = append(warnings, SanitizeWarning{
			Scope:   scope,
			StepID:  stepID,
			Line:    i + 1,
			Token:   token,
			Message: "Converted bare label to echo",
		})
	}

	return strings.Join(lines, "\n"), warnings
}

func heredocStartToken(line string) string {
	match := heredocStartRegex.FindStringSubmatch(line)
	if len(match) < 2 {
		return ""
	}
	return match[1]
}
```

internal/exec/sanitize_test.go
```
package exec

import "testing"

func TestSanitizeScript_LabelLine(t *testing.T) {
	input := "GenerateReport\noracle --help\n"
	got, warnings := SanitizeScript(input, "step", "01")
	if len(warnings) != 1 {
		t.Fatalf("expected 1 warning, got %d", len(warnings))
	}
	if warnings[0].Token != "GenerateReport" {
		t.Fatalf("expected token GenerateReport, got %s", warnings[0].Token)
	}
	wantPrefix := "echo \"GenerateReport\""
	if got[:len(wantPrefix)] != wantPrefix {
		t.Fatalf("expected sanitized line to start with %q, got %q", wantPrefix, got)
	}
}

func TestSanitizeScript_BuiltinUnchanged(t *testing.T) {
	input := "echo\n"
	got, warnings := SanitizeScript(input, "step", "01")
	if len(warnings) != 0 {
		t.Fatalf("expected no warnings, got %d", len(warnings))
	}
	if got != input {
		t.Fatalf("expected script unchanged, got %q", got)
	}
}

func TestSanitizeScript_HeredocUnchanged(t *testing.T) {
	input := "cat <<'EOF'\nGenerateReport\nEOF\n"
	got, warnings := SanitizeScript(input, "step", "01")
	if len(warnings) != 0 {
		t.Fatalf("expected no warnings, got %d", len(warnings))
	}
	if got != input {
		t.Fatalf("expected heredoc unchanged, got %q", got)
	}
}
```

internal/exec/stream.go
```
package exec

import (
	"io"
)

// LineWriter is an io.Writer that splits output into lines and calls a callback.
type LineWriter struct {
	Callback func(string)
	buffer   []byte
}

func (w *LineWriter) Write(p []byte) (n int, err error) {
	for _, b := range p {
		if b == '\n' {
			w.Callback(string(w.buffer))
			w.buffer = w.buffer[:0]
		} else {
			w.buffer = append(w.buffer, b)
		}
	}
	return len(p), nil
}

// Close flushes any remaining data in the buffer.
func (w *LineWriter) Close() error {
	if len(w.buffer) > 0 {
		w.Callback(string(w.buffer))
		w.buffer = w.buffer[:0]
	}
	return nil
}

// MultiWriter handles multiple writers efficiently.
func MultiWriter(writers ...io.Writer) io.Writer {
	return io.MultiWriter(writers...)
}
```

internal/overrides/merge.go
```
package overrides

// EffectiveFlags calculates the final flags for a step.
func (r *RuntimeOverrides) EffectiveFlags(stepID string, baseline []string) []string {
	if r == nil || r.ApplyToSteps == nil || !r.ApplyToSteps[stepID] {
		return baseline
	}

	var effective []string

	// Map for removed flags
	removed := make(map[string]bool)
	for _, f := range r.RemovedFlags {
		removed[f] = true
	}

	// Filter baseline
	for _, flag := range baseline {
		if !removed[flag] {
			effective = append(effective, flag)
		}
	}

	// Append added flags
	effective = append(effective, r.AddedFlags...)

	// Inject ChatGPTURL
	if r.ChatGPTURL != "" {
		effective = append(effective, "--chatgpt-url", r.ChatGPTURL)
	}

	return effective
}
```

internal/overrides/merge_test.go
```
package overrides

import (
	"reflect"
	"testing"
)

func TestEffectiveFlags(t *testing.T) {
	tests := []struct {
		name      string
		overrides *RuntimeOverrides
		stepID    string
		baseline  []string
		want      []string
	}{
		{
			name:      "No overrides (nil)",
			overrides: nil,
			stepID:    "01",
			baseline:  []string{"--json"},
			want:      []string{"--json"},
		},
		{
			name: "Step not targeted",
			overrides: &RuntimeOverrides{
				ApplyToSteps: map[string]bool{"02": true},
				AddedFlags:   []string{"--verbose"},
			},
			stepID:   "01",
			baseline: []string{"--json"},
			want:     []string{"--json"},
		},
		{
			name: "Step targeted: Add flags",
			overrides: &RuntimeOverrides{
				ApplyToSteps: map[string]bool{"01": true},
				AddedFlags:   []string{"--verbose"},
			},
			stepID:   "01",
			baseline: []string{"--json"},
			want:     []string{"--json", "--verbose"},
		},
		{
			name: "Step targeted: Remove flags",
			overrides: &RuntimeOverrides{
				ApplyToSteps: map[string]bool{"01": true},
				RemovedFlags: []string{"--json"},
			},
			stepID:   "01",
			baseline: []string{"--json", "--other"},
			want:     []string{"--other"},
		},
		{
			name: "Step targeted: Add and Remove",
			overrides: &RuntimeOverrides{
				ApplyToSteps: map[string]bool{"01": true},
				AddedFlags:   []string{"--new"},
				RemovedFlags: []string{"--old"},
			},
			stepID:   "01",
			baseline: []string{"--old", "--keep"},
			want:     []string{"--keep", "--new"},
		},
		{
			name: "Step targeted: Inject ChatGPT URL",
			overrides: &RuntimeOverrides{
				ApplyToSteps: map[string]bool{"01": true},
				ChatGPTURL:   "https://chat.openai.com/share/123",
			},
			stepID:   "01",
			baseline: []string{"--json"},
			want:     []string{"--json", "--chatgpt-url", "https://chat.openai.com/share/123"},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			got := tt.overrides.EffectiveFlags(tt.stepID, tt.baseline)
			if !reflect.DeepEqual(got, tt.want) {
				t.Errorf("EffectiveFlags() = %v, want %v", got, tt.want)
			}
		})
	}
}
```

internal/overrides/types.go
```
package overrides

// RuntimeOverrides holds configuration for runtime flag modifications.
type RuntimeOverrides struct {
	AddedFlags   []string        // Flags to append (e.g., "--model=gpt-4")
	RemovedFlags []string        // Flags to remove (e.g., "--json")
	ChatGPTURL   string          // Optional URL to inject via --chatgpt-url
	ApplyToSteps map[string]bool // Set of step IDs to apply overrides to. If empty, applies to none.
}
```

.tickets/PRD-TUI/Oraclepack TUI Integration.md
```
Parent Ticket:

* Title: Oraclepack TUI integration for PRD Generator Project URL + ticketify PRD run flow
* Summary: Enable oraclepack to route a ticket-derived PRD artifact (`tickets_prd.md`) to a specific “PRD Generator” ChatGPT Project URL via the TUI and automated runs. Address the current failure when attempting to run `tickets_prd.md` as a pack (“no bash code block found”) by introducing supported execution paths (micro-pack and/or single-shot call), and optionally generating a richer PRD context bundle + dedicated PRD-generator pack from ticketify outputs.
* Source:

  * Link/ID: Oraclepack TUI Integration (1).md
  * Original ticket excerpt (≤25 words) capturing the overall theme: “utilize our specific prd-generator from one of many gpt project urls… add that project url… as an option in the tui.”
* Global Constraints:

  * `tickets_prd.md` is content/artifact and cannot be executed as a pack unless wrapped in a valid oraclepack structure (requires a `bash` fenced block).
  * Pack parsing requires a ` ```bash … ``` ` fenced code block; otherwise error: “invalid pack structure: no bash code block found”.
  * Avoid hardcoding ChatGPT Project URLs into packs/repos; prefer selecting/storing via the TUI URL picker/store.
  * Support “one of many project urls” including per-step targeting for PRD generation steps.
  * “Simple oracle calls” should be possible without sending entire multi-step packs.
* Global Environment:

  * Unknown
* Global Evidence:

  * Error string: `Error: invalid pack structure: no bash code block found`.
  * “Projects in ChatGPT” (Projects retain chats/files within a project). ([OpenAI Help Center][1])
  * CommonMark: fenced code blocks support an “info string” after the opening fence (language identifier). ([CommonMark Spec][2])

Split Plan:

* Coverage Map:

  1. Original item: “add that project url and send it with our oraclepack in an automated manner… option in the tui.”
     Assigned Ticket ID: T1
  2. Original item: “simple way of utilizing oracle for simpler calls… do not require entire packs being sent.”
     Assigned Ticket ID: T4
  3. Original item: “oraclepack will not allow the `tickets_prd.md`… `invalid pack structure: no bash code block found`.”
     Assigned Ticket ID: T3
  4. Original item: “Add a new entry in the URL picker… Name: `PRD Generator`… Scope: `project`… or `global`.”
     Assigned Ticket ID: T1
  5. Original item: “Set it as default (`s`)…”
     Assigned Ticket ID: T1
  6. Original item: “Headless/CI: add a CLI flag… `oraclepack run --chatgpt-url <url>` (or `--chatgpt-url-name <saved-name>`).”
     Assigned Ticket ID: T2
  7. Original item: “Using multiple project URLs… `RuntimeOverrides` supports `ChatGPTURL` and `ApplyToSteps`… missing piece is Overrides Wizard UI.”
     Assigned Ticket ID: T5
  8. Original item: “Add a new wizard step: ‘ChatGPT URL’… reuse URLPickerModel… write to `pendingOverrides.ChatGPTURL`.”
     Assigned Ticket ID: T5
  9. Original item: “Option A: ‘micro-pack’… attach `tickets_prd.md`… run `oracle` once…”
     Assigned Ticket ID: T3
  10. Original item: “Option B: add `oraclepack call`… pick URL preset… pick files… run one `oracle` invocation… bypass `internal/pack/parser.go`…”
      Assigned Ticket ID: T4
  11. Original item: “Better idea: `tickets_prd.md` artifact parsed into a valid oraclepack… sent to PRD-generator project url… add missing context as part of stage.”
      Assigned Ticket ID: T6
  12. Original item: “Generate deterministic `prd_context.md`… feature summary, prioritized requirements, user stories + AC, constraints/deps/out-of-scope/risks/open questions, keep vs rewrite.”
      Assigned Ticket ID: T6
  13. Original item: “Generate `.oraclepack/ticketify/prd-generator.pack.md`… attach `tickets_prd.md` + `prd_context.md`… `--write-output ".taskmaster/docs/final_prd.md"`.”
      Assigned Ticket ID: T6
  14. Original item: “Wire it into the TUI… toggle `[ ] Generate enhanced PRD via PRD Generator Project`… prompt pick URL… run pack… apply `RuntimeOverrides{ChatGPTURL: <picked>, ApplyToSteps: {"01": true}}`.”
      Assigned Ticket ID: T7
  15. Original item: “Static context in ChatGPT Project; dynamic context in `prd_context.md` attachment.”
      Assigned Ticket ID: T6
* Dependencies:

  * T7 depends on T6 because the TUI flow runs the generated `prd-generator.pack.md` and attaches `prd_context.md`.
* Split Tickets:

```ticket T1
T# Title:
- Add/select PRD Generator ChatGPT Project URL in TUI URL picker (project/global scope + default)

Type:
- enhancement

Target Area:
- oraclepack TUI URL picker/store (“ChatGPT Project URLs”)

Summary:
- Provide a standard way to store and select a “PRD Generator” ChatGPT Project URL from the existing URL picker/store, with project vs global scope guidance and the ability to set it as the default. This enables routing PRD-generation runs through the intended ChatGPT Project without hardcoding URLs into packs.

In Scope:
- Ensure the TUI supports creating/selecting an entry named `PRD Generator` with a ChatGPT Project URL.
- Support scope selection: `project` (repo-specific) vs `global` (shared), as described.
- Support setting the selected entry as the default (`s`) for the relevant scope.

Out of Scope:
- Not provided

Current Behavior (Actual):
- Not provided

Expected Behavior:
- User can add/select `PRD Generator` as a named URL entry.
- User can set it as default for the current workflow/repo.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Do not hardcode URLs into packs/repos (prefer picker/store selection).
- Preserve support for project vs global URL scoping.

Evidence:
- “Add a new entry in the URL picker… Name: `PRD Generator`… Scope: `project`… `global`…”
- “Set it as default (`s`)…”

Open Items / Unknowns:
- Actual PRD Generator ChatGPT Project URL value(s) (not provided).
- Whether a predefined/seeded entry is required vs user-created entry (not provided).

Risks / Dependencies:
- Not provided

Acceptance Criteria:
- [ ] TUI allows creating/selecting a `PRD Generator` URL entry.
- [ ] TUI allows choosing `project` vs `global` scope for the entry.
- [ ] TUI allows setting the entry as default (`s`) and that default is subsequently used when selected.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Add a new entry in the URL picker: … Name: `PRD Generator`”
- “Scope: `project`… `global`…”
- “Set it as default (`s`)…”
```

```ticket T2
T# Title:
- Add headless/CI CLI override for ChatGPT URL selection during runs

Type:
- enhancement

Target Area:
- oraclepack CLI run command (headless / `--no-tui` runs)

Summary:
- Add a CLI override so headless/CI executions can force a ChatGPT URL (or saved URL name) rather than relying on interactive selection. This supports automated routing to the PRD Generator project URL.

In Scope:
- Add CLI support equivalent to: `oraclepack run --chatgpt-url <url>` and/or `--chatgpt-url-name <saved-name>`.
- Ensure the provided value sets the runner’s ChatGPT URL for the run.

Out of Scope:
- Not provided

Current Behavior (Actual):
- “Right now, the TUI resolves a URL; but there isn’t a CLI flag … that forces it in `--no-tui` runs.”

Expected Behavior:
- Headless/CI runs can specify a ChatGPT URL (or saved name) and have it applied for the run.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Must work without requiring the interactive TUI URL picker.
- Must not require editing packs to include URLs.

Evidence:
- “Headless/CI: add a CLI flag to override the picker”
- “Add `oraclepack run --chatgpt-url <url>` (or `--chatgpt-url-name <saved-name>`)...”

Open Items / Unknowns:
- Exact CLI flag naming/shape (both `--chatgpt-url` and `--chatgpt-url-name` are suggested; final selection not provided).

Risks / Dependencies:
- Not provided

Acceptance Criteria:
- [ ] `oraclepack run --chatgpt-url <url>` applies the provided URL for the run.
- [ ] If `--chatgpt-url-name <saved-name>` is implemented, it resolves to a stored URL and applies it for the run.
- [ ] Works in non-interactive/headless mode.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Headless/CI: add a CLI flag to override the picker”
- “Add `oraclepack run --chatgpt-url <url>` (or `--chatgpt-url-name <saved-name>`)...”
```

````ticket T3
T# Title:
- Provide a micro-pack wrapper to run PRD generation using tickets_prd.md (valid bash fence pack)

Type:
- enhancement

Target Area:
- oraclepack pack inputs (micro-pack file used to call `oracle` with `tickets_prd.md`)

Summary:
- Introduce a minimal, valid oraclepack “micro-pack” that wraps PRD generation as an executable pack step. This avoids attempting to run `tickets_prd.md` directly (which fails pack validation) while enabling attaching `tickets_prd.md` to a single `oracle` call.

In Scope:
- Provide a one-step (or 2–3 step) pack that:
  - Is valid for oraclepack parsing (contains a `bash` fenced code block).
  - Attaches `tickets_prd.md`.
  - Runs `oracle` once to generate a PRD output.
- Ensure this flow can be routed to the selected PRD Generator ChatGPT Project URL (via existing URL selection/overrides mechanism).

Out of Scope:
- Full “single-shot call” mode that bypasses pack parsing (see T4).

Current Behavior (Actual):
- Running `tickets_prd.md` as a pack fails with: “Error: invalid pack structure: no bash code block found”.

Expected Behavior:
- A micro-pack wrapper can be run successfully by oraclepack and performs the PRD-generation oracle call using `tickets_prd.md` as an attachment.

Reproduction Steps:
1) Attempt to run `tickets_prd.md` as a pack and observe “no bash code block found”.
2) Run the micro-pack wrapper pack and observe it parses and executes.

Requirements / Constraints:
- Pack must include a ` ```bash … ``` ` fenced block to be parseable.
- Must attach `tickets_prd.md` to the oracle invocation.

Evidence:
- Error: “invalid pack structure: no bash code block found”
- “Generate a 1-step pack… attach `tickets_prd.md`… run `oracle` once…”

Open Items / Unknowns:
- Final location/name of the micro-pack file (example name provided: `prd-generator-call.pack.md`).
- Exact prompt text and output path conventions for the oracle call (not fully specified).

Risks / Dependencies:
- Not provided

Acceptance Criteria:
- [ ] A micro-pack file exists and is parseable by oraclepack (contains a `bash` fenced block).
- [ ] Running the micro-pack executes a single `oracle` call that includes `tickets_prd.md` as an attachment.
- [ ] The flow does not require running `tickets_prd.md` directly as a pack.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Generate a 1-step pack… attach `tickets_prd.md`…”
- “Create a new file… valid pack… run `oracle` while attaching `tickets_prd.md`.”
- “Error: invalid pack structure: no bash code block found”
````

```ticket T4
T# Title:
- Add single-shot oracle invocation mode (CLI/TUI) that bypasses pack parsing

Type:
- enhancement

Target Area:
- oraclepack CLI + TUI (“single-call” mode)

Summary:
- Add a new execution path for “simple oracle calls” that does not require a full pack file or pack parsing. The user can select a ChatGPT URL preset, attach files such as `tickets_prd.md`, provide a prompt/template, and run exactly one `oracle` invocation.

In Scope:
- Implement a new subcommand such as `oraclepack call` (or `oraclepack oracle`) that:
  - Lets the user pick a ChatGPT URL preset.
  - Lets the user specify attachments (e.g., `tickets_prd.md`).
  - Runs one `oracle …` invocation.
- Implement a corresponding TUI flow/screen for “Single Oracle Call” with:
  - URL preset selection
  - attachments selection
  - prompt/template input
  - run
- Ensure this path bypasses pack parsing requirements (no need for a `bash` fenced block).

Out of Scope:
- Generating ticket-derived context bundle (`prd_context.md`) and a dedicated PRD generator pack (see T6/T7).

Current Behavior (Actual):
- “Simple calls” currently imply using packs; running `tickets_prd.md` directly fails pack validation.

Expected Behavior:
- Users can perform a single oracle call via oraclepack without needing a pack file format.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Must bypass `internal/pack/parser.go` (as described) so it does not require a `bashFenceRegex`-parseable pack structure.
- Must support selecting a ChatGPT URL preset and attaching files.

Evidence:
- “Option B (best UX): add a new CLI/TUI mode for single-shot calls”
- “Add a subcommand like: `oraclepack call`… pick ChatGPT URL preset… files to attach…”

Open Items / Unknowns:
- Exact CLI UX (flags for attachments, prompt, output path) not fully specified.
- Whether output-writing is required (“--write-output …” is shown in examples elsewhere but not mandated here).

Risks / Dependencies:
- Not provided

Acceptance Criteria:
- [ ] `oraclepack call` (or equivalent) runs a single oracle invocation without requiring a pack file.
- [ ] User can select a ChatGPT URL preset and attach `tickets_prd.md`.
- [ ] A TUI “Single Oracle Call” flow exists with URL selection, attachments selection, prompt/template entry, and run.
- [ ] Running this path does not trigger “no bash code block found” pack-structure errors.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Option B (best UX): add a new CLI/TUI mode for single-shot calls”
- “Add a subcommand like: `oraclepack call` (or `oraclepack oracle`)”
- “This avoids the structural requirement that triggers your error…”
```

```ticket T5
T# Title:
- Extend Overrides Wizard to support per-step ChatGPT URL selection (RuntimeOverrides.ChatGPTURL)

Type:
- enhancement

Target Area:
- oraclepack TUI Overrides Wizard UI

Summary:
- Enable selecting a ChatGPT URL in the Overrides Wizard and applying it to specific steps via per-step targeting. This supports “one of many project urls” where only PRD generation steps use the PRD Generator project while others use the default.

In Scope:
- Add a wizard step: “ChatGPT URL”.
- Reuse the existing URL picker/store UI model (URLPickerModel) to choose a URL.
- Store the selection into `pendingOverrides.ChatGPTURL`.
- Ensure per-step targeting continues to work via `ApplyToSteps`, so only selected steps get the override.

Out of Scope:
- Not provided

Current Behavior (Actual):
- Overrides Wizard “currently picks flags + target steps, but doesn’t let you pick a ChatGPT URL to apply for those targeted steps.”

Expected Behavior:
- Overrides Wizard allows selecting a ChatGPT URL override and applying it only to selected steps.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Must integrate with existing `RuntimeOverrides` structure (supports `ChatGPTURL` and `ApplyToSteps`).
- Must not force a single global URL for the entire run when per-step targeting is desired.

Evidence:
- “`RuntimeOverrides` supports `ChatGPTURL` and `ApplyToSteps` targeting.”
- “Add a new wizard step: ‘ChatGPT URL’… Write the chosen value into `pendingOverrides.ChatGPTURL`.”

Open Items / Unknowns:
- Exact UX flow placement/order in the wizard (not provided).
- How conflicts are resolved between default URL and step override when both are present (not provided).

Risks / Dependencies:
- Not provided

Acceptance Criteria:
- [ ] Overrides Wizard includes a “ChatGPT URL” selection step.
- [ ] Selected URL is stored in `pendingOverrides.ChatGPTURL`.
- [ ] When overrides are applied to a subset of steps, only those steps use the overridden ChatGPT URL; other steps use the default.
- [ ] Existing step-targeting selection remains functional.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “`RuntimeOverrides` supports `ChatGPTURL` … `ApplyToSteps` targeting.”
- “Add a new wizard step: **‘ChatGPT URL’**”
- “Write the chosen value into `pendingOverrides.ChatGPTURL`.”
```

````ticket T6
T# Title:
- Enhance ticketify outputs: generate prd_context.md + prd-generator.pack.md for PRD Generator Project

Type:
- enhancement

Target Area:
- oraclepack-ticketify outputs/artifacts generation

Summary:
- Generate a deterministic PRD context bundle alongside `tickets_prd.md`, then generate a dedicated, valid micro-pack that calls `oracle` against the PRD Generator ChatGPT Project URL using both `tickets_prd.md` and the new context artifact. This supplies the missing context needed for higher-quality PRD generation while keeping the PRD Generator’s stable instructions in the ChatGPT Project.

In Scope:
- Generate `.oraclepack/ticketify/prd_context.md` containing ticket-derived context, including:
  - product/feature summary inferred from tickets
  - prioritized requirements (functional + non-functional)
  - user stories + acceptance criteria extracted from tickets
  - constraints, dependencies, out-of-scope, risks, open questions
  - explicit “what to keep vs rewrite” instructions for the PRD generator
- Generate `.oraclepack/ticketify/prd-generator.pack.md` that:
  - Is a valid pack with a `bash` fenced code block.
  - Attaches BOTH `tickets_prd.md` and `prd_context.md`.
  - Calls `oracle … --write-output ".taskmaster/docs/final_prd.md"` (as shown in the example).
- Preserve the intended split of context:
  - Static context lives in the PRD Generator ChatGPT Project.
  - Dynamic context is attached via `prd_context.md`.

Out of Scope:
- Not provided

Current Behavior (Actual):
- `tickets_prd.md` alone “does not include the context it would need” for the PRD generator.

Expected Behavior:
- ticketify produces `prd_context.md` and `prd-generator.pack.md` so PRD generation can run with complete, deterministic inputs.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Outputs should be deterministic and ticket-derived (“stable ordering/determinism” is implied by “deterministic… ticket-derived”).
- Generated PRD pack must be valid for oraclepack parsing (contains ` ```bash … ``` `).
- Avoid hardcoding ChatGPT Project URLs into the generated pack; selection/override handled externally (TUI/overrides).

Evidence:
- “Generate a deterministic ‘PRD context bundle’ artifact…”
- “Emit a second markdown file… `.oraclepack/ticketify/prd-generator.pack.md`”
- “Attach BOTH… `tickets_prd.md`… `prd_context.md`… `--write-output ".taskmaster/docs/final_prd.md"`”

Open Items / Unknowns:
- Exact prompt content to send to PRD Generator project (not fully specified).
- Exact source inputs from ticketify flow used to derive `prd_context.md` (“index/actions/etc.” referenced but not enumerated).

Risks / Dependencies:
- Not provided

Acceptance Criteria:
- [ ] ticketify produces `.oraclepack/ticketify/prd_context.md` with the listed context sections/bullets.
- [ ] ticketify produces `.oraclepack/ticketify/prd-generator.pack.md` that is parseable by oraclepack (contains a `bash` fence).
- [ ] The generated pack attaches both `tickets_prd.md` and `prd_context.md`.
- [ ] The generated pack writes output to `.taskmaster/docs/final_prd.md` (as specified in the example).
- [ ] Generated artifacts are deterministic (same ticket inputs produce stable output ordering/content structure).

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Generate a deterministic ‘PRD context bundle’ artifact”
- “Emit a second markdown file… `.oraclepack/ticketify/prd-generator.pack.md`”
- “Attach BOTH… `tickets_prd.md`… `prd_context.md`”
````

```ticket T7
T# Title:
- Add TUI option to run ticketify → PRD Generator flow using selected ChatGPT Project URL

Type:
- enhancement

Target Area:
- oraclepack TUI (new toggle/flow for PRD generation)

Summary:
- Add a TUI toggle/option to run the generated PRD generator pack and route it to the PRD Generator ChatGPT Project URL. The TUI should prompt for (or auto-select) the PRD Generator URL entry, execute `prd-generator.pack.md`, and apply per-step ChatGPT URL overrides to the PRD generation step.

In Scope:
- Add a TUI toggle like: `[ ] Generate enhanced PRD via PRD Generator Project`.
- When enabled:
  1) Prompt user to pick the PRD-generator URL from the existing URL picker (or auto-select “PRD Generator” if present).
  2) Run the generated `prd-generator.pack.md`.
  3) Apply `RuntimeOverrides{ChatGPTURL: <picked>, ApplyToSteps: {"01": true}}` (or whichever step calls oracle).

Out of Scope:
- Not provided

Current Behavior (Actual):
- Not provided

Expected Behavior:
[TRUNCATED]
```

.tickets/PRD-TUI/PRD-generator URL routing.md
```
Title:

* Add PRD-generator project URL routing + ticketfy→PRD “micro-pack” generation; avoid `tickets_prd.md` pack-parse failure

Summary:

* `oraclepack-ticketfy` generates `tickets_prd.md`, but oraclepack cannot execute it as a pack and fails with `Error: invalid pack structure: no bash code block found`.
* Need an automated way (via TUI option) to route a PRD-generation run to a specific “PRD generator” ChatGPT Project URL (one of many project URLs), without sending entire packs for simple calls.

Background / Context:

* User wants oraclepack (TUI) to support selecting/storing multiple ChatGPT Project URLs and sending the chosen URL “with oraclepack” for PRD generation.
* Current understanding (per assistant): runner injects selected URL into `oracle …` invocations via `--chatgpt-url <selected>`, and there is a URL picker/store concept with defaults.
* User proposes: parse/transform `tickets_prd.md` (artifact) into a valid oraclepack that calls `oracle` against the PRD-generator project URL, and include additional context missing from `tickets_prd.md` as part of that stage.

Current Behavior (Actual):

* Running/using `tickets_prd.md` as a pack fails validation with: `Error: invalid pack structure: no bash code block found`.
* PRD generation flow is not currently integrated as a first-class TUI option that:

  * selects a PRD-generator ChatGPT Project URL “from one of many project urls”, and
  * runs a lightweight, single-purpose call without requiring a full pack workflow.
* Missing UI support (per assistant) for per-step ChatGPT URL selection in Overrides Wizard; URL selection appears global for the run today.

Expected Behavior:

* `tickets_prd.md` should be usable as input to PRD generation without being treated as a runnable pack.
* TUI should offer an option to run PRD generation routed to a specific PRD-generator ChatGPT Project URL (selectable from stored URLs), optionally scoped to only the PRD step(s).
* Workflow should support “simple oracle calls” that do not require sending entire packs.

Requirements:

* Do not attempt to execute `tickets_prd.md` directly as an oraclepack pack; instead, generate a valid runnable pack that calls `oracle` and attaches `tickets_prd.md`.
* Add an automated way (TUI option) to select and apply a PRD-generator ChatGPT Project URL for the PRD generation flow.
* Support “one of many project urls” (multiple ChatGPT Project URLs) and the ability to target PRD generation steps specifically (per-step URL override).
* Include “missing context” needed by the PRD generator as part of the stage (ticket-derived context bundle alongside `tickets_prd.md`).
* Provide a lightweight path for single-shot oracle calls (CLI/TUI) that does not require pack parsing (per assistant suggestion: new `oraclepack call` mode).

Out of Scope:

* Not provided.

Reproduction Steps:

1. Generate `tickets_prd.md` via `oraclepack-ticketfy`.
2. Attempt to run `tickets_prd.md` through oraclepack as if it were a runnable pack.
3. Observe error: `Error: invalid pack structure: no bash code block found`.

Environment:

* OS: Unknown
* oraclepack version/commit: Unknown
* oracle CLI version: Unknown
* ticketfy skill version: Unknown
* TUI vs no-TUI: Unknown

Evidence:

* Error message: `Error: invalid pack structure: no bash code block found`.
* Proposed workaround “micro-pack” example (per assistant) that wraps an `oracle` call and attaches `.taskmaster/docs/tickets_prd.md`.
* Suggested architecture (per assistant):

  * Add Overrides Wizard step “ChatGPT URL” writing to `pendingOverrides.ChatGPTURL`.
  * Generate `.oraclepack/ticketify/prd_context.md` and `.oraclepack/ticketify/prd-generator.pack.md`.
  * Optional new command path bypassing `internal/pack/parser.go` (pack parsing) via `oraclepack call ...`.

Decisions / Agreements:

* Constraint acknowledged: `tickets_prd.md` is an artifact and not runnable as a pack; running it directly will fail due to missing ` ```bash … ``` ` fenced block (per assistant).
* Preferred direction (user): convert artifact → valid oraclepack routed to PRD-generator project URL with added context for higher-quality PRD generation.

Open Items / Unknowns:

* Exact location/path of generated `tickets_prd.md` in the repo (example paths were suggested, but actual is not provided).
* How ChatGPT Project URLs are stored/serialized (format, file path, scope rules) in the current implementation: Not provided.
* Whether headless/CI runs need a CLI override flag (`--chatgpt-url` or `--chatgpt-url-name`): implied as needed, but exact requirement not confirmed.

Risks / Dependencies:

* Must preserve strict pack schema expectations (bash fenced block requirement); any solution that weakens validation could impact runner ingest reliability.
* Per-step URL routing depends on runtime overrides and a TUI flow to author/apply them (missing UI support noted).
* PRD generator quality depends on providing adequate context (new context bundle artifact needed).

Acceptance Criteria:

* [ ] Attempting to run `tickets_prd.md` directly is no longer part of the intended flow; documentation/UX guides user to PRD-generation pathway instead.
* [ ] Ticketfy stage outputs (or an adjacent stage) include:

  * [ ] a deterministic PRD context bundle artifact (e.g., `prd_context.md`), and
  * [ ] a valid runnable PRD generator pack (single `bash` fence) that attaches `tickets_prd.md` (+ context bundle) and invokes `oracle`.
* [ ] TUI exposes an option like “Generate enhanced PRD via PRD Generator Project” that:

  * [ ] lets user select a stored ChatGPT Project URL (PRD Generator),
  * [ ] applies it to the PRD generation run (optionally step-targeted).
* [ ] (If implemented) `oraclepack call` (single-shot) can run an `oracle` invocation with selected ChatGPT URL + attachments, without requiring pack parsing.

Priority & Severity (if inferable from text):

* Not provided.

Labels (optional):

* enhancement
* tui
* workflow
* prd
* url-routing
* pack-validation
```

.tickets/actions/Enable Action Packs Dispatch.md
```
Title:

* Enable oraclepack Action Packs to dispatch to non-oracle executors (codex/gemini/task-master/tm)

Summary:

* Current oraclepack usage feels “oracle-only” because certain UX features (flag injection and overrides validation) are hard-coded to `oracle` invocations, while the user needs Action Packs that actually execute work via other agents/tools (e.g., `codex exec`, `gemini`, `task-master`, `tm`). Update the Stage-3 Action Pack generation and/or oraclepack runner logic so Action Packs can deterministically run the correct executor commands for each action item.

Background / Context:

* User concern: “oraclepack is a wrapper around `oracle`” and adding more `oracle` calls won’t implement tasks; Action Packs must run the real tools/agents used in their workflow (examples: `codex exec ...`, `tm ...`, `gemini ...`).
* Current behavior explanation: oraclepack executes shell steps but has special handling only for lines starting with `oracle` (detection regex, flag injection, and overrides validation via `oracle --dry-run summary`).
* Stage-3 Action Pack template already runs non-oracle tools (`task-master …` and `tm autopilot`) and performs guarded checks for autopilot.
* Referenced repos/tools: Gemini CLI, Claude Task Master, OpenAI Codex, steipete/oracle.
* Referenced code/assets: `oraclepack-tui.md`, `oracle_pack_and_taskify-skills.md` (not included in transcript).

Current Behavior (Actual):

* Oraclepack “nice UX features” are oracle-specific:

  * Detects invocations using a regex anchored to literal `oracle`.
  * Injects selected flags only into `oracle …` lines.
  * Validates overrides by running `oracle --dry-run summary` only for detected oracle invocations.
* Action Packs can run arbitrary shell commands, but oraclepack’s overrides/validation UX does not generalize to other tools (codex/gemini/task-master/tm).

Expected Behavior:

* Generated Action Packs can deterministically dispatch execution to the intended executor per action item (e.g., `codex exec …`, `gemini -p …`, `task-master …`, `tm …`) rather than relying on more `oracle` calls.
* Optional: oraclepack’s overrides/flag-injection UX can recognize additional command prefixes beyond `oracle` (if desired).

Requirements:

* Update the Stage-3 generator (“oraclepack-taskify” / Stage-3 Action Pack template) to support configurable tool command strings beyond existing `oracle_cmd`, `task_master_cmd`, `tm_cmd`:

  * Add `codex_cmd` (default `codex`)
  * Add `gemini_cmd` (default `gemini`)
  * Optional: add `autopilot_cmd` (default `${tm_cmd} autopilot`).
* Extend `_actions.json` schema to include an executor plan:

  * `tooling`: include `{ oracle_cmd, task_master_cmd, codex_cmd, gemini_cmd }`
  * Per action item: `executor` (`"codex" | "gemini" | "tm" | "manual"`), `exec_prompt` (deterministic; no code fences), optional `inputs` (paths/globs).
* Add a new Action Pack execution path for implementation:

  * Either add `mode=implement`, or add a new “Step 09” gated by `MODE == implement`.
  * Step reads `<out_dir>/_actions.json`, selects top N items (using existing `top_n`), then dispatches:

    * `codex exec …` when `executor == codex`
    * `gemini -p …` when `executor == gemini`.
* Safety constraint:

  * Keep defaults strict (avoid “yolo” execution by default); Gemini approval/tool execution should remain conservative unless explicitly opted in.
* Optional (nice-to-have): generalize oraclepack’s oracle-specific detection/injection:

  * Generalize `ExtractOracleInvocations` / `InjectFlags` to recognize a registry of prefixes (`oracle`, `codex`, `gemini`, `task-master`, `tm`).
  * Add per-tool override sets (so “Oracle Flags” aren’t incorrectly applied to other tools).

Out of Scope:

* Not provided.

Reproduction Steps:

* Not provided.

Environment:

* OS: Unknown
* oraclepack version/commit: Unknown
* Shell/runner context: Unknown
* Stage-3 generator version/commit: Unknown

Evidence:

* User statement of need: actionpacks must call their agents/tools (examples: `codex exec ...`, `tm ...`, `gemini ...`).
* Oraclepack oracle-specific UX behavior (regex detection, flag injection, `oracle --dry-run summary` validation).
* Proposed schema + implement mode/Step 09 dispatcher design.
* Attachment: Oraclepack Action Pack Integration.md

Decisions / Agreements:

* “Fastest path” identified in transcript: upgrade Stage-3 Action Packs to include an executor dispatch step and extend `_actions.json` with `executor` metadata; modifying oraclepack core is optional.

Open Items / Unknowns:

* Current `_actions.json` schema (exact fields/types) is not provided.
* Current Stage-3 Action Pack template structure (exact steps and modes) is not provided beyond `backlog|pipelines|autopilot`.
* Exact locations/implementations of `ExtractOracleInvocations` / `InjectFlags` in `oraclepack-tui.md` are not provided in this transcript.
* Expected non-interactive invocation patterns/flags for each tool in this project (codex/gemini/task-master/tm) beyond the examples are not provided.

Risks / Dependencies:

* Dependency on external CLIs and their execution/approval modes (especially Gemini CLI) with safety implications; defaults must remain conservative.
* If oraclepack overrides/validation stays oracle-only, users may expect those UX features to apply to non-oracle commands; requires clear separation or per-tool override support.

Acceptance Criteria:

* `_actions.json` produced by the Stage-3 generator includes:

  * `tooling` with `{ oracle_cmd, task_master_cmd, codex_cmd, gemini_cmd }`
  * Per-item `executor` and `exec_prompt` (and optional `inputs`).
* Action Pack supports `implement` execution (via `mode=implement` or Step 09) that:

  * Reads `<out_dir>/_actions.json`
  * Selects top N actions
  * Runs `codex exec …` for `executor=codex` and `gemini -p …` for `executor=gemini` deterministically.
* Defaults do not enable unrestricted/automatic tool execution without opt-in (conservative approval/safety posture).
* (Optional) oraclepack runner recognizes non-oracle prefixes for invocation detection and does not incorrectly apply oracle-specific overrides to other tools.

Priority & Severity (if inferable from text):

* Priority: Not provided
* Severity: Not provided

Labels (optional):

* enhancement
* action-pack
* executor-dispatch
* cli-integration
* oraclepack
* taskify
```

.tickets/actions/Improving Oraclepack Workflow.md
```
Title:

* Add deterministic chaining + structured outputs to oraclepack (fix prelude semantics and enable stage-3 “actions” workflow)

Summary:

* The current oraclepack workflow is a 2-stage pipeline (pack generation → oraclepack execution) but has a “disconnect” after execution: the 20 Markdown outputs are not machine-consumable for automated follow-on work, blocking a seamless next stage for actionable implementation.

    Workflow Improvement Suggestions

* Additionally, the runner executes the pack prelude and each step in separate `bash -lc` processes, so prelude-defined variables do not persist into steps, creating a mismatch between template expectations and runtime behavior.

    Workflow Improvement Suggestions

Background / Context:

* Stage 1: a Codex “skill” or Gemini CLI “command” generates a single Markdown “oracle-pack” document whose machine-critical content is a single fenced `bash` block containing 20 numbered steps that call `oracle` with `--write-output ...`.

    Workflow Improvement Suggestions

* Stage 2: oraclepack parses that Markdown by extracting the first \`\`\`bash fence and splitting steps by a step-header pattern, then runs a “prelude” and each step in separate shells, producing 20 output files.

    Workflow Improvement Suggestions

* Goal: improve workflow productivity and longer runtimes with minimal human interaction, including automatically passing the final 20 results into a next stage that yields actionable implementation steps.

    Workflow Improvement Suggestions

Current Behavior (Actual):

* Prelude variables do not persist into step execution because prelude and steps run in separate `bash -lc` processes; packs must use explicit paths instead of relying on prelude variables like `$out_dir`.

    Workflow Improvement Suggestions

* The 20 `oracle` outputs are human-readable Markdown but lack a machine-friendly handoff artifact (e.g., JSON/YAML), making automated downstream processing brittle.

    Workflow Improvement Suggestions

* Parser/run is vulnerable to “format drift” from pack generators (extra code fences, missing/incorrect headers, multiple `bash` fences—parser grabs the first).

    Workflow Improvement Suggestions

Expected Behavior:

* Pack prelude semantics should match user/template expectations (either reliably shared across steps or explicitly non-shared with enforced guidance).

    Workflow Improvement Suggestions

* After a run, oraclepack should produce a deterministic, machine-readable “handoff” that enables an immediate next stage without manual intervention (“without missing a beat”).

    Workflow Improvement Suggestions

* Pack ingestion should be resilient and self-validating (fail fast on drift and contract violations).

    Workflow Improvement Suggestions

Requirements:

* Prelude semantics (choose and make official):

    Workflow Improvement Suggestions

  * Option A: “Prelude is prep-only” (no shared vars): update pack template guidance accordingly.

  * Option B: “Prelude is sourced into every step”: implement by prefixing each step script with prelude content (or run all steps in a single long-lived shell session).

* Stage-1 → Stage-2 contract hardening (“self-healing”):

    Workflow Improvement Suggestions

  * Standardize step headers to the conservative form `# NN)`.

  * Enforce exactly one fenced `bash` block per pack (or validation error).

  * Run `oraclepack validate` immediately after pack generation (wrapper/scriptable convention).

* Add a machine-readable “run index” artifact per run:

    Workflow Improvement Suggestions

  * Must include per-step `--write-output` paths, exit codes, timestamps.

  * Include parsed metadata when available (ROI/category/reference from step header line).

* Add a first-class “chain” capability to generate an “actions” next stage:

    Workflow Improvement Suggestions

  * Proposed interface: `oraclepack chain <pack.md> --mode actions`.

  * Must synthesize: `oracle-out/_summary.md` (human) and `oracle-out/_actions.json` (machine).

  * `_actions.json` should normalize each item with at least: `category`, `roi`, `reference`, `recommended_action` (“Next smallest concrete experiment”), `missing_artifacts[]`, `risk_notes[]`.

        Workflow Improvement Suggestions

  * Emit a follow-on pack: `docs/oracle-actions-YYYY-MM-DD.md`.

        Workflow Improvement Suggestions

* Execution/runtime considerations:

  * Keep compatibility with non-interactive operation (`--no-tui`, `--run-all`) and stop-on-fail behavior so chaining can run in CI.

        Workflow Improvement Suggestions

  * Optional: opt-in parallel execution with a small concurrency cap if provider/rate limits allow.

        Workflow Improvement Suggestions

* Improve pack input/context usage:

  * Support “focus + exclusion” inputs (e.g., `focus_categories=permissions,migrations`, `exclude_paths=docs,node_modules,dist`) without changing pack shape.

        Workflow Improvement Suggestions

  * Treat “extra\_files” as a deliberate context bundle (org standards/ADRs/threat model/coding conventions) appended to commands.

        Workflow Improvement Suggestions

Out of Scope:

* Not provided

Reproduction Steps:

1. Generate an oracle-pack whose prelude defines `out_dir="..."` and steps reference `$out_dir/...`.

2. Run oraclepack on the pack.

3. Observe that step shells do not see prelude-defined variables (because each step runs in a separate `bash -lc`), requiring explicit paths instead.

    Workflow Improvement Suggestions

Environment:

* OS: Unknown

* oraclepack: Unknown version (Go wrapper around `oracle`)

    Workflow Improvement Suggestions

* Shell execution model: `bash -lc` per step (per assistant analysis)

    Workflow Improvement Suggestions

* Pack generators: Codex skill and Gemini CLI command workflows

    Workflow Improvement Suggestions

Evidence:

* “oraclepack executes **prelude and steps in separate `bash -lc` processes**, so variables defined in the prelude do **not** persist into the step shells.”

    Workflow Improvement Suggestions

* Format drift risks listed: extra code fences, missing/incorrect step headers, multiple `bash` fences (parser grabs the first).

    Workflow Improvement Suggestions

* Proposed chain command + structured artifacts: `_summary.md`, `_actions.json`, and `docs/oracle-actions-YYYY-MM-DD.md`.

    Workflow Improvement Suggestions

Decisions / Agreements:

* None explicitly finalized; two alternative fixes for prelude semantics were presented (runner fix vs template fix), but no selection recorded.

    Workflow Improvement Suggestions

Open Items / Unknowns:

* Which prelude semantic is intended as the official contract (“prep-only” vs “sourced into every step”).

    Workflow Improvement Suggestions

* Exact current parser rules (regex specifics), validation behavior, and current report/state outputs (whether a run index already exists).

    Workflow Improvement Suggestions

* Whether Task Master integration is desired as a required dependency or just an optional downstream consumer.

    Workflow Improvement Suggestions

Risks / Dependencies:

* Dependency on consistent pack formatting across multiple generators (Codex/Gemini); drift can break parsing/validation.

    Workflow Improvement Suggestions

* If parallelism is added, provider rate limits and error handling may complicate deterministic runs.

    Workflow Improvement Suggestions

* Downstream automation quality depends on having a structured index/JSON handoff rather than parsing free-form Markdown answers.

    Workflow Improvement Suggestions

Acceptance Criteria:

* Running a pack that defines variables in the prelude and references them in steps behaves according to the selected official contract:

    *   If “sourced prelude”: steps can reference prelude-defined variables successfully.

    *   If “prep-only”: validation or guidance prevents packs from relying on prelude vars (or template guidance is updated and enforced).

        Workflow Improvement Suggestions

* `oraclepack validate` reliably fails on packs with:

    *   multiple `bash` fences,

    *   missing/incorrect `# NN)` step headers (per enforced convention),

    *   other contract-breaking drift conditions.

        Workflow Improvement Suggestions

* After a run, oraclepack emits a machine-readable run index that includes per-step output paths, exit codes, and timestamps.

    Workflow Improvement Suggestions

* `oraclepack chain <pack.md> --mode actions` produces:

    *   `oracle-out/_summary.md`,

    *   `oracle-out/_actions.json` with the specified normalized fields,

    *   `docs/oracle-actions-YYYY-MM-DD.md` suitable for immediate stage-2 execution.

        Workflow Improvement Suggestions

* Chaining works in non-interactive mode and respects stop-on-fail behavior to support CI usage.

    Workflow Improvement Suggestions

Priority & Severity (if inferable from text):

* Priority: Not provided

* Severity: Not provided

Labels (optional):

* enhancement

* workflow

* automation

* cli

* parsing

* schema

* ci

---
```

.tickets/actions/Oraclepack Action Pack Integration.md
```
Parent Ticket:

* Title: Oraclepack Action Pack Integration: dispatch Action Packs to external agents/tools (Codex/Gemini/Task Master)
* Summary:

  * Current concern: oraclepack is perceived as “oracle-only,” and adding more `oracle` calls won’t implement tasks.
  * Desired outcome: Action Packs should run the correct agent/tool commands (e.g., `codex exec …`, `tm …`, `gemini …`) and be tool-agnostic in how they dispatch work.
  * Optional scope: extend oraclepack’s oracle-specific UX (flag injection / validation) to support non-`oracle` commands.
* Source:

  * Link/ID (if present) or “Not provided”: Not provided
  * Original ticket excerpt (≤25 words) capturing the overall theme: “make it so our actionpacks will perform the correct calls to the agents… Example ‘codex exec …’, ‘tm …’, ‘gemini …’”
* Global Constraints:

  * Not provided
* Global Environment:

  * Tools referenced as available/on PATH in discussion: `oracle`, `codex`, `gemini`, `task-master`, `tm`
  * Action Pack modes referenced: `backlog|pipelines|autopilot` (and proposed `implement`)
  * Runner behavior referenced: steps execute as `bash`; stdin/TTY not attached (impacting interactive CLIs)
* Global Evidence:

  * Referenced files: `oracle_pack_and_taskify-skills.md`, `oraclepack-tui.md`
  * Referenced tool repos: `https://github.com/google-gemini/gemini-cli`, `https://github.com/eyaltoledano/claude-task-master`, `https://github.com/openai/codex`, `https://github.com/steipete/oracle`
  * Mentioned artifacts/screens: “screenshot of oraclepack consuming oraclepack-taskify artifacts”; “oracle-actions-pack-2026-01-07.md”

Split Plan:

* Coverage Map:

  * “oraclepack is a wrapper around `oracle`… can not see how… more oracle calls will help us implement” → Info-only
  * “make it so our actionpacks will perform the correct calls… ‘codex exec …’, ‘tm …’, ‘gemini …’” → T3
  * “oraclepack… special logic only for lines that start with `oracle`… detect… inject flags… overrides validation” → T5
  * “Stage-3 skill already supports… `oracle_cmd`, `task_master_cmd`, `tm_cmd`… Extend… `codex_cmd`, `gemini_cmd`, optionally `autopilot_cmd`” → T1
  * “Extend `_actions.json`… include… `tooling`… per item `executor`, `exec_prompt`, `inputs`” → T2
  * “Add an ‘implement’ mode (or a Step 09)… reads… `_actions.json`… selects top N… dispatches… `codex exec…` / `gemini -p…`” → T3
  * “Keep safety defaults strict (do not ‘yolo’ by default)” → T4
  * “interactive CLIs… may fail/hang because oraclepack doesn’t provide stdin/TTY” → T4
  * “This particular Action Pack does not call `codex`, `gemini`…” → Info-only
  * “Optional: improve oraclepack UX to ‘understand’ non-oracle commands… registry of prefixes… per-tool override sets” → T5
* Dependencies:

  * T3 depends on T2 because the proposed dispatcher reads `_actions.json` fields like `executor` / `exec_prompt`.
  * T2 depends on T1 because the proposed `_actions.json.tooling` includes `codex_cmd` / `gemini_cmd` command strings.
* Split Tickets:

```ticket T1
T# Title:
- Add Codex/Gemini command configuration to Stage-3 generator (alongside oracle/task-master/tm)

Type:
- enhancement

Target Area:
- Stage-3 generator / skill template that currently supports `oracle_cmd`, `task_master_cmd`, `tm_cmd`

Summary:
- Extend the Stage-3 generation inputs to support additional tool command strings so Action Packs can invoke Codex and Gemini explicitly.
- This is intended to mirror the existing configurable command pattern already used for `oracle` and Task Master tools.

In Scope:
- Add `codex_cmd` (default `codex`) to the generator inputs.
- Add `gemini_cmd` (default `gemini`) to the generator inputs.
- Add optional `autopilot_cmd` (default `${tm_cmd} autopilot`) to the generator inputs.
- Ensure generated Action Pack uses these command variables where relevant.

Out of Scope:
- Not provided

Current Behavior (Actual):
- Generator supports configurable tool command strings: `oracle_cmd`, `task_master_cmd`, `tm_cmd`.

Expected Behavior:
- Generator also supports configurable tool command strings: `codex_cmd`, `gemini_cmd` (and optional `autopilot_cmd`), enabling Action Packs to call these tools directly.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Preserve the existing configurable command pattern already used for `oracle_cmd`, `task_master_cmd`, `tm_cmd`.
- Defaults as stated in the ticket text (`codex`, `gemini`, `${tm_cmd} autopilot`).

Evidence:
- References to existing pattern: `oracle_cmd`, `task_master_cmd`, `tm_cmd`
- Proposed additions: `codex_cmd`, `gemini_cmd`, `autopilot_cmd`

Open Items / Unknowns:
- Where the Stage-3 generator defines/declares these args (exact file/path not provided).
- How generated artifacts currently surface tool command strings (exact schema not provided).

Risks / Dependencies:
- Depends on T2 if these command strings must also be emitted into `_actions.json.tooling`.

Acceptance Criteria:
- Stage-3 generator accepts `codex_cmd` and `gemini_cmd` (and optional `autopilot_cmd`) as inputs.
- Defaults match the ticket text when values are not provided.
- Existing inputs (`oracle_cmd`, `task_master_cmd`, `tm_cmd`) remain supported and unchanged.
- Generated Action Pack artifacts include/use these variables (where the template expects tool invocations).

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Your Stage-3 skill already supports… `oracle_cmd`, `task_master_cmd`, `tm_cmd`”
- “Extend that same pattern for: `codex_cmd`… `gemini_cmd`… optionally `autopilot_cmd`”
```

```ticket T2
T# Title:
- Extend `_actions.json` to include per-item executor metadata and tool command strings

Type:
- enhancement

Target Area:
- Canonical actions artifacts (`_actions.json` / `_actions.md`) generated from Stage-2 outputs

Summary:
- Add explicit executor metadata to each action item so downstream Action Pack steps can deterministically decide which tool to run.
- Add a `tooling` object to carry tool command strings (including Codex/Gemini) for use by the dispatcher.

In Scope:
- Extend `_actions.json` to include `tooling` with: `{ oracle_cmd, task_master_cmd, codex_cmd, gemini_cmd }`.
- For each action item, add:
  - `executor`: `"codex" | "gemini" | "tm" | "manual"`
  - `exec_prompt`: short instruction string (no code fences; deterministic)
  - `inputs`: optional list of paths/globs (as referenced by ticket text)
- Ensure `_actions.md` can be produced from the JSON after the schema extension (format details not provided in ticket).

Out of Scope:
- Not provided

Current Behavior (Actual):
- `_actions.json` exists and includes `tooling` and per-item fields such as `recommended_next_action`, `acceptance_criteria` (as described in ticket text).

Expected Behavior:
- `_actions.json` includes the new `tooling` and per-item executor fields so execution can be dispatched without guessing.
- `_actions.md` can still be generated from `_actions.json`.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- `exec_prompt` must be short and deterministic (“no code fences” stated in ticket text).
- `inputs` is optional and can be derived from “missing_artifacts / repo anchors” (source details not provided).

Evidence:
- Proposed schema fields: `tooling`, `executor`, `exec_prompt`, `inputs`
- Existing per-item fields referenced: `recommended_next_action`, `acceptance_criteria`

Open Items / Unknowns:
- Exact current `_actions.json` schema and where it is defined (not provided).
- How `_actions.md` is rendered from `_actions.json` (not provided).

Risks / Dependencies:
- T3 depends on these fields being present to implement the dispatcher logic.

Acceptance Criteria:
- `_actions.json` includes `tooling` with the listed command keys.
- Each action item includes `executor` and `exec_prompt`; `inputs` is present when available and omitted/empty when not.
- The executor enum matches the ticket text: `codex|gemini|tm|manual`.
- `_actions.md` generation continues to work with the extended JSON structure.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Extend `_actions.json` to include an executor plan per item”
- “Add fields like… `tooling`: `{ oracle_cmd, task_master_cmd, codex_cmd, gemini_cmd }`”
- “per item… `executor`… `exec_prompt`… `inputs`”
```

```ticket T3
T# Title:
- Add `implement` dispatch mode (or Step 09) to Action Pack template to run Codex/Gemini based on `_actions.json`

Type:
- enhancement

Target Area:
- Stage-3 Action Pack template (modes: `backlog|pipelines|autopilot`) and step execution flow

Summary:
- Introduce an execution path that reads `_actions.json`, selects the top N actions, and dispatches to the appropriate tool based on `executor`.
- This is intended to make Action Packs perform actual implementation calls (e.g., `codex exec …`, `gemini -p …`) instead of only producing planning artifacts.

In Scope:
- Add either:
  - `mode=implement`, or
  - a new Step 09 gated by `MODE == implement`.
- In that mode/step:
  - Read `<out_dir>/_actions.json`.
  - Select the top N items (based on existing `top_n` concept referenced in ticket text).
  - Dispatch:
    - `codex exec …` for items with executor `codex`
    - `gemini -p …` for items with executor `gemini`
  - (Other executor values referenced in ticket text: `tm`, `manual` — behavior not specified beyond inclusion in enum.)

Out of Scope:
- Not provided

Current Behavior (Actual):
- Action Pack modes exist: `backlog|pipelines|autopilot`.
- Current example pack “does not call `codex`, `gemini`, etc. at all” (per ticket text).

Expected Behavior:
- When `MODE=implement`, the Action Pack executes tool commands for actions according to `_actions.json.executor`.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Use `_actions.json` as the source of truth for executor decisions (as described).
- Top-N selection should use the existing `top_n` referenced in ticket text.

Evidence:
- Proposed mode/step: “Add an ‘implement’ mode (or a Step 09)”
- Proposed dispatch: “`codex exec …`… `gemini -p …`”
- Top-N: “selects the top N items (you already have `top_n`)”

Open Items / Unknowns:
- Where `top_n` is currently defined and how ranking is determined (not provided).
- Exact location/structure for `<out_dir>/_actions.json` (not provided).

Risks / Dependencies:
- Depends on T2 because dispatcher requires `executor`/`exec_prompt` data in `_actions.json`.
- Depends on T1 if dispatcher uses `codex_cmd` / `gemini_cmd` variables.

Acceptance Criteria:
- Action Pack supports a distinct execution path for `implement` (as a mode or gated step).
- In `implement`, the Action Pack reads `_actions.json` and dispatches at least `codex` and `gemini` executors using the stated command forms.
- Existing modes (`backlog|pipelines|autopilot`) remain unchanged in behavior.
- If `_actions.json` is missing/unreadable, the implement path fails clearly (exact messaging not provided).

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Add an ‘implement’ mode (or a Step 09)… reads `<out_dir>/_actions.json`”
- “dispatches deterministically: `codex exec …`… `gemini -p …`”
- “This particular Action Pack does not call `codex`, `gemini`, etc. at all”
```

```ticket T4
T# Title:
- Add non-interactive and safety guardrails for Codex/Gemini execution in Action Packs

Type:
- enhancement

Target Area:
- Action Pack execution behavior when running non-`oracle` tools (Codex/Gemini), including runner constraints around stdin/TTY

Summary:
- The ticket notes that oraclepack runs step scripts without attaching stdin/TTY, which can break or hang interactive CLIs.
- Add guardrails so Action Packs use non-interactive invocation patterns and keep defaults safe (explicitly: do not “yolo” by default).

In Scope:
- Ensure Codex invocation is non-interactive (ticket references `codex exec …` as the intended entrypoint).
- Ensure Gemini invocation is non-interactive (ticket references `gemini -p/--prompt` as intended).
- Apply safety defaults: “Keep safety defaults strict (do not ‘yolo’ by default)” (flag specifics not mandated beyond this phrase).
- Reflect/acknowledge runner constraint: “does not attach stdin/TTY” and the resulting failure mode for interactive tools.

Out of Scope:
- Not provided

Current Behavior (Actual):
- Runner behavior described: executes scripts via `bash -lc`, does not attach stdin/TTY; interactive CLIs may fail or stall.

Expected Behavior:
- Action Packs avoid interactive-only command forms and use non-interactive command forms for Codex/Gemini.
- Defaults remain conservative and do not enable “yolo” behavior by default.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Must account for “oraclepack doesn’t provide stdin/TTY to subprocesses” (per ticket text).
- Must keep safety defaults strict; do not enable “yolo” by default.

Evidence:
- “oraclepack will execute each step… but it does not attach stdin/TTY to the subprocess”
- “interactive CLIs… fail immediately… or stall waiting for input”
- “Keep safety defaults strict (do not ‘yolo’ by default)”

Open Items / Unknowns:
- Exact approval/safety flags to use for Gemini/Codex (not provided in ticket text beyond “yolo” mention).
- Where to place guardrails (template preflight vs dispatcher vs documentation) not specified.

Risks / Dependencies:
- Works alongside T3 (implement dispatcher); guardrails should apply to that path.

Acceptance Criteria:
- Implement path uses non-interactive forms (`codex exec …`, `gemini -p/--prompt …`) as referenced in ticket text.
- Default behavior does not enable “yolo” execution.
- Action Pack behavior is compatible with “no stdin/TTY” runner constraint (i.e., does not require interactive prompts to proceed).

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “oraclepack… does not attach stdin/TTY… interactive CLIs… fail… or stall”
- “Keep safety defaults strict (do not ‘yolo’ by default)”
- “Codex… `codex exec`… Gemini CLI… `--prompt` / `-p`”
```

```ticket T5
T# Title:
- Generalize oraclepack override injection/validation beyond `oracle` to a multi-tool command registry (optional)

Type:
- enhancement

Target Area:
- oraclepack core: command detection for overrides injection and overrides validation (currently `oracle`-anchored)

Summary:
- The ticket identifies that oraclepack’s “nice UX features” (flag overrides + validation) are currently oracle-specific because detection/injection targets only `oracle` commands.
- Optional work: generalize detection to support additional tool prefixes and add per-tool override sets.

In Scope:
- Generalize command detection/injection from `oracle`-only to a small registry of command prefixes (explicitly listed in ticket text): `oracle`, `codex`, `gemini`, `task-master`, `tm`.
- Add per-tool override sets so “Oracle Flags” are not the only concept when tools differ.

Out of Scope:
- Not provided

Current Behavior (Actual):
- Special logic targets only lines that start with `oracle`: detects invocations, injects flags into `oracle …`, and validates overrides using `oracle --dry-run summary` (as described in ticket text).

Expected Behavior:
- The system can detect/inject overrides for additional tool prefixes listed above.
- Overrides configuration is tool-specific (per-tool override sets).

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Must preserve the existing oracle behavior while extending to additional command prefixes.

Evidence:
- “special logic only for lines that start with `oracle`… detects… injects… overrides validation”
- “Generalize… to a small registry of command prefixes (`oracle`, `codex`, `gemini`, `task-master`, `tm`)”
- “Add per-tool override sets”

Open Items / Unknowns:
- Exact internal functions/files to modify (names mentioned but paths not provided in this ticket text).
- How validation should work for non-`oracle` tools (not specified beyond “per-tool override sets”).

Risks / Dependencies:
- Not provided

Acceptance Criteria:
- Non-`oracle` command prefixes listed in the ticket are recognized by the override injection mechanism.
- Overrides can be configured per tool (not only “Oracle Flags”).
- Existing `oracle` override injection and validation behavior continues to function.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Oraclepack… special logic only for lines that start with `oracle`”
- “Generalize… to… prefixes (`oracle`, `codex`, `gemini`, `task-master`, `tm`)”
- “Add per-tool override sets”
```
```

.tickets/actions/Oraclepack Action Pack Issue.md
```
Parent Ticket:

* Title: Oraclepack Action Pack compatibility and non-`oracle` command handling clarity
* Summary: Clarify what happens when running `oraclepack-taskify`-generated Action Packs in current oraclepack, especially the difference between “executing the pack” vs “dispatching/wrapping non-`oracle` commands.” Capture current limitations: oraclepack’s special handling (flag injection + override validation) targets `oracle` invocations only; other CLIs run as plain shell commands and may fail/block depending on PATH and interactivity.
* Source:

  * Link/ID: Not provided
  * Original ticket excerpt (≤25 words) capturing the overall theme: “Two meanings of ‘run these actionpack artifacts’… execute the pack file vs dispatch non-`oracle` commands.”
* Global Constraints:

  * Action Pack is described as “oraclepack-ingestible” with “single ```bash fence” and “# NN) step headers.”
* Global Environment:

  * Unknown
* Global Evidence:

  * docs.task-master.dev link(s) referenced in ticket text
  * developers.openai.com Codex CLI link(s) referenced in ticket text
  * docs.cloud.google.com / google-gemini.github.io Gemini CLI link(s) referenced in ticket text

Split Plan:

* Coverage Map:

  * Original item: “Can our current oraclepack run these actionpack artifacts… generated from the oraclepack-taskify skill?” → Assigned Ticket ID: T1
  * Original item: “Action Pack… ‘oraclepack-ingestible’ (single ```bash fence, # NN) step headers, deterministic paths…)” → Assigned Ticket ID: T1
  * Original item: “How you’d run it… `oraclepack validate …` / `oraclepack run …`” → Assigned Ticket ID: T1
  * Original item: “Actionpacks calling other agents/tools (codex exec, tm autopilot, gemini)… will run them as long as installed and usable non-interactively” → Assigned Ticket ID: T1
  * Original item: “Why did another reviewer say otherwise?” → Assigned Ticket ID: T1
  * Original item: “oraclepack runs each step as a bash script (bash -lc <step script>)” → Assigned Ticket ID: T1
  * Original item: “injects flags into commands that begin with oracle… does not match tm/task-master/codex/gemini” → Assigned Ticket ID: T3
  * Original item: “TUI ‘override validation’ only targets oracle… steps without oracle invocations are skipped” → Assigned Ticket ID: T2
  * Original item: “If binary isn’t installed/on PATH → step fails; if CLI is interactive → it will block” → Assigned Ticket ID: T1
  * Original item: “Only way it ‘gets confused’ is if you expect oracle output text to magically invoke Codex/Gemini” → Assigned Ticket ID: T1
  * Original item: “Two meanings… execute vs dispatch/apply oraclepack overrides to non-oracle commands” → Assigned Ticket ID: T1
  * Original item: “Reviewer answered ‘No’ because broader goal is dispatcher behavior… not interpret actions” → Assigned Ticket ID: Info-only
  * Original item: “Reconciliation: both statements can be true” → Assigned Ticket ID: Info-only
* Dependencies:

  * Not provided
* Split Tickets:

````ticket T1
T# Title: Document current Action Pack execution semantics and operator expectations
Type: docs
Target Area: oraclepack documentation / runbook for Action Packs
Summary:
  Clarify what “running an Action Pack” means in current oraclepack: steps execute as shell via `bash -lc`, and any `tm`/`codex`/`gemini` lines run as plain shell commands. Document the two meanings that caused reviewer disagreement: executing the pack vs dispatching/applying oracle-specific override logic to non-`oracle` commands. Include operator-facing notes on common failure modes already described (PATH missing binaries, interactive CLIs blocking, environment guardrails for autopilot).
In Scope:
  - Explain: “oraclepack executes each step’s body as shell via `bash -lc <command>`.”
  - Explain: non-`oracle` commands (`tm`, `task-master`, `codex`, `gemini`) are executed “directly as normal shell commands.”
  - Provide the exact run examples already given (`oraclepack validate …` and `oraclepack run …`).
  - Capture the limitation: oraclepack’s oracle-specific overrides/validation do not apply to non-`oracle` commands.
  - Document noted failure/blocking conditions:
    - Missing binaries not on PATH.
    - Interactive CLIs blocking waiting for input.
    - Autopilot “fail fast” environment issues (e.g., not in git repo, dirty tree) as stated.
Out of Scope:
  - Implementing dispatcher behavior for non-`oracle` tools (not specified beyond “broader goal” mention).
Current Behavior (Actual):
  - Steps are run as `bash -lc <step script>`.
  - Non-`oracle` commands run directly; no automatic dispatch/wrapping is applied.
Expected Behavior:
  - Operators can correctly predict:
    - What will execute (literal commands in the pack).
    - What will not happen automatically (no “magic” invocation of Codex/Gemini from oracle output text).
Reproduction Steps:
  - Not provided
Requirements / Constraints:
  - Preserve stated Action Pack constraints: “single ```bash fence” and “# NN) step headers” (as described).
Evidence:
  - Included links mentioned in ticket text:
    - docs.task-master.dev references
    - developers.openai.com Codex CLI references
    - Gemini CLI references (docs.cloud.google.com / google-gemini.github.io)
Open Items / Unknowns:
  - Exact location(s) where this documentation should live (Not provided).
  - Whether this should be surfaced in CLI help text vs README vs TUI (Not provided).
Risks / Dependencies:
  - Not provided
Acceptance Criteria:
  - Documentation explicitly states:
    - Packs execute step bodies via `bash -lc`.
    - Non-`oracle` commands run as-is and are not routed through oracle-specific logic.
    - Common failure modes listed in the ticket text (PATH missing, interactive blocking, autopilot environment guards).
  - Documentation includes the exact run commands already provided (`oraclepack validate …`, `oraclepack run …`).
Priority & Severity (if inferable from input text):
  - Priority: Not provided
  - Severity: Not provided
Source:
  - “oraclepack executes each step’s body as shell via `bash -lc <command>`.”
  - “Will oraclepack dispatch non-`oracle` commands…? No… only targets commands that start with `oracle`.”
  - “If the CLI is interactive → it will block waiting for input.”
````

```ticket T2
T# Title: Make TUI override validation behavior explicit for steps without `oracle` invocations
Type: enhancement
Target Area: TUI overrides flow / override validation messaging
Summary:
  The ticket text states that TUI “override validation” runs `oracle --dry-run summary` on detected `oracle` invocations and skips steps without `oracle` calls. Make this behavior explicit in the TUI so operators do not misinterpret skipped steps as “validated,” especially when packs include `tm`/`codex`/`gemini` commands.
In Scope:
  - Surface an explicit note/state in the overrides validation flow indicating:
    - Validation applies only to detected `oracle` invocations.
    - Steps without `oracle` invocations are skipped by this validator.
Out of Scope:
  - Adding validation implementations for `tm`/`codex`/`gemini` (not described in ticket text).
Current Behavior (Actual):
  - “Override validation… only targets `oracle` commands… Steps without oracle invocations are skipped.”
Expected Behavior:
  - TUI clearly communicates when steps are skipped (and why), avoiding operator confusion.
Reproduction Steps:
  - Not provided
Requirements / Constraints:
  - Must preserve current behavior described (validate only `oracle` invocations) unless changed elsewhere (Not provided).
Evidence:
  - “The TUI ‘override validation’ also only targets `oracle` commands… Steps without oracle invocations are skipped…”
Open Items / Unknowns:
  - Exact UI copy/placement and which screen(s) in the TUI should show this (Not provided).
Risks / Dependencies:
  - Not provided
Acceptance Criteria:
  - When override validation runs, the UI explicitly indicates:
    - It validates only `oracle` invocations (via `oracle --dry-run summary`, as stated).
    - Steps without `oracle` invocations are skipped (and shown as skipped).
Priority & Severity (if inferable from input text):
  - Priority: Not provided
  - Severity: Not provided
Source:
  - “The TUI ‘override validation’ also only targets `oracle` commands… runs `oracle --dry-run summary`…”
  - “Steps without oracle invocations are skipped by that validator.”
```

```ticket T3
T# Title: Extend runtime flag-injection matching beyond `oracle` invocations (configurable prefixes)
Type: enhancement
Target Area: command rewriting / runtime override injection
Summary:
  The ticket text states oraclepack injects flags only into commands that begin with `oracle` (regex anchored to `^(\s*)(oracle)\b`) and does not match `tm`, `task-master`, `codex`, or `gemini`. Add support for matching additional command prefixes (or a configurable list) so override injection is not limited to `oracle` only, aligning with packs that include other CLIs.
In Scope:
  - Expand the “inject flags” behavior beyond `oracle`-only matching, as motivated by:
    - “does not match `tm`, `task-master`, `codex`, `gemini`, etc.”
  - Preserve anchored/prefix-based matching semantics as described (no broad substring matching implied).
Out of Scope:
  - Defining tool-specific semantics for what flags should be injected for each CLI (Not provided).
  - Implementing dispatcher logic that changes execution from “literal shell command” to “interpreted actions” (Not provided).
Current Behavior (Actual):
  - “Injects flags into commands that begin with `oracle`… regex anchored to `^(\s*)(oracle)\b`.”
  - “It does not match `tm`, `task-master`, `codex`, `gemini`, etc.”
Expected Behavior:
  - Flag injection can apply to non-`oracle` command prefixes as configured/defined (details not provided in ticket text).
Reproduction Steps:
  - Not provided
Requirements / Constraints:
  - Must not break execution of packs that rely on current `oracle`-only behavior (Not provided).
Evidence:
  - “injects flags into commands that begin with `oracle` (regex anchored to `^(\s*)(oracle)\b`). It does not match `tm`, `task-master`, `codex`, `gemini`, etc.”
Open Items / Unknowns:
  - Which non-`oracle` commands should be included first (list not provided beyond examples).
  - Where configuration should live (Not provided).
  - Whether injection should be opt-in per pack/step or global (Not provided).
Risks / Dependencies:
  - Risk: unintended rewriting of commands if prefix matching is overly broad (mitigate via anchored matching; exact approach not provided).
Acceptance Criteria:
  - There is a documented/configured way to include additional command prefixes for injection beyond `oracle`.
  - Existing `oracle` prefix injection continues to work unchanged.
  - Demonstrably, a command beginning with one added prefix is recognized for injection (exact flags and CLI semantics: Not provided).
Priority & Severity (if inferable from input text):
  - Priority: Not provided
  - Severity: Not provided
Source:
  - “injects flags into commands that begin with `oracle` (regex is anchored to `^(\\s*)(oracle)\\b`).”
  - “It does not match `tm`, `task-master`, `codex`, `gemini`, etc.”
```
```

.tickets/actions/Oraclepack Action Packs.md
```
Parent Ticket:

* Title: Oraclepack Action Packs: tool-agnostic execution (Codex/Gemini/Task Master) instead of oracle-only flows
* Summary:

  * Current pain point: oraclepack is a wrapper around `oracle`, and “more oracle calls” won’t implement taskified work; Action Packs must run real tool commands (e.g., `codex`, `gemini`, `tm`, `task-master`).
  * Key idea: keep oracle as “planner” and make Action Packs do deterministic executor dispatch via `_actions.json` metadata and a new implement mode/step.
* Source:

  * Link/ID (if present) or “Not provided”: Uploaded file: Oraclepack Action Pack Integration.md
  * Original ticket excerpt (≤25 words) capturing the overall theme: “make it so our actionpacks will perform the correct calls… Example ‘codex exec …’, ‘tm …’, ‘gemini …’”.
* Global Constraints:

  * Action Packs should be “tool-agnostic” (dispatch to `codex`, `gemini`, `tm`, etc.).
  * `exec_prompt` should be short and deterministic (explicitly “no code fences”).
  * Safety defaults must be strict (“do not yolo by default”); conservative approval/tool execution unless opted-in.
  * Optional/“nice-to-have”: generalize oraclepack’s oracle-specific overrides UX for other command prefixes.
* Global Environment:

  * Unknown
* Global Evidence:

  * Mentioned repos/tools:

    * `https://github.com/google-gemini/gemini-cli`
    * `https://github.com/eyaltoledano/claude-task-master`
    * `https://github.com/openai/codex`
    * `https://github.com/steipete/oracle`
  * Reference docs cited/used in the ticket text:

    * Codex CLI reference (supports “codex exec”). ([OpenAI Developers][1])
    * Gemini CLI docs (tools/approval concepts referenced by the ticket). ([Gemini CLI][2])
    * Claude Task Master repository. ([GitHub][3])

Split Plan:

* Coverage Map:

  * “make it so our actionpacks will perform the correct calls… ‘codex exec …’, ‘tm …’, ‘gemini …’” → T3
  * Oraclepack has special logic only for lines starting with `oracle` (regex detection / flag injection / validation) → T5
  * “Stage-3 Action Pack template already runs non-oracle tools (`task-master …` and `tm autopilot`) … guarded branch checks” → T3
  * Stage-3 skill supports `oracle_cmd`, `task_master_cmd`, `tm_cmd` → T1
  * “Extend that same pattern for `codex_cmd`, `gemini_cmd`, optionally `autopilot_cmd`” → T1
  * “Extend `_actions.json` … `executor`, `exec_prompt` (no code fences), `inputs`, plus expanded `tooling`” → T2
  * “Add an ‘implement’ mode (or Step 09)… reads `<out_dir>/_actions.json`… selects top N (`top_n`)… dispatches” → T3
  * “Keep safety defaults strict (do not ‘yolo’ by default)” → T4
  * “Minimal changes… add args… update Prompt A… update Action Pack template” → T1, T2, T3
  * “Optional: improve oraclepack UX… registry of command prefixes… per-tool override sets” → T5
  * “Concrete command patterns… `codex exec`, `gemini -p`, Task Master pipeline commands” → Info-only
  * “If you want, I can propose the exact schema delta… Step 09 bash logic” → Info-only
* Dependencies:

  * T3 depends on T2 because the implement/dispatcher step reads `_actions.json` and needs `executor`/`exec_prompt` metadata.
  * T2 depends on T1 because `_actions.json.tooling` expansion references new tool command fields (`codex_cmd`, `gemini_cmd`, optional `autopilot_cmd`).
  * T4 depends on T3 because safety defaults/opt-ins apply to the implement/dispatcher execution path.
  * T5 is independent (optional) but may follow T3 if you want the TUI/overrides UX to apply to non-oracle commands.
* Split Tickets:

```ticket T1
T1 Title:
- Extend oraclepack-taskify Stage-3 generator to accept and propagate executor CLI command configs (codex/gemini/autopilot)

Type:
- enhancement

Target Area:
- oraclepack-taskify (Stage-3 generator inputs/args and emitted configs)

Summary:
- The Stage-3 generator already supports configurable command strings for `oracle_cmd`, `task_master_cmd`, and `tm_cmd`.
- Extend the same configuration pattern to include `codex_cmd` and `gemini_cmd`, and optionally `autopilot_cmd`, so Action Packs can invoke the intended executors without hard-coding tool names.

In Scope:
- Add generator inputs/args for:
  - `codex_cmd` (default `codex`)
  - `gemini_cmd` (default `gemini`)
  - optional `autopilot_cmd` (default `${tm_cmd} autopilot`)
- Ensure generated artifacts carry these command strings for later use by the Action Pack execution steps.

Out of Scope:
- Modifying oraclepack core/TUI behavior (handled in T5)
- Implement-mode dispatcher logic (handled in T3)

Current Behavior (Actual):
- Stage-3 skill supports configurable tool command strings:
  - `oracle_cmd`, `task_master_cmd`, `tm_cmd`

Expected Behavior:
- Stage-3 generator also supports `codex_cmd`, `gemini_cmd`, and optionally `autopilot_cmd`, using the same configuration pattern.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Preserve the existing “configurable tool command strings” pattern already used by the Stage-3 generator.
- Defaults as stated in the ticket text.

Evidence:
- References: “Your Stage-3 skill already supports… `oracle_cmd`, `task_master_cmd`, `tm_cmd`… Extend… `codex_cmd`… `gemini_cmd`… optionally `autopilot_cmd`…”

Open Items / Unknowns:
- Where these args are defined/passed in the current generator (file paths not provided).
- Whether additional executors beyond codex/gemini/tm are needed (not provided).

Risks / Dependencies:
- Depends on T2 if `_actions.json.tooling` is expanded to include these command strings.

Acceptance Criteria:
- Stage-3 generator accepts `codex_cmd` and `gemini_cmd` (and optional `autopilot_cmd`) inputs.
- Defaults match: `codex`, `gemini`, and `${tm_cmd} autopilot` (optional).
- Generated outputs expose these command strings for downstream Action Pack steps.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Your Stage-3 skill already supports configurable tool command strings: `oracle_cmd`, `task_master_cmd`, `tm_cmd`”
- “Extend that same pattern for: `codex_cmd`… `gemini_cmd`… optionally `autopilot_cmd`”
```

```ticket T2
T2 Title:
- Extend `_actions.json` schema + Prompt A to emit per-item executor metadata (executor/exec_prompt/inputs) and expanded tooling

Type:
- enhancement

Target Area:
- Canonical actions schema (`_actions.json`) and “Prompt A” (canonical actions synthesis)

Summary:
- The current actions schema has `tooling` (oracle/task-master) and per-item fields like `recommended_next_action` and `acceptance_criteria`.
- Add executor planning fields per action item so Action Packs can deterministically select and run the correct executor (`codex`, `gemini`, `tm`, or manual), and include relevant inputs.

In Scope:
- Update `_actions.json` to add:
  - `tooling`: `{ oracle_cmd, task_master_cmd, codex_cmd, gemini_cmd }`
  - per-item fields:
    - `executor`: `"codex" | "gemini" | "tm" | "manual"`
    - `exec_prompt`: short instruction string (explicitly “no code fences; deterministic”)
    - `inputs`: optional list of paths/globs (from `missing_artifacts` / repo anchors)
- Update “Prompt A” to emit the above fields for each action item.

Out of Scope:
- Implement-mode dispatcher logic that consumes `_actions.json` (handled in T3)
- oraclepack core UX changes (handled in T5)

Current Behavior (Actual):
- `_actions.json` has `tooling` (oracle/task-master) and per-item fields like `recommended_next_action`, `acceptance_criteria`.

Expected Behavior:
- `_actions.json` includes explicit executor plan per item (`executor`, `exec_prompt`, optional `inputs`) and expanded `tooling` including codex/gemini command strings.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- `exec_prompt` must be short and deterministic; explicitly “no code fences”.
- Executor enum values and tooling fields as written in the ticket text.

Evidence:
- References: “Extend `_actions.json` to include an executor plan per item… `executor`… `exec_prompt`… `inputs`…”

Open Items / Unknowns:
- The exact existing `_actions.json` schema shape and where it’s validated (not provided).
- Whether `missing_artifacts` / repo anchors already exist in the schema (not provided).

Risks / Dependencies:
- Depends on T1 if `tooling` is expected to include the new `codex_cmd`/`gemini_cmd` command strings.
- Required by T3 since the dispatcher reads `_actions.json`.

Acceptance Criteria:
- `_actions.json` schema includes `tooling` with `{ oracle_cmd, task_master_cmd, codex_cmd, gemini_cmd }`.
- Each action item can include:
  - `executor` with allowed values: `codex`, `gemini`, `tm`, `manual`
  - `exec_prompt` (no code fences requirement captured)
  - optional `inputs` list
- Prompt A output includes these fields per item.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Extend `_actions.json` to include an executor plan per item”
- “`executor`: ‘codex’ | ‘gemini’ | ‘tm’ | ‘manual’”
- “`exec_prompt`: a short instruction string (no code fences; deterministic)”
```

```ticket T3
T3 Title:
- Add Action Pack “implement” mode (or Step 09) to dispatch executor commands based on `_actions.json`

Type:
- enhancement

Target Area:
- Stage-3 Action Pack template (runner-ingestible actionpack artifacts)

Summary:
- Action Packs must execute real tool commands to implement tasks; adding more `oracle` calls only produces more analysis/synthesis.
- Add an implement execution path that reads `_actions.json`, selects top N actions (`top_n`), and dispatches to the specified executor (e.g., `codex exec …`, `gemini -p …`) using per-item metadata.

In Scope:
- Add either:
  - `mode=implement`, or
  - a new Step 09 guarded by `if MODE == implement`
- Implement-mode behavior:
  - Read `<out_dir>/_actions.json`
  - Select the top N items (uses existing `top_n`)
  - Dispatch deterministically:
    - `codex exec …` for items with `executor=codex`
    - `gemini -p …` for items with `executor=gemini`
- Keep existing modes (`backlog|pipelines|autopilot`) intact.

Out of Scope:
- Changing oraclepack core logic for overrides/flag injection/validation (handled in T5)

Current Behavior (Actual):
- Implementation happens only when the Action Pack runs real tool commands (e.g., `task-master …`, `tm autopilot`).
- The Action Pack already runs non-oracle tools (`task-master …` and `tm autopilot`) and includes guarded branch checks for autopilot.

Expected Behavior:
- An implement mode/step exists that consumes `_actions.json` and runs executor-specific commands deterministically based on per-item metadata.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Must read `<out_dir>/_actions.json`.
- Must use existing `top_n` to select items.
- Must dispatch based on `executor` field.
- Preserve deterministic behavior as described (stable ordering / fail-fast preflight referenced as desired properties).

Evidence:
- References: “Add an ‘implement’ mode (or a Step 09)… reads `<out_dir>/_actions.json`… selects the top N… dispatches deterministically…”

Open Items / Unknowns:
- The exact Action Pack template file path and step numbering constraints (not provided).
- How “top N” is currently computed/ordered (not provided).

Risks / Dependencies:
- Depends on T2 since implement mode reads `_actions.json` executor metadata.
- Safety defaults for tool execution are addressed in T4.

Acceptance Criteria:
- Action Pack supports `mode=implement` (or an equivalent Step 09 guarded behavior).
- Implement mode:
  - Reads `<out_dir>/_actions.json`
  - Selects top N via `top_n`
  - Runs `codex exec …` for `executor=codex`
  - Runs `gemini -p …` for `executor=gemini`
- Existing `backlog|pipelines|autopilot` behavior remains unchanged.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “implementation only happens when the Action Pack runs real tool commands”
- “Add an ‘implement’ mode (or a Step 09)… reads `<out_dir>/_actions.json`… selects the top N… dispatches deterministically”
```

```ticket T4
T4 Title:
- Enforce conservative safety defaults for executor dispatch (no auto-approve “yolo” behavior unless opted-in)

Type:
- chore

Target Area:
- Action Pack implement/dispatcher execution path (gemini/codex dispatch configuration)

Summary:
- The ticket explicitly calls out safety: executor tools may run commands or perform actions; defaults should be conservative.
- Add/confirm guardrails so the implement/dispatcher mode does not auto-approve tool execution by default, and requires explicit opt-in for riskier behaviors.

In Scope:
- Ensure implement/dispatcher mode defaults are “strict” and not “yolo by default”.
- Ensure any approval/tool-execution modes are conservative unless a user opts in (mechanism not specified in the ticket text).

Out of Scope:
- Defining new security models or sandboxing systems beyond what’s stated (not provided).

Current Behavior (Actual):
- Not provided (safety behavior in implement/dispatcher mode is not yet implemented per ticket text).

Expected Behavior:
- Implement/dispatcher execution has conservative defaults around tool approvals/execution; opt-in required for less restrictive modes.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- “Keep safety defaults strict (do not ‘yolo’ by default)”
- “keep defaults conservative unless a user opts in”

Evidence:
- References: “Keep safety defaults strict (do not ‘yolo’ by default)… sandboxing and explicit approvals matter…”

Open Items / Unknowns:
- Which specific flags/options are used to control approvals for each executor (not provided).
- How/where opt-in is configured (env var, arg, config) (not provided).

Risks / Dependencies:
- Depends on T3 because the implement/dispatcher path is where safety defaults apply.

Acceptance Criteria:
- Implement/dispatcher mode does not default to auto-approving tool execution.
- Any non-conservative approval behavior requires explicit user opt-in (as defined by existing config patterns; specifics not provided).

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Keep safety defaults strict (do not ‘yolo’ by default)”
- “keep defaults conservative unless a user opts in”
```

```ticket T5
T5 Title:
- Optional: Generalize oraclepack “oracle-only” overrides UX to support multiple command prefixes (codex/gemini/task-master/tm)

Type:
- enhancement

Target Area:
- oraclepack core/TUI overrides and validation logic (oracle-specific detection/injection/validation)

Summary:
- Oraclepack can run any shell command, but its “nice UX features” (flag overrides + validation) are oracle-specific.
- Optionally generalize the command detection and flag-injection mechanisms so overrides/validation can apply to non-oracle tools used by Action Packs.

In Scope:
- Generalize `ExtractOracleInvocations` / `InjectFlags` to a small registry of command prefixes:
  - `oracle`, `codex`, `gemini`, `task-master`, `tm`
- Add per-tool override sets (so “Oracle Flags” semantics don’t incorrectly apply to other tools).
- Keep current oracle behavior intact.

Out of Scope:
- Implement-mode executor dispatch itself (handled in T3)
- Any new validation semantics beyond “oracle --dry-run summary” analogy (not provided)

Current Behavior (Actual):
- Special logic only for lines that start with `oracle`:
  - Invocation detection via regex anchored to literal `oracle`
  - Flag injection only into `oracle …` lines
  - Overrides validation runs `oracle --dry-run summary` only for detected oracle invocations

Expected Behavior:
- oraclepack recognizes multiple command prefixes for the purposes of overrides/flag handling and (where applicable) validation hooks, without breaking existing oracle behavior.

Reproduction Steps:
- Not provided

Requirements / Constraints:
- Must not regress oracle detection/injection/validation behavior.
- Registry-based handling for additional tool prefixes as listed in the ticket text.

Evidence:
- References: “special logic only for lines that start with `oracle`… detects… injects… validation runs `oracle --dry-run summary`…”
- References: “Optional: improve oraclepack UX… registry of command prefixes… Add per-tool override sets…”

Open Items / Unknowns:
- Exact code locations for `ExtractOracleInvocations` / `InjectFlags` and override sets in the repo (paths not provided in this ticket text).

Risks / Dependencies:
- Not required to make Action Packs execute non-oracle tools; explicitly described as “nice-to-have”.
- Potential semantic mismatch if oracle-style overrides are applied to other CLIs without per-tool override sets.

Acceptance Criteria:
- oraclepack supports a registry of command prefixes including: `oracle`, `codex`, `gemini`, `task-master`, `tm`.
- Overrides/flag injection is not hard-coded to only `oracle` command lines.
- Per-tool override sets exist (or equivalent structure) so overrides are not incorrectly treated as “Oracle Flags” for non-oracle tools.
- Existing oracle-only behavior remains functional.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Oraclepack executes each step as shell, but it has special logic only for lines that start with `oracle`”
- “Generalize `ExtractOracleInvocations` / `InjectFlags`… registry of command prefixes (`oracle`, `codex`, `gemini`, `task-master`, `tm`)”
- “Add per-tool override sets…”
```

[1]: https://developers.openai.com/codex/cli/reference/?utm_source=chatgpt.com "Command line options"
[2]: https://geminicli.com/docs/tools/?utm_source=chatgpt.com "Gemini CLI tools"
[3]: https://github.com/eyaltoledano/claude-task-master?utm_source=chatgpt.com "eyaltoledano/claude-task-master"
```

.tickets/actions/Oraclepack Compatibility Issues.md
```
Parent Ticket:

* Title: Oraclepack Actionpack Compatibility: non-`oracle` tools execution, dispatcher/overrides gaps, and adding Codex/Gemini headless steps
* Summary:

  * There is confusion about whether oraclepack can run Action Packs that include non-`oracle` commands (e.g., `task-master` / `tm`, `codex`, `gemini`). The current behavior is that oraclepack executes each step as shell (`bash -lc ...`) and only applies oracle-specific injection/validation to commands that begin with `oracle`. The request also includes adding headless `gemini` + non-interactive `codex exec` automation into the placeholder steps of `ticket-action-pack.md`, and optionally extending this pattern to taskify-generated packs.
* Source:

  * Link/ID: Not provided
  * Original ticket excerpt (≤25 words) capturing the overall theme: “injects flags into commands that begin with `oracle`… does not match `tm`, `codex`, `gemini`… won’t dispatch/wrap non-`oracle` commands” (per file)
* Global Constraints:

  * Action Pack is “oraclepack-ingestible” (single `bash` fence, `# NN)` steps) (per file)
  * Do not assume oraclepack overrides apply to non-`oracle` commands (per file)
* Global Environment:

  * Steps run via `bash -lc ...` in the project root; oraclepack does not change `WorkDir` to `out_dir` (per file)
  * ROI filter behavior may skip steps with no `ROI=` if a threshold > 0 is used (per file)
* Global Evidence:

  * References: `oracle_pack_and_taskify-skills.md`, `oraclepack-tui.md`, `ticket-action-pack.md` (per file)
  * Noted behaviors: oracle-only regex targeting; override validation runs `oracle --dry-run summary` on detected oracle invocations (per file)
  * Mentioned outputs: `.oraclepack/ticketify/_tickets_index.json`, `_actions.json`, `_actions.md`, `.taskmaster/docs/tickets_prd.md`, `.oraclepack/ticketify/tm-complexity.json`, `ticket-action-pack.state.json`, `ticket-action-pack.report.json` (per file)

Split Plan:

* Coverage Map:

  * “oraclepack runs each step as a bash script (`bash -lc <step script>`).” → T1
  * “injects flags into commands that begin with `oracle`… regex anchored to `^(\\s*)(oracle)\\b`.” → T2
  * “TUI override validation… runs `oracle --dry-run summary`… skips steps without oracle invocations.” → T2
  * “`tm` / `task-master` run directly… not routed through oracle.” → T1
  * “If you manually add `codex` / `gemini` lines… oraclepack will try to run them directly.” → T1
  * “If CLI isn’t installed/on PATH → step fails; if interactive → blocks.” → T3
  * “If you don’t add those commands… pack mainly uses `oracle` + Task Master; won’t ‘implement’ via Codex/Gemini.” → T1
  * `ticket-action-pack.md` Step 01 writes `.oraclepack/ticketify/_tickets_index.json` → Info-only
  * `ticket-action-pack.md` Step 02 writes `_actions.json` + `_actions.md` → Info-only
  * `ticket-action-pack.md` Step 03 writes `.taskmaster/docs/tickets_prd.md` → Info-only
  * `ticket-action-pack.md` Steps 05–07 run `task-master parse-prd`, `analyze-complexity`, `expand --all` and write `.oraclepack/ticketify/tm-complexity.json` → Info-only
  * “Steps 08–20 are placeholders/notes (echo guidance).” → T3
  * “Best insertion points… placeholder steps (09–13 and 16).” → T3
  * Step 09: Gemini headless selects next target, writes `.oraclepack/ticketify/next.json` → T3
  * Step 10: `codex exec` implements selected action, writes `.oraclepack/ticketify/codex-implement.md` → T3
  * Step 11: verification via `codex exec` and/or Gemini diff review, writes `.oraclepack/ticketify/codex-verify.md` and/or `.oraclepack/ticketify/gemini-review.json` → T3
  * Step 16: Gemini drafts PR body, writes `.oraclepack/ticketify/PR.md` → T3
  * “Optional… add an agent-mode to oraclepack-taskify packs… keep 20-step contract intact.” → T4
  * “Key constraint… overrides only target commands that begin with `oracle`; codex/gemini won’t inherit unless wrap/extend oraclepack.” → T2
  * Failure notes: missing `.tickets/`, missing `task-master` / provider keys, ROI filter gotcha → T1
* Dependencies:

  * T3 depends on T2 because codex/gemini steps will not participate in oraclepack override injection/validation unless oraclepack is extended beyond `oracle`-prefixed commands (per file).
  * T4 depends on T2 for the same reason (per file).
* Split Tickets:

```ticket T1
T# Title:
- Clarify current oraclepack Action Pack execution semantics (and common failure modes)

Type:
- docs

Target Area:
- oraclepack CLI/TUI user-facing documentation (exact file(s) not provided)

Summary:
- Document the current behavior that oraclepack executes Action Pack steps as `bash -lc ...` and only applies oracle-specific behavior to `oracle`-prefixed commands. Capture practical implications for running packs containing `task-master`/`tm`, `codex`, and `gemini`, including common failure modes and the ROI filter gotcha noted in the ticket content.

In Scope:
- Document that steps execute as shell (`bash -lc ...`) and whatever commands appear in the step body are executed.
- Document that non-`oracle` commands (`task-master`/`tm`, `codex`, `gemini`) run directly and are not routed through oracle.
- Document the “interactive CLI can block” and “missing binary on PATH fails the step” implications.
- Document `ticket-action-pack.md` likely failure points called out: missing `.tickets/`, missing `task-master`/provider configuration/API keys, ROI filter gotcha.
- Document that Steps 08–20 are placeholders unless replaced with real commands.

Out of Scope:
- Changing oraclepack dispatcher / override injection logic.
- Editing `ticket-action-pack.md` steps to add new automation.

Current Behavior (Actual):
- Confusion among reviewers/users about whether oraclepack “runs everything through oracle.”
- Running packs without `oracle ...` commands results in no oracle-specific override behavior being applied.

Expected Behavior:
- A clear, discoverable doc section explains what oraclepack does/does not do with non-`oracle` commands and how to interpret failures.

Reproduction Steps:
- Not provided.

Requirements / Constraints:
- Preserve the current semantics described in the ticket content (no implied change to execution model).

Evidence:
- “oraclepack runs each step as a bash script (`bash -lc <step script>`).”
- “If the CLI is interactive → it will block waiting for input.”
- “ROI filter gotcha… steps with no `ROI=`… may be skipped.”

Open Items / Unknowns:
- Where documentation should live (README, `oraclepack-tui.md`, or other) is not provided.
- Whether this should be shown in TUI help text vs repository docs is not provided.

Risks / Dependencies:
- Not provided.

Acceptance Criteria:
- Documentation explicitly states:
  - Steps execute via `bash -lc ...` and run the literal commands present.
  - Only `oracle`-prefixed commands receive oraclepack’s special handling.
  - Non-`oracle` tools (`tm`/`task-master`, `codex`, `gemini`) run directly (PATH/interactive caveats included).
  - The listed failure modes and ROI filter gotcha are described with practical guidance.
- Documentation includes a short “What to expect after running `ticket-action-pack.md`” section referencing the artifact paths named in the ticket content.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “oraclepack runs each step as a bash script (`bash -lc <step script>`).”
- “injects flags into commands that begin with `oracle`… does not match `tm`, `codex`, `gemini`.”
- “ROI filter gotcha… steps with no `ROI=`… may be skipped.”
```

```ticket T2
T# Title:
- Extend oraclepack override injection/validation beyond `oracle`-prefixed commands (dispatcher changes)

Type:
- enhancement

Target Area:
- oraclepack command detection + overrides/validation pipeline (regex/dispatch behavior; exact file paths not provided)

Summary:
- The current oraclepack behavior applies oracle-specific transforms only to commands that begin with `oracle` and the TUI override validation only targets oracle invocations. Implement “dispatcher changes” so that non-`oracle` commands (explicitly referenced: `tm`/`task-master`, `codex`, `gemini`) can participate in the same override/validation flow, or otherwise be handled explicitly as first-class command targets.

In Scope:
- Update command detection so it is not limited to `oracle` (currently anchored to `^(\\s*)(oracle)\\b` per the ticket text).
- Update override validation so it does not only run `oracle --dry-run summary` on detected oracle invocations and skip steps without oracle invocations.
- Ensure steps containing `tm`/`task-master`, `codex`, and/or `gemini` can be detected for dispatcher/validation purposes (as described in the ticket content).

Out of Scope:
- Adding new `codex exec` / `gemini` automation steps to specific packs (handled in T3).
- Changing Task Master’s behavior or requirements.

Current Behavior (Actual):
- Flag injection “only… injects flags into commands that begin with `oracle`… does not match `tm`, `task-master`, `codex`, `gemini`.”
- TUI override validation “only targets `oracle` commands… runs `oracle --dry-run summary`… steps without oracle invocations are skipped.”

Expected Behavior:
- Dispatcher/override handling is not limited to `oracle`-prefixed commands for the explicitly mentioned tool commands, so non-`oracle` steps are not silently excluded from override/validation.

Reproduction Steps:
- Not provided.

Requirements / Constraints:
- Must preserve existing `oracle` command behavior.
- Must address the limitation called out: overrides/validation currently only target `oracle` commands.

Evidence:
- “injects flags into commands that begin with `oracle` (regex… `^(\\s*)(oracle)\\b`).”
- “override validation… runs `oracle --dry-run summary`… steps without oracle invocations are skipped.”
- “codex/gemini won’t inherit oraclepack overrides unless you wrap them yourself or extend oraclepack.”

Open Items / Unknowns:
- Exact desired behavior for applying overrides to `tm`/`task-master`, `codex`, and `gemini` is not provided (which flags apply, how validation works).
- Whether the dispatcher should “interpret actions” vs only broaden prefix-based detection is not provided.

Risks / Dependencies:
- Risk: unclear spec for how overrides should apply to each non-`oracle` tool could lead to partial/incorrect behavior.

Acceptance Criteria:
- A pack step containing at least one of the referenced non-`oracle` command prefixes (`tm`/`task-master`, `codex`, `gemini`) is no longer automatically excluded from the override/validation pipeline solely due to not starting with `oracle`.
- Existing behavior for `oracle`-prefixed commands remains unchanged.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “injects flags into commands that begin with `oracle`… does not match `tm`, `codex`, `gemini`.”
- “override validation… only targets `oracle` commands… steps without oracle invocations are skipped.”
- “codex/gemini won’t inherit oraclepack overrides unless you wrap them yourself or extend oraclepack.”
```

```ticket T3
T# Title:
- Replace `ticket-action-pack.md` placeholder steps with headless Gemini + non-interactive Codex automation

Type:
- enhancement

Target Area:
- `ticket-action-pack.md` (ticketify Action Pack content/template; exact generator location not provided)

Summary:
- Steps 08–20 are described as placeholders/notes that only echo guidance. Replace specific placeholder steps (explicitly called out: 09–13 and 16) to add end-to-end automation using headless `gemini` and `codex exec`, producing machine-readable and human-readable artifacts under `.oraclepack/ticketify/`.

In Scope:
- Step 09: Add headless `gemini` selection that writes `.oraclepack/ticketify/next.json`.
- Step 10: Add non-interactive `codex exec` implementation that consumes `next.json` and writes `.oraclepack/ticketify/codex-implement.md`.
- Step 11: Add verification automation via `codex exec` and/or Gemini diff review:
  - `.oraclepack/ticketify/codex-verify.md` and/or `.oraclepack/ticketify/gemini-review.json`.
- Step 16: Add PR draft automation that writes `.oraclepack/ticketify/PR.md`.
- Include command-availability guards and “skip” behavior as shown in the referenced step snippets (e.g., `command -v ...` checks) to avoid hard failures when tools are missing.

Out of Scope:
- Changing Steps 01–07 semantics (ticket discovery/actions/PRD/Task Master parse/complexity/expand).
- Extending oraclepack’s override injection/validation to cover `codex`/`gemini` (handled in T2).

Current Behavior (Actual):
- Steps 08–20 “are effectively placeholders/notes (echo guidance)” and “don’t dispatch Codex/Gemini or implement code unless the step body explicitly contains those commands.”
- If `codex`/`gemini` are added and the binary is missing → step fails; if interactive → blocks.

Expected Behavior:
- Running the updated steps produces the specified `.oraclepack/ticketify/*` artifacts and enables a headless “select → implement → verify → draft PR” workflow driven by the earlier-generated ticketify outputs.

Reproduction Steps:
- Not provided.

Requirements / Constraints:
- Must write the artifacts to the paths specified in the step examples (e.g., `.oraclepack/ticketify/next.json`, `codex-implement.md`, `codex-verify.md`, `gemini-review.json`, `PR.md`).
- Must tolerate missing `codex`/`gemini` binaries via skip behavior (per the example snippets).

Evidence:
- “Best insertion points are the placeholder steps… (09–13 and 16).”
- Step outputs in examples:
  - “Wrote .oraclepack/ticketify/next.json”
  - “Wrote .oraclepack/ticketify/codex-implement.md”
  - “Wrote .oraclepack/ticketify/codex-verify.md”
  - “Wrote .oraclepack/ticketify/gemini-review.json”
  - “Wrote .oraclepack/ticketify/PR.md”
- “If the CLI is interactive → it will block waiting for input.”

Open Items / Unknowns:
- Whether Step 11 should use Codex execution, Gemini review, or both by default is not provided.
- Whether Steps 12–13 should be modified (they are within the suggested 09–13 range but specifics are not included in the provided snippets).

Risks / Dependencies:
- Depends on T2 if these steps must participate in oraclepack’s overrides/validation system (otherwise, they run as direct shell commands).
- Risk: tool interactivity can block runs if headless/non-interactive flags are not sufficient (noted in the ticket content).

Acceptance Criteria:
- After running Step 09, `.oraclepack/ticketify/next.json` exists.
- After running Step 10 (with Step 09 completed), `.oraclepack/ticketify/codex-implement.md` exists.
- After running Step 11, at least one of:
  - `.oraclepack/ticketify/codex-verify.md` or `.oraclepack/ticketify/gemini-review.json`
  exists (as configured by the updated pack).
- After running Step 16, `.oraclepack/ticketify/PR.md` exists.
- If `codex` is not available on PATH, Step 10 and any Codex-based Step 11 behavior performs the documented skip behavior (no hard crash beyond what the step defines).
- If `gemini` is not available on PATH, Step 09/16 and any Gemini-based Step 11 behavior performs the documented skip behavior.

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Steps 08–20… placeholders/notes… don’t dispatch Codex/Gemini… unless… contains the actual `codex` / `gemini` commands.”
- “Best insertion points… placeholder steps… (09–13 and 16).”
- “If the CLI is interactive → it will block waiting for input.”
```

```ticket T4
T# Title:
- Add “agent-mode” to oraclepack-taskify Action Pack generation (Codex/Gemini path in place of autopilot)

Type:
- enhancement

Target Area:
- oraclepack-taskify Action Pack template/generator (exact file paths not provided)

Summary:
- Extend taskify-generated Action Packs so they can optionally use an “agent-mode” (e.g., `mode=codex` / `mode=gemini`) in the phase after Task Master has expanded tasks (when `tasks.json` and `tm-complexity.json` exist). The ticket text specifies keeping the 20-step contract intact by swapping the existing autopilot entrypoint step slot with agent implementation.

In Scope:
- Add a mode switch for taskify-generated packs (explicitly suggested: `mode=codex` / `mode=gemini`).
- Place the agent-mode insertion “right after Task Master expands tasks” (per ticket content).
- Keep the “20-step contract intact” by swapping “autopilot entrypoint” with “agent implementation” using the same step slot (per ticket content).

Out of Scope:
- Modifying `ticket-action-pack.md` (handled in T3).
- Defining new Task Master workflows beyond what is described.

Current Behavior (Actual):
- Taskify Action Pack can include a “guarded `tm autopilot` entrypoint” (per ticket content).
- Without dispatcher/agent commands in steps, no Codex/Gemini implementation occurs (per ticket content).

Expected Behavior:
- A taskify-generated Action Pack can be generated in an agent-mode that uses Codex/Gemini implementation in the appropriate step slot while retaining the existing step-count/schema contract.

Reproduction Steps:
- Not provided.

Requirements / Constraints:
- Maintain the existing pack schema/contract: “keeping the 20-step contract intact” (per ticket content).
- Agent-mode placement occurs after Task Master expansion (“the point where you have `tasks.json` and `tm-complexity.json`”) (per ticket content).

Evidence:
- “Optional… add an agent-mode to oraclepack-taskify packs… right after Task Master expands tasks… keep the 20-step contract intact.”
- “swap ‘autopilot entrypoint’ with ‘agent implementation’ using the same step slot.”

Open Items / Unknowns:
- How the mode is selected (CLI flag, TUI option, config) is not provided in the included content.
- Exact step number/slot to replace is not provided.

Risks / Dependencies:
- Depends on T2 if Codex/Gemini calls must receive oraclepack overrides/validation (per ticket’s “won’t inherit unless wrap/extend” note).

Acceptance Criteria:
- There is a documented/implemented way to generate a taskify Action Pack in `mode=codex` and/or `mode=gemini`.
- In agent-mode, the pack still conforms to the same step-count contract described in the ticket content (20 steps; autopilot entrypoint swapped rather than expanded beyond contract).
- Agent-mode insertion occurs after Task Master task expansion artifacts exist (as described in the ticket content).

Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided

Source:
- “Optional… add an agent-mode to oraclepack-taskify packs… right after Task Master expands tasks… keep the 20-step contract intact.”
- “swap ‘autopilot entrypoint’ with ‘agent implementation’ using the same step slot.”
```
```

.tickets/mcp/Expose Oraclepack as MCP.md
```
Parent Ticket:

* Title: Expose oraclepack as MCP tools (with Taskify Stage-2/Stage-3 helpers)
* Summary: Provide an MCP server that exposes `oraclepack` CLI capabilities (validate/list/run) plus helper tools for Stage-2 detection/validation and Stage-3 action-pack validation/execution/artifact summarization, with secure-by-default controls (allowlisted filesystem roots, execution gating, timeouts, truncation) and support for stdio + streamable-http transports.
* Source:

  * Link/ID (if present) or “Not provided”: /mnt/data/MCP tools for Oraclepack.md
  * Original ticket excerpt (≤25 words) capturing the overall theme: “Expose `oraclepack` … as **MCP tools**, so an agent can … run packs … validate Stage-2 … validate Stage-3 … summarize artifacts.”
* Global Constraints:

  * Support MCP transports: “stdio” and “streamable-http”.
  * Security defaults: “deny-by-default execution”, “allowlisted roots”, “stdout/stderr truncation and timeouts”.
* Global Environment:

  * Unknown
* Global Evidence:

  * MCP tool list and env var config list.
  * Reference implementation structure (README/requirements and Python modules).

Split Plan:

* Coverage Map:

  * “Expose `oraclepack` (validate/list/run) … as **MCP tools**” → T1
  * “run packs non-interactively (`--no-tui --yes --run-all`)” → T5
  * “validate Stage-2 outputs (01-*.md..20-*.md)” → T4
  * “validate Stage-3 Action Packs (single ```bash fence, step headers…)” → T7
  * “summarize Stage-3 artifacts (`_actions.json`, PRD, Task Master outputs, etc.)” → T7
  * “Tools: oraclepack_validate_pack / oraclepack_list_steps / oraclepack_run_pack …” → T5
  * “Tools: oraclepack_read_file …” → T5
  * “Tools: … taskify_detect_stage2 / taskify_validate_stage2 …” → T5
  * “Tools: … taskify_validate_action_pack / taskify_artifacts_summary …” → T5
  * “Tools: … taskify_run_action_pack …” → T5
  * “Transports: stdio … streamable-http …” → T6
  * “Tool annotations: readOnlyHint / destructiveHint / openWorldHint …” → T6
  * “Security defaults: ORACLEPACK_ENABLE_EXEC=1 gating …” → T2
  * “Security defaults: allowlisted filesystem roots …” → T2
  * “Security defaults: truncation and timeouts …” → T3
  * “Env vars: ORACLEPACK_ALLOWED_ROOTS / BIN / WORKDIR / ENABLE_EXEC / CHARACTER_LIMIT / MAX_READ_BYTES” → T2
  * “Typical Stage-3 usage: detect/validate → validate action pack → run → summarize” → Info-only
  * “Reference implementation tree (README, requirements.txt, modules list)” → Info-only
  * Links to MCP specs / python-sdk repo mentioned → Info-only
* Dependencies:

  * T5 depends on T2 because server tools must enforce allowed roots and execution gating.
  * T5 depends on T3 because `oraclepack_*run*` tools need subprocess execution with timeouts/truncation.
  * T5 depends on T4 because `oraclepack_taskify_*stage2*` tools call Stage-2 detection/validation.
  * T5 depends on T7 because `oraclepack_taskify_*action_pack*` tools call action-pack validation/summarization helpers.
  * T6 depends on T5 because annotations/transport-hardening apply to the MCP server surface.
* Split Tickets:

```ticket T1
T# Title: Scaffold oraclepack MCP server project (README + packaging entrypoints)
Type: chore
Target Area: oraclepack-mcp-server repo scaffolding (README.md, requirements.txt, __init__.py, __main__.py)
Summary:
- Create the MCP server project structure that exposes `oraclepack` + Taskify helpers as MCP tools, including installation and run instructions and the tool list.
- Ensure the package has an executable entrypoint to start the MCP server with selectable transport.
In Scope:
- Create/maintain project tree with:
  - README describing purpose, install, configuration env vars, run modes, tools list, and typical Stage-3 usage.
  - requirements.txt listing dependencies.
  - Python package layout with `oraclepack_mcp_server/__init__.py` and `oraclepack_mcp_server/__main__.py`.
- CLI args in `__main__.py` to accept `--transport` with choices `stdio` and `streamable-http`.
Out of Scope:
- Implementing tool logic (handled in other tickets).
Current Behavior (Actual):
- Not provided.
Expected Behavior:
- A runnable package that starts an MCP server with a chosen transport.
Reproduction Steps:
- Not provided.
Requirements / Constraints:
- Must support `--transport` choices: `stdio`, `streamable-http`.
Evidence:
- Project tree and entrypoint snippet showing `choices=["stdio", "streamable-http"]`. :contentReference[oaicite:26]{index=26}
Open Items / Unknowns:
- Exact repository root / packaging approach (pip package vs repo-local module): Not provided.
Risks / Dependencies:
- Not provided.
Acceptance Criteria:
- [ ] Repository includes README.md, requirements.txt, and `oraclepack_mcp_server` package directory.
- [ ] Running `python -m oraclepack_mcp_server --transport stdio` is supported (starts server process).
- [ ] Running `python -m oraclepack_mcp_server --transport streamable-http` is supported (starts server process).
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “oraclepack-mcp-server (MCP wrapper for oraclepack + taskify helpers) … tree … README.md … requirements.txt … __main__.py” :contentReference[oaicite:27]{index=27}
- “choices=[‘stdio’, ‘streamable-http’] … mcp.run(transport=args.transport)” :contentReference[oaicite:28]{index=28}
```

```ticket T2
T# Title: Implement config + filesystem security controls (allowed roots, exec gating, max read bytes)
Type: chore
Target Area: oraclepack_mcp_server/config.py and oraclepack_mcp_server/security.py
Summary:
- Implement secure-by-default configuration for the MCP server, driven by environment variables, including allowlisted filesystem roots and explicit execution enablement.
- Provide safe path resolution under allowed roots and bounded file reads for tool operations.
In Scope:
- Env-driven config including:
  - `ORACLEPACK_ALLOWED_ROOTS` (colon-separated roots)
  - `ORACLEPACK_BIN`
  - `ORACLEPACK_WORKDIR`
  - `ORACLEPACK_ENABLE_EXEC`
  - `ORACLEPACK_CHARACTER_LIMIT`
  - `ORACLEPACK_MAX_READ_BYTES`
- Path allowlisting:
  - Resolve requested file paths and ensure they live under at least one allowed root.
  - Raise an explicit “path not allowed” error on violation.
- Safe file reads:
  - Read text/bytes with max size enforcement and “truncated” indicator.
Out of Scope:
- Subprocess execution and output truncation (handled in T3).
Current Behavior (Actual):
- Not provided.
Expected Behavior:
- Server loads config from env and enforces filesystem access boundaries for read tools.
Reproduction Steps:
- Not provided.
Requirements / Constraints:
- Execution must be deny-by-default unless `ORACLEPACK_ENABLE_EXEC=1`.
- Filesystem access must be restricted to allowlisted roots.
Evidence:
- Env var list and semantics. :contentReference[oaicite:29]{index=29}
- Security guidance: “deny-by-default execution … allowlisted roots”. :contentReference[oaicite:30]{index=30}
Open Items / Unknowns:
- Whether Windows path separator support is required for `ORACLEPACK_ALLOWED_ROOTS`: Not provided.
Risks / Dependencies:
- Not provided.
Acceptance Criteria:
- [ ] Config loader reads the listed env vars and applies defaults as documented.
- [ ] Path resolution rejects paths outside allowed roots.
- [ ] File reads enforce max bytes and indicate truncation.
- [ ] Exec gating flag is available for run tools to check.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Environment variables: ORACLEPACK_ALLOWED_ROOTS … ORACLEPACK_ENABLE_EXEC … ORACLEPACK_MAX_READ_BYTES …” :contentReference[oaicite:31]{index=31}
- “Hard deny-by-default execution … Restrict filesystem access to allowlisted roots …” :contentReference[oaicite:32]{index=32}
```

```ticket T3
T# Title: Implement oraclepack subprocess runner with timeouts and stdout/stderr truncation
Type: chore
Target Area: oraclepack_mcp_server/oraclepack_cli.py (subprocess execution)
Summary:
- Provide a subprocess wrapper to invoke the `oraclepack` CLI with a hard timeout and bounded stdout/stderr capture to prevent wedging the MCP server.
- Return structured results including exit code, duration, and truncation indicators.
In Scope:
- Async subprocess execution wrapper (create subprocess, capture stdout/stderr).
- Timeout behavior:
  - Kill process on timeout and return an explicit “Timed out after {timeout}s” error result.
- Character-limit truncation for stdout/stderr based on configured limit.
Out of Scope:
- MCP tool registration (handled in T5).
Current Behavior (Actual):
- Not provided.
Expected Behavior:
- Running oraclepack commands yields deterministic, bounded outputs suitable for returning via MCP tools.
Reproduction Steps:
- Not provided.
Requirements / Constraints:
- Must enforce “stdout/stderr truncation and timeouts”.
Evidence:
- Guidance: “Enforce stdout/stderr truncation and timeouts …”. :contentReference[oaicite:33]{index=33}
- Runner timeout error example snippet. :contentReference[oaicite:34]{index=34}
Open Items / Unknowns:
- Default timeout values per tool beyond examples (3600/7200) are not provided outside snippets.
Risks / Dependencies:
- Not provided.
Acceptance Criteria:
- [ ] Runner returns: ok, exit_code, duration_s, stdout, stderr, stdout_truncated, stderr_truncated.
- [ ] Timeout produces exit_code=124 (or equivalent) and includes a timeout message.
- [ ] Outputs are truncated to configured character limit and flags are set accordingly.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Enforce stdout/stderr truncation and timeouts so a pack can’t wedge the server process.” :contentReference[oaicite:35]{index=35}
- “Timed out after {timeout_s}s: …” return structure snippet. :contentReference[oaicite:36]{index=36}
```

```ticket T4
T# Title: Implement Taskify Stage-2 detection and validation (01-*.md..20-*.md + single-pack form)
Type: chore
Target Area: oraclepack_mcp_server/taskify.py (Stage-2 detection + validation)
Summary:
- Implement deterministic detection of Stage-2 outputs for agents, supporting both directory-form outputs (01-*.md..20-*.md) and a single-pack input file form.
- Provide validation that ensures exactly one match per prefix 01..20 and returns missing/ambiguous details.
In Scope:
- `validate_stage2_dir(out_dir)`:
  - For each prefix 01..20, glob `{pfx}-*.md`
  - Return missing patterns and ambiguous prefix matches.
- `detect_stage2(stage2_path, repo_root)`:
  - Support explicit dir path.
  - Support explicit file path with out_dir rules:
    - If under `docs/oracle-questions-YYYY-MM-DD/…`, use sibling `oracle-out` under that docs subtree; else default `repo_root/oracle-out`.
  - Support “auto” discovery (best-effort, deterministic ordering), including checking `repo_root/oracle-out`.
Out of Scope:
- Stage-3 action pack validation (handled in T7).
Current Behavior (Actual):
- Not provided.
Expected Behavior:
- Agents can resolve and validate Stage-2 outputs deterministically for downstream Stage-3 workflows.
Reproduction Steps:
- Not provided.
Requirements / Constraints:
- “Detect Stage-2 outputs (dir-form 01-*.md..20-*.md OR single-pack form)”.
- “Validate Stage-2 outputs (exactly one match per prefix 01..20)”.
Evidence:
- Requirements text for Stage-2 detection/validation. :contentReference[oaicite:37]{index=37}
- Validation logic snippet for 01..20 and ambiguous/missing. :contentReference[oaicite:38]{index=38}
- Out-dir rule snippet referencing `docs/oracle-questions-YYYY-MM-DD/…` → `oracle-out`. :contentReference[oaicite:39]{index=39}
Open Items / Unknowns:
- Full “auto discovery” search order beyond checking `repo_root/oracle-out`: Not provided in visible excerpts.
Risks / Dependencies:
- Not provided.
Acceptance Criteria:
- [ ] Validation returns ok=false with `missing` when any prefix has no matches.
- [ ] Validation returns ok=false with `ambiguous` when any prefix has >1 match.
- [ ] Validation returns ok=true only when exactly one match exists for every prefix 01..20.
- [ ] Detection supports explicit dir and explicit file resolution and produces an `out_dir`.
- [ ] Detection supports “auto” and returns deterministic results for the same filesystem state.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Detect Stage-2 outputs (dir-form 01-*.md..20-*.md OR single-pack form) … Validate … exactly one match per prefix 01..20.” :contentReference[oaicite:40]{index=40}
- “out_dir rules … if under docs/oracle-questions-YYYY-MM-DD/ … then …/oracle-out else oracle-out” :contentReference[oaicite:41]{index=41}
```

```ticket T5
T# Title: Implement MCP tools for oraclepack and taskify helper operations
Type: enhancement
Target Area: oraclepack_mcp_server/server.py (MCP tool registration + schemas + formatting)
Summary:
- Implement the MCP server surface that maps `oraclepack` CLI operations and Taskify helper functions into callable MCP tools.
- Provide consistent response formatting (markdown/json) and ensure run tools respect execution gating.
In Scope:
- Tool schemas/inputs covering:
  - `oraclepack_validate_pack`
  - `oraclepack_list_steps`
  - `oraclepack_run_pack` (gated)
  - `oraclepack_read_file`
  - `oraclepack_taskify_detect_stage2`
  - `oraclepack_taskify_validate_stage2`
  - `oraclepack_taskify_validate_action_pack`
  - `oraclepack_taskify_artifacts_summary`
  - `oraclepack_taskify_run_action_pack` (gated)
- Response formatting:
  - Support JSON and Markdown result formats (including stdout/stderr blocks and truncation notes).
- CLI arg mapping for oraclepack operations (including references to flags like `--no-tui`, `--out-dir`, `--oracle-bin` as inputs or internal argv composition).
- Ensure `ORACLEPACK_ENABLE_EXEC=1` gating is enforced for run tools.
Out of Scope:
- Implementing the underlying Stage-2 detection/validation logic (T4) and Stage-3 validation/summary logic (T7), except wiring them in.
Current Behavior (Actual):
- Not provided.
Expected Behavior:
- MCP clients can invoke oraclepack and taskify workflows end-to-end via tools and receive bounded, formatted results.
Reproduction Steps:
- Not provided.
Requirements / Constraints:
- Must expose the tool list as stated.
- Run tools must be disabled by default unless enabled via env flag.
Evidence:
- Tool list and gating note. :contentReference[oaicite:42]{index=42}
- Server schema snippets (e.g., ReadFileInput, Taskify*Input, timeout defaults). :contentReference[oaicite:43]{index=43}
Open Items / Unknowns:
- Exact argument surface for `oraclepack_validate_pack` / `oraclepack_list_steps` (flags and required params) is not fully specified in excerpts.
Risks / Dependencies:
- Depends on config/security/runner/taskify modules existing and being wired correctly.
Acceptance Criteria:
- [ ] All tools listed in the parent ticket are registered and callable.
- [ ] `oraclepack_read_file` enforces allowed roots and max read bytes.
- [ ] `oraclepack_run_pack` and `oraclepack_taskify_run_action_pack` refuse execution unless `ORACLEPACK_ENABLE_EXEC=1`.
- [ ] Response formatter supports markdown and json outputs and includes truncation indicators.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Tools — oraclepack_validate_pack … oraclepack_taskify_run_action_pack (requires ORACLEPACK_ENABLE_EXEC=1)” :contentReference[oaicite:44]{index=44}
- “Map … oraclepack CLI capabilities (validate/list/run + flags like --no-tui, --out-dir, --oracle-bin) into MCP tools” :contentReference[oaicite:45]{index=45}
```

```ticket T6
T# Title: Add MCP transport hardening guidance + tool UX annotations (readOnly/destructive/openWorld)
Type: enhancement
Target Area: MCP server transport configuration and tool metadata (server.py / deployment guidance)
Summary:
- Ensure the MCP server supports stdio and streamable-http in a way suitable for “real-time” usage, including the recommended security posture for HTTP transport.
- Add MCP tool annotations so clients can present appropriate approval UX for read-only vs execution tools.
In Scope:
- Transport support considerations:
  - stdio: ensure logs go to stderr (per guidance in ticket text).
  - streamable-http: implement recommended protections (“Origin validation”, “bind to localhost + auth”).
- Tool annotations:
  - Mark validate/list/read tools as `readOnlyHint: true`.
  - Mark run tools as `destructiveHint: true` and `openWorldHint: true`.
Out of Scope:
- Implementing tool business logic (T5).
Current Behavior (Actual):
- Not provided.
Expected Behavior:
- MCP clients see proper tool risk hints and HTTP transport is protected as recommended for local/real-time usage.
Reproduction Steps:
- Not provided.
Requirements / Constraints:
- Must support “stdio” and “streamable-http”.
- Must provide tool annotations as described.
Evidence:
- Transport choices and HTTP security recommendations. :contentReference[oaicite:46]{index=46}
- Tool annotation guidance (readOnlyHint/destructiveHint/openWorldHint). :contentReference[oaicite:47]{index=47}
Open Items / Unknowns:
- Exact auth mechanism for streamable-http (token, mTLS, etc.): Not provided.
Risks / Dependencies:
- Depends on MCP SDK capabilities available in the chosen implementation.
Acceptance Criteria:
- [ ] Running with `--transport stdio` is supported and does not interleave logs on stdout.
- [ ] Running with `--transport streamable-http` includes Origin validation and uses localhost binding + authentication (mechanism documented/implemented).
- [ ] Validate/list/read tools are annotated as read-only; run tools are annotated as destructive/open-world.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Streamable HTTP … implement Origin validation and bind to localhost + auth to avoid DNS rebinding …” :contentReference[oaicite:48]{index=48}
- “mark validate/list/read tools as readOnlyHint … mark run tools as destructiveHint, openWorldHint …” :contentReference[oaicite:49]{index=49}
```

````ticket T7
T# Title: Implement Stage-3 Action Pack validation + artifact summarization helpers
Type: chore
Target Area: oraclepack_mcp_server/taskify.py (Stage-3 helpers) and wiring into server tools
Summary:
- Implement helper functions to validate Stage-3 “Action Pack” markdown constraints before execution and to summarize key Stage-3 artifacts produced by running action packs.
- These helpers support deterministic agent workflows around Taskify outputs.
In Scope:
- Action Pack validation logic:
  - Enforce “single ```bash fence” and “step headers” constraints as stated in the parent ticket.
- Artifacts summary logic:
  - Summarize outputs such as `_actions.json`, `_actions.md`, PRD path, `tm-complexity.json`, and “pipelines doc” when present.
- Integration points:
  - Provide outputs suitable for `oraclepack_taskify_validate_action_pack` and `oraclepack_taskify_artifacts_summary` tools (registered in T5).
Out of Scope:
- Stage-2 detection/validation (T4).
- Actual execution of action packs (tool wiring and subprocess invocation handled in T5/T3).
Current Behavior (Actual):
- Not provided.
Expected Behavior:
- Action packs can be validated for structural correctness prior to execution, and resulting artifacts can be summarized for quick agent consumption.
Reproduction Steps:
- Not provided.
Requirements / Constraints:
- Validate Stage-3 Action Pack “single ```bash fence, step headers `# NN)`”.
- Summarize Stage-3 artifacts: `_actions.json`, PRD path, `tm-complexity.json`, pipelines doc, etc.
Evidence:
- Stage-3 validation requirement text. :contentReference[oaicite:50]{index=50}
- Artifact summary examples list. :contentReference[oaicite:51]{index=51}
Open Items / Unknowns:
- Exact, formal grammar for “step headers” beyond the example text: Not provided.
- Exact artifact filenames/paths beyond examples: Not provided.
Risks / Dependencies:
- Not provided.
Acceptance Criteria:
- [ ] Validation fails with a clear error when the action pack violates the “single bash fence” constraint.
- [ ] Validation fails with a clear error when step headers do not meet the stated expectations.
- [ ] Artifact summarizer reports presence/absence of the example artifacts and returns a readable summary.
- [ ] Tool outputs are deterministic for the same filesystem state.
Priority & Severity (if inferable from input text):
- Priority: Not provided
- Severity: Not provided
Source:
- “Validate Stage-3 Action Pack … (single ```bash fence, step headers `# NN)` …)” :contentReference[oaicite:52]{index=52}
- “Summarize Stage-3 artifacts (e.g., `_actions.json`, `_actions.md`, PRD path, `tm-complexity.json`, pipelines doc)” :contentReference[oaicite:53]{index=53}
````
```

.tickets/mcp/MCP Server for Oraclepack.md
```
Title:

* Add MCP server that exposes `oraclepack` + Taskify Stage-2/Stage-3 helpers as tools for agents

Summary:

* Agents need real-time access to `oraclepack` capabilities via MCP so they can validate, inspect, and run packs, then consume Taskify artifacts produced by the `oracle_pack_and_taskify-skills.md` workflow.
* Implement a secure-by-default Python MCP server that wraps the `oraclepack` CLI and adds deterministic helpers for Stage-2 detection/validation and Stage-3 Action Pack validation/execution + artifact summarization.

Background / Context:

* Request: “give access to agents/assistants the following oraclepack tool as a MCP tool… so they can perform actions using the artifacts generated from `oracle_pack_and_taskify-skills.md` … in real time.”
* Proposed reference implementation (from the conversation) is a Python project named `oraclepack-mcp-server` using FastMCP (MCP Python SDK), supporting `stdio` and `streamable-http` transports.
* Stage-2 outputs are expected to be 20 markdown files matching `01-*.md` … `20-*.md`; Stage-2 “single-pack form” needs out-dir resolution rules when the pack lives under `docs/oracle-questions-YYYY-MM-DD/...`.

Current Behavior (Actual):

* No MCP tool surface is available for `oraclepack` and Taskify workflows (agents cannot call validated tools to run/inspect packs and artifacts). (per user)

Expected Behavior:

* Agents can use MCP tools to:

  * Validate and inspect packs.
  * Run packs non-interactively to generate artifacts.
  * Detect/validate Stage-2 outputs and validate Stage-3 Action Packs before execution.
  * Summarize Stage-3 artifacts for immediate downstream consumption.

Requirements:

* MCP server implementation

  * Provide a Python MCP server project structure (e.g., `oraclepack-mcp-server/` with `oraclepack_mcp_server/` package).
  * Support transports:

    * `stdio`
    * `streamable-http`
* Tool surface (MCP tools)

  * `oraclepack_validate_pack`
  * `oraclepack_list_steps`
  * `oraclepack_run_pack` (execution gated)
  * `oraclepack_read_file`
  * `oraclepack_taskify_detect_stage2`
  * `oraclepack_taskify_validate_stage2`
  * `oraclepack_taskify_validate_action_pack`
  * `oraclepack_taskify_artifacts_summary`
  * `oraclepack_taskify_run_action_pack` (execution gated)
* Execution + safety controls

  * Deny-by-default execution; require `ORACLEPACK_ENABLE_EXEC=1` to enable “run” tools.
  * Restrict filesystem reads to allowlisted roots via `ORACLEPACK_ALLOWED_ROOTS` (colon-separated); block paths outside allowed roots.
  * Enforce timeouts and truncate stdout/stderr (`ORACLEPACK_CHARACTER_LIMIT`) and cap file read sizes (`ORACLEPACK_MAX_READ_BYTES`).
* Stage-2 reliability helpers

  * Validate Stage-2 directory contains exactly one match per prefix `01`..`20` (missing/ambiguous detection).
  * Deterministic Stage-2 detection:

    * Accept explicit dir or file.
    * If file is under `docs/oracle-questions-YYYY-MM-DD/...`, set out-dir to `docs/oracle-questions-YYYY-MM-DD/oracle-out`; otherwise default `repo_root/oracle-out`.
* Stage-3 reliability helpers

  * Validate Action Pack structure constraints before executing (e.g., “single ```bash fence, step headers”).
  * Summarize produced artifacts (examples cited: `_actions.json`, PRD path, Task Master outputs).
* Agent UX metadata

  * Apply MCP tool annotations:

    * validate/list/read: `readOnlyHint: true`
    * run: `destructiveHint: true`, `openWorldHint: true`

Out of Scope:

* Not provided.

Reproduction Steps:

* Not provided.

Environment:

* Language/runtime: Python (MCP server), wraps external `oraclepack` CLI.
* OS: Unknown
* Deployment: Unknown (local stdio vs HTTP service)
* MCP SDK version: Unknown (example uses `mcp>=1.0.0`, `pydantic>=2.0.0`).

Evidence:

* Conversation transcript + proposed reference implementation: `/mnt/data/MCP tools for Oraclepack.md`.
* Proposed env vars and tool list (deny-by-default exec, allowed roots, transports).
* Stage-2 directory validation (`01-*.md..20-*.md`) and Stage-2 out-dir resolution logic for `docs/oracle-questions-YYYY-MM-DD`.

Decisions / Agreements:

* Use a Python MCP server (FastMCP / MCP Python SDK) to expose `oraclepack` CLI + Taskify helpers.
* Support both `stdio` and `streamable-http` transports.
* Default-secure posture: execution gated by `ORACLEPACK_ENABLE_EXEC`, filesystem access constrained by allowlisted roots, truncation + timeout enforced.

Open Items / Unknowns:

* Where this MCP server should live (same repo as `oraclepack` vs separate repo) is not provided.
* Authentication / origin validation requirements for `streamable-http` deployment are mentioned conceptually but concrete requirements are not provided.
* Exact definition of “artifacts summary” contents/format beyond examples (`_actions.json`, PRD, Task Master outputs) is not provided.
* Whether `oraclepack_run_pack` must always use `--no-tui --yes --run-all` vs configurable flags is not provided (example suggests non-interactive flags).

Risks / Dependencies:

* Dependency on external `oraclepack` binary path/config (`ORACLEPACK_BIN`) and correct working directory (`ORACLEPACK_WORKDIR`).
* Security risk if exec is enabled without strict path/root controls and timeouts; mitigations are required as above.
* Stage-2 ambiguity risk when multiple `NN-*.md` match the same prefix; must report ambiguity deterministically and fail validation.

Acceptance Criteria:

* [ ] MCP server starts successfully in both `stdio` and `streamable-http` modes.
* [ ] All listed tools are exposed with the documented names.
* [ ] When `ORACLEPACK_ENABLE_EXEC!=1`, run tools refuse to execute and return a clear error; validate/list/read tools still work.
* [ ] `oraclepack_read_file` rejects paths outside `ORACLEPACK_ALLOWED_ROOTS`.
* [ ] Stage-2 validation enforces exactly one file per prefix `01`..`20` and returns `missing` and `ambiguous` sets when invalid.
* [ ] Stage-2 detection resolves out-dir correctly for both:

  * explicit dir inputs
  * single-pack file under `docs/oracle-questions-YYYY-MM-DD/...` → `docs/oracle-questions-YYYY-MM-DD/oracle-out`
  * otherwise default `repo_root/oracle-out`.
* [ ] stdout/stderr truncation and timeouts are enforced on CLI subprocess execution.
* [ ] Tool annotations are applied as specified for read-only vs destructive tools.

Priority & Severity (if inferable from text):

* Not provided.

Labels (optional):

* enhancement
* mcp
* oraclepack
* cli-wrapper
* taskify
* security
* tooling
```

.tickets/mcp/gaps-still-not-covered.md
```
## Gaps still not covered in the current oraclepack MCP proposal

### Transport + deployment correctness

* **`--transport streamable-http` is wired to the wrong FastMCP transport.** The proposal claims `transport="sse"` “maps to streamable-http”, but FastMCP supports Streamable HTTP explicitly and documents SSE as being superseded.  ([GitHub][1])
* **No production-grade HTTP hardening (auth, TLS posture, DNS-rebinding mitigations).** MCP security guidance explicitly warns about local HTTP servers (SSE/Streamable HTTP) without auth and recommends stdio or authenticated IPC/HTTP with mitigations. ([Model Context Protocol][2])
* **Dependency is unpinned despite a high-severity DNS rebinding advisory in the Python SDK.** The proposal uses `mcp[cli]>=0.1.0` (no minimum safe version). The advisory indicates affected versions and a patched release.  ([GitHub][3])

### Security model gaps (filesystem + execution)

* **Symlink escape is not addressed.** `validate_path()` normalizes with `abspath/normpath` and then `safe_read_file()` opens the path; this pattern typically allows “inside-root symlink → outside-root target” unless you resolve and check the realpath. No test covers symlink traversal.
* **Execution is only gated by a boolean env flag, without least-privilege scoping.** The server exposes “run pack” as open-world/destructive when enabled, but does not add per-tool scoping, allowlists, or authorization flows for HTTP mode.  ([Model Context Protocol][2])

### Parity gaps vs oraclepack TUI/runner workflows

* **No URL/project selection tooling exposed.** The TUI has explicit URL store + picker plumbing (the thing you need for “choose PRD-generator project URL”), but MCP doesn’t expose tools to list/select/manage those URLs.
* **No runtime overrides wizard parity.** The TUI supports an overrides flow (per-step flag add/remove, targeting, validation), but MCP doesn’t expose “get overrides / set overrides / validate overrides / apply and run”.
* **No structured access to run state/report artifacts.** MCP returns raw stdout/stderr strings and truncates them; it doesn’t provide first-class tools/resources for reading the oraclepack state/report outputs as structured objects.

### Execution control + UX gaps for agents

* **No step-level execution controls.** The MCP API offers `oraclepack_run_pack(... run_all=True)` but does not provide “run step N”, “run subset”, “resume”, “re-run failed only”, etc.
* **No streaming logs / cancellation.** `run_oraclepack()` waits for completion, then returns (with truncation). There’s no incremental progress, no cancellation hook, and timeout uses a hard kill only.

### Validation gaps (especially for “ticket-action-pack.md” style artifacts)

* **Action-pack validation in MCP is weaker than your existing validator script.** The MCP `validate_action_pack` logic is comparatively minimal, while the repo’s `validate-action-pack.sh` encodes stricter structural rules; MCP does not currently match those guardrails.

### Capability gaps (authoring/editing)

* **No “write/update pack” capability.** The server can read/list/validate/run packs, but cannot create/edit packs or write back transformed artifacts (which is often needed for “tickets → pack” workflows).

[1]: https://github.com/modelcontextprotocol/python-sdk?utm_source=chatgpt.com "GitHub - modelcontextprotocol/python-sdk: The official Python SDK for Model Context Protocol servers and clients"
[2]: https://modelcontextprotocol.io/specification/2025-11-25/basic/security_best_practices?utm_source=chatgpt.com "Security Best Practices - Model Context Protocol"
[3]: https://github.com/advisories/GHSA-9h52-p55h-vw2f?utm_source=chatgpt.com "Model Context Protocol (MCP) Python SDK does not enable DNS rebinding protection by default · CVE-2025-66416 · GitHub Advisory Database · GitHub"
```

.tickets/mcp/gaps_part2-mcp-builder.md
```
## Still needed to make “oraclepack as an MCP tool” production-ready

### 1) Fix transport + deployment mode choice (local vs remote)

* **Use the correct Streamable HTTP transport string** (`transport="streamable-http"`) and stop treating SSE as the Streamable HTTP equivalent. The Python SDK’s examples use `mcp.run(transport="streamable-http")`. ([GitHub][1])
* If you intend to run this as a **remote** MCP server (for multi-client / “real time” usage), implement the Streamable HTTP security requirements:

  * validate `Origin` header (DNS rebinding protection)
  * bind to `127.0.0.1` when local
  * require authentication ([Model Context Protocol][2])
* If you intend “agents/assistants” to run it **locally**, default to **stdio** and keep Streamable HTTP optional. (The MCP spec defines stdio + Streamable HTTP as the standard transports.) ([Model Context Protocol][2])

### 2) Bring `oraclepack_run_pack` up to parity with the Go CLI flags

Your current MCP tool only exposes `yes` and `run_all`.
But the CLI supports additional run-time controls (at least `--resume`, `--stop-on-fail`, ROI threshold/mode, plus the persistent `--oracle-bin` and `--out-dir`).
To avoid capability gaps (and ad-hoc “extra args” escape hatches), expose these explicitly in the tool schema.

### 3) Make Stage-2 auto-discovery match the **oraclepack-taskify** contract

The Stage 3 skill is strict about:

* deterministic discovery (lexicographic / ISO-date ordering; no mtimes)
* directory-form must contain **exactly one** `01-*.md` … `20-*.md`, else fail fast with explicit errors
  Also, the Action Pack template itself searches locations including `docs/oracle-out` and `docs/oracle-questions-*/…`.
  So the MCP-side “detect stage2” logic should:
* search the same ordered locations
* validate a candidate before returning it (not “first directory that exists”)
* prefer newest by lexicographic rules when multiple date-stamped runs exist

### 4) Tighten Action Pack validation to exactly match the skill’s validator

The skill’s validator requires:

* **exactly one** ```bash fence and **no other** fences
* sequential `# NN)` step headers inside the bash block
  If your Python validator is looser than `validate-action-pack.sh`, you’ll get drift (packs “validate” in MCP but fail in real usage).

### 5) Add “artifact-first” read tools for Stage-3 outputs (so assistants can act in real time)

Stage 3 produces canonical machine/human artifacts like:

* `<out_dir>/_actions.json`, `<out_dir>/_actions.md`
* `.taskmaster/docs/oracle-actions-prd.md`
* `<out_dir>/tm-complexity.json`
  To enable “agents/assistants” to use them immediately, add read-only tools like:
* list latest runs / outputs (by stable ordering)
* read + parse `_actions.json` (return structured JSON, not only text)
* read Task Master outputs (tasks.json location(s) you expect)

### 6) Operational hardening (especially if exec is enabled)

You already gate execution behind an env flag (`ORACLEPACK_ENABLE_EXEC`).
Still needed:

* enforce allowed roots not just for reads, but also for **where packs are allowed to write** (at minimum, validate/normalize `out_dir`)
* timeouts + output truncation + concurrency limits (oraclepack can run arbitrary bash steps)
* clear error taxonomy in tool responses (so clients can recover deterministically)

### 7) Client onboarding configs (so assistants can actually connect)

Depending on the target clients:

* **Codex**: document config via `~/.codex/config.toml` and/or `codex mcp` commands. ([OpenAI Developers][3])
* **Inspector**: document using the inspector to test/debug and export server configs (`mcp.json`). ([GitHub][4])
* **ChatGPT / Responses API remote MCP** (if that’s a goal): document remote server URL + auth patterns. ([OpenAI Platform][5])

### 8) Acceptance tests that lock the contracts

Minimum tests to prevent regressions:

* Stage-2 detection test matrix (oracle-out, docs/oracle-out, docs/oracle-questions-*/…, single-pack form)
* Action Pack validator parity with `validate-action-pack.sh`
* run-pack flag mapping correctness (`--resume`, ROI options, `--out-dir`, etc.)

---

## Minimum set to ship safely

1. Correct Streamable HTTP wiring (`transport="streamable-http"`) + security requirements if remote ([GitHub][1])
2. Expand `oraclepack_run_pack` to match the CLI surface
3. Stage-2 detection + Action Pack validation exactly match the oraclepack-taskify skill scripts
4. Add read tools for `_actions.json` / PRD / Task Master outputs so agents can “use artifacts in real time”

[1]: https://github.com/modelcontextprotocol/python-sdk "GitHub - modelcontextprotocol/python-sdk: The official Python SDK for Model Context Protocol servers and clients"
[2]: https://modelcontextprotocol.io/specification/2025-06-18/basic/transports "Transports - Model Context Protocol"
[3]: https://developers.openai.com/codex/mcp/?utm_source=chatgpt.com "Model Context Protocol"
[4]: https://github.com/modelcontextprotocol/inspector "GitHub - modelcontextprotocol/inspector: Visual testing tool for MCP servers"
[5]: https://platform.openai.com/docs/guides/tools-connectors-mcp?utm_source=chatgpt.com "Connectors and MCP servers | OpenAI API"
```

.tickets/mcp/oraclepack-MCP.md
```
## MCP surface for `oraclepack` (so agents can act on Taskify artifacts)

### What to expose as MCP tools

Map the existing `oraclepack` CLI capabilities (validate/list/run + flags like `--no-tui`, `--out-dir`, `--oracle-bin`) into MCP tools so an agent can run packs non-interactively and then inspect the resulting state/report/artifacts.

Add a small “taskify helper” layer to make the **Stage-2 → Stage-3** workflow deterministic for agents:

* **Detect Stage-2 outputs** (dir-form `01-*.md..20-*.md` OR single-pack form) using the ordered resolver rules described in your skill.
* **Validate Stage-2 outputs** (exactly one match per prefix 01..20).
* **Validate Stage-3 Action Pack** structure constraints (single ```bash fence, step headers `# NN)`, etc.) before executing anything.
* **Summarize Stage-3 artifacts** (e.g., `_actions.json`, `_actions.md`, PRD path, `tm-complexity.json`, pipelines doc) so agents can immediately consume them.

### Transport choices (real-time vs local)

* **stdio** is simplest for local agent runtimes; it requires MCP messages only on stdout (logs must go to stderr). ([Model Context Protocol][1])
* **Streamable HTTP** is better for “real-time” multi-client usage; implement Origin validation and bind to localhost + auth to avoid DNS rebinding and local-network abuse. ([Model Context Protocol][1])

### Tool UX metadata (important for agents)

Use MCP **tool annotations** so clients can correctly present approval UX:

* mark validate/list/read tools as `readOnlyHint: true`
* mark run tools as `destructiveHint: true`, `openWorldHint: true` (they can touch filesystem, run processes, etc.) ([Model Context Protocol][2])

### Security defaults (recommended)

* Hard **deny-by-default execution**: require an env flag (e.g. `ORACLEPACK_ENABLE_EXEC=1`) to enable “run” tools.
* Restrict filesystem access to **allowlisted roots** to avoid path traversal and accidental exfiltration of secrets.
* Enforce stdout/stderr truncation and timeouts so a pack can’t wedge the server process.

## Reference implementation

I provided a complete, drop-in **Python MCP server** (FastMCP from the official MCP Python SDK) that exposes:

* `oraclepack_validate_pack`, `oraclepack_list_steps`, `oraclepack_run_pack`
* `oraclepack_taskify_detect_stage2`, `oraclepack_taskify_validate_stage2`
* `oraclepack_taskify_validate_action_pack`, `oraclepack_taskify_artifacts_summary`
* `oraclepack_taskify_run_action_pack`

It supports **stdio** and **streamable-http** transports per the official SDK. ([GitHub][3])

The full multi-file project is in the canvas titled **“oraclepack-mcp-server”**.

[1]: https://modelcontextprotocol.io/specification/2025-03-26/basic/transports "Transports - Model Context Protocol"
[2]: https://modelcontextprotocol.io/legacy/concepts/tools "Tools - Model Context Protocol"
[3]: https://github.com/modelcontextprotocol/python-sdk "GitHub - modelcontextprotocol/python-sdk: The official Python SDK for Model Context Protocol servers and clients"
```

.tickets/mcp/oraclepack_mcp_server.md
```
# oraclepack-mcp-server (MCP wrapper for oraclepack + taskify helpers)

## tree

```text
oraclepack-mcp-server/
  README.md
  requirements.txt
  oraclepack_mcp_server/
    __init__.py
    __main__.py
    config.py
    security.py
    oraclepack_cli.py
    taskify.py
    server.py
```

---

```md
<!-- path: oraclepack-mcp-server/README.md -->
# oraclepack-mcp-server

Expose `oraclepack` (validate/list/run) plus a few Stage-3 (oraclepack-taskify) helpers as **MCP tools**, so an agent can:
- validate and inspect packs
- run packs non-interactively (`--no-tui --yes --run-all`) to produce artifacts
- validate Stage-2 outputs (01-*.md..20-*.md)
- validate Stage-3 Action Packs (single ```bash fence, step headers, etc.)
- summarize Stage-3 artifacts (`_actions.json`, PRD, Task Master outputs, etc.)

## Install

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

## Configure (recommended)

Environment variables:

- `ORACLEPACK_ALLOWED_ROOTS` (default: current working directory)
  - Colon-separated list of allowed filesystem roots the server may read from.
  - Example: `ORACLEPACK_ALLOWED_ROOTS=/repo:/tmp/oracle-out`
- `ORACLEPACK_BIN` (default: `oraclepack`) – path to the oraclepack CLI
- `ORACLEPACK_WORKDIR` (default: current working directory)
  - Where packs are executed from (important for relative paths).
- `ORACLEPACK_ENABLE_EXEC` (default: `0`)
  - Must be `1` to enable `oraclepack_run_pack` and `oraclepack_taskify_run_action_pack`.
- `ORACLEPACK_CHARACTER_LIMIT` (default: `25000`) – truncate large stdout/stderr
- `ORACLEPACK_MAX_READ_BYTES` (default: `500000`) – max bytes read from a file

## Run (stdio)

```bash
# Stdio transport is the simplest local integration.
python -m oraclepack_mcp_server --transport stdio
```

## Run (Streamable HTTP)

```bash
python -m oraclepack_mcp_server --transport streamable-http
```

## Tools

- `oraclepack_validate_pack`
- `oraclepack_list_steps`
- `oraclepack_run_pack` (requires `ORACLEPACK_ENABLE_EXEC=1`)
- `oraclepack_read_file`
- `oraclepack_taskify_detect_stage2`
- `oraclepack_taskify_validate_stage2`
- `oraclepack_taskify_validate_action_pack`
- `oraclepack_taskify_artifacts_summary`
- `oraclepack_taskify_run_action_pack` (requires `ORACLEPACK_ENABLE_EXEC=1`)

## Typical Stage-3 usage

1) Detect/validate Stage-2 outputs (directory or single-pack)
2) Validate the Action Pack markdown
3) Run the Action Pack via `oraclepack run ...`
4) Summarize produced artifacts
```

```txt
# path: oraclepack-mcp-server/requirements.txt
mcp>=1.0.0
pydantic>=2.0.0
```

```python
# path: oraclepack-mcp-server/oraclepack_mcp_server/__init__.py
__all__ = []
```

```python
# path: oraclepack-mcp-server/oraclepack_mcp_server/config.py
from __future__ import annotations

import os
from dataclasses import dataclass
from pathlib import Path


def _truthy(value: str | None) -> bool:
    if value is None:
        return False
    return value.strip().lower() in {"1", "true", "yes", "y", "on"}


@dataclass(frozen=True)
class ServerConfig:
    allowed_roots: tuple[Path, ...]
    oraclepack_bin: str
    workdir: Path
    enable_exec: bool
    character_limit: int
    max_read_bytes: int


def load_config() -> ServerConfig:
    # Allowed roots: colon-separated. Default to CWD.
    roots_raw = os.environ.get("ORACLEPACK_ALLOWED_ROOTS")
    if roots_raw:
        roots = tuple(Path(p).expanduser().resolve() for p in roots_raw.split(":") if p.strip())
    else:
        roots = (Path.cwd().resolve(),)

    oraclepack_bin = os.environ.get("ORACLEPACK_BIN", "oraclepack")
    workdir = Path(os.environ.get("ORACLEPACK_WORKDIR", str(Path.cwd()))).expanduser().resolve()

    enable_exec = _truthy(os.environ.get("ORACLEPACK_ENABLE_EXEC", "0"))

    character_limit = int(os.environ.get("ORACLEPACK_CHARACTER_LIMIT", "25000"))
    max_read_bytes = int(os.environ.get("ORACLEPACK_MAX_READ_BYTES", "500000"))

    return ServerConfig(
        allowed_roots=roots,
        oraclepack_bin=oraclepack_bin,
        workdir=workdir,
        enable_exec=enable_exec,
        character_limit=character_limit,
        max_read_bytes=max_read_bytes,
    )
```

```python
# path: oraclepack-mcp-server/oraclepack_mcp_server/security.py
from __future__ import annotations

from pathlib import Path


class PathNotAllowedError(ValueError):
    pass


def resolve_under_roots(path: Path, allowed_roots: tuple[Path, ...]) -> Path:
    """Resolve a path and enforce it lives under at least one allowed root."""
    p = path.expanduser().resolve()

    for root in allowed_roots:
        r = root.expanduser().resolve()
        try:
            p.relative_to(r)
            return p
        except ValueError:
            continue

    raise PathNotAllowedError(
        f"Path not allowed (outside allowed roots). path={p} roots={[str(r) for r in allowed_roots]}"
    )


def safe_read_text(path: Path, max_bytes: int) -> tuple[str, bool]:
    """Read up to max_bytes from a file as UTF-8 (replace errors)."""
    data = path.read_bytes()
    truncated = False
    if len(data) > max_bytes:
        data = data[:max_bytes]
        truncated = True
    return data.decode("utf-8", errors="replace"), truncated


def safe_read_bytes(path: Path, max_bytes: int) -> tuple[bytes, bool]:
    data = path.read_bytes()
    truncated = False
    if len(data) > max_bytes:
        data = data[:max_bytes]
        truncated = True
    return data, truncated
```

```python
# path: oraclepack-mcp-server/oraclepack_mcp_server/oraclepack_cli.py
from __future__ import annotations

import asyncio
import os
import time
from dataclasses import dataclass
from pathlib import Path


@dataclass
class CmdResult:
    ok: bool
    exit_code: int
    duration_s: float
    stdout: str
    stderr: str
    stdout_truncated: bool
    stderr_truncated: bool


def _truncate(s: str, limit: int) -> tuple[str, bool]:
    if limit <= 0:
        return s, False
    if len(s) <= limit:
        return s, False
    return s[:limit], True


async def run_cmd(
    argv: list[str],
    cwd: Path,
    timeout_s: int,
    env: dict[str, str] | None,
    character_limit: int,
) -> CmdResult:
    start = time.time()

    proc = await asyncio.create_subprocess_exec(
        *argv,
        cwd=str(cwd),
        env=(os.environ | (env or {})),
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
    )

    try:
        out_b, err_b = await asyncio.wait_for(proc.communicate(), timeout=timeout_s)
    except asyncio.TimeoutError:
        proc.kill()
        await proc.communicate()
        duration = time.time() - start
        return CmdResult(
            ok=False,
            exit_code=124,
            duration_s=duration,
            stdout="",
            stderr=f"Timed out after {timeout_s}s: {' '.join(argv)}",
            stdout_truncated=False,
            stderr_truncated=False,
        )

    duration = time.time() - start
    out = out_b.decode("utf-8", errors="replace") if out_b else ""
    err = err_b.decode("utf-8", errors="replace") if err_b else ""

    out, out_tr = _truncate(out, character_limit)
    err, err_tr = _truncate(err, character_limit)

    exit_code = proc.returncode if proc.returncode is not None else 1
    return CmdResult(
        ok=(exit_code == 0),
        exit_code=exit_code,
        duration_s=duration,
        stdout=out,
        stderr=err,
        stdout_truncated=out_tr,
        stderr_truncated=err_tr,
    )
```

```python
# path: oraclepack-mcp-server/oraclepack_mcp_server/taskify.py
from __future__ import annotations

import re
from dataclasses import dataclass
from datetime import date
from pathlib import Path


@dataclass
class Stage2Resolution:
    kind: str  # "dir" | "file"
    stage2_path: Path
    out_dir: Path
    notes: list[str]


PREFIXES = [f"{i:02d}" for i in range(1, 21)]


def _is_iso_date(s: str) -> bool:
    # Minimal heuristic for YYYY-MM-DD
    return bool(re.fullmatch(r"\d{4}-\d{2}-\d{2}", s))


def validate_stage2_dir(out_dir: Path) -> dict:
    missing: list[str] = []
    ambiguous: dict[str, list[str]] = {}
    selected: dict[str, str] = {}

    for pfx in PREFIXES:
        matches = sorted(out_dir.glob(f"{pfx}-*.md"))
        if len(matches) == 0:
            missing.append(f"{pfx}-*.md")
        elif len(matches) > 1:
            ambiguous[pfx] = [m.name for m in matches]
        else:
            selected[pfx] = matches[0].name

    ok = (not missing) and (not ambiguous)
    return {
        "ok": ok,
        "out_dir": str(out_dir),
        "selected": selected,
        "missing": missing,
        "ambiguous": ambiguous,
    }


def _lexi_newest(paths: list[Path]) -> Path | None:
    # Deterministic: lexicographic max
    return sorted(paths, key=lambda p: p.name)[-1] if paths else None


def detect_stage2(stage2_path: str, repo_root: Path) -> Stage2Resolution:
    notes: list[str] = []

    if stage2_path != "auto":
        p = (repo_root / stage2_path).expanduser()
        if p.exists() and p.is_dir():
            return Stage2Resolution(kind="dir", stage2_path=p.resolve(), out_dir=p.resolve(), notes=["explicit dir"])
        if p.exists() and p.is_file():
            # out_dir rules from skill: if under docs/oracle-questions-YYYY-MM-DD/ then parent/oracle-out else oracle-out
            p_res = p.resolve()
            out = repo_root / "oracle-out"
            parts = list(p_res.parts)
            if "docs" in parts:
                try:
                    idx = parts.index("docs")
                    # docs/oracle-questions-YYYY-MM-DD/.../oracle-pack-YYYY-MM-DD.md
                    if idx + 1 < len(parts) and parts[idx + 1].startswith("oracle-questions-"):
                        out = Path(*parts[: idx + 2]) / "oracle-out"
                except ValueError:
                    pass
            return Stage2Resolution(kind="file", stage2_path=p_res, out_dir=out.resolve(), notes=["explicit file"])
        raise FileNotFoundError(f"stage2_path not found: {p}")

    # auto discovery (best-effort, deterministic ordering)
    searched: list[str] = []

    # 1) repo_root/oracle-out
    candidate = repo_root / "oracle-out"
    searched.append(str(candidate))
    if candidate.is_dir():
        v = validate_stage2_dir(candidate)
        if v["ok"]:
            notes.append("auto: selected repo_root/oracle-out")
            return Stage2Resolution(kind="dir", stage2_path=candidate.resolve(), out_dir=candidate.resolve(), notes=notes)

    # 2) docs/oracle-questions-YYYY-MM-DD/oracle-out (newest by lexicographic date suffix)
    docs = repo_root / "docs"
    if docs.is_dir():
        qdirs = [p for p in docs.glob("oracle-questions-*") if p.is_dir()]
        # deterministic: sort by name and take newest
        newest_q = _lexi_newest(qdirs)
        if newest_q:
            candidate = newest_q / "oracle-out"
            searched.append(str(candidate))
            if candidate.is_dir():
                v = validate_stage2_dir(candidate)
                if v["ok"]:
                    notes.append(f"auto: selected {candidate}")
                    return Stage2Resolution(kind="dir", stage2_path=candidate.resolve(), out_dir=candidate.resolve(), notes=notes)

    # 3) single-pack form (newer): look for docs/oracle-pack-*.md or docs/oraclepacks/oracle-pack-*.md
    file_candidates: list[Path] = []
    if docs.is_dir():
        file_candidates += list(docs.glob("oracle-pack-*.md"))
        file_candidates += list((docs / "oraclepacks").glob("oracle-pack-*.md"))
        file_candidates += list(docs.glob("oracle-questions-*/oraclepacks/oracle-pack-*.md"))

    newest_file = _lexi_newest(sorted([p for p in file_candidates if p.is_file()], key=lambda p: p.name))
    if newest_file:
        notes.append(f"auto: selected single-pack {newest_file}")
        out = repo_root / "oracle-out"
        # If under docs/oracle-questions-YYYY-MM-DD/..., default out_dir there.
        if "docs" in newest_file.parts:
            try:
                idx = newest_file.parts.index("docs")
                if idx + 1 < len(newest_file.parts) and newest_file.parts[idx + 1].startswith("oracle-questions-"):
                    out = Path(*newest_file.parts[: idx + 2]) / "oracle-out"
            except ValueError:
                pass
        return Stage2Resolution(kind="file", stage2_path=newest_file.resolve(), out_dir=out.resolve(), notes=notes)

    raise FileNotFoundError(
        "stage2_path=auto could not resolve Stage-2 outputs. Searched:\n- " + "\n- ".join(searched)
    )


def validate_action_pack(pack_path: Path) -> dict:
    text = pack_path.read_text(encoding="utf-8", errors="replace")

    bash_fence = re.findall(r"(?m)^\s*```bash\s*$", text)
    any_fence = re.findall(r"(?m)^\s*```\s*", text)

    errors: list[str] = []
    if len(bash_fence) != 1:
        errors.append(f"expected exactly one ```bash fence; found {len(bash_fence)}")
    if len(any_fence) != 2:
        # One opening and one closing fence expected, and it must be a bash fence.
        errors.append(f"expected no other code fences; found {len(any_fence)} total fences")

    # Extract bash block content if possible
    bash_block = ""
    m = re.search(r"```bash\s*\n(?P<body>[\s\S]*?)\n```\s*", text)
    if m:
        bash_block = m.group("body")

    # Validate step headers inside bash fence
    step_headers = re.findall(r"(?m)^\s*#\s*(\d{2})\)\s+.*$", bash_block)
    if not step_headers:
        errors.append("no step headers found inside the bash fence (expected lines like '# 01) ...')")
    else:
        # Ensure they start at 01 and are strictly increasing by 1.
        nums = [int(x) for x in step_headers]
        if nums[0] != 1:
            errors.append(f"first step must be 01; got {nums[0]:02d}")
        for prev, cur in zip(nums, nums[1:]):
            if cur != prev + 1:
                errors.append(f"step numbers must be sequential; got {prev:02d} then {cur:02d}")

    return {
        "ok": len(errors) == 0,
        "pack_path": str(pack_path),
        "step_count": len(step_headers),
        "errors": errors,
    }


def default_pack_path(today: date | None = None) -> str:
    d = today or date.today()
    return f"docs/oracle-actions-pack-{d.isoformat()}.md"
```

```python
# path: oraclepack-mcp-server/oraclepack_mcp_server/server.py
from __future__ import annotations

import json
from enum import Enum
from pathlib import Path
from typing import Any

from pydantic import BaseModel, Field
from mcp.server.fastmcp import FastMCP

from .config import load_config
from .security import resolve_under_roots, safe_read_text, PathNotAllowedError
from .oraclepack_cli import run_cmd
from .taskify import detect_stage2, validate_stage2_dir, validate_action_pack


class ResponseFormat(str, Enum):
    markdown = "markdown"
    json = "json"


class PackPathInput(BaseModel):
    pack_path: str = Field(..., description="Path to the pack markdown file")
    response_format: ResponseFormat = Field(default=ResponseFormat.markdown)


class RunPackInput(BaseModel):
    pack_path: str = Field(..., description="Path to the pack markdown file")
    out_dir: str | None = Field(default=None, description="Output directory for step execution (passes --out-dir).")

    no_tui: bool = Field(default=True, description="If true, pass --no-tui")
    yes: bool = Field(default=True, description="If true, pass --yes")
    run_all: bool = Field(default=True, description="If true, pass --run-all")

    resume: bool = Field(default=False, description="If true, pass --resume")
    stop_on_fail: bool = Field(default=True, description="If true, pass --stop-on-fail (default true)")

    roi_threshold: float = Field(default=0.0, description="Pass --roi-threshold")
    roi_mode: str = Field(default="over", description="Pass --roi-mode ('over' or 'under')")

    timeout_s: int = Field(default=3600, description="Hard timeout for the oraclepack process")
    response_format: ResponseFormat = Field(default=ResponseFormat.markdown)


class ReadFileInput(BaseModel):
    path: str = Field(..., description="Path to a file within ORACLEPACK_ALLOWED_ROOTS")
    max_bytes: int | None = Field(default=None, description="Override max bytes read")
    response_format: ResponseFormat = Field(default=ResponseFormat.markdown)


class TaskifyDetectStage2Input(BaseModel):
    stage2_path: str = Field(default="auto", description="Dir or file, or 'auto'")
    repo_root: str = Field(default=".", description="Repo root for relative resolution")
    response_format: ResponseFormat = Field(default=ResponseFormat.markdown)


class TaskifyValidateStage2Input(BaseModel):
    out_dir: str = Field(..., description="Directory that should contain 01-*.md..20-*.md")
    response_format: ResponseFormat = Field(default=ResponseFormat.markdown)


class TaskifyValidateActionPackInput(BaseModel):
    pack_path: str = Field(..., description="Path to Stage-3 Action Pack markdown")
    response_format: ResponseFormat = Field(default=ResponseFormat.markdown)


class TaskifyArtifactsSummaryInput(BaseModel):
    out_dir: str = Field(..., description="Stage-3 out_dir (where _actions.json etc are written)")
    response_format: ResponseFormat = Field(default=ResponseFormat.markdown)


class TaskifyRunActionPackInput(BaseModel):
    pack_path: str = Field(..., description="Path to the Stage-3 Action Pack markdown")
    out_dir: str | None = Field(default=None, description="Pass --out-dir for execution")
    timeout_s: int = Field(default=7200)
    response_format: ResponseFormat = Field(default=ResponseFormat.markdown)


cfg = load_config()

mcp = FastMCP(
    name="oraclepack-mcp-server",
    # For production Streamable HTTP deployments, stateless_http + json_response is recommended.
    # Clients may override by running behind an ASGI app if needed.
    stateless_http=True,
    json_response=True,
)


def _md_codeblock(lang: str, content: str) -> str:
    return f"```{lang}\n{content}\n```"


def _format_cmd_result(result: Any, response_format: ResponseFormat) -> Any:
    if response_format == ResponseFormat.json:
        return {
            "ok": result.ok,
            "exit_code": result.exit_code,
            "duration_s": result.duration_s,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "stdout_truncated": result.stdout_truncated,
            "stderr_truncated": result.stderr_truncated,
        }

    lines = []
    lines.append(f"**ok**: {result.ok}")
    lines.append(f"**exit_code**: {result.exit_code}")
    lines.append(f"**duration_s**: {result.duration_s:.2f}")
    lines.append("")

    if result.stdout:
        lines.append("## stdout")
        lines.append(_md_codeblock("text", result.stdout))
        if result.stdout_truncated:
            lines.append(f"(stdout truncated to {cfg.character_limit} chars)")

    if result.stderr:
        lines.append("## stderr")
        lines.append(_md_codeblock("text", result.stderr))
        if result.stderr_truncated:
            lines.append(f"(stderr truncated to {cfg.character_limit} chars)")

    return "\n".join(lines)


def _ensure_exec_enabled() -> None:
    if not cfg.enable_exec:
        raise PermissionError(
            "Execution is disabled. Set ORACLEPACK_ENABLE_EXEC=1 to enable pack execution tools."
        )


@mcp.tool(
    name="oraclepack_validate_pack",
    annotations={
        "title": "Validate oraclepack pack",
        "readOnlyHint": True,
        "destructiveHint": False,
        "idempotentHint": True,
        "openWorldHint": False,
    },
)
async def oraclepack_validate_pack(params: PackPathInput) -> Any:
    pack_path = resolve_under_roots(Path(params.pack_path), cfg.allowed_roots)

    argv = [cfg.oraclepack_bin, "validate", str(pack_path)]
    result = await run_cmd(argv, cwd=cfg.workdir, timeout_s=120, env={}, character_limit=cfg.character_limit)
    return _format_cmd_result(result, params.response_format)


@mcp.tool(
    name="oraclepack_list_steps",
    annotations={
        "title": "List steps in an oraclepack pack",
        "readOnlyHint": True,
        "destructiveHint": False,
        "idempotentHint": True,
        "openWorldHint": False,
    },
)
async def oraclepack_list_steps(params: PackPathInput) -> Any:
    pack_path = resolve_under_roots(Path(params.pack_path), cfg.allowed_roots)

    argv = [cfg.oraclepack_bin, "list", str(pack_path)]
    result = await run_cmd(argv, cwd=cfg.workdir, timeout_s=120, env={}, character_limit=cfg.character_limit)
    return _format_cmd_result(result, params.response_format)


@mcp.tool(
    name="oraclepack_run_pack",
    annotations={
        "title": "Run an oraclepack pack (non-interactive)",
        "readOnlyHint": False,
        "destructiveHint": True,
        "idempotentHint": False,
        "openWorldHint": True,
    },
)
async def oraclepack_run_pack(params: RunPackInput) -> Any:
    _ensure_exec_enabled()

    pack_path = resolve_under_roots(Path(params.pack_path), cfg.allowed_roots)

    argv: list[str] = [cfg.oraclepack_bin]
    if params.no_tui:
        argv += ["--no-tui"]
    if params.out_dir:
        out_dir = resolve_under_roots(Path(params.out_dir), cfg.allowed_roots)
        argv += ["--out-dir", str(out_dir)]

    argv += ["run"]

    if params.yes:
        argv += ["--yes"]
    if params.run_all:
        argv += ["--run-all"]

    if params.resume:
        argv += ["--resume"]

    # stop-on-fail is default true in oraclepack; pass explicitly for clarity.
    argv += ["--stop-on-fail", "true" if params.stop_on_fail else "false"]

    argv += ["--roi-threshold", str(params.roi_threshold), "--roi-mode", params.roi_mode]

    argv += [str(pack_path)]

    result = await run_cmd(argv, cwd=cfg.workdir, timeout_s=params.timeout_s, env={}, character_limit=cfg.character_limit)
    return _format_cmd_result(result, params.response_format)


@mcp.tool(
    name="oraclepack_read_file",
    annotations={
        "title": "Read a file under allowed roots",
        "readOnlyHint": True,
        "destructiveHint": False,
        "idempotentHint": True,
        "openWorldHint": False,
    },
)
async def oraclepack_read_file(params: ReadFileInput) -> Any:
    p = resolve_under_roots(Path(params.path), cfg.allowed_roots)
    if not p.exists() or not p.is_file():
        raise FileNotFoundError(f"file not found: {p}")

    max_bytes = params.max_bytes if params.max_bytes is not None else cfg.max_read_bytes
    text, truncated = safe_read_text(p, max_bytes=max_bytes)

    if params.response_format == ResponseFormat.json:
        return {"path": str(p), "truncated": truncated, "content": text}

    note = f"\n\n(content truncated to {max_bytes} bytes)" if truncated else ""
[TRUNCATED]
```

.tickets/other/Oraclepack Pipeline Improvements.md
```
Title:

* Implement deterministic oraclepack pipeline improvements (strict validation, run manifests, resume/caching, Stage 3 “Actionizer”)

Summary:

* The current two-stage oraclepack workflow (Stage 1 pack generation → Stage 2 execution) is “weakly connected” and lacks deterministic handoff metadata, robust resume/retry, and an automated Stage 3 that converts 20 outputs into actionable engineering work.

    Oracle Pack Workflow Analysis

* This ticket proposes additive, backward-compatible enhancements to oraclepack and the Stage 1 generator prompts so runs are reproducible, CI-friendly, and produce machine-readable artifacts suitable for automation.

    Oracle Pack Workflow Analysis

Background / Context:

* Workflow context:

  * Stage 1: Codex skill or Gemini CLI slash command generates a single Markdown oracle question pack under `docs/*oracle-pack*.md`, following a strict oraclepack schema and containing exactly 20 `oracle ...` commands.

        Oracle Pack Workflow Analysis

  * Stage 2: oraclepack (Go wrapper around `@steipete/oracle`) executes the 20 commands and writes per-question outputs (via `--write-output`).

        Oracle Pack Workflow Analysis

  * Stage 3 is currently missing: outputs are not automatically turned into actionable implementation work.

        Oracle Pack Workflow Analysis

* Non-negotiable constraints:

  * No schema-breaking changes to the oraclepack Markdown pack schema without a backward-compatible migration path and validator-safe proof.

  * Automation must be deterministic and reproducible (no interactive steps in the critical path).

  * Stage 1 output must remain a single-pack deliverable that oraclepack can validate/run (no extra blocks/headers; no schema drift).

  * Prefer minimal file attachments per question; avoid broad globs unless unavoidable.

  * Optimize for longer runtimes with minimal human interaction (batching, resume/retry, caching, stable outputs, CI-friendly).

        Oracle Pack Workflow Analysis

Current Behavior (Actual):

* Stage 1 (generation) failure modes / friction points:

  * Packs can drift from the strict schema (extra fenced blocks, step-like headers, missing fields, wrong ordering, wrong count ≠ 20), causing ingestion/validation issues.

        Oracle Pack Workflow Analysis

  * Attachments may be bloated (broad globs, “just in case” files), increasing token cost and reducing signal-to-noise.

        Oracle Pack Workflow Analysis

  * ROI scoring can be inconsistent (unstable prioritization vs stated rationale).

        Oracle Pack Workflow Analysis

  * Coverage duplication across 20 questions (overlapping targets) wastes runs/budget.

        Oracle Pack Workflow Analysis

* Stage 2 (execution) failure modes / friction points:

  * Resume/retry semantics are weak (reruns may re-execute completed steps; partial failures require manual selection).

        Oracle Pack Workflow Analysis

  * Output determinism gaps: inconsistent output paths/slugs/out\_dir naming undermine CI diffs and Stage 3 discovery.

        Oracle Pack Workflow Analysis

  * Concurrency/rate limiting is not first-class (provider throttling/timeouts lead to nondeterministic failures).

        Oracle Pack Workflow Analysis

* Cross-stage handoff issues:

  * Missing traceability between pack ↔ outputs (no explicit manifest tying outputs to pack hash, git SHA, tool versions, provider/model settings).

        Oracle Pack Workflow Analysis

  * Stage 2 may be bypassed (pack executed “by hand”), losing wrapper state/report and consistent run directory.

        Oracle Pack Workflow Analysis

Expected Behavior:

* Stage 1 packs are always validator-safe and deterministic (single pack, exactly 20 oracle invocations, no schema drift).

    Oracle Pack Workflow Analysis

* Stage 2 produces stable, discoverable, machine-readable run artifacts that bind pack ↔ outputs and enable idempotent resume/rerun.

    Oracle Pack Workflow Analysis

* Stage 3 (“Actionizer”) exists and deterministically converts the 20 outputs into actionable engineering work artifacts (backlog + change plan + optional issue export), without duplicating work on reruns.

    Oracle Pack Workflow Analysis

* CI can run validate → run → actionize non-interactively with structured outputs and policy-driven exit codes.

    Oracle Pack Workflow Analysis

Requirements:

* Validation / linting (additive, backward-compatible):

  * Add `oraclepack validate --strict --json` that reports counts (steps=20, bash\_blocks=1, oracle\_invocations=20), ordering checks (ROI desc; ties effort asc), and required fields presence.

        Oracle Pack Workflow Analysis

* Deterministic run directory + manifest:

  * On `run`, create `.oraclepack/runs/<pack_id>/` and emit `run.json` + `steps.json`.

        Oracle Pack Workflow Analysis

  * `pack_id = YYYY-MM-DD__<gitshort>__<packhash8>`.

        Oracle Pack Workflow Analysis

  * `run.json` must include: `pack_path`, `pack_hash`, `git_sha`, `oraclepack_version`, `oracle_version`, `created_at`.

        Oracle Pack Workflow Analysis

  * `steps.json` must include: `step_id` (01..20), `reference`, `category`, `roi`, `command_hash`, `output_path`, `output_hash`, `status` (pending|ok|failed|skipped).

        Oracle Pack Workflow Analysis

* Resume/rerun semantics:

  * Make resume default: if `run.json` exists, skip steps whose output exists and matches recorded hash.

  * Support explicit overrides: `--rerun all|failed|01,03,07`.

        Oracle Pack Workflow Analysis

* Concurrency and rate limiting:

  * Add global `--max-parallel N` and optionally per-provider caps via config.

  * Implement exponential backoff + jitter on transient errors (e.g., 429/503) with a retry budget.

        Oracle Pack Workflow Analysis

* Deterministic caching (optional initially):

  * Implement caching keyed by `sha256(prompt + attached_file_hashes + oracle_flags + model)`, stored under `.oraclepack/cache/<invocation_key>.md`; rerun reuses cached outputs when key matches.

        Oracle Pack Workflow Analysis

* Stage 3 (“Actionizer”) design and artifacts:

  * Implement `oraclepack actionize --run-dir .oraclepack/runs/<pack_id>`.

  * Inputs: `run.json` + 20 outputs under `.oraclepack/runs/<pack_id>/outputs/`.

        Oracle Pack Workflow Analysis

  * Deterministic processing: normalize outputs → dedupe → categorize via fixed taxonomy → generate action tasks, including blocked/conflict handling.

        Oracle Pack Workflow Analysis

  * Outputs under `.oraclepack/runs/<pack_id>/actionizer/`:

    * `normalized.jsonl`, `backlog.md`, `change-plan.md`

    * Optional: `github-issues.json`, `taskmaster.json`.

            Oracle Pack Workflow Analysis

  * Idempotency: stable IDs derived from `pack_hash` (e.g., `OP3-<packhash8>-<issue_index>-<task_index>`), stable paths, byte-identical regeneration when inputs unchanged.

        Oracle Pack Workflow Analysis

* Stage 1 prompt/skill improvements (without breaking schema):

  * Embed structured mini-metadata inside each `-p` prompt text (not new pack headers), e.g., `QuestionId`, `Category`, `Reference`, `ExpectedArtifacts`.

        Oracle Pack Workflow Analysis

  * Enforce deterministic attachment minimization heuristics (reference file + 0–2 neighbors; avoid broad globs unless evidence demands).

        Oracle Pack Workflow Analysis

  * Standardize generator prompt across Codex skills and Gemini CLI commands using a single canonical prompt file in repo.

        Oracle Pack Workflow Analysis

* CI-native mode:

  * Provide `oraclepack run --ci --non-interactive --json-log` and `oraclepack actionize --ci`.

  * CI policy can fail build if validation fails, completion rate below threshold, or action yield below threshold (threshold values: Not provided).

        Oracle Pack Workflow Analysis

* Security/safety:

  * Path safety: prevent `--write-output` from escaping run dir (reject `..` traversal).

        Oracle Pack Workflow Analysis

Out of Scope:

* Breaking changes to the existing oraclepack Markdown pack schema (unless a backward-compatible migration path and validator-safe proof are provided).

    Oracle Pack Workflow Analysis

Reproduction Steps:

1. Generate a pack via Stage 1 and save to `docs/oracle-pack-YYYY-MM-DD.md`.

    Oracle Pack Workflow Analysis

2. Run `oraclepack validate docs/oracle-pack-YYYY-MM-DD.md` and observe schema drift / strictness gaps (exact current validator behavior: Unknown).

    Oracle Pack Workflow Analysis

3. Execute the pack, interrupt mid-run, rerun, and observe whether completed steps are skipped (current behavior: weak/unclear).

    Oracle Pack Workflow Analysis

4. Compare two runs on the same commit and observe output path/slug stability and traceability artifacts (manifest missing today).

    Oracle Pack Workflow Analysis

Environment:

* Tooling:

  * oraclepack (Go wrapper around `@steipete/oracle`).

        Oracle Pack Workflow Analysis

  * Stage 1 generators: Codex skills or Gemini CLI slash commands.

        Oracle Pack Workflow Analysis

* Repository/OS/versions: Unknown (git SHA, oraclepack version, oracle version, provider/model settings not provided in the conversation; also identified as missing traceability today).

    Oracle Pack Workflow Analysis

Evidence:

* Proposed stable artifact layout and handoff contract:

    Oracle Pack Workflow Analysis

  * `docs/oracle-pack-YYYY-MM-DD.md`

  * `.oraclepack/runs/<pack_id>/run.json`

  * `.oraclepack/runs/<pack_id>/steps.json`

  * `.oraclepack/runs/<pack_id>/outputs/01-<slug>.md … 20-<slug>.md`

  * `.oraclepack/runs/<pack_id>/actionizer/{normalized.jsonl, backlog.md, change-plan.md}`

* Proposed commands (some flag names explicitly “proposed where not already present”):

    Oracle Pack Workflow Analysis

  * `oraclepack validate --strict docs/oracle-pack-YYYY-MM-DD.md --json > .oraclepack/validate.json`

  * `oraclepack run docs/oracle-pack-YYYY-MM-DD.md --max-parallel 4 --resume --ci`

  * `oraclepack actionize --run-dir .oraclepack/runs/<pack_id> --ci`

* Example Stage 3 output record shape (JSONL line):

    Oracle Pack Workflow Analysis

Decisions / Agreements:

* Do not break the oraclepack Markdown pack schema; any change must be backward-compatible with a validator-safe proof.

    Oracle Pack Workflow Analysis

* Stage 3 (“Actionizer”) is required and should be implemented as a first-class oraclepack subcommand (`actionize`) producing deterministic artifacts with idempotent reruns.

    Oracle Pack Workflow Analysis

* Traceability and determinism should be achieved via additive sidecar files (e.g., `run.json`, `steps.json`) rather than pack schema changes.

    Oracle Pack Workflow Analysis

Open Items / Unknowns:

* Current oraclepack CLI surface area:

  * Whether `validate --strict`, `--json`, `run --ci`, `--resume`, `--json-log`, and `actionize` exist today vs need implementation (conversation notes some flags are “proposed”).

        Oracle Pack Workflow Analysis

* Current on-disk state/report formats and locations (“state lives today (intended): oraclepack state/report + per-step outputs”; exact paths not provided).

    Oracle Pack Workflow Analysis

* Threshold definitions for CI policy (“completion rate < threshold”, “action yield < threshold”): Not provided.

    Oracle Pack Workflow Analysis

* Exact strict pack schema invariants enforced today (beyond “strict output contract” and “exactly 20” requirement): Not provided in this conversation (referenced as external inputs).

    Oracle Pack Workflow Analysis

Risks / Dependencies:

* Risk: filesystem layout changes may affect existing users; mitigation is additive behavior that preserves current out\_dir behavior.

    Oracle Pack Workflow Analysis

* Risk: caching correctness depends on hashing all attached file contents; incomplete hashing risks “cache poisoning.”

    Oracle Pack Workflow Analysis

* Risk: provider throttling/timeouts require robust transient-error classification for backoff/retry behavior.

    Oracle Pack Workflow Analysis

* Dependency: Stage 3 quality depends on stable, parseable structure in per-question outputs; mitigated by deterministic normalization heuristics and improved Stage 1 prompt shaping.

Acceptance Criteria:

* Validation:

  * `oraclepack validate --strict --json` deterministically reports schema invariants (20 steps, 20 oracle invocations, schema drift detection) and can gate CI.

        Oracle Pack Workflow Analysis

* Run determinism and traceability:

  * Running a pack produces `.oraclepack/runs/<pack_id>/{run.json,steps.json,outputs/}` with stable `pack_id` and stable output naming.

  * `run.json` includes required metadata fields; `steps.json` includes required per-step fields and statuses.

        Oracle Pack Workflow Analysis

* Resume/rerun:

  * Interrupting a run mid-way and rerunning resumes without re-executing completed steps (validated via output hashes and statuses).

  * `--rerun failed|all|<step list>` behaves as specified.

        Oracle Pack Workflow Analysis

* Concurrency/rate limiting:

  * `--max-parallel N` bounds concurrency; transient failures (e.g., throttling/timeouts) are retried with backoff within a retry budget and recorded in step status.

        Oracle Pack Workflow Analysis

* Caching (if implemented):

  * Rerunning on unchanged inputs (same prompt, same attached file digests, same flags/model) results in zero provider calls and identical outputs.

        Oracle Pack Workflow Analysis

* Stage 3 “Actionizer”:

  * `oraclepack actionize --run-dir ...` generates deterministic artifacts under `actionizer/` (`normalized.jsonl`, `backlog.md`, `change-plan.md`).

  * Reruns do not duplicate tasks (stable IDs) and produce byte-identical output when inputs unchanged.

  * Missing/contradictory answers produce explicit `blocked`/`conflict` tasks with required evidence patterns.

* CI mode:

  * `--ci --non-interactive --json-log` runs without TUI/interaction and uses structured logs and policy-driven exit codes.

        Oracle Pack Workflow Analysis

Priority & Severity (if inferable from text):

* Priority: Not provided

* Severity: Not provided

Labels (optional):

* enhancement, cli, determinism, validation, resume, caching, concurrency, workflow, stage3-actionizer

---
```

.tickets/other/Oraclepack Prompt Generator.md
```
* Title: Create oraclepack-style prompt/skill generator for tickets and .tickets
* Summary:

  * Need a reusable prompt (and/or “skill” template) that can generate an oraclepack-style prompt/skill specifically for “tickets” and/or “.tickets”.
  * Must support the existing placeholder-driven wrapper pattern (e.g., `{user-idea}`, `{project-in-question}`, `{PAIN-POINT}`, `{REFERENCE-FILE}`, `{CAPABILITY}`, `{TARGET-AGENT}`, `{OPTIMIZE-PROMPT}`), including optional fields and “infer from context” behavior as described.
  * Also need guidance on what to change in the current skill and what other viable integration options exist (within the constraints already used in prior work).
* Source:

  * Link/ID: Not provided
  * Original ticket excerpt: “prompt that can create an oraclepack prompt/skill but for our tickets and/or .tickets”
* Global Constraints:

  * Optional inputs may be omitted; proceed by inferring from context or requesting missing info within the generated prompt template (“Not always provided…”).
  * “Pain point” is optional; proceed without it if absent.
  * `{REFERENCE-FILE}` may be provided as additional constraints/spec content.
* Global Environment:

  * Unknown
* Global Evidence:

  * Existing wrapper pattern + MCP prompt/tool/resource publication precedent captured in: `/mnt/data/MCP server implementation.md`

Split Plan:

* Coverage Map:

  * Original item: “We need a prompt that can create an oraclepack prompt/skill but for our tickets and/or .tickets.”

    * Assigned Ticket ID: T2
  * Original item: “What could we do to our current skill…”

    * Assigned Ticket ID: T3
  * Original item: “…and/or what else are our options for this request?”

    * Assigned Ticket ID: T4
  * Original item: Wrapper placeholders + optionality rules (“Not always provided…”, “Our pain point…”, `{REFERENCE-FILE}`, `{TARGET-AGENT}`, `{CAPABILITY}`, `{OPTIMIZE-PROMPT}`)

    * Assigned Ticket ID: T1
  * Original item: “optimized prompt that will get the {TARGET-AGENT} to find us a solution for adding capabilities…”

    * Assigned Ticket ID: T2
* Dependencies:

  * T2 depends on T1 because the prompt/skill generator must align to the placeholder schema + optionality rules.
  * T3 depends on T2 because “current skill” changes should incorporate the finalized ticket prompt/skill template.
  * T5 depends on T2 and T3 because examples/validation need the final template and integration approach.

````ticket T1
T1 Title: Define ticket/.tickets prompt input schema and placeholder mapping
Type: docs
Target Area: Ticket input model (tickets and/or .tickets) + wrapper placeholders
Summary:
  - Define the canonical set of inputs and placeholders required to generate an oraclepack-style ticket prompt/skill.
  - Preserve the existing wrapper’s rules around optional inputs and context inference.
  - Provide a clear mapping between “tickets/.tickets” fields (if any) and wrapper placeholders without inventing unspecified fields.
In Scope:
  - Enumerate required vs optional placeholders: {user-idea}, {project-in-question}, {ADDITIONAL-INFORMATION}, {PAIN-POINT}, {REFERENCE-FILE}, {CAPABILITY}, {TARGET-AGENT}, {OPTIMIZE-PROMPT}.
  - Document handling rules explicitly stated: optional fields, “infer from context”, and behavior when pain point is absent.
  - Clarify what “tickets” vs “.tickets” means in this system using “Unknown/Not provided” where details are missing.
Out of Scope:
  - Defining new ticket fields beyond what is provided.
  - Implementing tooling or code changes (covered elsewhere).
Current Behavior (Actual):
  - Placeholder set and optionality rules exist in the wrapper pattern, but ticket/.tickets-specific mapping is not defined.
Expected Behavior:
  - A documented, stable mapping that the ticket prompt/skill generator can follow.
Reproduction Steps:
  - Not provided
Requirements / Constraints:
  - Do not add new placeholders or required fields beyond what is already used in the wrapper.
  - Preserve optionality rules: proceed safely when PAIN-POINT or additional info is absent.
Evidence:
  - Reference wrapper placeholders and prompt-engineer wrapper structure as precedent. (/mnt/data/MCP server implementation.md) :contentReference[oaicite:1]{index=1}
Open Items / Unknowns:
  - Exact structure/format of “tickets” and “.tickets” (not provided).
  - Whether “.tickets” is a file extension, folder convention, or schema name (not provided).
Risks / Dependencies:
  - Risk of mismatch between ticket data shape and placeholder mapping if .tickets format is not standardized.
Acceptance Criteria:
  - A single written spec exists that lists:
    - All placeholders and which are optional.
    - Rules for missing fields (“infer from context” as described).
    - How ticket/.tickets inputs populate placeholders (or explicitly “Unknown” where not provided).
Priority & Severity (if inferable from input text):
  - Priority: Not provided
  - Severity: Not provided
Source:
  - “Not always provided, inference from context…”
  - “Our pain point: {PAIN-POINT} … if not just continue…”
  - “```md {REFERENCE-FILE}.md”
````

```ticket T2
T2 Title: Author oraclepack-style prompt/skill template for ticket and .tickets generation
Type: enhancement
Target Area: Prompt/skill template content (oraclepack-style) for tickets/.tickets
Summary:
  - Create the actual prompt/skill template that produces an oraclepack-style prompt/skill when given a ticket or .tickets input.
  - The template must use the existing wrapper structure and placeholders, and must instruct the TARGET-AGENT to generate the desired capability for the project/tool in question.
  - Ensure the template explicitly supports optional inputs and reference-file injection as described.
In Scope:
  - Produce the “ticket prompt-engineer wrapper” template that mirrors the existing wrapper pattern but targets tickets/.tickets.
  - Include all placeholders: {user-idea}, {project-in-question}, {ADDITIONAL-INFORMATION}, {PAIN-POINT}, {REFERENCE-FILE}, {CAPABILITY}, {TARGET-AGENT}, {OPTIMIZE-PROMPT}.
  - Ensure the prompt text includes the “optimized prompt that will get the {TARGET-AGENT}…” requirement, scoped to tickets/.tickets.
Out of Scope:
  - Any new MCP server requirements, tools, or resource URI schemes not explicitly requested for tickets/.tickets.
Current Behavior (Actual):
  - There is no ticket/.tickets-specific oraclepack-style prompt/skill generator template.
Expected Behavior:
  - A single reusable prompt/skill template exists that can be filled with placeholders to drive a TARGET-AGENT to create ticket/.tickets capabilities.
Reproduction Steps:
  - Not provided
Requirements / Constraints:
  - Must follow the wrapper’s optionality rules and placeholder usage.
  - Must treat {REFERENCE-FILE} content as “additional constraints/spec” when present.
Evidence:
  - Wrapper structure and placeholder set captured in existing reference prompt material. :contentReference[oaicite:2]{index=2}
Open Items / Unknowns:
  - Where this template will live (file path/naming) in the current repo/tooling (not provided).
Risks / Dependencies:
  - Depends on T1 for a stable placeholder-to-ticket mapping.
Acceptance Criteria:
  - Template includes:
    - All stated placeholders.
    - Explicit instruction to proceed when optional fields are missing.
    - A clearly stated “question to the prompt-engineer: {OPTIMIZE-PROMPT}” section.
  - Template is copy/paste ready and self-contained.
Priority & Severity (if inferable from input text):
  - Priority: Not provided
  - Severity: Not provided
Source:
  - “create an oraclepack prompt/skill but for our tickets and/or .tickets”
  - “optimized prompt that will get the {TARGET-AGENT}… giving it {CAPABILITY}”
  - “Our question to the prompt-engineer: {OPTIMIZE-PROMPT}”
```

```ticket T3
T3 Title: Update current skill to support ticket/.tickets prompt-skill generation
Type: enhancement
Target Area: Existing “current skill” (location/name not provided)
Summary:
  - Identify changes required to the existing skill so it can generate or host the new tickets/.tickets oraclepack-style prompt/skill template.
  - Ensure the current skill can accept the ticket/.tickets inputs and populate the standardized placeholders.
  - Preserve existing behavior for non-ticket use cases (if any), since only ticket support is being added.
In Scope:
  - Incorporate the finalized template from T2 into the current skill workflow.
  - Add/adjust input handling so the current skill can be driven by “tickets and/or .tickets” as the source material.
  - Ensure optional inputs (pain point, additional information, reference file) remain optional in the workflow.
Out of Scope:
  - Designing a brand-new system if the current skill can be extended (unless extension is impossible; not provided).
Current Behavior (Actual):
  - Current skill does not explicitly support generating oraclepack-style prompts/skills for tickets/.tickets (per request).
Expected Behavior:
  - Current skill can produce the tickets/.tickets oraclepack-style prompt/skill using the same wrapper placeholder mechanism.
Reproduction Steps:
  - Not provided
Requirements / Constraints:
  - Do not remove or break existing skill behavior (implied by “current skill” extension request).
Evidence:
  - “What could we do to our current skill…”
Open Items / Unknowns:
  - Current skill name, file path, and execution context (not provided).
  - How tickets/.tickets are currently stored or passed into the system (not provided).
Risks / Dependencies:
  - Depends on T2 for the template content.
Acceptance Criteria:
  - Current skill supports a ticket/.tickets-driven flow that results in the T2 template with placeholders populated (or explicitly left blank when optional).
  - No regression to existing skill behaviors (validation method not provided; document what was exercised).
Priority & Severity (if inferable from input text):
  - Priority: Not provided
  - Severity: Not provided
Source:
  - “What could we do to our current skill…”
  - “prompt… for our tickets and/or .tickets”
```

```ticket T4
T4 Title: Document integration options for delivering the tickets/.tickets prompt-skill capability
Type: docs
Target Area: Delivery/integration approach (within existing patterns)
Summary:
  - Provide a concise options write-up for how to deliver and reuse the tickets/.tickets prompt/skill generator, aligned to the existing approach patterns already in use.
  - Focus on the two explicitly requested dimensions: changes to the current skill and “other options” for fulfilling the request.
  - Avoid committing to new systems; frame as documented options with constraints and unknowns.
In Scope:
  - Option 1: Extend current skill to include tickets/.tickets support (ties to T3).
  - Option 2: Provide a standalone tickets/.tickets prompt/skill template artifact that can be consumed independently (ties to T2).
  - List constraints/unknowns impacting option choice (e.g., unknown .tickets format, unknown current-skill location).
Out of Scope:
  - Implementing the chosen option (handled by T3 and/or T2).
Current Behavior (Actual):
  - No documented approach exists for how tickets/.tickets prompt/skill generation should be delivered.
Expected Behavior:
  - A short decision-ready document exists describing the options and what each requires, without adding new requirements.
Reproduction Steps:
  - Not provided
Requirements / Constraints:
  - Options must stay within what’s already requested (modify current skill and/or alternative ways to package the prompt/skill).
Evidence:
  - “what else are our options for this request?”
Open Items / Unknowns:
  - Whether the user prefers a single consolidated skill vs multiple dedicated skills (not provided).
Risks / Dependencies:
  - Depends on T1/T2 clarity to accurately describe what each option would deliver.
Acceptance Criteria:
  - Document lists at least:
    - “Modify current skill” option (summary, prerequisites, impact).
    - “Standalone template” option (summary, prerequisites, impact).
    - Explicit unknowns that block a final choice.
Priority & Severity (if inferable from input text):
  - Priority: Not provided
  - Severity: Not provided
Source:
  - “What could we do to our current skill…”
  - “…what else are our options for this request?”
```

````ticket T5
T5 Title: Add examples and validation checks for ticket/.tickets prompt-skill generation
Type: tests
Target Area: Examples + validation of generated prompt/skill output
Summary:
  - Provide concrete example inputs (ticket and/or .tickets) and the expected generated prompt/skill output shape for validation.
  - Ensure examples exercise optional fields (missing PAIN-POINT, missing ADDITIONAL-INFORMATION, with/without REFERENCE-FILE).
  - Add lightweight validation criteria to confirm generated output preserves placeholders and wrapper structure.
In Scope:
  - Example cases covering:
    - Only {user-idea} + {project-in-question}
    - With {PAIN-POINT}
    - With {REFERENCE-FILE}
  - Validation checklist for generated output structure (placeholders present; optional fields handled).
Out of Scope:
  - End-to-end integration tests that require specific repo tooling not provided.
Current Behavior (Actual):
  - No examples/validation for tickets/.tickets prompt-skill generation are defined.
Expected Behavior:
  - Examples exist and can be used to validate that the template and current-skill integration behave as intended.
Reproduction Steps:
  - Not provided
Requirements / Constraints:
  - Must preserve the wrapper structure and placeholders as-is.
Evidence:
  - Placeholder and wrapper expectations referenced in the existing wrapper pattern. :contentReference[oaicite:3]{index=3}
Open Items / Unknowns:
  - Exact acceptance mechanism for “validation checks” in the existing system (not provided).
Risks / Dependencies:
  - Depends on T2 (template) and T3 (integration) for meaningful expected outputs.
Acceptance Criteria:
  - At least 3 example inputs exist (covering optionality cases).
  - Each example includes an expected output outline that confirms:
    - Placeholders are present.
    - Optional fields can be omitted without breaking structure.
Priority & Severity (if inferable from input text):
  - Priority: Not provided
  - Severity: Not provided
Source:
  - “Not always provided…”
  - “Our pain point: {PAIN-POINT} … continue without needing it.”
  - “```md {REFERENCE-FILE}.md”
````
```

.tickets/other/Oraclepack Workflow Enhancement.md
```
Title:

* Stabilize oraclepack “oracle-pack” pipeline and add profile-based context + Stage-3 synthesis for actionable follow-through

Summary:

* The current two-step workflow generates an `oracle-pack` Markdown file (20 `oracle` calls) via Codex skills/Gemini CLI commands, then runs it through the `oraclepack` Go wrapper to produce outputs and state/report artifacts.

    Workflow Optimization for Oracl…

    Workflow Optimization for Oracl…

* A key failure mode is schema/format drift in the pack file (human-doc + machine-ingest combined), which can break ingestion; an example drift is step headers using an em dash (`# 01 — ROI=…`) while the documented contract expects `# NN)`.

    Workflow Optimization for Oracl…

* Requested outcome: improve workflow continuity, enable richer context injection without breaking the strict pack contract, and add an automatic next stage that turns the “final twenty questions/answers” into actionable implementation steps with minimal human interaction.

    Workflow Optimization for Oracl…

    Workflow Optimization for Oracl…

Background / Context:

* Workflow stages:

  * Stage 1: LLM authoring creates `docs/oracle-pack-YYYY-MM-DD.md` containing 20 `oracle` commands (with ROI metadata and per-step output paths).

        Workflow Optimization for Oracl…

  * Stage 2: `oraclepack` executes the pack to produce 20 outputs under `oracle-out/...` plus state/report JSON artifacts.

        Workflow Optimization for Oracl…

* `oraclepack` is a wrapper around `oracle` intended for batched/bulk requests.

    Workflow Optimization for Oracl…

* Core concern: “disconnection” after the 20-question output; desire to chain into a useful, actionable implementation stage.

    Workflow Optimization for Oracl…

    Workflow Optimization for Oracl…

Current Behavior (Actual):

* Pack file acts as both:

  * Human documentation, and

  * A strict machine-ingest contract, making formatting drift a pipeline-breaking event.

        Workflow Optimization for Oracl…

* Documented/expected step-header schema (`# NN)`) can drift to alternative formats (example: `# 01 — ROI=…`), risking parse/validation failures.

    Workflow Optimization for Oracl…

* High-risk edits include adding additional code fences (especially additional bash fences) or introducing lines that accidentally match the step-header pattern.

    Workflow Optimization for Oracl…

Expected Behavior:

* Packs remain schema-stable and reliably parse/validate/run across providers (Codex skills, Gemini CLI commands).

    Workflow Optimization for Oracl…

* Richer “skill context” can be injected without changing the pack’s ingest shape (no added code fences / no header drift).

    Workflow Optimization for Oracl…

* After Stage 2 produces 20 outputs + report JSON, a subsequent stage can automatically convert results into actionable implementation steps.

    Workflow Optimization for Oracl…

Requirements:

* Preserve the non-negotiable pack contract:

  * Pack is Markdown containing exactly one `bash` code block; the first bash block is executed.

        Workflow Optimization for Oracl…

  * Steps are identified via header pattern `# NN)` with sequential numbering starting at `01`.

        Workflow Optimization for Oracl…

  * Prelude content before the first step header executes once.

        Workflow Optimization for Oracl…

* Standardize Stage-1 generation to the strict header form `# NN)` (avoid em dash variants).

    Workflow Optimization for Oracl…

* Add a hard gate between Stage 1 and Stage 2:

  * Make `oraclepack validate` mandatory before `oraclepack run` (prevent schema drift reaching execution).

        Workflow Optimization for Oracl…

* Provide schema-safe extensibility for context injection:

  * Allow context to be injected via `oracle -p` prompt text and/or `oracle -f` file/directory attachments (preferred for larger context).

        Workflow Optimization for Oracl…

  * Use prelude variables and templating only if it does not interfere with header parsing.

        Workflow Optimization for Oracl…

  * Avoid adding extra code fences or lines resembling step headers.

        Workflow Optimization for Oracl…

* Implement “Context Profiles” as file-backed bundles:

  * Add `skills/oracle-pack/references/profiles/<name>.md` and inject via `oracle -f "$profile_file"` plus a short prompt preamble (“Follow the attached profile standards”).

  * Add an optional `profile` input to the Stage-1 skill/command, with backwards-compatible behavior when absent.

        Workflow Optimization for Oracl…

* Add a first-class Stage 3 synthesis step:

  * Provide a command shape such as `oraclepack synthesize --in oracle-out --report pack.report.json --out docs/implementation-pack-YYYY-MM-DD.md` that reads the 20 outputs, extracts proposed changes/file targets/tests, and emits a new validated pack for implementation.

        Workflow Optimization for Oracl…

  * Support minimal-interaction execution for Stage 3 (e.g., headless usage via Codex/Gemini CLI).

        Workflow Optimization for Oracl…

Out of Scope:

* Not provided.

Reproduction Steps:

* Not provided.

Environment:

* `oraclepack` Go program wrapping `oracle` CLI.

* Stage-1 generation tools mentioned: Codex skills, Gemini CLI commands.

    Workflow Optimization for Oracl…

* OS/CI details: Unknown.

Evidence:

* Attachment: “Workflow Optimization for Oraclepack.md”.

    Workflow Optimization for Oracl…

    Workflow Optimization for Oracl…

* Example schema drift called out: step headers using `# 01 — ROI=…` vs documented `# NN)`.

    Workflow Optimization for Oracl…

* Proposed validation/run sequence:

  * `oraclepack validate docs/oracle-pack-YYYY-MM-DD.md`

  * `oraclepack list docs/oracle-pack-YYYY-MM-DD.md`

  * `oraclepack run docs/oracle-pack-YYYY-MM-DD.md --no-tui --run-all --stop-on-fail=true --out-dir oracle-out`

        Workflow Optimization for Oracl…

Decisions / Agreements:

* Treat the pack as a stable intermediate representation (IR) and keep context flowing only through `-p` and `-f` to avoid breaking the ingest contract.

* Prefer “Context Profiles” as a file-backed mechanism located under `skills/oracle-pack/references/profiles/`.

* Add a validation gate (`validate` before `run`) to reduce pipeline breakage from formatting drift.

    Workflow Optimization for Oracl…

Open Items / Unknowns:

* Exact current parser/validator behavior regarding em dash header variants (whether it currently accepts them) is not provided; only that it is avoidable schema drift.

    Workflow Optimization for Oracl…

* Exact filenames/paths for current `SKILL.md` and template files in the repo are referenced conceptually but not provided in full.

    Workflow Optimization for Oracl…

* Whether `oraclepack synthesize` already exists or is a new feature request is not provided; it is described as a proposed product shape.

    Workflow Optimization for Oracl…

Risks / Dependencies:

* Dependency on `oracle` CLI flags and behavior (`-p/--prompt`, `-f/--file`, `--write-output`, `--files-report`, `--dry-run`).

    Workflow Optimization for Oracl…

* Risk of pack invalidation from added code fences, additional bash blocks, or accidental header-like lines.

    Workflow Optimization for Oracl…

* Cross-provider consistency risk (Codex skills vs Gemini CLI commands) unless Stage 1 is standardized around a shared template/profile mechanism.

    Workflow Optimization for Oracl…

Acceptance Criteria:

* Pack schema stability

  * Packs validate when they contain exactly one bash block and step headers are strictly `# NN)` starting at `01`.

  * Stage-1 generation output uses `# NN)` (no em dash variant) across providers.

        Workflow Optimization for Oracl…

* Validation gate

  * Workflow includes a required `oraclepack validate` pass before any `oraclepack run`.

        Workflow Optimization for Oracl…

* Context Profiles

  * A `profile` selection results in `oracle -f "$profile_file"` being attached per step without adding new code fences or breaking parsing.

        Workflow Optimization for Oracl…

  * Absence of `profile` preserves current behavior (backwards compatible).

        Workflow Optimization for Oracl…

* Stage 3 synthesis

  * A synthesis step can consume `oracle-out` outputs + report JSON and emit a follow-on implementation pack intended to be validated and run.

        Workflow Optimization for Oracl…

Priority & Severity (if inferable from text):

* Not provided.

Labels (optional):

* enhancement

* workflow

* cli

* parsing

* validation

* context-bundles

* automation

---
```

.tickets/other/Verbose Payload Rendering TUI.md
```
Title:

* Add verbose payload rendering in TUI to display full prepared scripts/flags for oraclepack runs

Summary:

* The TUI should support a verbose mode that prints the full “prepared payload” being executed for oraclepack runs, including effective flags (post overrides and `--chatgpt-url` injection) and the entire script passed to execution.

    Verbose TUI Payload Rendering

* This is needed to verify exactly what payloads are being sent/executed during oraclepack runs and to support tests that confirm the rendered payload contents.

    Verbose TUI Payload Rendering

Background / Context:

* Proposed approach: add a reusable “prepared payload” layer to `internal/exec.Runner` (prepare prelude/step scripts after overrides + flag injection + sanitization), then have the TUI emit these prepared payload blocks to its log viewport immediately before execution.

    Verbose TUI Payload Rendering

* Files implicated by the proposal include `internal/exec/runner.go`, `internal/tui/tui.go`, `internal/cli/run.go`, plus new helpers/tests under `internal/tui/` and `internal/exec/`.

    Verbose TUI Payload Rendering

Current Behavior (Actual):

* The TUI does not provide a verbose rendering that shows the full prepared payload (full script + effective flags + extracted `oracle …` invocations) being executed for oraclepack runs.

    Verbose TUI Payload Rendering

Expected Behavior:

* When verbose payload logging is enabled, the TUI log viewport prints a payload block before each step runs that includes: effective oracle flags, extracted oracle invocations (full lines), and the full prepared script that will be executed.

    Verbose TUI Payload Rendering

* Verbose payload logging can be enabled via CLI flag (e.g., `--verbose-payload` with `-v`) and toggled in the TUI via a keybinding (proposed: `p`).

    Verbose TUI Payload Rendering

Requirements:

* Exec runner: expose “prepared payload” APIs:

  * `PreparePreludePayload(p *pack.Prelude) PreparedPreludePayload`

  * `PrepareStepPayload(s *pack.Step) PreparedStepPayload`

  * `RunPreparedPrelude(...)` / `RunPreparedStep(...)` to execute the prepared scripts.

        Verbose TUI Payload Rendering

* Prepared payload structures must include:

  * `Script` (sanitized, post injection),

  * `EffectiveFlags` (for steps),

  * `OracleInvocations` extracted from the prepared script,

  * sanitizer `Warnings`.

        Verbose TUI Payload Rendering

* TUI formatting helper:

  * Add `internal/tui/verbose_payload.go` to format payload blocks (header, effective flags, oracle invocations, then full script).

        Verbose TUI Payload Rendering

* TUI integration:

  * Add a `verbosePayload bool` toggle to the TUI model.

  * In the run flow, call `PrepareStepPayload` and, when enabled, push formatted payload lines into `logChan` before `RunPreparedStep`.

  * Add keybinding `p` to toggle `verbosePayload`.

        Verbose TUI Payload Rendering

* CLI wiring:

  * Add `--verbose-payload` / `-v` flag and pass it into `tui.NewModel(..., verbosePayload)`.

        Verbose TUI Payload Rendering

* Tests:

  * New `internal/exec/runner_payload_test.go` verifying prepared payload includes effective flags and injected oracle command text.

  * New `internal/tui/verbose_payload_test.go` verifying formatted lines include flags, invocation, and script content.

  * Update existing TUI tests to include the new `NewModel` arg.

        Verbose TUI Payload Rendering

Out of Scope:

* Not provided.

Reproduction Steps:

* Not provided.

Environment:

* Language/runtime: Go (per referenced `.go` files and packages).

    Verbose TUI Payload Rendering

* TUI framework: Bubble Tea (`tea.NewProgram(...)` referenced).

    Verbose TUI Payload Rendering

* OS / terminal / versions: Unknown.

Evidence:

* Proposed change list and implementation sketch in: /mnt/data/Verbose TUI Payload Rendering.md

    Verbose TUI Payload Rendering

* Proposed file tree changes:

  * `internal/exec/runner.go` (modify)

  * `internal/exec/runner_payload_test.go` (new)

  * `internal/tui/verbose_payload.go` (new)

  * `internal/tui/verbose_payload_test.go` (new)

  * `internal/tui/tui.go` (modify)

  * `internal/cli/run.go` (modify)

  * Update TUI tests to pass new model arg.

        Verbose TUI Payload Rendering

Decisions / Agreements:

* Adopt a “prepared payload” abstraction in `exec.Runner` to ensure the TUI logs exactly what will run after overrides, injection, and sanitization.

    Verbose TUI Payload Rendering

* Add both CLI flag control (`--verbose-payload` / `-v`) and an in-TUI toggle (proposed key: `p`).

    Verbose TUI Payload Rendering

Open Items / Unknowns:

* Exact existing TUI run flow for prelude execution (whether/where prelude runs in TUI) is not provided; proposal notes “if you also execute a prelude… do the same.”

    Verbose TUI Payload Rendering

* Exact current `NewModel(...)` signature call sites and all affected tests/files beyond those listed are not fully enumerated (some are referenced as examples).

    Verbose TUI Payload Rendering

Risks / Dependencies:

* Not provided.

Acceptance Criteria:

* Running the TUI with `--verbose-payload` causes each executed step to prepend a log block that includes:

  * “payload (step <id>)” header,

  * “effective oracle flags: …” line,

  * extracted “oracle invocations:” section (or explicit none found),

  * full “script:” content (not truncated),

  * “end payload” footer.

        Verbose TUI Payload Rendering

* Toggling `p` in the TUI flips payload logging on/off for subsequent step executions.

    Verbose TUI Payload Rendering

* `Runner.PrepareStepPayload` produces:

  * effective flags reflecting overrides and `--chatgpt-url`,

  * a prepared script containing the injected oracle invocation with those flags.

        Verbose TUI Payload Rendering

* New tests (`runner_payload_test.go`, `verbose_payload_test.go`) pass, and existing TUI tests compile and pass after updating `NewModel` call signature.

    Verbose TUI Payload Rendering

Priority & Severity (if inferable from text):

* Not provided.

Labels (optional):

* enhancement

* tui

* logging

* exec-runner

* cli

* testing

* go

---
```

docs/oracle-questions-2026-01-08/_groups.json
```
{
  "PRD-TUI": [
    ".tickets/PRD-TUI/Oraclepack TUI Integration.md",
    ".tickets/PRD-TUI/PRD-generator URL routing.md"
  ],
  "actions": [
    ".tickets/actions/Enable Action Packs Dispatch.md",
    ".tickets/actions/Improving Oraclepack Workflow.md",
    ".tickets/actions/Oraclepack Action Pack Integration.md",
    ".tickets/actions/Oraclepack Action Pack Issue.md",
    ".tickets/actions/Oraclepack Action Packs.md",
    ".tickets/actions/Oraclepack Compatibility Issues.md"
  ],
  "mcp": [
    ".tickets/mcp/Expose Oraclepack as MCP.md",
    ".tickets/mcp/MCP Server for Oraclepack.md",
    ".tickets/mcp/gaps-still-not-covered.md",
    ".tickets/mcp/gaps_part2-mcp-builder.md",
    ".tickets/mcp/oraclepack-MCP.md",
    ".tickets/mcp/oraclepack_mcp_server.md"
  ],
  "misc": [
    ".tickets/Oraclepack File Storage.md",
    ".tickets/Oraclepack Schema Approach.md",
    ".tickets/Oraclepack bash fix.md",
    ".tickets/Publish OraclePack MCP.md"
  ],
  "other": [
    ".tickets/other/Oraclepack Pipeline Improvements.md",
    ".tickets/other/Oraclepack Prompt Generator.md",
    ".tickets/other/Oraclepack Workflow Enhancement.md",
    ".tickets/other/Verbose Payload Rendering TUI.md"
  ]
}
```

docs/oracle-questions-2026-01-08/manifest.json
```
{
  "groups": [
    {
      "attached_paths": [
        ".tickets/PRD-TUI/Oraclepack TUI Integration.md",
        ".tickets/PRD-TUI/PRD-generator URL routing.md"
      ],
      "group": "PRD-TUI",
      "original_tickets": [
        ".tickets/PRD-TUI/Oraclepack TUI Integration.md",
        ".tickets/PRD-TUI/PRD-generator URL routing.md"
      ],
      "out_dir": "docs/oracle-questions-2026-01-08/prd-tui",
      "pack_path": "docs/oracle-questions-2026-01-08/packs/prd-tui.md",
      "part": 1,
      "slug": "prd-tui"
    },
    {
      "attached_paths": [
        ".tickets/actions/Enable Action Packs Dispatch.md",
        ".tickets/actions/Improving Oraclepack Workflow.md",
        ".tickets/actions/Oraclepack Action Pack Integration.md",
        ".tickets/actions/Oraclepack Action Pack Issue.md",
        ".tickets/actions/Oraclepack Action Packs.md",
        ".tickets/actions/Oraclepack Compatibility Issues.md"
      ],
      "group": "actions",
      "original_tickets": [
        ".tickets/actions/Enable Action Packs Dispatch.md",
        ".tickets/actions/Improving Oraclepack Workflow.md",
        ".tickets/actions/Oraclepack Action Pack Integration.md",
        ".tickets/actions/Oraclepack Action Pack Issue.md",
        ".tickets/actions/Oraclepack Action Packs.md",
        ".tickets/actions/Oraclepack Compatibility Issues.md"
      ],
      "out_dir": "docs/oracle-questions-2026-01-08/actions",
      "pack_path": "docs/oracle-questions-2026-01-08/packs/actions.md",
      "part": 1,
      "slug": "actions"
    },
    {
      "attached_paths": [
        ".tickets/mcp/Expose Oraclepack as MCP.md",
        ".tickets/mcp/MCP Server for Oraclepack.md",
        ".tickets/mcp/gaps-still-not-covered.md",
        ".tickets/mcp/gaps_part2-mcp-builder.md",
        ".tickets/mcp/oraclepack-MCP.md",
        ".tickets/mcp/oraclepack_mcp_server.md"
      ],
      "group": "mcp",
      "original_tickets": [
        ".tickets/mcp/Expose Oraclepack as MCP.md",
        ".tickets/mcp/MCP Server for Oraclepack.md",
        ".tickets/mcp/gaps-still-not-covered.md",
        ".tickets/mcp/gaps_part2-mcp-builder.md",
        ".tickets/mcp/oraclepack-MCP.md",
        ".tickets/mcp/oraclepack_mcp_server.md"
      ],
      "out_dir": "docs/oracle-questions-2026-01-08/mcp",
      "pack_path": "docs/oracle-questions-2026-01-08/packs/mcp.md",
      "part": 1,
      "slug": "mcp"
    },
    {
      "attached_paths": [
        ".tickets/Oraclepack File Storage.md",
        ".tickets/Oraclepack Schema Approach.md",
        ".tickets/Oraclepack bash fix.md",
        ".tickets/Publish OraclePack MCP.md"
      ],
      "group": "misc",
      "original_tickets": [
        ".tickets/Oraclepack File Storage.md",
        ".tickets/Oraclepack Schema Approach.md",
        ".tickets/Oraclepack bash fix.md",
        ".tickets/Publish OraclePack MCP.md"
      ],
      "out_dir": "docs/oracle-questions-2026-01-08/misc",
      "pack_path": "docs/oracle-questions-2026-01-08/packs/misc.md",
      "part": 1,
      "slug": "misc"
    },
    {
      "attached_paths": [
        ".tickets/other/Oraclepack Pipeline Improvements.md",
        ".tickets/other/Oraclepack Prompt Generator.md",
        ".tickets/other/Oraclepack Workflow Enhancement.md",
        ".tickets/other/Verbose Payload Rendering TUI.md"
      ],
      "group": "other",
      "original_tickets": [
        ".tickets/other/Oraclepack Pipeline Improvements.md",
        ".tickets/other/Oraclepack Prompt Generator.md",
        ".tickets/other/Oraclepack Workflow Enhancement.md",
        ".tickets/other/Verbose Payload Rendering TUI.md"
      ],
      "out_dir": "docs/oracle-questions-2026-01-08/other",
      "pack_path": "docs/oracle-questions-2026-01-08/packs/other.md",
      "part": 1,
      "slug": "other"
    }
  ]
}
```

oraclepack-mcp-server/.pytest_cache/CACHEDIR.TAG
```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html
```

oraclepack-mcp-server/oraclepack_mcp_server.egg-info/PKG-INFO
```
Metadata-Version: 2.4
Name: oraclepack-mcp-server
Version: 0.1.0
Summary: MCP wrapper for oraclepack CLI
Author: Oraclepack Contributor
Requires-Python: >=3.10
Requires-Dist: mcp[cli]>=0.1.0
Requires-Dist: pydantic-settings>=2.0.0
Requires-Dist: pydantic>=2.0.0
```

oraclepack-mcp-server/oraclepack_mcp_server.egg-info/SOURCES.txt
```
README.md
pyproject.toml
oraclepack_mcp_server/__init__.py
oraclepack_mcp_server/__main__.py
oraclepack_mcp_server/config.py
oraclepack_mcp_server/oraclepack_cli.py
oraclepack_mcp_server/security.py
oraclepack_mcp_server/server.py
oraclepack_mcp_server/taskify.py
oraclepack_mcp_server.egg-info/PKG-INFO
oraclepack_mcp_server.egg-info/SOURCES.txt
oraclepack_mcp_server.egg-info/dependency_links.txt
oraclepack_mcp_server.egg-info/entry_points.txt
oraclepack_mcp_server.egg-info/requires.txt
oraclepack_mcp_server.egg-info/top_level.txt
tests/test_config.py
```

oraclepack-mcp-server/oraclepack_mcp_server.egg-info/dependency_links.txt
```

```

oraclepack-mcp-server/oraclepack_mcp_server.egg-info/entry_points.txt
```
[console_scripts]
oraclepack-mcp = oraclepack_mcp_server.__main__:main
```

oraclepack-mcp-server/oraclepack_mcp_server.egg-info/requires.txt
```
mcp[cli]>=0.1.0
pydantic-settings>=2.0.0
pydantic>=2.0.0
```

oraclepack-mcp-server/oraclepack_mcp_server.egg-info/top_level.txt
```
oraclepack_mcp_server
```

oraclepack-mcp-server/oraclepack_mcp_server/__init__.py
```
```

oraclepack-mcp-server/oraclepack_mcp_server/__main__.py
```
import argparse
import asyncio
from .server import mcp

def main():
    parser = argparse.ArgumentParser(description="Oraclepack MCP Server")
    parser.add_argument(
        "--transport", 
        choices=["stdio", "streamable-http"], 
        default="stdio",
        help="MCP transport to use (default: stdio)"
    )
    parser.add_argument(
        "--host", 
        default="localhost",
        help="Host to bind for streamable-http (default: localhost)"
    )
    parser.add_argument(
        "--port", 
        type=int, 
        default=8000,
        help="Port to bind for streamable-http (default: 8000)"
    )
    
    args = parser.parse_args()
    
    if args.transport == "stdio":
        mcp.run(transport="stdio")
    elif args.transport == "streamable-http":
        # FastMCP.run(transport="sse") is what maps to streamable-http in python SDK
        mcp.run(transport="sse", host=args.host, port=args.port)

if __name__ == "__main__":
    main()
```

oraclepack-mcp-server/oraclepack_mcp_server/config.py
```
import os
from pathlib import Path
from typing import List, Union, Any
from pydantic import Field, field_validator
from pydantic_settings import BaseSettings, SettingsConfigDict

class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_prefix="ORACLEPACK_",
        env_file=".env",
        extra="ignore"
    )

    bin: str = Field(default="oraclepack", description="Path to the oraclepack binary")
    # Use Union to prevent pydantic-settings from forcing JSON decode
    allowed_roots: Any = Field(
        default_factory=lambda: [Path.cwd()],
        description="List of allowed filesystem roots"
    )
    workdir: Path = Field(default_factory=Path.cwd, description="Working directory for execution")
    enable_exec: bool = Field(default=False, description="Enable execution tools")
    max_read_bytes: int = Field(default=65536, description="Max bytes for file read operations")
    character_limit: int = Field(default=32000, description="Max characters for tool outputs")

    @field_validator("allowed_roots", mode="before")
    @classmethod
    def parse_allowed_roots(cls, v: Any) -> List[Path]:
        if isinstance(v, str):
            # Support both colon and comma separation
            delimiter = ":" if ":" in v else ","
            return [Path(p.strip()) for p in v.split(delimiter) if p.strip()]
        if isinstance(v, list):
            return [Path(p) if isinstance(p, (str, Path)) else p for p in v]
        return v

settings = Settings()
```

oraclepack-mcp-server/oraclepack_mcp_server/oraclepack_cli.py
```
import asyncio
import time
from dataclasses import dataclass
from typing import List, Optional
from .config import settings

@dataclass
class OraclepackResult:
    ok: bool
    exit_code: int
    duration_s: float
    stdout: str
    stderr: str
    stdout_truncated: bool
    stderr_truncated: bool
    error: Optional[str] = None

def truncate_output(text: str, limit: int) -> tuple[str, bool]:
    """Truncates text to limit and returns (truncated_text, is_truncated)."""
    if len(text) > limit:
        return text[:limit], True
    return text, False

async def run_oraclepack(args: List[str], timeout: float = 3600.0) -> OraclepackResult:
    """
    Runs the oraclepack CLI with the given arguments.
    Handles timeouts and output truncation.
    """
    start_time = time.time()
    
    cmd = [settings.bin] + args
    
    try:
        # Create the subprocess
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=settings.workdir
        )
        
        try:
            # Wait for completion with timeout
            stdout_bytes, stderr_bytes = await asyncio.wait_for(process.communicate(), timeout=timeout)
            exit_code = process.returncode
        except asyncio.TimeoutError:
            # Handle timeout
            process.kill()
            await process.wait() # Ensure process is cleaned up
            stdout_bytes, stderr_bytes = b"", b"Timed out after " + str(timeout).encode() + b"s"
            exit_code = 124 # Standard timeout exit code
            
    except Exception as e:
        duration = time.time() - start_time
        return OraclepackResult(
            ok=False,
            exit_code=-1,
            duration_s=duration,
            stdout="",
            stderr="",
            stdout_truncated=False,
            stderr_truncated=False,
            error=str(e)
        )

    duration = time.time() - start_time
    
    stdout_raw = stdout_bytes.decode("utf-8", errors="replace")
    stderr_raw = stderr_bytes.decode("utf-8", errors="replace")
    
    stdout, stdout_truncated = truncate_output(stdout_raw, settings.character_limit)
    stderr, stderr_truncated = truncate_output(stderr_raw, settings.character_limit)
    
    return OraclepackResult(
        ok=(exit_code == 0),
        exit_code=exit_code,
        duration_s=duration,
        stdout=stdout,
        stderr=stderr,
        stdout_truncated=stdout_truncated,
        stderr_truncated=stderr_truncated
    )
```

oraclepack-mcp-server/oraclepack_mcp_server/security.py
```
import os
from pathlib import Path
from typing import List, Optional
from .config import settings

class SecurityError(Exception):
    """Raised for security-related violations."""
    pass

def is_exec_enabled() -> bool:
    """Returns True if execution tools are explicitly enabled."""
    return settings.enable_exec

def validate_path(path: str | Path) -> Path:
    """
    Resolves a path and ensures it resides within one of the allowed roots.
    Returns the resolved Path if valid, otherwise raises SecurityError.
    """
    p = Path(path)
    # Always normalize the path to remove .. and other noise
    try:
        # resolve() is best but it follows symlinks and requires existence for full resolution on some platforms.
        # abspath + normpath is a good fallback for non-existent files.
        resolved_p = Path(os.path.abspath(os.path.normpath(p)))
    except Exception as e:
        raise SecurityError(f"Could not resolve path '{path}': {e}")

    # Check if resolved_p starts with any of the allowed roots
    is_allowed = False
    for root in settings.allowed_roots:
        try:
            resolved_root = Path(os.path.abspath(os.path.normpath(root)))
            # commonpath returns the common prefix. 
            # If resolved_p is under resolved_root, commonpath should be resolved_root.
            common = os.path.commonpath([str(resolved_root), str(resolved_p)])
            if common == str(resolved_root):
                is_allowed = True
                break
        except ValueError:
            # Different drives on Windows or other incompatibilities
            continue

    if not is_allowed:
        raise SecurityError(f"Access to path '{path}' is not allowed by ORACLEPACK_ALLOWED_ROOTS.")

    return resolved_p

def safe_read_file(path: str | Path) -> tuple[str, bool]:
    """
    Validates the path and reads its content up to max_read_bytes.
    Returns (content, truncated).
    """
    resolved_path = validate_path(path)
    
    if not resolved_path.exists():
        raise SecurityError(f"Path '{path}' does not exist.")
    if not resolved_path.is_file():
        raise SecurityError(f"Path '{path}' is not a file.")

    with open(resolved_path, "rb") as f:
        content_bytes = f.read(settings.max_read_bytes + 1)
        truncated = len(content_bytes) > settings.max_read_bytes
        content = content_bytes[:settings.max_read_bytes].decode("utf-8", errors="replace")
        return content, truncated
```

oraclepack-mcp-server/oraclepack_mcp_server/server.py
```
import logging
import sys
import os
from mcp.server.fastmcp import FastMCP
from mcp.types import ToolAnnotations
from .config import settings
from . import security
from . import oraclepack_cli
from . import taskify

# Configure logging to stderr to avoid interleaving with stdio transport
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stderr
)
logger = logging.getLogger("oraclepack-mcp-server")

# Initialize FastMCP
mcp = FastMCP("Oraclepack")

@mcp.tool(annotations=ToolAnnotations(readOnlyHint=True))
async def oraclepack_read_file(path: str) -> str:
    """
    Reads a file within allowed roots.
    Enforces ORACLEPACK_ALLOWED_ROOTS and ORACLEPACK_MAX_READ_BYTES.
    """
    content, truncated = security.safe_read_file(path)
    if truncated:
        return f"--- TRUNCATED (Max {settings.max_read_bytes} bytes) ---\n{content}"
    return content

@mcp.tool(annotations=ToolAnnotations(readOnlyHint=True))
async def oraclepack_list_packs(directory: str = ".") -> str:
    """Lists available oracle packs (*.md) in a directory."""
    resolved_dir = security.validate_path(directory)
    if not resolved_dir.is_dir():
        return f"Path '{directory}' is not a directory."
    
    packs = list(resolved_dir.glob("*.md"))
    if not packs:
        return f"No oracle packs found in '{directory}'."
    
    return "\n".join([p.name for p in packs])

@mcp.tool(annotations=ToolAnnotations(readOnlyHint=True))
async def oraclepack_validate_pack(pack_path: str) -> str:
    """Validates an oracle pack using the Go CLI."""
    resolved_path = security.validate_path(pack_path)
    result = await oraclepack_cli.run_oraclepack(["validate", str(resolved_path)])
    if not result.ok:
        return f"Validation failed:\n{result.stderr or result.error}"
    return "Pack is valid."

@mcp.tool(annotations=ToolAnnotations(readOnlyHint=True))
async def oraclepack_list_steps(pack_path: str) -> str:
    """Lists steps in an oracle pack."""
    resolved_path = security.validate_path(pack_path)
    result = await oraclepack_cli.run_oraclepack(["list", str(resolved_path)])
    if not result.ok:
        return f"Failed to list steps:\n{result.stderr or result.error}"
    return result.stdout

@mcp.tool(annotations=ToolAnnotations(destructiveHint=True, openWorldHint=True))
async def oraclepack_run_pack(pack_path: str, yes: bool = True, run_all: bool = True) -> str:
    """
    Runs an oracle pack. REQUIRES ORACLEPACK_ENABLE_EXEC=1.
    """
    if not security.is_exec_enabled():
        return "Execution is disabled. Set ORACLEPACK_ENABLE_EXEC=1 to enable."
    
    resolved_path = security.validate_path(pack_path)
    args = ["run", str(resolved_path), "--no-tui"]
    if yes: args.append("--yes")
    if run_all: args.append("--run-all")
    
    result = await oraclepack_cli.run_oraclepack(args)
    
    # Verbose Payload Rendering
    output = [f"# Execution Report: {pack_path}"]
    output.append(f"**Status**: {'✅ SUCCESS' if result.ok else '❌ FAILED'}")
    output.append(f"**Exit Code**: {result.exit_code}")
    output.append(f"**Duration**: {result.duration_s:.2f}s")
    
    if result.error:
        output.append(f"\n### Error\n{result.error}")
    
    if result.stdout:
        output.append("\n### Standard Output")
        output.append(f"```\n{result.stdout}\n```")
        if result.stdout_truncated:
            output.append("*Note: Output was truncated.*")
            
    if result.stderr:
        output.append("\n### Standard Error")
        output.append(f"```\n{result.stderr}\n```")
        if result.stderr_truncated:
            output.append("*Note: Error output was truncated.*")
            
    # Add artifact summary if successful or partially successful
    parent_dir = resolved_path.parent
    summary = taskify.artifacts_summary(parent_dir)
    output.append("\n### Artifacts Summary")
    for name, info in summary["artifacts"].items():
        if info:
            output.append(f"- {name}: FOUND")
        else:
            output.append(f"- {name}: NOT FOUND")
        
    return "\n".join(output)

@mcp.tool(annotations=ToolAnnotations(readOnlyHint=True))
async def oraclepack_taskify_detect_stage2(path: str = "auto") -> str:
    """Detects Stage-2 outputs."""
    out_dir, mode = taskify.detect_stage2(path, os.getcwd())
    if not out_dir:
        return f"Could not detect Stage-2 outputs in mode '{mode}'."
    return f"Detected Stage-2 directory: {out_dir} (Mode: {mode})"

@mcp.tool(annotations=ToolAnnotations(readOnlyHint=True))
async def oraclepack_taskify_validate_stage2(out_dir: str) -> str:
    """Validates Stage-2 directory structure (prefixes 01..20)."""
    resolved_dir = security.validate_path(out_dir)
    result = taskify.validate_stage2_dir(resolved_dir)
    if result.ok:
        return f"Stage-2 directory is valid. Found {len(result.valid_files)} files."
    
    output = ["Stage-2 validation failed:"]
    if result.missing:
        output.append(f"Missing prefixes: {', '.join(result.missing)}")
    if result.ambiguous:
        output.append("Ambiguous prefixes (multiple matches):")
        for pfx, matches in result.ambiguous.items():
            output.append(f"  {pfx}: {', '.join(matches)}")
            
    return "\n".join(output)

@mcp.tool(annotations=ToolAnnotations(readOnlyHint=True))
async def oraclepack_taskify_validate_action_pack(file_path: str) -> str:
    """Validates Stage-3 action pack structure."""
    resolved_path = security.validate_path(file_path)
    result = taskify.validate_action_pack(resolved_path)
    if result.ok:
        return f"Action pack is valid. Detected steps: {', '.join(result.steps)}"
    return f"Action pack validation failed: {result.error}"

@mcp.tool(annotations=ToolAnnotations(readOnlyHint=True))
async def oraclepack_taskify_artifacts_summary(out_dir: str) -> str:
    """Summarizes Stage-3 artifacts."""
    resolved_dir = security.validate_path(out_dir)
    summary = taskify.artifacts_summary(resolved_dir)
    
    output = [f"Artifacts Summary for {summary['out_dir']}:"]
    for name, info in summary["artifacts"].items():
        if info:
            output.append(f"- {name}: FOUND ({info['size']} bytes) at {info['path']}")
        else:
            output.append(f"- {name}: NOT FOUND")
            
    return "\n".join(output)

@mcp.tool(annotations=ToolAnnotations(destructiveHint=True, openWorldHint=True))
async def oraclepack_taskify_run_action_pack(file_path: str) -> str:
    """
    Runs a Stage-3 action pack. REQUIRES ORACLEPACK_ENABLE_EXEC=1.
    """
    # Simply wraps oraclepack_run_pack with action pack defaults
    return await oraclepack_run_pack(file_path, yes=True, run_all=True)

@mcp.tool(annotations=ToolAnnotations(readOnlyHint=True))
async def oraclepack_taskify_generate_prompt(file_path: str) -> str:
    """Generates instructions for an agent to run an action pack."""
    resolved_path = security.validate_path(file_path)
    result = taskify.validate_action_pack(resolved_path)
    if not result.ok:
        return f"Validation failed: {result.error}"
    return taskify.generate_agent_prompt(file_path, result.steps)
```

oraclepack-mcp-server/oraclepack_mcp_server/taskify.py
```
import os
import re
import glob
from pathlib import Path
from typing import List, Dict, Optional, Set, Tuple, Any
from dataclasses import dataclass, field

@dataclass
class Stage2ValidationResult:
    ok: bool
    missing: List[str] = field(default_factory=list)
    ambiguous: Dict[str, List[str]] = field(default_factory=dict)
    valid_files: List[str] = field(default_factory=list)

@dataclass
class ActionPackValidationResult:
    ok: bool
    error: Optional[str] = None
    steps: List[str] = field(default_factory=list)

def validate_stage2_dir(out_dir: str | Path) -> Stage2ValidationResult:
    """
    Enforces exactly one file per prefix 01..20.
    Returns Stage2ValidationResult with missing and ambiguous sets.
    """
    out_dir = Path(out_dir)
    missing = []
    ambiguous = {}
    valid_files = []
    
    for i in range(1, 21):
        pfx = f"{i:02d}"
        matches = list(out_dir.glob(f"{pfx}-*.md"))
        
        if not matches:
            missing.append(pfx)
        elif len(matches) > 1:
            ambiguous[pfx] = [m.name for m in matches]
        else:
            valid_files.append(matches[0].name)
            
    return Stage2ValidationResult(
        ok=(not missing and not ambiguous),
        missing=missing,
        ambiguous=ambiguous,
        valid_files=valid_files
    )

def detect_stage2(stage2_path: str, repo_root: str | Path) -> Tuple[Optional[Path], str]:
    """
    Resolves out_dir for Stage-2.
    Supports explicit dir, explicit file, and 'auto'.
    Returns (out_dir, mode).
    """
    repo_root = Path(repo_root)
    
    if stage2_path == "auto":
        candidates = [
            Path.cwd() / "oracle-out",
            repo_root / "oracle-out"
        ]
        
        docs_dir = repo_root / "docs"
        if docs_dir.exists():
            q_dirs = sorted(list(docs_dir.glob("oracle-questions-*")), reverse=True)
            for qd in q_dirs:
                candidates.append(qd / "oracle-out")
                
        for c in candidates:
            if c.exists() and c.is_dir():
                return c, "auto"
        return None, "auto"

    p = Path(stage2_path)
    if p.is_dir():
        return p, "explicit_dir"
    
    if p.is_file():
        parent = p.parent
        if (parent / "oracle-out").exists():
            return parent / "oracle-out", "explicit_file"
        return parent, "explicit_file"

    return None, "unknown"

def validate_action_pack(file_path: str | Path) -> ActionPackValidationResult:
    """
    Validates Stage-3 Action Pack constraints:
    - Single bash code fence
    - Step headers # NN)
    """
    try:
        content = Path(file_path).read_text()
    except Exception as e:
        return ActionPackValidationResult(ok=False, error=f"Read error: {e}")

    fences = re.findall(r"```bash", content)
    if len(fences) == 0:
        return ActionPackValidationResult(ok=False, error="No ```bash code fence found.")
    if len(fences) > 1:
        return ActionPackValidationResult(ok=False, error="Multiple ```bash code fences found. Only one is allowed.")

    steps = re.findall(r"^#\s*(\d+)\)", content, re.MULTILINE)
    if not steps:
        return ActionPackValidationResult(ok=False, error="No step headers (e.g. '# 01)') found.")

    return ActionPackValidationResult(ok=True, steps=steps)

def artifacts_summary(out_dir: str | Path) -> Dict[str, Any]:
    """
    Summarizes key Stage-3 artifacts.
    """
    out_dir = Path(out_dir)
    summary = {
        "out_dir": str(out_dir),
        "artifacts": {}
    }
    
    important_files = [
        "_actions.json",
        "_actions.md",
        "_tickets_index.json",
        "ticket-action-pack.md",
        "tm-complexity.json",
        "PRD.md",
        "prd.md",
        "tickets_prd.md"
    ]
    
    for f in important_files:
        found = False
        for search_path in [out_dir / f, out_dir.parent / f, out_dir.parent.parent / f]:
            if search_path.exists():
                summary["artifacts"][f] = {
                    "path": str(search_path),
                    "size": search_path.stat().st_size
                }
                found = True
                break
        if not found:
            summary["artifacts"][f] = None
            
    return summary

def generate_agent_prompt(pack_path: str, steps: List[str]) -> str:
    """
    Generates a prompt for an agent to run an action pack.
    """
    return f"""
# Oraclepack Action Pack Instructions

You are about to run an Oraclepack Action Pack: `{pack_path}`.
This pack contains {len(steps)} steps: {', '.join(steps)}.

## Recommended Workflow

1. **Verify**: Use `oraclepack_taskify_validate_action_pack` to ensure structure is correct.
2. **Execution**: Use `oraclepack_taskify_run_action_pack` to execute the steps non-interactively.
3. **Artifacts**: After execution, use `oraclepack_taskify_artifacts_summary` to see produced files.
4. **Inspection**: Read `_actions.json` or `_actions.md` to understand the outcomes of each step.

## Security Note
Execution tools require `ORACLEPACK_ENABLE_EXEC=1` in the server environment.
"""
```

oraclepack-mcp-server/tests/test_cli.py
```
import asyncio
import pytest
from unittest.mock import AsyncMock, patch, MagicMock
from oraclepack_mcp_server.oraclepack_cli import run_oraclepack, OraclepackResult
from oraclepack_mcp_server.config import settings

@pytest.mark.asyncio
async def test_run_oraclepack_success():
    # Mock process.communicate
    mock_stdout = b"success output"
    mock_stderr = b""
    
    with patch("asyncio.create_subprocess_exec", new_callable=AsyncMock) as mock_exec:
        mock_process = AsyncMock()
        mock_process.communicate.return_value = (mock_stdout, mock_stderr)
        mock_process.returncode = 0
        mock_exec.return_value = mock_process
        
        result = await run_oraclepack(["list", "pack.md"])
        
        assert result.ok is True
        assert result.exit_code == 0
        assert result.stdout == "success output"
        assert result.stdout_truncated is False

@pytest.mark.asyncio
async def test_run_oraclepack_timeout():
    with patch("asyncio.create_subprocess_exec", new_callable=AsyncMock) as mock_exec:
        mock_process = AsyncMock()
        
        async def slow_communicate():
            await asyncio.sleep(10)
            return (b"", b"")
            
        mock_process.communicate.side_effect = slow_communicate
        mock_exec.return_value = mock_process
        
        # Run with short timeout
        result = await run_oraclepack(["run", "pack.md"], timeout=0.1)
        
        assert result.ok is False
        assert result.exit_code == 124
        assert "Timed out" in result.stderr

@pytest.mark.asyncio
async def test_run_oraclepack_truncation(monkeypatch):
    monkeypatch.setattr(settings, "character_limit", 5)
    
    mock_stdout = b"1234567890"
    mock_stderr = b""
    
    with patch("asyncio.create_subprocess_exec", new_callable=AsyncMock) as mock_exec:
        mock_process = AsyncMock()
        mock_process.communicate.return_value = (mock_stdout, mock_stderr)
        mock_process.returncode = 0
        mock_exec.return_value = mock_process
        
        result = await run_oraclepack(["list"])
        
        assert result.stdout == "12345"
        assert result.stdout_truncated is True
```

oraclepack-mcp-server/tests/test_config.py
```
import os
import pytest
from pathlib import Path
from oraclepack_mcp_server.config import Settings

def test_default_config():
    # Clear env vars that might interfere
    for key in os.environ:
        if key.startswith("ORACLEPACK_"):
            del os.environ[key]
    
    # Reload settings or create a new instance
    # Note: the 'settings' object is already instantiated, so we test a new instance
    s = Settings()
    assert s.bin == "oraclepack"
    assert s.enable_exec is False
    assert s.character_limit == 32000
    assert Path.cwd() in s.allowed_roots

def test_env_override():
    os.environ["ORACLEPACK_BIN"] = "/custom/path/oraclepack"
    os.environ["ORACLEPACK_ENABLE_EXEC"] = "1"
    os.environ["ORACLEPACK_ALLOWED_ROOTS"] = "/tmp:/var/log"
    os.environ["ORACLEPACK_CHARACTER_LIMIT"] = "1000"
    
    s = Settings()
    assert s.bin == "/custom/path/oraclepack"
    assert s.enable_exec is True
    assert Path("/tmp") in s.allowed_roots
    assert Path("/var/log") in s.allowed_roots
    assert s.character_limit == 1000
    
    # Cleanup
    del os.environ["ORACLEPACK_BIN"]
    del os.environ["ORACLEPACK_ENABLE_EXEC"]
    del os.environ["ORACLEPACK_ALLOWED_ROOTS"]
    del os.environ["ORACLEPACK_CHARACTER_LIMIT"]
```

oraclepack-mcp-server/tests/test_integration.py
```
import asyncio
import pytest
import sys
from mcp.client.session import ClientSession
from mcp.client.stdio import stdio_client, StdioServerParameters
from mcp.types import CallToolRequestParams
import os
from pathlib import Path

@pytest.mark.asyncio
async def test_server_tools_list():
    """
    Spins up the server via stdio and checks if it can list its tools.
    """
    # Path to our package
    server_params = StdioServerParameters(
        command=sys.executable,
        args=["-m", "oraclepack_mcp_server", "--transport", "stdio"],
        env={**os.environ, "PYTHONPATH": str(Path(__file__).parent.parent)}
    )
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            tools = await session.list_tools()
            tool_names = [t.name for t in tools.tools]
            
            assert "oraclepack_read_file" in tool_names
            assert "oraclepack_validate_pack" in tool_names
            assert "oraclepack_run_pack" in tool_names
            assert "oraclepack_taskify_detect_stage2" in tool_names
            assert "oraclepack_taskify_validate_stage2" in tool_names
            assert "oraclepack_taskify_validate_action_pack" in tool_names
            assert "oraclepack_taskify_artifacts_summary" in tool_names
            assert "oraclepack_taskify_generate_prompt" in tool_names

@pytest.mark.asyncio
async def test_oraclepack_read_file_unauthorized(tmp_path):
    """
    Verifies that the server enforces allowed roots.
    """
    root1 = tmp_path / "allowed"
    root1.mkdir()
    outside = tmp_path / "outside.txt"
    outside.touch()
    
    server_params = StdioServerParameters(
        command=sys.executable,
        args=["-m", "oraclepack_mcp_server", "--transport", "stdio"],
        env={
            **os.environ, 
            "PYTHONPATH": str(Path(__file__).parent.parent),
            "ORACLEPACK_ALLOWED_ROOTS": str(root1)
        }
    )
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            # Try to read file outside allowed root
            result = await session.call_tool("oraclepack_read_file", {"path": str(outside)})
            
            # FastMCP returns the result even if there was an internal exception string returned
            assert "Access to path" in result.content[0].text
            assert "is not allowed" in result.content[0].text
```

oraclepack-mcp-server/tests/test_security.py
```
import os
import pytest
from pathlib import Path
from oraclepack_mcp_server.security import validate_path, is_exec_enabled, SecurityError, safe_read_file
from oraclepack_mcp_server.config import Settings, settings

def test_is_exec_enabled(monkeypatch):
    # Test with default (False)
    monkeypatch.setattr(settings, "enable_exec", False)
    assert is_exec_enabled() is False
    
    # Test with True
    monkeypatch.setattr(settings, "enable_exec", True)
    assert is_exec_enabled() is True

def test_validate_path_allowed(tmp_path, monkeypatch):
    # Setup tmp_path as an allowed root
    monkeypatch.setattr(settings, "allowed_roots", [tmp_path])
    
    # Path inside allowed root
    test_file = tmp_path / "test.txt"
    test_file.touch()
    
    assert validate_path(test_file) == test_file.resolve()
    assert validate_path(str(test_file)) == test_file.resolve()

def test_validate_path_denied(tmp_path, monkeypatch):
    # Setup allowed root
    root1 = tmp_path / "root1"
    root1.mkdir()
    monkeypatch.setattr(settings, "allowed_roots", [root1])
    
    # Path outside allowed root
    outside_file = tmp_path / "outside.txt"
    outside_file.touch()
    
    with pytest.raises(SecurityError, match="not allowed"):
        validate_path(outside_file)

def test_validate_path_traversal(tmp_path, monkeypatch):
    root1 = tmp_path / "root1"
    root1.mkdir()
    monkeypatch.setattr(settings, "allowed_roots", [root1])
    
    # Try to traverse out
    traversal_path = root1 / ".." / "outside.txt"
    
    with pytest.raises(SecurityError, match="not allowed"):
        validate_path(traversal_path)

def test_safe_read_file(tmp_path, monkeypatch):
    monkeypatch.setattr(settings, "allowed_roots", [tmp_path])
    monkeypatch.setattr(settings, "max_read_bytes", 10)
    
    test_file = tmp_path / "large.txt"
    test_file.write_text("0123456789ABCDE") # 15 chars
    
    content, truncated = safe_read_file(test_file)
    assert content == "0123456789"
    assert truncated is True
    
    small_file = tmp_path / "small.txt"
    small_file.write_text("hello")
    content, truncated = safe_read_file(small_file)
    assert content == "hello"
    assert truncated is False
```

oraclepack-mcp-server/tests/test_taskify.py
```
import pytest
from pathlib import Path
from oraclepack_mcp_server.taskify import validate_stage2_dir, detect_stage2, validate_action_pack

def test_validate_stage2_dir_ok(tmp_path):
    # Create 01..20 files
    for i in range(1, 21):
        (tmp_path / f"{i:02d}-test.md").touch()
    
    result = validate_stage2_dir(tmp_path)
    assert result.ok is True
    assert len(result.valid_files) == 20

def test_validate_stage2_dir_missing(tmp_path):
    # Missing 05 and 10
    for i in range(1, 21):
        if i in [5, 10]: continue
        (tmp_path / f"{i:02d}-test.md").touch()
    
    result = validate_stage2_dir(tmp_path)
    assert result.ok is False
    assert "05" in result.missing
    assert "10" in result.missing

def test_validate_stage2_dir_ambiguous(tmp_path):
    # Double 01
    (tmp_path / "01-a.md").touch()
    (tmp_path / "01-b.md").touch()
    for i in range(2, 21):
        (tmp_path / f"{i:02d}-test.md").touch()
        
    result = validate_stage2_dir(tmp_path)
    assert result.ok is False
    assert "01" in result.ambiguous
    assert len(result.ambiguous["01"]) == 2

def test_validate_action_pack_ok(tmp_path):
    pack_file = tmp_path / "pack.md"
    pack_file.write_text("""
# My Action Pack
# 01) Step One
```bash
echo hello
```
# 02) Step Two
""")
    result = validate_action_pack(pack_file)
    assert result.ok is True
    assert result.steps == ["01", "02"]

def test_validate_action_pack_multiple_fences(tmp_path):
    pack_file = tmp_path / "pack.md"
    pack_file.write_text("""
```bash
echo one
```
```bash
echo two
```
""")
    result = validate_action_pack(pack_file)
    assert result.ok is False
    assert "Multiple" in result.error

def test_detect_stage2_auto(tmp_path, monkeypatch):
    oracle_out = tmp_path / "oracle-out"
    oracle_out.mkdir()
    
    # Mock current working directory or just pass repo_root
    result_dir, mode = detect_stage2("auto", tmp_path)
    assert result_dir == oracle_out
    assert mode == "auto"
```

skills/oraclepack-pipeline-improver/SKILL.md
```
---
name: oraclepack-pipeline-improver
description: Improve an oraclepack (Go wrapper around @steipete/oracle) pipeline by specifying/implementing deterministic validate→run→actionize behavior:strict pack validation, run manifests, stable run directories, resume/rerun semantics, concurrency/backoff, optional caching, and a Stage 3 “Actionizer” that converts 20 oracle outputs into actionable engineering work artifacts.
metadata:
  short-description: Deterministic oraclepack validate/run/actionize pipeline spec + implementation rails
---

## Quick start

Use this skill when the user wants to:

- make oraclepack runs deterministic and resume-safe,
- add a strict validator and machine-readable outputs,
- add Stage 3 “actionize” to convert the 20 question outputs into an actionable backlog/change plan,
- make the pipeline CI-friendly and path-safe.

Interpret the user’s free-text `{{args}}` as the target subset (validate/run/actionize/caching/CI) plus any paths to focus on.

If repo context or current CLI behavior is missing, write **Unknown/TODO** and proceed with a spec-first answer.

## Workflow

### 1) Establish “observed vs proposed”

1. List what inputs are available (repo files, current CLI help text, sample pack md, run output dirs).
2. Split all statements into:
   - **Observed** (backed by provided evidence),
   - **Proposed** (the target contract to implement),
   - **Unknown/TODO** (needs files/flags not provided).

### 2) Define the target pipeline contract (deterministic by default)

Produce a concrete contract for:

- `oraclepack validate` (strict + JSON output),
- `oraclepack run` (stable run dir + `run.json`/`steps.json` + outputs + resume/rerun),
- `oraclepack actionize` (reads run dir and produces `actionizer/` artifacts),
- CI mode behavior (non-interactive, structured logs, policy-driven exit codes),
- Path safety for output writing.

Use:

- references/cli-contract.md
- references/run-manifest-spec.md
- references/actionizer-spec.md

### 3) Map contract → implementation deltas (minimal, additive, backward-compatible)

1. Identify current commands/flags and current on-disk layout (Observed).
2. Propose additive changes:
   - new flags and new subcommands should not break existing pack schema without an explicit migration path,
   - new on-disk outputs should be in `.oraclepack/runs/<pack_id>/...` without removing legacy output locations (unless requested).
3. For each proposed change, specify:
   - code touchpoints (files/modules: **Unknown** if repo not provided),
   - acceptance tests and fixtures,
   - failure modes and user-visible error messages.

### 4) Stage 1 prompt shaping (pack generation) to help Stage 3 parse reliably

If the workflow includes Stage 1 pack generation:

- propose embedding **mini-metadata inside each prompt** (does not change pack schema),
- keep metadata parseable and consistent.

Use references/stage1-prompt-metadata.md.

### 5) Produce final deliverables (spec + plan, optionally code)

Deliverables should be:

1. **Pipeline contract** (validate/run/actionize + CI + safety).
2. **On-disk schemas** (`run.json`, `steps.json`, `normalized.jsonl`, `backlog.md`, `change-plan.md`).
3. **Acceptance criteria** and a minimal test plan.
4. **Implementation plan** (ordered steps, smallest shippable increments).
5. If code context is provided and the user wants implementation: output concrete file edits + new files.

## Output contract

Unless the user asks for something else, output a single Markdown report with:

- **Scope** (what parts of validate/run/actionize/CI/caching are included)
- **Observed current behavior** (or **Unknown**)
- **Proposed contract** (link to reference sections where applicable)
- **Disk layout + schemas**
- **Acceptance criteria**
- **Implementation plan** (phased; smallest first)
- **Risks / unknowns**
- **Missing inputs** (exact paths/flags/help output needed)

If asked to generate templates, use the assets:

- assets/backlog-template.md
- assets/change-plan-template.md
- assets/normalized.example.jsonl

## Failure modes

- Missing repo / CLI help / sample run dirs → mark **Unknown** and provide a spec-first response.
- Missing definitions for CI thresholds / policies → include **TODO** defaults and clearly label them as policy choices.
- Any “current behavior” claim without evidence → downgrade to **Unknown**.

## Invocation examples

1) Add strict validator + JSON output:

- `$oraclepack-pipeline-improver Add oraclepack validate --strict --json; define schema checks and CI gating exit codes`

1) Deterministic run dir + resume/rerun:

- `$oraclepack-pipeline-improver Specify .oraclepack/runs/<pack_id>/ layout, run.json/steps.json, resume default, --rerun failed|all|01,03`

1) Concurrency + backoff policy:

- `$oraclepack-pipeline-improver Add --max-parallel N and transient error retry budget/backoff rules`

1) Stage 3 Actionizer:

- `$oraclepack-pipeline-improver Implement oraclepack actionize; generate normalized.jsonl + backlog.md + change-plan.md with stable IDs`

1) CI mode:

- `$oraclepack-pipeline-improver Provide run --ci --non-interactive --json-log and actionize --ci; policy-driven exit codes`

1) Stage 1 prompt metadata shaping:

- `$oraclepack-pipeline-improver Add prompt-embedded metadata (QuestionId/Category/Reference/ExpectedArtifacts) without changing pack schema`
```

skills/oraclepack-tickets-pack/SKILL.md
```
---
name: oraclepack-tickets-pack
description: Generate a runner-ingestible oraclepack Stage-1 question pack (single Markdown doc) driven by `.tickets/` content. Exactly one ```bash fence, exactly 20 steps (01..20), strict ROI header tokens, deterministic ticket bundling, minimal per-step attachments, coverage check.
metadata:
  short-description: Ticket-driven Stage-1 oraclepack pack generator + validators
---

# oraclepack-tickets-pack (Stage 1)

## Purpose

Produce a **ticket-driven** oraclepack Stage-1 pack (Markdown) that is **runner-ingestible** and **schema-compatible** with existing oraclepack pack format.

The generated pack’s questions and minimal attachments are guided primarily by a deterministic **ticket bundle** built from `.tickets/` (or explicit ticket paths).

## Use when

- You have tickets stored under `.tickets/` (or you can provide explicit ticket file paths), and you want a strict 20-step oraclepack Stage-1 question pack that:
  - references tickets as the primary context in every step
  - uses minimal attachments per step
  - preserves existing oraclepack Markdown pack schema (backward compatible)

## Hard requirements (output contract)

The produced pack (single Markdown file) MUST satisfy:

1) **Schema safety / compatibility**
- Do not break the existing oraclepack Markdown pack schema.
- Exactly **one** fenced code block labeled `bash` in the entire document.
- No other fenced code blocks anywhere (no additional ``` fences).

1) **Runner-ingestible strictness**
- Exactly **20** steps inside the single `bash` fence.
- Steps are numbered **01..20** in order.
- Each step header starts with `# NN)` and includes the strict header tokens in the header line:
  - `ROI= ... impact= ... confidence= ... effort= ... horizon= ... category= ... reference= ...`
- Every step includes:
  - `--write-output "<out_dir>/<nn>-<slug>.md"`
- Steps must be **self-contained** and must **not rely on shell variables created in previous steps**.

1) **Attachment minimization**
- Default **0–2 native attachments per step**.
- Each step should normally attach:
  - `-f "<ticket_bundle_path>"` (primary context)
  - plus at most **one** additional repo file when needed
- If `extra_files` are provided, append them **literally**, but keep the step’s native attachments ≤2.

1) **Path safety**
- `--write-output` destinations must be deterministic and must not escape `out_dir` (no `..` traversal).
- No absolute write paths.

1) **Determinism**
- Ticket discovery ordering must be stable:
  - lexicographic ordering only
  - no timestamps / mtimes used for selection

The pack MUST end with a **Coverage check** section listing all 10 categories as `OK` or `Missing(<step ids>)`.

## Inputs (do not ask follow-ups)

Parse the user’s trailing text as whitespace-separated `KEY=value` tokens (last-one-wins). Unknown keys ignored.

Supported keys (defaults in parentheses):

- `codebase_name` (`Unknown`)
- `out_dir` (`docs/oracle-questions-YYYY-MM-DD`)
- `oracle_cmd` (`oracle`)
- `oracle_flags` (`--files-report`)
- `extra_files` (empty; appended literally)
- `ticket_root` (`.tickets`)
- `ticket_glob` (`**/*.md` relative to `ticket_root`)
- `ticket_paths` (optional; comma-separated explicit ticket files; if present, ignore `ticket_glob`)
- `ticket_bundle_path` (`<out_dir>/_tickets_bundle.md`)
- `mode` (`tickets`; reserved)

Notes:
- `YYYY-MM-DD` is computed at pack generation time for default `out_dir`.
- If oracle flag support is uncertain (engine/model/etc), **omit unsupported flags**; never invent flags.

## Workflow (deterministic)

1) Read:
- `references/ticket-bundling.md` (how to build the bundle deterministically)
- `references/attachment-minimization.md` (attachment limits + extra_files handling)

1) Render a pack by starting from:
- `references/tickets-pack-template.md`

1) Resolve args deterministically:
- Fill placeholders for `out_dir`, `ticket_root`, `ticket_glob`, `ticket_paths`, `ticket_bundle_path`, `oracle_cmd`, `oracle_flags`, `extra_files`.
- Ensure ticket selection and concatenation are lexicographically stable.

1) Ensure the 20 steps are **ticket-scoped**:
- Use the fixed 10 categories (2 steps per category):
  - contracts/interfaces
  - invariants
  - caching/state
  - background jobs
  - observability
  - permissions
  - migrations
  - UX flows
  - failure modes
  - feature flags
- Each step prompt must explicitly reference the **ticket bundle** as primary context.
- Each step prompt must include the mandatory Answer format (4 parts).

1) Validate output:
- `python3 skills/oraclepack-tickets-pack/scripts/validate_pack.py <pack.md>`
- Optional attachment lint:
- `python3 skills/oraclepack-tickets-pack/scripts/lint_attachments.py <pack.md>`

## Failure behavior (must be encoded into the generated pack)

- `ticket_root` missing OR no tickets matched:
  - Still generate the pack.
  - Prelude must write a clear warning into the ticket bundle and emit a clear stderr message.
  - Step 01 prompt must request: “which ticket paths to attach next” (exact missing file/path pattern(s)).

- Oracle flag uncertainty:
  - Omit unsupported flags.
  - Never invent flags.

- Output path ambiguity:
  - Validator must catch missing `--write-output`, invalid numbering, invalid headers, missing coverage check, or unsafe write paths.

## Deliverables

This skill produces:
- One runner-ingestible Stage-1 oraclepack pack (single Markdown doc) that passes `scripts/validate_pack.py`.

## Reference assets

- Template pack: `references/tickets-pack-template.md`
- Ticket bundling: `references/ticket-bundling.md`
- Attachment rules: `references/attachment-minimization.md`
- Validator: `scripts/validate_pack.py`
- Optional linter: `scripts/lint_attachments.py`
```

skills/oraclepack-tickets-pack-grouped/SKILL.md
```
---
name: oraclepack-tickets-pack-grouped
description: Generate multiple runner-ingestible oraclepack Stage-1 packs grouped by ticket topic/domain (subdir + deterministic inference) with direct ticket attachments. Use when the user wants per-topic/per-domain mini-packs, grouped via subdirectory discovery and inferred assignment of loose tickets, with strict 20-step schema and validation.
---

# oraclepack-tickets-pack-grouped (Stage 1)

## Goal

Produce **multiple** ticket-driven Stage-1 packs, one per inferred topic/domain, with direct ticket attachments. Each pack is schema-safe and self-contained.

## Use this skill

Use when the user wants separate packs per topic/domain, grouped by `.tickets/` subdirectories plus deterministic inference for loose tickets.

## Inputs (parse trailing KEY=value; last-one-wins)

Supported keys (defaults in parentheses):
- `codebase_name` (`Unknown`)
- `out_dir` (`docs/oracle-questions-YYYY-MM-DD`)
- `oracle_cmd` (`oracle`)
- `oracle_flags` (`--files-report`)
- `extra_files` (empty; appended literally)
- `ticket_root` (`.tickets`)
- `ticket_glob` (`**/*.md`)
- `ticket_paths` (empty; comma-separated explicit files; if present, ignore glob)
- `ticket_max_files` (`25`)
- `group_mode` (`subdir+infer`)
- `group_min_score` (`0.08`)
- `group_max_files` (`25`)
- `group_max_chars` (`200000`)
- `dedupe_mode` (`report`)
- `dedupe_jaccard` (`0.55`)
- `dedupe_overlap_hi` (`0.80`)
- `dedupe_overlap_lo` (`0.70`)
- `dedupe_delta_min` (`0.15`)
- `dedupe_body_chars` (`2000`)
- `mode` (`tickets-grouped-direct`)

Notes:
- `YYYY-MM-DD` is computed at pack generation time for default `out_dir`.
- If oracle flag support is uncertain, omit unsupported flags; never invent flags.

## Workflow (deterministic)

1) Read:
- `references/ticket-grouping.md`
- `references/attachment-minimization.md`
- `references/tickets-pack-template.md`

2) Ask user if custom args are needed (numbered picker):

```
1) Use defaults (no args)
2) Provide custom args
```

If `2`, ask for KEY=value args and run with those; otherwise run with defaults.

3) Generate packs (deterministic grouping + per-group pack files):

```bash
python3 /home/user/.codex/skills/oraclepack-tickets-pack-grouped/scripts/generate_grouped_packs.py \
  codebase_name=oraclepack \
  out_dir=docs/oracle-questions-2026-01-08
```

Outputs:
- `{{out_dir}}/packs/*.md` (one pack per group/part)
- `{{out_dir}}/_groups.json` (group -> ticket list)

4) Size control (mandatory; fail fast):
- Run `oracle --dry-run summary --files-report ...` for the **largest** group pack (or each pack if unsure).
- Enforce caps:
  - browser: ≤ 60,000 tokens total input per step
  - api: ≤ 180,000 tokens total input per step
- If exceeded, reduce via `group_max_files` or use explicit `ticket_paths`.

5) Validate every pack (mandatory):

```bash
python3 /home/user/.codex/skills/oraclepack-tickets-pack-grouped/scripts/validate_pack.py <pack.md>
python3 /home/user/.codex/skills/oraclepack-tickets-pack-grouped/scripts/lint_attachments.py <pack.md>
```

## Sharded packs workflow (topic/domain mini-packs)

Use this when you want a manifest-driven, sharded pack per topic/domain with bundle attachments:

First ask the user which args mode to use:

```
1) Use defaults (no args)
2) Provide custom args
```

If `2`, collect args and use them in the commands below.

```bash
python3 /home/user/.codex/skills/oraclepack-tickets-pack-grouped/scripts/shard_tickets.py \\
  --ticket-root .tickets \\
  --out-dir docs/oracle-questions-sharded

python3 /home/user/.codex/skills/oraclepack-tickets-pack-grouped/scripts/render_group_packs.py \\
  --manifest docs/oracle-questions-sharded/manifest.json \\
  --out-dir docs/oracle-questions-sharded

python3 /home/user/.codex/skills/oraclepack-tickets-pack-grouped/scripts/validate_shards.py \\
  --manifest docs/oracle-questions-sharded/manifest.json
```

## Failure behavior

- If no tickets resolve, packs still generate with empty attachments.
- Step 01 prompt must request exact missing ticket file/path pattern(s).

## Output contract

Each pack MUST:
- Have exactly one `bash` fence
- Have exactly 20 steps (01..20)
- Include ROI header tokens
- Include `--write-output` with a group-specific `out_dir`
- Attach tickets directly via `${ticket_args[@]}`
- End with Coverage check outside the bash fence
```

.config/mcp/mcp-builder/SKILL.md
```
---
name: mcp-builder
description: Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).
license: Complete terms in LICENSE.txt
---

# MCP Server Development Guide

## Overview

Create MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. The quality of an MCP server is measured by how well it enables LLMs to accomplish real-world tasks.

---

# Process

## 🚀 High-Level Workflow

Creating a high-quality MCP server involves four main phases:

### Phase 1: Deep Research and Planning

#### 1.1 Understand Modern MCP Design

**API Coverage vs. Workflow Tools:**
Balance comprehensive API endpoint coverage with specialized workflow tools. Workflow tools can be more convenient for specific tasks, while comprehensive coverage gives agents flexibility to compose operations. Performance varies by client—some clients benefit from code execution that combines basic tools, while others work better with higher-level workflows. When uncertain, prioritize comprehensive API coverage.

**Tool Naming and Discoverability:**
Clear, descriptive tool names help agents find the right tools quickly. Use consistent prefixes (e.g., `github_create_issue`, `github_list_repos`) and action-oriented naming.

**Context Management:**
Agents benefit from concise tool descriptions and the ability to filter/paginate results. Design tools that return focused, relevant data. Some clients support code execution which can help agents filter and process data efficiently.

**Actionable Error Messages:**
Error messages should guide agents toward solutions with specific suggestions and next steps.

#### 1.2 Study MCP Protocol Documentation

**Navigate the MCP specification:**

Start with the sitemap to find relevant pages: `https://modelcontextprotocol.io/sitemap.xml`

Then fetch specific pages with `.md` suffix for markdown format (e.g., `https://modelcontextprotocol.io/specification/draft.md`).

Key pages to review:
- Specification overview and architecture
- Transport mechanisms (streamable HTTP, stdio)
- Tool, resource, and prompt definitions

#### 1.3 Study Framework Documentation

**Recommended stack:**
- **Language**: TypeScript (high-quality SDK support and good compatibility in many execution environments e.g. MCPB. Plus AI models are good at generating TypeScript code, benefiting from its broad usage, static typing and good linting tools)
- **Transport**: Streamable HTTP for remote servers, using stateless JSON (simpler to scale and maintain, as opposed to stateful sessions and streaming responses). stdio for local servers.

**Load framework documentation:**

- **MCP Best Practices**: [📋 View Best Practices](./reference/mcp_best_practices.md) - Core guidelines

**For TypeScript (recommended):**
- **TypeScript SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`
- [⚡ TypeScript Guide](./reference/node_mcp_server.md) - TypeScript patterns and examples

**For Python:**
- **Python SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`
- [🐍 Python Guide](./reference/python_mcp_server.md) - Python patterns and examples

#### 1.4 Plan Your Implementation

**Understand the API:**
Review the service's API documentation to identify key endpoints, authentication requirements, and data models. Use web search and WebFetch as needed.

**Tool Selection:**
Prioritize comprehensive API coverage. List endpoints to implement, starting with the most common operations.

---

### Phase 2: Implementation

#### 2.1 Set Up Project Structure

See language-specific guides for project setup:
- [⚡ TypeScript Guide](./reference/node_mcp_server.md) - Project structure, package.json, tsconfig.json
- [🐍 Python Guide](./reference/python_mcp_server.md) - Module organization, dependencies

#### 2.2 Implement Core Infrastructure

Create shared utilities:
- API client with authentication
- Error handling helpers
- Response formatting (JSON/Markdown)
- Pagination support

#### 2.3 Implement Tools

For each tool:

**Input Schema:**
- Use Zod (TypeScript) or Pydantic (Python)
- Include constraints and clear descriptions
- Add examples in field descriptions

**Output Schema:**
- Define `outputSchema` where possible for structured data
- Use `structuredContent` in tool responses (TypeScript SDK feature)
- Helps clients understand and process tool outputs

**Tool Description:**
- Concise summary of functionality
- Parameter descriptions
- Return type schema

**Implementation:**
- Async/await for I/O operations
- Proper error handling with actionable messages
- Support pagination where applicable
- Return both text content and structured data when using modern SDKs

**Annotations:**
- `readOnlyHint`: true/false
- `destructiveHint`: true/false
- `idempotentHint`: true/false
- `openWorldHint`: true/false

---

### Phase 3: Review and Test

#### 3.1 Code Quality

Review for:
- No duplicated code (DRY principle)
- Consistent error handling
- Full type coverage
- Clear tool descriptions

#### 3.2 Build and Test

**TypeScript:**
- Run `npm run build` to verify compilation
- Test with MCP Inspector: `npx @modelcontextprotocol/inspector`

**Python:**
- Verify syntax: `python -m py_compile your_server.py`
- Test with MCP Inspector

See language-specific guides for detailed testing approaches and quality checklists.

---

### Phase 4: Create Evaluations

After implementing your MCP server, create comprehensive evaluations to test its effectiveness.

**Load [✅ Evaluation Guide](./reference/evaluation.md) for complete evaluation guidelines.**

#### 4.1 Understand Evaluation Purpose

Use evaluations to test whether LLMs can effectively use your MCP server to answer realistic, complex questions.

#### 4.2 Create 10 Evaluation Questions

To create effective evaluations, follow the process outlined in the evaluation guide:

1. **Tool Inspection**: List available tools and understand their capabilities
2. **Content Exploration**: Use READ-ONLY operations to explore available data
3. **Question Generation**: Create 10 complex, realistic questions
4. **Answer Verification**: Solve each question yourself to verify answers

#### 4.3 Evaluation Requirements

Ensure each question is:
- **Independent**: Not dependent on other questions
- **Read-only**: Only non-destructive operations required
- **Complex**: Requiring multiple tool calls and deep exploration
- **Realistic**: Based on real use cases humans would care about
- **Verifiable**: Single, clear answer that can be verified by string comparison
- **Stable**: Answer won't change over time

#### 4.4 Output Format

Create an XML file with this structure:

```xml
<evaluation>
  <qa_pair>
    <question>Find discussions about AI model launches with animal codenames. One model needed a specific safety designation that uses the format ASL-X. What number X was being determined for the model named after a spotted wild cat?</question>
    <answer>3</answer>
  </qa_pair>
<!-- More qa_pairs... -->
</evaluation>
```

---

# Reference Files

## 📚 Documentation Library

Load these resources as needed during development:

### Core MCP Documentation (Load First)
- **MCP Protocol**: Start with sitemap at `https://modelcontextprotocol.io/sitemap.xml`, then fetch specific pages with `.md` suffix
- [📋 MCP Best Practices](./reference/mcp_best_practices.md) - Universal MCP guidelines including:
  - Server and tool naming conventions
  - Response format guidelines (JSON vs Markdown)
  - Pagination best practices
  - Transport selection (streamable HTTP vs stdio)
  - Security and error handling standards

### SDK Documentation (Load During Phase 1/2)
- **Python SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`
- **TypeScript SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`

### Language-Specific Implementation Guides (Load During Phase 2)
- [🐍 Python Implementation Guide](./reference/python_mcp_server.md) - Complete Python/FastMCP guide with:
  - Server initialization patterns
  - Pydantic model examples
  - Tool registration with `@mcp.tool`
  - Complete working examples
  - Quality checklist

- [⚡ TypeScript Implementation Guide](./reference/node_mcp_server.md) - Complete TypeScript guide with:
  - Project structure
  - Zod schema patterns
  - Tool registration with `server.registerTool`
  - Complete working examples
  - Quality checklist

### Evaluation Guide (Load During Phase 4)
- [✅ Evaluation Guide](./reference/evaluation.md) - Complete evaluation creation guide with:
  - Question creation guidelines
  - Answer verification strategies
  - XML format specifications
  - Example questions and answers
  - Running an evaluation with the provided scripts
```

.config/mcp/oraclepack-gold-pack/SKILL.md
```
---
name: oraclepack-gold-pack
description: Generate a single canonical Stage-1 oraclepack question pack as Markdown:exactly one ```bash fence containing exactly 20 steps (01..20) with strict ROI header tokens, per-step --write-output, fixed categories + coverage check. Use when you need a gold, runner-ingestible pack template (Stage 1 only; not Stage 3 taskify).
metadata:
  short-description: Gold Stage-1 oraclepack pack generator + validators
---

# Oraclepack Gold Pack (Stage 1)

This skill produces the **canonical Stage-1** oraclepack question pack (20 Oracle CLI calls). It is intentionally strict to prevent schema drift.

**Non-negotiable contract (pack output):**
- Exactly **one** fenced code block: starts with exactly ` ```bash` on its own line, and ends with exactly ` ````
- No other fenced code blocks anywhere in the pack.
- Exactly **20** steps, numbered **01..20** in order.
- Every step has a header line matching:
  - `# NN) ROI=... impact=... confidence=... effort=... horizon=... category=... reference=...`
- Every step includes `--write-output "<out_dir>/<nn>-<slug>.md"`.
- Categories are fixed to this exact set (no additions/renames):
  - `contracts/interfaces`
  - `invariants`
  - `caching/state`
  - `background jobs`
  - `observability`
  - `permissions`
  - `migrations`
  - `UX flows`
  - `failure modes`
  - `feature flags`
- Pack ends with a **Coverage check** section listing all 10 categories as `OK` or `Missing(<step ids>)`.

The pack template is the contract. The scratch doc is **not** a pack format.

References:
- Contract template: `references/oracle-pack-template.md`
- Repo discovery: `references/inference-first-discovery.md`
- Attachment rules: `references/attachment-minimization.md`
- Scratch playbook (not pack): `references/oracle-scratch-format.md`

## Quick start

1) Generate a pack file (intended path):
- `docs/oracle-pack-YYYY-MM-DD.md`

1) Validate it (recommended before running oraclepack):
- `python3 scripts/validate_pack.py docs/oracle-pack-YYYY-MM-DD.md`

1) Optional attachment lint:
- `python3 scripts/lint_attachments.py docs/oracle-pack-YYYY-MM-DD.md`

## Inputs (do not ask follow-ups)

Interpret the user’s trailing text as conceptual `{{args}}`. Extract:

- `codebase_name` (default `Unknown`)
- `constraints` (default `None`)
- `non_goals` (default `None`)
- `team_size` (default `Unknown`)
- `deadline` (default `Unknown`)
- `out_dir` (default `docs/oracle-questions-YYYY-MM-DD`)
- `oracle_cmd` (default `oracle`)
- `oracle_flags` (default `--files-report`)
- `engine` (`api|browser`; optional; if provided, append to flags *only if your oracle CLI supports it*, else omit and record `TODO(engine flag unknown)`)
- `model` (optional; if provided, append to flags *only if your oracle CLI supports it*, else omit and record `TODO(model flag unknown)`)
- `extra_files` (default empty; if provided, append **literally** to every command)

If any value is missing: use defaults and proceed.

## Workflow (deterministic)

### 1) Read the contract template first
Open `references/oracle-pack-template.md` and treat it as the **single source of truth** for formatting.

### 2) Repo discovery (inference-first)
Follow `references/inference-first-discovery.md`:
- Read a small set of “anchors” first.
- Infer what’s present in the repo.
- Only then choose the best 1–2 attachments per step.

### 3) Plan the 20 probes (2 per category)
Use the fixed categories and produce **exactly 2 steps per category** (20 total). Keep each step’s prompt focused and non-overlapping.

For each step:
- Pick a **reference anchor** (`reference=` token): `{path}:{symbol}` OR `{path}` OR `Unknown`.
- Pick ≤2 attachments (or fewer) using `references/attachment-minimization.md`.
- Ensure the prompt asks for:
  - Direct answer (bullets)
  - Risks/unknowns
  - Next smallest concrete experiment
  - Missing artifact patterns to request if evidence is insufficient

### 4) Emit the pack (single file)
Produce exactly one Markdown document with:
- Title + parsed args section (plain markdown; no code fences)
- Exactly one ` ```bash` fence containing the 20 steps
- A Coverage check section after the fence

### 5) Validate and correct drift
Run:
- `python3 scripts/validate_pack.py <pack.md>`
If it fails, fix the pack until it passes.

Optionally run:
- `python3 scripts/lint_attachments.py <pack.md>`
If it fails, reduce attachments to ≤2 per step (before any literal `extra_files`).

## Output contract

When invoked, you produce:
- One runner-ingestible Markdown pack (intended filename: `docs/oracle-pack-YYYY-MM-DD.md`)

You do **not**:
- Run oraclepack
- Generate Stage-3 “action packs” (that is `oraclepack-taskify`)

## Failure modes (do not guess)

- Missing repo evidence → set `reference=Unknown`, attach fewer files, and explicitly request missing file/path patterns in the prompt.
- Uncertain CLI flag support (`engine`, `model`) → omit flags and write `TODO(engine/model flag unknown)` in the pack’s parsed args notes (do not invent flags).
- Any schema drift → fix until `scripts/validate_pack.py` passes.

## Invocation examples

1) “Generate a gold oraclepack Stage-1 pack for this repo. out_dir=docs/oracle-questions-2026-01-06”
2) “Make the strict 20-step pack for codebase_name=AcmeAPI constraints=‘no DB changes’”
3) “Create the canonical pack; engine=browser model=gpt-5.2-pro (if supported)”
4) “Produce the gold pack; add extra_files='-f docs/ARCHITECTURE.md -f docs/API.md'”
5) “Regenerate this pack but fix headers and coverage check so it validates.”
```

.config/skills/oraclepack-pipeline-improver/SKILL.md
```
---
name: oraclepack-pipeline-improver
description: Improve an oraclepack (Go wrapper around @steipete/oracle) pipeline by specifying/implementing deterministic validate→run→actionize behavior:strict pack validation, run manifests, stable run directories, resume/rerun semantics, concurrency/backoff, optional caching, and a Stage 3 “Actionizer” that converts 20 oracle outputs into actionable engineering work artifacts.
metadata:
  short-description: Deterministic oraclepack validate/run/actionize pipeline spec + implementation rails
---

## Quick start

Use this skill when the user wants to:

- make oraclepack runs deterministic and resume-safe,
- add a strict validator and machine-readable outputs,
- add Stage 3 “actionize” to convert the 20 question outputs into an actionable backlog/change plan,
- make the pipeline CI-friendly and path-safe.

Interpret the user’s free-text `{{args}}` as the target subset (validate/run/actionize/caching/CI) plus any paths to focus on.

If repo context or current CLI behavior is missing, write **Unknown/TODO** and proceed with a spec-first answer.

## Workflow

### 1) Establish “observed vs proposed”

1. List what inputs are available (repo files, current CLI help text, sample pack md, run output dirs).
2. Split all statements into:
   - **Observed** (backed by provided evidence),
   - **Proposed** (the target contract to implement),
   - **Unknown/TODO** (needs files/flags not provided).

### 2) Define the target pipeline contract (deterministic by default)

Produce a concrete contract for:

- `oraclepack validate` (strict + JSON output),
- `oraclepack run` (stable run dir + `run.json`/`steps.json` + outputs + resume/rerun),
- `oraclepack actionize` (reads run dir and produces `actionizer/` artifacts),
- CI mode behavior (non-interactive, structured logs, policy-driven exit codes),
- Path safety for output writing.

Use:

- references/cli-contract.md
- references/run-manifest-spec.md
- references/actionizer-spec.md

### 3) Map contract → implementation deltas (minimal, additive, backward-compatible)

1. Identify current commands/flags and current on-disk layout (Observed).
2. Propose additive changes:
   - new flags and new subcommands should not break existing pack schema without an explicit migration path,
   - new on-disk outputs should be in `.oraclepack/runs/<pack_id>/...` without removing legacy output locations (unless requested).
3. For each proposed change, specify:
   - code touchpoints (files/modules: **Unknown** if repo not provided),
   - acceptance tests and fixtures,
   - failure modes and user-visible error messages.

### 4) Stage 1 prompt shaping (pack generation) to help Stage 3 parse reliably

If the workflow includes Stage 1 pack generation:

- propose embedding **mini-metadata inside each prompt** (does not change pack schema),
- keep metadata parseable and consistent.

Use references/stage1-prompt-metadata.md.

### 5) Produce final deliverables (spec + plan, optionally code)

Deliverables should be:

1. **Pipeline contract** (validate/run/actionize + CI + safety).
2. **On-disk schemas** (`run.json`, `steps.json`, `normalized.jsonl`, `backlog.md`, `change-plan.md`).
3. **Acceptance criteria** and a minimal test plan.
4. **Implementation plan** (ordered steps, smallest shippable increments).
5. If code context is provided and the user wants implementation: output concrete file edits + new files.

## Output contract

Unless the user asks for something else, output a single Markdown report with:

- **Scope** (what parts of validate/run/actionize/CI/caching are included)
- **Observed current behavior** (or **Unknown**)
- **Proposed contract** (link to reference sections where applicable)
- **Disk layout + schemas**
- **Acceptance criteria**
- **Implementation plan** (phased; smallest first)
- **Risks / unknowns**
- **Missing inputs** (exact paths/flags/help output needed)

If asked to generate templates, use the assets:

- assets/backlog-template.md
- assets/change-plan-template.md
- assets/normalized.example.jsonl

## Failure modes

- Missing repo / CLI help / sample run dirs → mark **Unknown** and provide a spec-first response.
- Missing definitions for CI thresholds / policies → include **TODO** defaults and clearly label them as policy choices.
- Any “current behavior” claim without evidence → downgrade to **Unknown**.

## Invocation examples

1) Add strict validator + JSON output:

- `$oraclepack-pipeline-improver Add oraclepack validate --strict --json; define schema checks and CI gating exit codes`

1) Deterministic run dir + resume/rerun:

- `$oraclepack-pipeline-improver Specify .oraclepack/runs/<pack_id>/ layout, run.json/steps.json, resume default, --rerun failed|all|01,03`

1) Concurrency + backoff policy:

- `$oraclepack-pipeline-improver Add --max-parallel N and transient error retry budget/backoff rules`

1) Stage 3 Actionizer:

- `$oraclepack-pipeline-improver Implement oraclepack actionize; generate normalized.jsonl + backlog.md + change-plan.md with stable IDs`

1) CI mode:

- `$oraclepack-pipeline-improver Provide run --ci --non-interactive --json-log and actionize --ci; policy-driven exit codes`

1) Stage 1 prompt metadata shaping:

- `$oraclepack-pipeline-improver Add prompt-embedded metadata (QuestionId/Category/Reference/ExpectedArtifacts) without changing pack schema`
```

.config/mcp/oraclepack-taskify/SKILL.md
```
---
name: oraclepack-taskify
description: Generate a Stage-3 Action Pack from oraclepack output (oracle-out 01–20 .md answers) that synthesizes a canonical actions plan + Task Master PRD, runs Task Master to create/expand tasks, and by default starts a guarded autopilot to begin implementation.
metadata:
  short-description: Stage 3:answers → tasks → pipelines/autopilot
---

# oraclepack-taskify

## Use when

Use this skill only after **oraclepack Stage 2** has produced **20 answer files** under an output directory (default `oracle-out/`), and the user wants Stage 3 work products such as:

- “Stage 3” / “taskify” / “actionize” / “turn oracle outputs into tasks”
- “Task Master follow-up” / “PRD from oracle-out” / “implementation plan”
- “Start work automatically from oracle-out” / “autopilot top tasks”

## Deliverable

When invoked, produce exactly one primary deliverable:

- A single Markdown doc at `pack_path` (default `docs/oracle-actions-pack-YYYY-MM-DD.md`)

The generated Action Pack MUST be oraclepack-ingestible and MUST obey:

- Exactly **one** fenced code block labeled `bash` in the entire document.
- No other code fences anywhere in the document.
- Inside the bash fence, include sequential step headers exactly like: `# NN)` where `NN` is `01, 02, 03...`
- Each step is self-contained and must **not rely on shell variables created in previous steps**.
- Each step writes artifacts to explicit, deterministic paths.

## Skill interface (args)

Parse user trailing text as whitespace-separated `KEY=value` tokens (last-one-wins). Do not ask follow-ups.

Supported args (all optional):

- `out_dir` (default `oracle-out`)
- `pack_path` (default `docs/oracle-actions-pack-YYYY-MM-DD.md`)
- `actions_json` (default `<out_dir>/_actions.json`)
- `actions_md` (default `<out_dir>/_actions.md`)
- `prd_path` (default `.taskmaster/docs/oracle-actions-prd.md`)
- `tag` (default `oraclepack`)
- `mode` (default `autopilot`; allowed `backlog|pipelines|autopilot`)
- `top_n` (default `10`; clamp to `1..20`)
- `oracle_cmd` (default `oracle`; allow a multi-word command like `npx -y @steipete/oracle` only if the user requests it)
- `task_master_cmd` (default `task-master`)
- `tm_cmd` (default `tm`; used only in autopilot mode)
- `extra_files` (default empty; if provided, treat as a comma-separated list of file paths; attach them wherever the synthesis step accepts file inputs)

If any referenced file/path does not exist, the skill still outputs the Action Pack, but includes an early step that prints a clear error and exits non-zero.

## Workflow (what to do when invoked)

1) Parse args from `KEY=value` tokens (no follow-ups; last-one-wins; unknown keys ignored).

2) Resolve defaults deterministically:
   - Compute `YYYY-MM-DD` using the local date at generation time.
   - Apply defaults and clamp `top_n` to `1..20`.
   - Default `mode=autopilot` unless explicitly overridden.
   - Derive:
     - `actions_json = <out_dir>/_actions.json` unless user overrides
     - `actions_md = <out_dir>/_actions.md` unless user overrides

3) Render the Action Pack:
   - Start from `assets/action-pack-template.md`.
   - Substitute placeholders:
     - `{{pack_date}}`, `{{out_dir}}`, `{{pack_path}}`, `{{actions_json}}`, `{{actions_md}}`, `{{prd_path}}`, `{{tag}}`, `{{mode}}`, `{{top_n}}`, `{{oracle_cmd}}`, `{{task_master_cmd}}`, `{{tm_cmd}}`
   - Expand `extra_files` into literal bash lines of the form:
     - `oracle_file_flags+=( -f "<path>" )`
     - and insert them only where the template indicates “Extra attachments”.

4) Ensure Action Pack contract:
   - Exactly one `bash` code fence in the document.
   - No other code fences.
   - Step headers `# 01)`.. are sequential and stable.
   - Each step re-declares its variables and does not depend on variables from earlier steps.

5) Write the final pack to `pack_path` (create parent dirs).

## Modes

### mode=backlog

Action Pack should:
- Synthesize canonical `_actions.json` + `_actions.md`
- Write PRD to `prd_path`
- Run:
  - `task-master parse-prd <prd_path>` (attempt with tag scoping if supported)
  - `task-master analyze-complexity --output <out_dir>/tm-complexity.json`
  - `task-master expand --all`

### mode=pipelines

Do everything in `backlog`, then:
- Generate deterministic pipelines from tasks.json
- Write: `docs/oracle-actions-pipelines.md`

### mode=autopilot (default)

Do everything in `backlog`, then:
- Enforce branch safety and tests-first guardrails
- Start a guarded autopilot entrypoint (expects `tm`-style autopilot tooling)
- Never commit to the default branch (do not run `git commit` on main/master; create a work branch first)

Important: if the environment does not provide a compatible `tm autopilot`, Step 08 will fail fast with a clear error. To avoid that, run Stage 3 with `mode=backlog` or `mode=pipelines`.

## Determinism + safety rules

- No interactive prompts in the generated pack.
- Stable ordering: select exactly the 20 outputs by filename prefix ordering `01`..`20`.
- Fail fast when required tools are missing:
  - `command -v <task_master_cmd first word>`
  - `command -v <oracle_cmd first word>`
  - `command -v <tm_cmd first word>` only in autopilot mode
- Always create directories before writing files.
- Avoid destructive commands:
  - Do not delete files.
  - Do not force-push.
  - Do not commit to main/master (autopilot mode creates a new branch).
- If multiple outputs exist for a prefix (e.g., `01-*.md` expands to more than one file), exit non-zero with an explicit error listing the matches.

## Failure modes (handle without questions)

- Missing `out_dir` → pack Step 01 exits non-zero with a clear message.
- Missing any of `01-*.md`..`20-*.md` → Step 01 exits non-zero (and prints which one is missing).
- Missing required tools → Step 01 exits non-zero (and prints which command is missing).
- Unknown `mode` → treat as `autopilot` (clamp at generation time) and render `mode=autopilot` in the pack.

## Resources

- `assets/action-pack-template.md`: base template for the Action Pack deliverable.
- `assets/actions-json-schema.md`: canonical schema spec for `_actions.json` normalization.
- `assets/prd-synthesis-prompt.md`: exact prompt text embedded into the Action Pack for synthesis.
- `references/*`: Stage 3 overview and guardrails for future maintenance.
- `scripts/*`: optional helpers (standalone); may also be embedded verbatim into packs if desired.

## Invocation examples

- `$oraclepack-taskify out_dir=oracle-out` (defaults to mode=autopilot)
- `$oraclepack-taskify out_dir=oracle-out mode=backlog`
- `$oraclepack-taskify out_dir=oracle-out mode=pipelines tag=oraclepack-top top_n=10`
- `$oraclepack-taskify out_dir=oracle-out mode=autopilot tag=oraclepack-top pack_path=docs/oracle-actions-pack-2026-01-05.md`
- `$oraclepack-taskify out_dir=oracle-out extra_files=README.md,package.json`
```

.config/skills/oraclepack-tickets-pack/SKILL.md
```
---
name: oraclepack-tickets-pack
description: Generate a runner-ingestible oraclepack Stage-1 question pack (single Markdown doc) driven by `.tickets/` content. Exactly one ```bash fence, exactly 20 steps (01..20), strict ROI header tokens, deterministic ticket bundling, minimal per-step attachments, coverage check.
metadata:
  short-description: Ticket-driven Stage-1 oraclepack pack generator + validators
---

# oraclepack-tickets-pack (Stage 1)

## Purpose

Produce a **ticket-driven** oraclepack Stage-1 pack (Markdown) that is **runner-ingestible** and **schema-compatible** with existing oraclepack pack format.

The generated pack’s questions and minimal attachments are guided primarily by a deterministic **ticket bundle** built from `.tickets/` (or explicit ticket paths).

## Use when

- You have tickets stored under `.tickets/` (or you can provide explicit ticket file paths), and you want a strict 20-step oraclepack Stage-1 question pack that:
  - references tickets as the primary context in every step
  - uses minimal attachments per step
  - preserves existing oraclepack Markdown pack schema (backward compatible)

## Hard requirements (output contract)

The produced pack (single Markdown file) MUST satisfy:

1) **Schema safety / compatibility**
- Do not break the existing oraclepack Markdown pack schema.
- Exactly **one** fenced code block labeled `bash` in the entire document.
- No other fenced code blocks anywhere (no additional ``` fences).

1) **Runner-ingestible strictness**
- Exactly **20** steps inside the single `bash` fence.
- Steps are numbered **01..20** in order.
- Each step header starts with `# NN)` and includes the strict header tokens in the header line:
  - `ROI= ... impact= ... confidence= ... effort= ... horizon= ... category= ... reference= ...`
- Every step includes:
  - `--write-output "<out_dir>/<nn>-<slug>.md"`
- Steps must be **self-contained** and must **not rely on shell variables created in previous steps**.

1) **Attachment minimization**
- Default **0–2 native attachments per step**.
- Each step should normally attach:
  - `-f "<ticket_bundle_path>"` (primary context)
  - plus at most **one** additional repo file when needed
- If `extra_files` are provided, append them **literally**, but keep the step’s native attachments ≤2.

1) **Path safety**
- `--write-output` destinations must be deterministic and must not escape `out_dir` (no `..` traversal).
- No absolute write paths.

1) **Determinism**
- Ticket discovery ordering must be stable:
  - lexicographic ordering only
  - no timestamps / mtimes used for selection

The pack MUST end with a **Coverage check** section listing all 10 categories as `OK` or `Missing(<step ids>)`.

## Inputs (do not ask follow-ups)

Parse the user’s trailing text as whitespace-separated `KEY=value` tokens (last-one-wins). Unknown keys ignored.

Supported keys (defaults in parentheses):

- `codebase_name` (`Unknown`)
- `out_dir` (`docs/oracle-questions-YYYY-MM-DD`)
- `oracle_cmd` (`oracle`)
- `oracle_flags` (`--files-report`)
- `extra_files` (empty; appended literally)
- `ticket_root` (`.tickets`)
- `ticket_glob` (`**/*.md` relative to `ticket_root`)
- `ticket_paths` (optional; comma-separated explicit ticket files; if present, ignore `ticket_glob`)
- `ticket_bundle_path` (`<out_dir>/_tickets_bundle.md`)
- `mode` (`tickets`; reserved)

Notes:
- `YYYY-MM-DD` is computed at pack generation time for default `out_dir`.
- If oracle flag support is uncertain (engine/model/etc), **omit unsupported flags**; never invent flags.

## Workflow (deterministic)

1) Read:
- `references/ticket-bundling.md` (how to build the bundle deterministically)
- `references/attachment-minimization.md` (attachment limits + extra_files handling)

1) Render a pack by starting from:
- `references/tickets-pack-template.md`

1) Resolve args deterministically:
- Fill placeholders for `out_dir`, `ticket_root`, `ticket_glob`, `ticket_paths`, `ticket_bundle_path`, `oracle_cmd`, `oracle_flags`, `extra_files`.
- Ensure ticket selection and concatenation are lexicographically stable.

1) Ensure the 20 steps are **ticket-scoped**:
- Use the fixed 10 categories (2 steps per category):
  - contracts/interfaces
  - invariants
  - caching/state
  - background jobs
  - observability
  - permissions
  - migrations
  - UX flows
  - failure modes
  - feature flags
- Each step prompt must explicitly reference the **ticket bundle** as primary context.
- Each step prompt must include the mandatory Answer format (4 parts).

1) Validate output:
- `python3 skills/oraclepack-tickets-pack/scripts/validate_pack.py <pack.md>`
- Optional attachment lint:
- `python3 skills/oraclepack-tickets-pack/scripts/lint_attachments.py <pack.md>`

## Failure behavior (must be encoded into the generated pack)

- `ticket_root` missing OR no tickets matched:
  - Still generate the pack.
  - Prelude must write a clear warning into the ticket bundle and emit a clear stderr message.
  - Step 01 prompt must request: “which ticket paths to attach next” (exact missing file/path pattern(s)).

- Oracle flag uncertainty:
  - Omit unsupported flags.
  - Never invent flags.

- Output path ambiguity:
  - Validator must catch missing `--write-output`, invalid numbering, invalid headers, missing coverage check, or unsafe write paths.

## Deliverables

This skill produces:
- One runner-ingestible Stage-1 oraclepack pack (single Markdown doc) that passes `scripts/validate_pack.py`.

## Reference assets

- Template pack: `references/tickets-pack-template.md`
- Ticket bundling: `references/ticket-bundling.md`
- Attachment rules: `references/attachment-minimization.md`
- Validator: `scripts/validate_pack.py`
- Optional linter: `scripts/lint_attachments.py`
```

.mypy_cache/3.12/_typeshed/__init__.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/_typeshed/__init__.meta.json
```
{"data_mtime":1767891128,"dep_lines":[6,5,7,8,9,10,25,359,1,1,1,1],"dep_prios":[5,10,5,5,5,5,5,5,5,30,30,30],"dependencies":["collections.abc","sys","dataclasses","os","types","typing","typing_extensions","enum","builtins","_collections_abc","_frozen_importlib","abc"],"hash":"f49a3cc3dd65130625c84369013c885ffadf7721","id":"_typeshed","ignore_all":true,"interface_hash":"e0e8aca9a074a0f8216d2398b0c0be14ed255e97","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_typeshed/__init__.pyi","plugin_data":null,"size":12192,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/_typeshed/importlib.data.json
```
{".class":"MypyFile","_fullname":"_typeshed.importlib","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","LoaderProtocol":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"_typeshed.importlib.LoaderProtocol","name":"LoaderProtocol","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":["is_protocol"],"fullname":"_typeshed.importlib.LoaderProtocol","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"_typeshed.importlib","mro":["_typeshed.importlib.LoaderProtocol","builtins.object"],"names":{".class":"SymbolTable","load_module":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":[null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"_typeshed.importlib.LoaderProtocol.load_module","name":"load_module","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":[null,null],"arg_types":["_typeshed.importlib.LoaderProtocol","builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"load_module of LoaderProtocol","ret_type":"types.ModuleType","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"MetaPathFinderProtocol":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"_typeshed.importlib.MetaPathFinderProtocol","name":"MetaPathFinderProtocol","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":["is_protocol"],"fullname":"_typeshed.importlib.MetaPathFinderProtocol","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"_typeshed.importlib","mro":["_typeshed.importlib.MetaPathFinderProtocol","builtins.object"],"names":{".class":"SymbolTable","find_spec":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0,1],"arg_names":[null,null,null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"_typeshed.importlib.MetaPathFinderProtocol.find_spec","name":"find_spec","type":{".class":"CallableType","arg_kinds":[0,0,0,1],"arg_names":[null,null,null,null],"arg_types":["_typeshed.importlib.MetaPathFinderProtocol","builtins.str",{".class":"UnionType","items":[{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"typing.Sequence"},{".class":"NoneType"}],"uses_pep604_syntax":true},{".class":"UnionType","items":["types.ModuleType",{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"find_spec of MetaPathFinderProtocol","ret_type":{".class":"UnionType","items":["_frozen_importlib.ModuleSpec",{".class":"NoneType"}],"uses_pep604_syntax":true},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"ModuleSpec":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.ModuleSpec","kind":"Gdef","module_hidden":true,"module_public":false},"ModuleType":{".class":"SymbolTableNode","cross_ref":"types.ModuleType","kind":"Gdef","module_hidden":true,"module_public":false},"PathEntryFinderProtocol":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"_typeshed.importlib.PathEntryFinderProtocol","name":"PathEntryFinderProtocol","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":["is_protocol"],"fullname":"_typeshed.importlib.PathEntryFinderProtocol","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"_typeshed.importlib","mro":["_typeshed.importlib.PathEntryFinderProtocol","builtins.object"],"names":{".class":"SymbolTable","find_spec":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,1],"arg_names":[null,null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"_typeshed.importlib.PathEntryFinderProtocol.find_spec","name":"find_spec","type":{".class":"CallableType","arg_kinds":[0,0,1],"arg_names":[null,null,null],"arg_types":["_typeshed.importlib.PathEntryFinderProtocol","builtins.str",{".class":"UnionType","items":["types.ModuleType",{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"find_spec of PathEntryFinderProtocol","ret_type":{".class":"UnionType","items":["_frozen_importlib.ModuleSpec",{".class":"NoneType"}],"uses_pep604_syntax":true},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"Protocol":{".class":"SymbolTableNode","cross_ref":"typing.Protocol","kind":"Gdef","module_hidden":true,"module_public":false},"Sequence":{".class":"SymbolTableNode","cross_ref":"typing.Sequence","kind":"Gdef","module_hidden":true,"module_public":false},"__all__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"_typeshed.importlib.__all__","name":"__all__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"_typeshed.importlib.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"_typeshed.importlib.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"_typeshed.importlib.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"_typeshed.importlib.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"_typeshed.importlib.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"_typeshed.importlib.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_typeshed/importlib.pyi"}
```

.mypy_cache/3.12/_typeshed/importlib.meta.json
```
{"data_mtime":1767891128,"dep_lines":[4,5,6,7,1,1,1],"dep_prios":[5,5,5,5,5,30,30],"dependencies":["collections.abc","importlib.machinery","types","typing","builtins","_frozen_importlib","abc"],"hash":"a2a3b405bbd03e0ac3627d81baaeecc3e007fe72","id":"_typeshed.importlib","ignore_all":true,"interface_hash":"537e7c797de9306d6cde8960f7eeacc51a3d0ed3","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/_typeshed/importlib.pyi","plugin_data":null,"size":727,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/collections/__init__.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/collections/__init__.meta.json
```
{"data_mtime":1767891128,"dep_lines":[11,1,2,3,4,5,8,1,1,1],"dep_prios":[5,10,5,5,5,5,5,5,30,30],"dependencies":["collections.abc","sys","_collections_abc","_typeshed","typing","typing_extensions","types","builtins","_frozen_importlib","abc"],"hash":"a5b235c5d5497f4bd19e862e356cc28be6cc8952","id":"collections","ignore_all":true,"interface_hash":"ec5af74a84a0e7244dc9c8a0c775a1e8dc2ed55d","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/collections/__init__.pyi","plugin_data":null,"size":23581,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/collections/abc.data.json
```
{".class":"MypyFile","_fullname":"collections.abc","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","AsyncGenerator":{".class":"SymbolTableNode","cross_ref":"typing.AsyncGenerator","kind":"Gdef"},"AsyncIterable":{".class":"SymbolTableNode","cross_ref":"typing.AsyncIterable","kind":"Gdef"},"AsyncIterator":{".class":"SymbolTableNode","cross_ref":"typing.AsyncIterator","kind":"Gdef"},"Awaitable":{".class":"SymbolTableNode","cross_ref":"typing.Awaitable","kind":"Gdef"},"Buffer":{".class":"SymbolTableNode","cross_ref":"_collections_abc.Buffer","kind":"Gdef"},"ByteString":{".class":"SymbolTableNode","cross_ref":"typing.ByteString","kind":"Gdef"},"Callable":{".class":"SymbolTableNode","cross_ref":"typing.Callable","kind":"Gdef"},"Collection":{".class":"SymbolTableNode","cross_ref":"typing.Collection","kind":"Gdef"},"Container":{".class":"SymbolTableNode","cross_ref":"typing.Container","kind":"Gdef"},"Coroutine":{".class":"SymbolTableNode","cross_ref":"typing.Coroutine","kind":"Gdef"},"Generator":{".class":"SymbolTableNode","cross_ref":"typing.Generator","kind":"Gdef"},"Hashable":{".class":"SymbolTableNode","cross_ref":"typing.Hashable","kind":"Gdef"},"ItemsView":{".class":"SymbolTableNode","cross_ref":"typing.ItemsView","kind":"Gdef"},"Iterable":{".class":"SymbolTableNode","cross_ref":"typing.Iterable","kind":"Gdef"},"Iterator":{".class":"SymbolTableNode","cross_ref":"typing.Iterator","kind":"Gdef"},"KeysView":{".class":"SymbolTableNode","cross_ref":"typing.KeysView","kind":"Gdef"},"Mapping":{".class":"SymbolTableNode","cross_ref":"typing.Mapping","kind":"Gdef"},"MappingView":{".class":"SymbolTableNode","cross_ref":"typing.MappingView","kind":"Gdef"},"MutableMapping":{".class":"SymbolTableNode","cross_ref":"typing.MutableMapping","kind":"Gdef"},"MutableSequence":{".class":"SymbolTableNode","cross_ref":"typing.MutableSequence","kind":"Gdef"},"MutableSet":{".class":"SymbolTableNode","cross_ref":"typing.MutableSet","kind":"Gdef"},"Reversible":{".class":"SymbolTableNode","cross_ref":"typing.Reversible","kind":"Gdef"},"Sequence":{".class":"SymbolTableNode","cross_ref":"typing.Sequence","kind":"Gdef"},"Set":{".class":"SymbolTableNode","cross_ref":"typing.AbstractSet","kind":"Gdef"},"Sized":{".class":"SymbolTableNode","cross_ref":"typing.Sized","kind":"Gdef"},"ValuesView":{".class":"SymbolTableNode","cross_ref":"typing.ValuesView","kind":"Gdef"},"__all__":{".class":"SymbolTableNode","cross_ref":"_collections_abc.__all__","kind":"Gdef","module_public":false},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"collections.abc.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"collections.abc.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"collections.abc.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"collections.abc.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"collections.abc.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"collections.abc.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/collections/abc.pyi"}
```

.mypy_cache/3.12/collections/abc.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,1,1,1,1],"dep_prios":[5,5,30,30,30],"dependencies":["_collections_abc","builtins","_frozen_importlib","abc","typing"],"hash":"b533e3bac0da22e9dc59fd0341a2de22ba566c4b","id":"collections.abc","ignore_all":true,"interface_hash":"0a835857d00a605356d4831091f66b795d38403d","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/collections/abc.pyi","plugin_data":null,"size":79,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/__init__.data.json
```
{".class":"MypyFile","_fullname":"importlib","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","Loader":{".class":"SymbolTableNode","cross_ref":"importlib._abc.Loader","kind":"Gdef","module_hidden":true,"module_public":false},"ModuleType":{".class":"SymbolTableNode","cross_ref":"types.ModuleType","kind":"Gdef","module_hidden":true,"module_public":false},"__all__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"importlib.__all__","name":"__all__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.__file__","name":"__file__","type":"builtins.str"}},"__import__":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.__import__","kind":"Gdef"},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.__package__","name":"__package__","type":"builtins.str"}},"__path__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.__path__","name":"__path__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"import_module":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1],"arg_names":["name","package"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.import_module","name":"import_module","type":{".class":"CallableType","arg_kinds":[0,1],"arg_names":["name","package"],"arg_types":["builtins.str",{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"import_module","ret_type":"types.ModuleType","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"invalidate_caches":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[],"arg_names":[],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.invalidate_caches","name":"invalidate_caches","type":{".class":"CallableType","arg_kinds":[],"arg_names":[],"arg_types":[],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"invalidate_caches","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"reload":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["module"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.reload","name":"reload","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["module"],"arg_types":["types.ModuleType"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"reload","ret_type":"types.ModuleType","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/__init__.pyi"}
```

.mypy_cache/3.12/importlib/__init__.meta.json
```
{"data_mtime":1767891128,"dep_lines":[2,3,1,4,1,1,1,1,1],"dep_prios":[5,5,10,5,5,30,30,30,30],"dependencies":["importlib._bootstrap","importlib.abc","sys","types","builtins","_frozen_importlib","_typeshed","abc","typing"],"hash":"696eed73d030a0492323852b916bb4655325693b","id":"importlib","ignore_all":true,"interface_hash":"2f6b9e91b142fb668e81bf14198347e7189c5a60","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/__init__.pyi","plugin_data":null,"size":569,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/_abc.data.json
```
{".class":"MypyFile","_fullname":"importlib._abc","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","ABCMeta":{".class":"SymbolTableNode","cross_ref":"abc.ABCMeta","kind":"Gdef","module_hidden":true,"module_public":false},"Loader":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":"abc.ABCMeta","defn":{".class":"ClassDef","fullname":"importlib._abc.Loader","name":"Loader","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"importlib._abc.Loader","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"importlib._abc","mro":["importlib._abc.Loader","builtins.object"],"names":{".class":"SymbolTable","create_module":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","spec"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib._abc.Loader.create_module","name":"create_module","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","spec"],"arg_types":["importlib._abc.Loader","_frozen_importlib.ModuleSpec"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"create_module of Loader","ret_type":{".class":"UnionType","items":["types.ModuleType",{".class":"NoneType"}],"uses_pep604_syntax":true},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"exec_module":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","module"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib._abc.Loader.exec_module","name":"exec_module","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","module"],"arg_types":["importlib._abc.Loader","types.ModuleType"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"exec_module of Loader","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"load_module":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","fullname"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib._abc.Loader.load_module","name":"load_module","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","fullname"],"arg_types":["importlib._abc.Loader","builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"load_module of Loader","ret_type":"types.ModuleType","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"ModuleSpec":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.ModuleSpec","kind":"Gdef","module_hidden":true,"module_public":false},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._abc.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._abc.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._abc.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._abc.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._abc.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._abc.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false},"types":{".class":"SymbolTableNode","cross_ref":"types","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/_abc.pyi"}
```

.mypy_cache/3.12/importlib/_abc.meta.json
```
{"data_mtime":1767891128,"dep_lines":[4,1,2,3,1,1,1,1],"dep_prios":[5,10,10,5,5,30,30,30],"dependencies":["importlib.machinery","sys","types","abc","builtins","_frozen_importlib","_typeshed","typing"],"hash":"0d42dcd951013ab41bdf924bf5ec37f00714a257","id":"importlib._abc","ignore_all":true,"interface_hash":"679f0dfcb9881dfe1fb70a5710f8c36fa5434f0b","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/_abc.pyi","plugin_data":null,"size":609,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/_bootstrap.data.json
```
{".class":"MypyFile","_fullname":"importlib._bootstrap","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","BuiltinImporter":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.BuiltinImporter","kind":"Gdef"},"FrozenImporter":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.FrozenImporter","kind":"Gdef"},"ModuleSpec":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.ModuleSpec","kind":"Gdef"},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap.__file__","name":"__file__","type":"builtins.str"}},"__import__":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.__import__","kind":"Gdef"},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"_init_module_attrs":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib._init_module_attrs","kind":"Gdef"},"module_from_spec":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.module_from_spec","kind":"Gdef"},"spec_from_loader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.spec_from_loader","kind":"Gdef"}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/_bootstrap.pyi"}
```

.mypy_cache/3.12/importlib/_bootstrap.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,1,1,1],"dep_prios":[5,5,30,30],"dependencies":["_frozen_importlib","builtins","abc","typing"],"hash":"91c3b137c6c392ec8ff0705874f87160198ae9af","id":"importlib._bootstrap","ignore_all":true,"interface_hash":"359042224562ef4fe5a1ba87464aa3c2c1b1616c","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/_bootstrap.pyi","plugin_data":null,"size":129,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/_bootstrap_external.data.json
```
{".class":"MypyFile","_fullname":"importlib._bootstrap_external","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","BYTECODE_SUFFIXES":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.BYTECODE_SUFFIXES","kind":"Gdef"},"DEBUG_BYTECODE_SUFFIXES":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.DEBUG_BYTECODE_SUFFIXES","kind":"Gdef"},"EXTENSION_SUFFIXES":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.EXTENSION_SUFFIXES","kind":"Gdef"},"ExtensionFileLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.ExtensionFileLoader","kind":"Gdef"},"FileFinder":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.FileFinder","kind":"Gdef"},"FileLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.FileLoader","kind":"Gdef"},"MAGIC_NUMBER":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.MAGIC_NUMBER","kind":"Gdef"},"NamespaceLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.NamespaceLoader","kind":"Gdef"},"OPTIMIZED_BYTECODE_SUFFIXES":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.OPTIMIZED_BYTECODE_SUFFIXES","kind":"Gdef"},"PathFinder":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.PathFinder","kind":"Gdef"},"SOURCE_SUFFIXES":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.SOURCE_SUFFIXES","kind":"Gdef"},"SourceFileLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.SourceFileLoader","kind":"Gdef"},"SourceLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.SourceLoader","kind":"Gdef"},"SourcelessFileLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.SourcelessFileLoader","kind":"Gdef"},"WindowsRegistryFinder":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.WindowsRegistryFinder","kind":"Gdef"},"_NamespaceLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external._NamespaceLoader","kind":"Gdef"},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap_external.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap_external.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap_external.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap_external.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap_external.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib._bootstrap_external.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"cache_from_source":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.cache_from_source","kind":"Gdef"},"decode_source":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.decode_source","kind":"Gdef"},"path_sep":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.path_sep","kind":"Gdef"},"path_sep_tuple":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.path_sep_tuple","kind":"Gdef"},"path_separators":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.path_separators","kind":"Gdef"},"source_from_cache":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.source_from_cache","kind":"Gdef"},"spec_from_file_location":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.spec_from_file_location","kind":"Gdef"}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/_bootstrap_external.pyi"}
```

.mypy_cache/3.12/importlib/_bootstrap_external.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,1,1,1,1],"dep_prios":[5,5,30,30,30],"dependencies":["_frozen_importlib_external","builtins","_frozen_importlib","abc","typing"],"hash":"68022b896ef0de6f8da7d6c9d4d434abd95c0da6","id":"importlib._bootstrap_external","ignore_all":true,"interface_hash":"29e4625cfe94a51fc807e0b0cc0d848246201dc4","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/_bootstrap_external.pyi","plugin_data":null,"size":117,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/abc.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/importlib/abc.meta.json
```
{"data_mtime":1767891128,"dep_lines":[6,7,8,28,1,2,3,4,5,7,9,10,1,1,1,1,1,1,1],"dep_prios":[5,10,5,5,10,10,10,5,5,20,5,5,5,30,30,30,30,30,30],"dependencies":["collections.abc","importlib._bootstrap_external","importlib.machinery","importlib._abc","_ast","sys","types","_typeshed","abc","importlib","io","typing","builtins","_collections_abc","_frozen_importlib","_frozen_importlib_external","_io","ast","os"],"hash":"1cb0e78eb5b401e80f23dcaa5278ea291f53e7dc","id":"importlib.abc","ignore_all":true,"interface_hash":"4d824e1682260fe00c898198ef9162a97549eb07","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/abc.pyi","plugin_data":null,"size":7123,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/machinery.data.json
```
{".class":"MypyFile","_fullname":"importlib.machinery","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","BYTECODE_SUFFIXES":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.BYTECODE_SUFFIXES","kind":"Gdef"},"BuiltinImporter":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.BuiltinImporter","kind":"Gdef"},"DEBUG_BYTECODE_SUFFIXES":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.DEBUG_BYTECODE_SUFFIXES","kind":"Gdef"},"EXTENSION_SUFFIXES":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.EXTENSION_SUFFIXES","kind":"Gdef"},"ExtensionFileLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.ExtensionFileLoader","kind":"Gdef"},"FileFinder":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.FileFinder","kind":"Gdef"},"FrozenImporter":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.FrozenImporter","kind":"Gdef"},"ModuleSpec":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib.ModuleSpec","kind":"Gdef"},"NamespaceLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.NamespaceLoader","kind":"Gdef"},"OPTIMIZED_BYTECODE_SUFFIXES":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.OPTIMIZED_BYTECODE_SUFFIXES","kind":"Gdef"},"PathFinder":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.PathFinder","kind":"Gdef"},"SOURCE_SUFFIXES":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.SOURCE_SUFFIXES","kind":"Gdef"},"SourceFileLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.SourceFileLoader","kind":"Gdef"},"SourcelessFileLoader":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.SourcelessFileLoader","kind":"Gdef"},"WindowsRegistryFinder":{".class":"SymbolTableNode","cross_ref":"_frozen_importlib_external.WindowsRegistryFinder","kind":"Gdef"},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.machinery.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.machinery.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.machinery.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.machinery.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.machinery.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.machinery.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"all_suffixes":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[],"arg_names":[],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.machinery.all_suffixes","name":"all_suffixes","type":{".class":"CallableType","arg_kinds":[],"arg_names":[],"arg_types":[],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"all_suffixes","ret_type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/machinery.pyi"}
```

.mypy_cache/3.12/importlib/machinery.meta.json
```
{"data_mtime":1767891128,"dep_lines":[2,3,1,1,1,1,1,1],"dep_prios":[5,5,10,5,30,30,30,30],"dependencies":["importlib._bootstrap","importlib._bootstrap_external","sys","builtins","_frozen_importlib","_typeshed","abc","typing"],"hash":"a306f9942e253d05433d97fbf1113fd4f35bdb58","id":"importlib.machinery","ignore_all":true,"interface_hash":"e008efc8995a7c3798e9267cf617f11c6cac286e","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/machinery.pyi","plugin_data":null,"size":839,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/readers.data.json
```
{".class":"MypyFile","_fullname":"importlib.readers","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","BufferedReader":{".class":"SymbolTableNode","cross_ref":"_io.BufferedReader","kind":"Gdef","module_hidden":true,"module_public":false},"FileReader":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["importlib.abc.TraversableResources"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"importlib.readers.FileReader","name":"FileReader","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"importlib.readers.FileReader","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"importlib.readers","mro":["importlib.readers.FileReader","importlib.abc.TraversableResources","importlib.abc.ResourceReader","builtins.object"],"names":{".class":"SymbolTable","__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","loader"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.FileReader.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","loader"],"arg_types":["importlib.readers.FileReader",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of FileReader","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"files":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.FileReader.files","name":"files","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["importlib.readers.FileReader"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"files of FileReader","ret_type":"pathlib.Path","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"path":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"importlib.readers.FileReader.path","name":"path","type":"pathlib.Path"}},"resource_path":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","resource"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.FileReader.resource_path","name":"resource_path","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","resource"],"arg_types":["importlib.readers.FileReader",{".class":"TypeAliasType","args":[],"type_ref":"_typeshed.StrPath"}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"resource_path of FileReader","ret_type":"builtins.str","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"Incomplete":{".class":"SymbolTableNode","cross_ref":"_typeshed.Incomplete","kind":"Gdef","module_hidden":true,"module_public":false},"Iterable":{".class":"SymbolTableNode","cross_ref":"typing.Iterable","kind":"Gdef","module_hidden":true,"module_public":false},"Iterator":{".class":"SymbolTableNode","cross_ref":"typing.Iterator","kind":"Gdef","module_hidden":true,"module_public":false},"Literal":{".class":"SymbolTableNode","cross_ref":"typing.Literal","kind":"Gdef","module_hidden":true,"module_public":false},"MultiplexedPath":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["importlib.abc.Traversable"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"importlib.readers.MultiplexedPath","name":"MultiplexedPath","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"importlib.readers.MultiplexedPath","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"importlib.readers","mro":["importlib.readers.MultiplexedPath","importlib.abc.Traversable","builtins.object"],"names":{".class":"SymbolTable","__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,2],"arg_names":["self","paths"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.MultiplexedPath.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,2],"arg_names":["self","paths"],"arg_types":["importlib.readers.MultiplexedPath","importlib.abc.Traversable"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of MultiplexedPath","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"is_dir":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.MultiplexedPath.is_dir","name":"is_dir","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["importlib.readers.MultiplexedPath"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"is_dir of MultiplexedPath","ret_type":{".class":"LiteralType","fallback":"builtins.bool","value":true},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"is_file":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.MultiplexedPath.is_file","name":"is_file","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["importlib.readers.MultiplexedPath"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"is_file of MultiplexedPath","ret_type":{".class":"LiteralType","fallback":"builtins.bool","value":false},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"iterdir":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.MultiplexedPath.iterdir","name":"iterdir","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["importlib.readers.MultiplexedPath"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"iterdir of MultiplexedPath","ret_type":{".class":"Instance","args":["importlib.abc.Traversable"],"extra_attrs":null,"type_ref":"typing.Iterator"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"joinpath":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,2],"arg_names":["self","descendants"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.MultiplexedPath.joinpath","name":"joinpath","type":{".class":"CallableType","arg_kinds":[0,2],"arg_names":["self","descendants"],"arg_types":["importlib.readers.MultiplexedPath","builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"joinpath of MultiplexedPath","ret_type":"importlib.abc.Traversable","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"name":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Decorator","func":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":["is_property","is_decorated"],"fullname":"importlib.readers.MultiplexedPath.name","name":"name","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["importlib.readers.MultiplexedPath"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"name of MultiplexedPath","ret_type":"builtins.str","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}},"is_overload":false,"var":{".class":"Var","flags":["is_initialized_in_class","is_property","is_ready","is_inferred"],"fullname":"importlib.readers.MultiplexedPath.name","name":"name","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["importlib.readers.MultiplexedPath"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"name of MultiplexedPath","ret_type":"builtins.str","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"open":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,2,4],"arg_names":["self","args","kwargs"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.MultiplexedPath.open","name":"open","type":{".class":"CallableType","arg_kinds":[0,2,4],"arg_names":["self","args","kwargs"],"arg_types":["importlib.readers.MultiplexedPath",{".class":"UninhabitedType"},{".class":"UninhabitedType"}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"open of MultiplexedPath","ret_type":{".class":"UninhabitedType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"read_bytes":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.MultiplexedPath.read_bytes","name":"read_bytes","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["importlib.readers.MultiplexedPath"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"read_bytes of MultiplexedPath","ret_type":{".class":"UninhabitedType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"read_text":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,2,4],"arg_names":["self","args","kwargs"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.MultiplexedPath.read_text","name":"read_text","type":{".class":"CallableType","arg_kinds":[0,2,4],"arg_names":["self","args","kwargs"],"arg_types":["importlib.readers.MultiplexedPath",{".class":"UninhabitedType"},{".class":"UninhabitedType"}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"read_text of MultiplexedPath","ret_type":{".class":"UninhabitedType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"NamespaceReader":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["importlib.abc.TraversableResources"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"importlib.readers.NamespaceReader","name":"NamespaceReader","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"importlib.readers.NamespaceReader","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"importlib.readers","mro":["importlib.readers.NamespaceReader","importlib.abc.TraversableResources","importlib.abc.ResourceReader","builtins.object"],"names":{".class":"SymbolTable","__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","namespace_path"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.NamespaceReader.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","namespace_path"],"arg_types":["importlib.readers.NamespaceReader",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of NamespaceReader","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"files":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.NamespaceReader.files","name":"files","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["importlib.readers.NamespaceReader"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"files of NamespaceReader","ret_type":"importlib.readers.MultiplexedPath","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"path":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"importlib.readers.NamespaceReader.path","name":"path","type":"importlib.readers.MultiplexedPath"}},"resource_path":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","resource"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.NamespaceReader.resource_path","name":"resource_path","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","resource"],"arg_types":["importlib.readers.NamespaceReader","builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"resource_path of NamespaceReader","ret_type":"builtins.str","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"Never":{".class":"SymbolTableNode","cross_ref":"typing.Never","kind":"Gdef","module_hidden":true,"module_public":false},"NoReturn":{".class":"SymbolTableNode","cross_ref":"typing.NoReturn","kind":"Gdef","module_hidden":true,"module_public":false},"StrPath":{".class":"SymbolTableNode","cross_ref":"_typeshed.StrPath","kind":"Gdef","module_hidden":true,"module_public":false},"TypeVar":{".class":"SymbolTableNode","cross_ref":"typing.TypeVar","kind":"Gdef","module_hidden":true,"module_public":false},"ZipReader":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["importlib.abc.TraversableResources"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"importlib.readers.ZipReader","name":"ZipReader","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"importlib.readers.ZipReader","has_param_spec_type":false,"metaclass_type":"abc.ABCMeta","metadata":{},"module_name":"importlib.readers","mro":["importlib.readers.ZipReader","importlib.abc.TraversableResources","importlib.abc.ResourceReader","builtins.object"],"names":{".class":"SymbolTable","__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0],"arg_names":["self","loader","module"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.ZipReader.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,0,0],"arg_names":["self","loader","module"],"arg_types":["importlib.readers.ZipReader",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1},"builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of ZipReader","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"archive":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"importlib.readers.ZipReader.archive","name":"archive","type":{".class":"TypeAliasType","args":[],"type_ref":"_typeshed.Incomplete"}}},"files":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.ZipReader.files","name":"files","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["importlib.readers.ZipReader"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"files of ZipReader","ret_type":"zipfile._path.Path","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"is_resource":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","path"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.ZipReader.is_resource","name":"is_resource","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","path"],"arg_types":["importlib.readers.ZipReader",{".class":"TypeAliasType","args":[],"type_ref":"_typeshed.StrPath"}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"is_resource of ZipReader","ret_type":"builtins.bool","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"open_resource":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","resource"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.readers.ZipReader.open_resource","name":"open_resource","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","resource"],"arg_types":["importlib.readers.ZipReader","builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"open_resource of ZipReader","ret_type":"_io.BufferedReader","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"prefix":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"importlib.readers.ZipReader.prefix","name":"prefix","type":"builtins.str"}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"__all__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"importlib.readers.__all__","name":"__all__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.readers.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.readers.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.readers.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.readers.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.readers.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.readers.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"abc":{".class":"SymbolTableNode","cross_ref":"importlib.resources.abc","kind":"Gdef","module_hidden":true,"module_public":false},"pathlib":{".class":"SymbolTableNode","cross_ref":"pathlib","kind":"Gdef","module_hidden":true,"module_public":false},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false},"zipfile":{".class":"SymbolTableNode","cross_ref":"zipfile","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/readers.pyi"}
```

.mypy_cache/3.12/importlib/readers.meta.json
```
{"data_mtime":1767891128,"dep_lines":[15,9,15,5,6,7,8,10,11,12,15,1,1,1,1,1,1,1,1],"dep_prios":[10,5,20,10,10,10,5,5,5,5,20,5,30,30,30,30,30,30,30],"dependencies":["importlib.resources.abc","collections.abc","importlib.resources","pathlib","sys","zipfile","_typeshed","io","typing","typing_extensions","importlib","builtins","_frozen_importlib","_io","abc","importlib.abc","os","types","zipfile._path"],"hash":"5527c48630fb2b623985ff211aabecfaba9fa570","id":"importlib.readers","ignore_all":true,"interface_hash":"195c3fcc79e512613b09739f7a932b24537778c6","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/readers.pyi","plugin_data":null,"size":2584,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/email/__init__.data.json
```
{".class":"MypyFile","_fullname":"email","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","Callable":{".class":"SymbolTableNode","cross_ref":"typing.Callable","kind":"Gdef","module_hidden":true,"module_public":false},"IO":{".class":"SymbolTableNode","cross_ref":"typing.IO","kind":"Gdef","module_hidden":true,"module_public":false},"Message":{".class":"SymbolTableNode","cross_ref":"email.message.Message","kind":"Gdef","module_hidden":true,"module_public":false},"Policy":{".class":"SymbolTableNode","cross_ref":"email._policybase.Policy","kind":"Gdef","module_hidden":true,"module_public":false},"TypeAlias":{".class":"SymbolTableNode","cross_ref":"typing.TypeAlias","kind":"Gdef","module_hidden":true,"module_public":false},"_ParamType":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"TypeAlias","alias_tvars":[],"column":0,"fullname":"email._ParamType","line":31,"no_args":false,"normalized":false,"python_3_12_type_alias":false,"target":{".class":"UnionType","items":["builtins.str",{".class":"TupleType","implicit":false,"items":[{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true},{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true},"builtins.str"],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}}],"uses_pep604_syntax":true}}},"_ParamsType":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"TypeAlias","alias_tvars":[],"column":0,"fullname":"email._ParamsType","line":32,"no_args":false,"normalized":false,"python_3_12_type_alias":false,"target":{".class":"UnionType","items":["builtins.str",{".class":"NoneType"},{".class":"TupleType","implicit":false,"items":["builtins.str",{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true},"builtins.str"],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}}],"uses_pep604_syntax":true}}},"__all__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"email.__all__","name":"__all__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.__package__","name":"__package__","type":"builtins.str"}},"__path__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.__path__","name":"__path__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"message_from_binary_file":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,5],"arg_names":["fp","_class","policy"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.message_from_binary_file","name":"message_from_binary_file","type":{".class":"CallableType","arg_kinds":[0,1,5],"arg_names":["fp","_class","policy"],"arg_types":[{".class":"Instance","args":["builtins.bytes"],"extra_attrs":null,"type_ref":"typing.IO"},{".class":"CallableType","arg_kinds":[],"arg_names":[],"arg_types":[],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":null,"ret_type":{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]},{".class":"Instance","args":[{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"}],"extra_attrs":null,"type_ref":"email._policybase.Policy"}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"message_from_binary_file","ret_type":{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"message_from_bytes":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,5],"arg_names":["s","_class","policy"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.message_from_bytes","name":"message_from_bytes","type":{".class":"CallableType","arg_kinds":[0,1,5],"arg_names":["s","_class","policy"],"arg_types":[{".class":"UnionType","items":["builtins.bytes","builtins.bytearray"],"uses_pep604_syntax":true},{".class":"CallableType","arg_kinds":[],"arg_names":[],"arg_types":[],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":null,"ret_type":{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]},{".class":"Instance","args":[{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"}],"extra_attrs":null,"type_ref":"email._policybase.Policy"}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"message_from_bytes","ret_type":{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"message_from_file":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,5],"arg_names":["fp","_class","policy"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.message_from_file","name":"message_from_file","type":{".class":"CallableType","arg_kinds":[0,1,5],"arg_names":["fp","_class","policy"],"arg_types":[{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"typing.IO"},{".class":"CallableType","arg_kinds":[],"arg_names":[],"arg_types":[],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":null,"ret_type":{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]},{".class":"Instance","args":[{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"}],"extra_attrs":null,"type_ref":"email._policybase.Policy"}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"message_from_file","ret_type":{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"message_from_string":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,5],"arg_names":["s","_class","policy"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.message_from_string","name":"message_from_string","type":{".class":"CallableType","arg_kinds":[0,1,5],"arg_names":["s","_class","policy"],"arg_types":["builtins.str",{".class":"CallableType","arg_kinds":[],"arg_names":[],"arg_types":[],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":null,"ret_type":{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]},{".class":"Instance","args":[{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"}],"extra_attrs":null,"type_ref":"email._policybase.Policy"}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"message_from_string","ret_type":{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/__init__.pyi"}
```

.mypy_cache/3.12/email/__init__.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,3,4,5,1,1,1,1,1],"dep_prios":[5,5,5,5,5,5,30,30,30,30],"dependencies":["collections.abc","email.message","email.policy","typing","typing_extensions","builtins","_frozen_importlib","abc","email._policybase","types"],"hash":"caecefbbbf09ce84b396b0013bced4c891a76f88","id":"email","ignore_all":true,"interface_hash":"06d780800431b8e9b7e8f2979d3d373329ff5fde","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/__init__.pyi","plugin_data":null,"size":1977,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/email/_policybase.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/email/_policybase.meta.json
```
{"data_mtime":1767891128,"dep_lines":[2,3,4,1,5,6,1,1,1],"dep_prios":[5,5,5,5,5,5,5,30,30],"dependencies":["email.errors","email.header","email.message","abc","typing","typing_extensions","builtins","_frozen_importlib","types"],"hash":"72180d54339bec1be169396e7679e646d9e44e3b","id":"email._policybase","ignore_all":true,"interface_hash":"1f4121bea771eb2aaadb7366df4090996f1e79ad","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/_policybase.pyi","plugin_data":null,"size":3060,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/email/charset.data.json
```
{".class":"MypyFile","_fullname":"email.charset","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","BASE64":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_final","is_ready"],"fullname":"email.charset.BASE64","name":"BASE64","type":"builtins.int"}},"Callable":{".class":"SymbolTableNode","cross_ref":"typing.Callable","kind":"Gdef","module_hidden":true,"module_public":false},"Charset":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.charset.Charset","name":"Charset","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.charset.Charset","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.charset","mro":["email.charset.Charset","builtins.object"],"names":{".class":"SymbolTable","__eq__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":[null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.charset.Charset.__eq__","name":"__eq__","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":[null,null],"arg_types":["email.charset.Charset","builtins.object"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__eq__ of Charset","ret_type":"builtins.bool","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"__hash__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_classvar","is_ready"],"fullname":"email.charset.Charset.__hash__","name":"__hash__","type":{".class":"NoneType"}}},"__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1],"arg_names":["self","input_charset"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.charset.Charset.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,1],"arg_names":["self","input_charset"],"arg_types":["email.charset.Charset","builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of Charset","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"__ne__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":[null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.charset.Charset.__ne__","name":"__ne__","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":[null,null],"arg_types":["email.charset.Charset","builtins.object"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__ne__ of Charset","ret_type":"builtins.bool","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"body_encode":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"OverloadedFuncDef","deprecated":null,"flags":[],"fullname":"email.charset.Charset.body_encode","impl":null,"items":[{".class":"Decorator","func":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","string"],"dataclass_transform_spec":null,"deprecated":null,"flags":["is_overload","is_decorated"],"fullname":"email.charset.Charset.body_encode","name":"body_encode","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","string"],"arg_types":["email.charset.Charset",{".class":"NoneType"}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"body_encode of Charset","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}},"is_overload":true,"var":{".class":"Var","flags":["is_ready","is_inferred"],"fullname":"email.charset.Charset.body_encode","name":"body_encode","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","string"],"arg_types":["email.charset.Charset",{".class":"NoneType"}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"body_encode of Charset","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},{".class":"Decorator","func":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","string"],"dataclass_transform_spec":null,"deprecated":null,"flags":["is_overload","is_decorated"],"fullname":"email.charset.Charset.body_encode","name":"body_encode","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","string"],"arg_types":["email.charset.Charset",{".class":"UnionType","items":["builtins.str","builtins.bytes"],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"body_encode of Charset","ret_type":"builtins.str","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}},"is_overload":true,"var":{".class":"Var","flags":["is_ready","is_inferred"],"fullname":"email.charset.Charset.body_encode","name":"body_encode","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","string"],"arg_types":["email.charset.Charset",{".class":"UnionType","items":["builtins.str","builtins.bytes"],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"body_encode of Charset","ret_type":"builtins.str","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}],"type":{".class":"Overloaded","items":[{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","string"],"arg_types":["email.charset.Charset",{".class":"NoneType"}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"body_encode of Charset","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]},{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","string"],"arg_types":["email.charset.Charset",{".class":"UnionType","items":["builtins.str","builtins.bytes"],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"body_encode of Charset","ret_type":"builtins.str","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}]}}},"body_encoding":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"email.charset.Charset.body_encoding","name":"body_encoding","type":"builtins.int"}},"get_body_encoding":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.charset.Charset.get_body_encoding","name":"get_body_encoding","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["email.charset.Charset"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"get_body_encoding of Charset","ret_type":{".class":"UnionType","items":["builtins.str",{".class":"CallableType","arg_kinds":[0],"arg_names":[null],"arg_types":[{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"}],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":null,"ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}],"uses_pep604_syntax":true},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"get_output_charset":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.charset.Charset.get_output_charset","name":"get_output_charset","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["self"],"arg_types":["email.charset.Charset"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"get_output_charset of Charset","ret_type":{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"header_encode":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","string"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.charset.Charset.header_encode","name":"header_encode","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","string"],"arg_types":["email.charset.Charset","builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"header_encode of Charset","ret_type":"builtins.str","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"header_encode_lines":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0],"arg_names":["self","string","maxlengths"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.charset.Charset.header_encode_lines","name":"header_encode_lines","type":{".class":"CallableType","arg_kinds":[0,0,0],"arg_names":["self","string","maxlengths"],"arg_types":["email.charset.Charset","builtins.str",{".class":"Instance","args":["builtins.int"],"extra_attrs":null,"type_ref":"typing.Iterator"}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"header_encode_lines of Charset","ret_type":{".class":"Instance","args":[{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true}],"extra_attrs":null,"type_ref":"builtins.list"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"header_encoding":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"email.charset.Charset.header_encoding","name":"header_encoding","type":"builtins.int"}},"input_charset":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"email.charset.Charset.input_charset","name":"input_charset","type":"builtins.str"}},"input_codec":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"email.charset.Charset.input_codec","name":"input_codec","type":{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true}}},"output_charset":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"email.charset.Charset.output_charset","name":"output_charset","type":{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true}}},"output_codec":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"email.charset.Charset.output_codec","name":"output_codec","type":{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"ClassVar":{".class":"SymbolTableNode","cross_ref":"typing.ClassVar","kind":"Gdef","module_hidden":true,"module_public":false},"Final":{".class":"SymbolTableNode","cross_ref":"typing.Final","kind":"Gdef","module_hidden":true,"module_public":false},"Iterator":{".class":"SymbolTableNode","cross_ref":"typing.Iterator","kind":"Gdef","module_hidden":true,"module_public":false},"Message":{".class":"SymbolTableNode","cross_ref":"email.message.Message","kind":"Gdef","module_hidden":true,"module_public":false},"QP":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_final","is_ready"],"fullname":"email.charset.QP","name":"QP","type":"builtins.int"}},"SHORTEST":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_final","is_ready"],"fullname":"email.charset.SHORTEST","name":"SHORTEST","type":"builtins.int"}},"__all__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"email.charset.__all__","name":"__all__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.charset.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.charset.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.charset.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.charset.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.charset.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.charset.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"add_alias":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["alias","canonical"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.charset.add_alias","name":"add_alias","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["alias","canonical"],"arg_types":["builtins.str","builtins.str"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"add_alias","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"add_charset":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,1,1],"arg_names":["charset","header_enc","body_enc","output_charset"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.charset.add_charset","name":"add_charset","type":{".class":"CallableType","arg_kinds":[0,1,1,1],"arg_names":["charset","header_enc","body_enc","output_charset"],"arg_types":["builtins.str",{".class":"UnionType","items":["builtins.int",{".class":"NoneType"}],"uses_pep604_syntax":true},{".class":"UnionType","items":["builtins.int",{".class":"NoneType"}],"uses_pep604_syntax":true},{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"add_charset","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"add_codec":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["charset","codecname"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.charset.add_codec","name":"add_codec","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["charset","codecname"],"arg_types":["builtins.str","builtins.str"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"add_codec","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"overload":{".class":"SymbolTableNode","cross_ref":"typing.overload","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/charset.pyi"}
```

.mypy_cache/3.12/email/charset.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,3,1,1,1,1],"dep_prios":[5,5,5,5,30,30,30],"dependencies":["collections.abc","email.message","typing","builtins","_frozen_importlib","abc","types"],"hash":"386b4196b21159aecbb306f8e3eb5cd5837ec6d5","id":"email.charset","ignore_all":true,"interface_hash":"6543ca193bc958a6dcbdb7259bf10e32c2ea7638","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/charset.pyi","plugin_data":null,"size":1369,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/email/contentmanager.data.json
```
{".class":"MypyFile","_fullname":"email.contentmanager","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","Any":{".class":"SymbolTableNode","cross_ref":"typing.Any","kind":"Gdef","module_hidden":true,"module_public":false},"Callable":{".class":"SymbolTableNode","cross_ref":"typing.Callable","kind":"Gdef","module_hidden":true,"module_public":false},"ContentManager":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.contentmanager.ContentManager","name":"ContentManager","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.contentmanager.ContentManager","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.contentmanager","mro":["email.contentmanager.ContentManager","builtins.object"],"names":{".class":"SymbolTable","add_get_handler":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0],"arg_names":["self","key","handler"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.contentmanager.ContentManager.add_get_handler","name":"add_get_handler","type":{".class":"CallableType","arg_kinds":[0,0,0],"arg_names":["self","key","handler"],"arg_types":["email.contentmanager.ContentManager","builtins.str",{".class":"CallableType","arg_kinds":[2,4],"arg_names":[null,null],"arg_types":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2}],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":true,"name":null,"ret_type":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"add_get_handler of ContentManager","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"add_set_handler":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0],"arg_names":["self","typekey","handler"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.contentmanager.ContentManager.add_set_handler","name":"add_set_handler","type":{".class":"CallableType","arg_kinds":[0,0,0],"arg_names":["self","typekey","handler"],"arg_types":["email.contentmanager.ContentManager","builtins.type",{".class":"CallableType","arg_kinds":[2,4],"arg_names":[null,null],"arg_types":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2}],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":true,"name":null,"ret_type":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"add_set_handler of ContentManager","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"get_content":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,2,4],"arg_names":["self","msg","args","kw"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.contentmanager.ContentManager.get_content","name":"get_content","type":{".class":"CallableType","arg_kinds":[0,0,2,4],"arg_names":["self","msg","args","kw"],"arg_types":["email.contentmanager.ContentManager",{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"get_content of ContentManager","ret_type":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"set_content":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0,2,4],"arg_names":["self","msg","obj","args","kw"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.contentmanager.ContentManager.set_content","name":"set_content","type":{".class":"CallableType","arg_kinds":[0,0,0,2,4],"arg_names":["self","msg","obj","args","kw"],"arg_types":["email.contentmanager.ContentManager",{".class":"Instance","args":["builtins.str","builtins.str"],"extra_attrs":null,"type_ref":"email.message.Message"},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"set_content of ContentManager","ret_type":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"Message":{".class":"SymbolTableNode","cross_ref":"email.message.Message","kind":"Gdef","module_hidden":true,"module_public":false},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.contentmanager.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.contentmanager.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.contentmanager.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.contentmanager.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.contentmanager.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.contentmanager.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"raw_data_manager":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.contentmanager.raw_data_manager","name":"raw_data_manager","type":"email.contentmanager.ContentManager"}}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/contentmanager.pyi"}
```

.mypy_cache/3.12/email/contentmanager.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,3,1,1,1,1],"dep_prios":[5,5,5,5,30,30,30],"dependencies":["collections.abc","email.message","typing","builtins","_frozen_importlib","abc","types"],"hash":"77dff546b3fbaac675acbd4270bbc061cd03c899","id":"email.contentmanager","ignore_all":true,"interface_hash":"c1209b7227502fd7da4336ef71be36f8fd71ca04","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/contentmanager.pyi","plugin_data":null,"size":480,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/email/errors.data.json
```
{".class":"MypyFile","_fullname":"email.errors","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","BoundaryError":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageParseError"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.BoundaryError","name":"BoundaryError","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.BoundaryError","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.BoundaryError","email.errors.MessageParseError","email.errors.MessageError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"CharsetError":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageError"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.CharsetError","name":"CharsetError","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.CharsetError","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.CharsetError","email.errors.MessageError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"CloseBoundaryNotFoundDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.CloseBoundaryNotFoundDefect","name":"CloseBoundaryNotFoundDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.CloseBoundaryNotFoundDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.CloseBoundaryNotFoundDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"FirstHeaderLineIsContinuationDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.FirstHeaderLineIsContinuationDefect","name":"FirstHeaderLineIsContinuationDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.FirstHeaderLineIsContinuationDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.FirstHeaderLineIsContinuationDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"HeaderDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.HeaderDefect","name":"HeaderDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.HeaderDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.HeaderDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"HeaderMissingRequiredValue":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.HeaderDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.HeaderMissingRequiredValue","name":"HeaderMissingRequiredValue","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.HeaderMissingRequiredValue","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.HeaderMissingRequiredValue","email.errors.HeaderDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"HeaderParseError":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageParseError"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.HeaderParseError","name":"HeaderParseError","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.HeaderParseError","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.HeaderParseError","email.errors.MessageParseError","email.errors.MessageError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"HeaderWriteError":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageError"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.HeaderWriteError","name":"HeaderWriteError","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.HeaderWriteError","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.HeaderWriteError","email.errors.MessageError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"InvalidBase64CharactersDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.InvalidBase64CharactersDefect","name":"InvalidBase64CharactersDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.InvalidBase64CharactersDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.InvalidBase64CharactersDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"InvalidBase64LengthDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.InvalidBase64LengthDefect","name":"InvalidBase64LengthDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.InvalidBase64LengthDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.InvalidBase64LengthDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"InvalidBase64PaddingDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.InvalidBase64PaddingDefect","name":"InvalidBase64PaddingDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.InvalidBase64PaddingDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.InvalidBase64PaddingDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"InvalidDateDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.HeaderDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.InvalidDateDefect","name":"InvalidDateDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.InvalidDateDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.InvalidDateDefect","email.errors.HeaderDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"InvalidHeaderDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.HeaderDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.InvalidHeaderDefect","name":"InvalidHeaderDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.InvalidHeaderDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.InvalidHeaderDefect","email.errors.HeaderDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"InvalidMultipartContentTransferEncodingDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.InvalidMultipartContentTransferEncodingDefect","name":"InvalidMultipartContentTransferEncodingDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.InvalidMultipartContentTransferEncodingDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.InvalidMultipartContentTransferEncodingDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"MalformedHeaderDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeAlias","alias_tvars":[],"column":0,"fullname":"email.errors.MalformedHeaderDefect","line":29,"no_args":true,"normalized":false,"python_3_12_type_alias":false,"target":"email.errors.MissingHeaderBodySeparatorDefect"}},"MessageDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.ValueError"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.MessageDefect","name":"MessageDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.MessageDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable","__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1],"arg_names":["self","line"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.errors.MessageDefect.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,1],"arg_names":["self","line"],"arg_types":["email.errors.MessageDefect",{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of MessageDefect","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"MessageError":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.Exception"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.MessageError","name":"MessageError","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.MessageError","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.MessageError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"MessageParseError":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageError"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.MessageParseError","name":"MessageParseError","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.MessageParseError","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.MessageParseError","email.errors.MessageError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"MisplacedEnvelopeHeaderDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.MisplacedEnvelopeHeaderDefect","name":"MisplacedEnvelopeHeaderDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.MisplacedEnvelopeHeaderDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.MisplacedEnvelopeHeaderDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"MissingHeaderBodySeparatorDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.MissingHeaderBodySeparatorDefect","name":"MissingHeaderBodySeparatorDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.MissingHeaderBodySeparatorDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.MissingHeaderBodySeparatorDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"MultipartConversionError":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageError","builtins.TypeError"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.MultipartConversionError","name":"MultipartConversionError","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.MultipartConversionError","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.MultipartConversionError","email.errors.MessageError","builtins.TypeError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"MultipartInvariantViolationDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.MultipartInvariantViolationDefect","name":"MultipartInvariantViolationDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.MultipartInvariantViolationDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.MultipartInvariantViolationDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"NoBoundaryInMultipartDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.NoBoundaryInMultipartDefect","name":"NoBoundaryInMultipartDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.NoBoundaryInMultipartDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.NoBoundaryInMultipartDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"NonASCIILocalPartDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.HeaderDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.NonASCIILocalPartDefect","name":"NonASCIILocalPartDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.NonASCIILocalPartDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.NonASCIILocalPartDefect","email.errors.HeaderDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"NonPrintableDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.HeaderDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.NonPrintableDefect","name":"NonPrintableDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.NonPrintableDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.NonPrintableDefect","email.errors.HeaderDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable","__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","non_printables"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.errors.NonPrintableDefect.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","non_printables"],"arg_types":["email.errors.NonPrintableDefect",{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of NonPrintableDefect","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"ObsoleteHeaderDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.HeaderDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.ObsoleteHeaderDefect","name":"ObsoleteHeaderDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.ObsoleteHeaderDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.ObsoleteHeaderDefect","email.errors.HeaderDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"StartBoundaryNotFoundDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.StartBoundaryNotFoundDefect","name":"StartBoundaryNotFoundDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.StartBoundaryNotFoundDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.StartBoundaryNotFoundDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"UndecodableBytesDefect":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["email.errors.MessageDefect"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.errors.UndecodableBytesDefect","name":"UndecodableBytesDefect","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.errors.UndecodableBytesDefect","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.errors","mro":["email.errors.UndecodableBytesDefect","email.errors.MessageDefect","builtins.ValueError","builtins.Exception","builtins.BaseException","builtins.object"],"names":{".class":"SymbolTable"},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.errors.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.errors.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.errors.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.errors.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.errors.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"email.errors.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/errors.pyi"}
```

.mypy_cache/3.12/email/errors.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,1,1,1,1,1,1],"dep_prios":[10,5,30,30,30,30,30],"dependencies":["sys","builtins","_frozen_importlib","_typeshed","abc","types","typing"],"hash":"7b86e1bd4be0c84d6eae4f72b0ee53542bfb65bd","id":"email.errors","ignore_all":true,"interface_hash":"87776d47f9e982a4af00e66ee65b42d54a887d2e","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/errors.pyi","plugin_data":null,"size":1635,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/email/header.data.json
```
{".class":"MypyFile","_fullname":"email.header","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","Any":{".class":"SymbolTableNode","cross_ref":"typing.Any","kind":"Gdef","module_hidden":true,"module_public":false},"Charset":{".class":"SymbolTableNode","cross_ref":"email.charset.Charset","kind":"Gdef","module_hidden":true,"module_public":false},"ClassVar":{".class":"SymbolTableNode","cross_ref":"typing.ClassVar","kind":"Gdef","module_hidden":true,"module_public":false},"Header":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"email.header.Header","name":"Header","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"email.header.Header","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"email.header","mro":["email.header.Header","builtins.object"],"names":{".class":"SymbolTable","__eq__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":[null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.header.Header.__eq__","name":"__eq__","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":[null,null],"arg_types":["email.header.Header","builtins.object"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__eq__ of Header","ret_type":"builtins.bool","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"__hash__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_classvar","is_ready"],"fullname":"email.header.Header.__hash__","name":"__hash__","type":{".class":"NoneType"}}},"__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,1,1,1,1,1],"arg_names":["self","s","charset","maxlinelen","header_name","continuation_ws","errors"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.header.Header.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,1,1,1,1,1,1],"arg_names":["self","s","charset","maxlinelen","header_name","continuation_ws","errors"],"arg_types":["email.header.Header",{".class":"UnionType","items":["builtins.bytes","builtins.bytearray","builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true},{".class":"UnionType","items":["email.charset.Charset","builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true},{".class":"UnionType","items":["builtins.int",{".class":"NoneType"}],"uses_pep604_syntax":true},{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true},"builtins.str","builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of Header","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"__ne__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":[null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.header.Header.__ne__","name":"__ne__","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":[null,null],"arg_types":["email.header.Header","builtins.object"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__ne__ of Header","ret_type":"builtins.bool","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"append":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,1,1],"arg_names":["self","s","charset","errors"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.header.Header.append","name":"append","type":{".class":"CallableType","arg_kinds":[0,0,1,1],"arg_names":["self","s","charset","errors"],"arg_types":["email.header.Header",{".class":"UnionType","items":["builtins.bytes","builtins.bytearray","builtins.str"],"uses_pep604_syntax":true},{".class":"UnionType","items":["email.charset.Charset","builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true},"builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"append of Header","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"encode":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,1,1],"arg_names":["self","splitchars","maxlinelen","linesep"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.header.Header.encode","name":"encode","type":{".class":"CallableType","arg_kinds":[0,1,1,1],"arg_names":["self","splitchars","maxlinelen","linesep"],"arg_types":["email.header.Header","builtins.str",{".class":"UnionType","items":["builtins.int",{".class":"NoneType"}],"uses_pep604_syntax":true},"builtins.str"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"encode of Header","ret_type":"builtins.str","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"Iterable":{".class":"SymbolTableNode","cross_ref":"typing.Iterable","kind":"Gdef","module_hidden":true,"module_public":false},"__all__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"email.header.__all__","name":"__all__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.header.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.header.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.header.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.header.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.header.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"email.header.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"decode_header":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["header"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.header.decode_header","name":"decode_header","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["header"],"arg_types":[{".class":"UnionType","items":["email.header.Header","builtins.str"],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"decode_header","ret_type":{".class":"Instance","args":[{".class":"TupleType","implicit":false,"items":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},{".class":"UnionType","items":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},{".class":"NoneType"}],"uses_pep604_syntax":true}],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}}],"extra_attrs":null,"type_ref":"builtins.list"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"make_header":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,1,1],"arg_names":["decoded_seq","maxlinelen","header_name","continuation_ws"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"email.header.make_header","name":"make_header","type":{".class":"CallableType","arg_kinds":[0,1,1,1],"arg_names":["decoded_seq","maxlinelen","header_name","continuation_ws"],"arg_types":[{".class":"Instance","args":[{".class":"TupleType","implicit":false,"items":[{".class":"UnionType","items":["builtins.bytes","builtins.bytearray","builtins.str"],"uses_pep604_syntax":true},{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true}],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}}],"extra_attrs":null,"type_ref":"typing.Iterable"},{".class":"UnionType","items":["builtins.int",{".class":"NoneType"}],"uses_pep604_syntax":true},{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true},"builtins.str"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"make_header","ret_type":"email.header.Header","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/header.pyi"}
```

.mypy_cache/3.12/email/header.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,3,1,1,1,1],"dep_prios":[5,5,5,5,30,30,30],"dependencies":["collections.abc","email.charset","typing","builtins","_frozen_importlib","abc","types"],"hash":"bdb289cae018f6186c3ab8204bfca2649f40a90a","id":"email.header","ignore_all":true,"interface_hash":"89cf77fb539896833008e81b8a6bb5b90970166f","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/header.pyi","plugin_data":null,"size":1332,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/email/message.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/email/message.meta.json
```
{"data_mtime":1767891128,"dep_lines":[2,4,5,6,7,1,3,8,9,1,1,1,1,1],"dep_prios":[5,5,5,5,5,5,5,5,5,5,30,30,30,30],"dependencies":["collections.abc","email.charset","email.contentmanager","email.errors","email.policy","_typeshed","email","typing","typing_extensions","builtins","_frozen_importlib","abc","email._policybase","types"],"hash":"93a10ff1414dcd3a960124748a7ab9d4a99358af","id":"email.message","ignore_all":true,"interface_hash":"439b224c7014268c7ccfbfb65ee359e9ffb739cf","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/message.pyi","plugin_data":null,"size":8976,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/email/policy.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/email/policy.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,2,3,4,5,6,1,1,1,1],"dep_prios":[5,5,5,5,5,5,5,30,30,30],"dependencies":["collections.abc","email._policybase","email.contentmanager","email.message","typing","typing_extensions","builtins","_frozen_importlib","abc","types"],"hash":"3e9ef188686de06c51666ef86d0cf6242ccf1995","id":"email.policy","ignore_all":true,"interface_hash":"f315c50ebd654c9f54e0a3943fa0768668516f2d","mtime":1762029370,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/email/policy.pyi","plugin_data":null,"size":2910,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/os/__init__.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/os/__init__.meta.json
```
{"data_mtime":1767891128,"dep_lines":[24,45,1,2,22,23,25,26,27,28,43,1474,1,1,1],"dep_prios":[5,10,10,5,5,5,5,5,5,5,5,5,30,30,30],"dependencies":["collections.abc","os.path","sys","_typeshed","abc","builtins","io","subprocess","types","typing","typing_extensions","resource","_collections_abc","_frozen_importlib","_io"],"hash":"ee1429bacfc7be2ddf5126ca8dbcaf4259be8b08","id":"os","ignore_all":true,"interface_hash":"b3ddd77543c8487cefcdbb74b905ca8b05169a0f","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/os/__init__.pyi","plugin_data":null,"size":53027,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/os/path.data.json
```
{".class":"MypyFile","_fullname":"os.path","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","__all__":{".class":"SymbolTableNode","cross_ref":"posixpath.__all__","kind":"Gdef","module_public":false},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"os.path.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"os.path.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"os.path.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"os.path.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"os.path.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"os.path.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"abspath":{".class":"SymbolTableNode","cross_ref":"posixpath.abspath","kind":"Gdef"},"altsep":{".class":"SymbolTableNode","cross_ref":"posixpath.altsep","kind":"Gdef"},"basename":{".class":"SymbolTableNode","cross_ref":"posixpath.basename","kind":"Gdef"},"commonpath":{".class":"SymbolTableNode","cross_ref":"posixpath.commonpath","kind":"Gdef"},"commonprefix":{".class":"SymbolTableNode","cross_ref":"genericpath.commonprefix","kind":"Gdef"},"curdir":{".class":"SymbolTableNode","cross_ref":"posixpath.curdir","kind":"Gdef"},"defpath":{".class":"SymbolTableNode","cross_ref":"posixpath.defpath","kind":"Gdef"},"devnull":{".class":"SymbolTableNode","cross_ref":"posixpath.devnull","kind":"Gdef"},"dirname":{".class":"SymbolTableNode","cross_ref":"posixpath.dirname","kind":"Gdef"},"exists":{".class":"SymbolTableNode","cross_ref":"genericpath.exists","kind":"Gdef"},"expanduser":{".class":"SymbolTableNode","cross_ref":"posixpath.expanduser","kind":"Gdef"},"expandvars":{".class":"SymbolTableNode","cross_ref":"posixpath.expandvars","kind":"Gdef"},"extsep":{".class":"SymbolTableNode","cross_ref":"posixpath.extsep","kind":"Gdef"},"getatime":{".class":"SymbolTableNode","cross_ref":"genericpath.getatime","kind":"Gdef"},"getctime":{".class":"SymbolTableNode","cross_ref":"genericpath.getctime","kind":"Gdef"},"getmtime":{".class":"SymbolTableNode","cross_ref":"genericpath.getmtime","kind":"Gdef"},"getsize":{".class":"SymbolTableNode","cross_ref":"genericpath.getsize","kind":"Gdef"},"isabs":{".class":"SymbolTableNode","cross_ref":"posixpath.isabs","kind":"Gdef"},"isdir":{".class":"SymbolTableNode","cross_ref":"genericpath.isdir","kind":"Gdef"},"isfile":{".class":"SymbolTableNode","cross_ref":"genericpath.isfile","kind":"Gdef"},"isjunction":{".class":"SymbolTableNode","cross_ref":"posixpath.isjunction","kind":"Gdef"},"islink":{".class":"SymbolTableNode","cross_ref":"posixpath.islink","kind":"Gdef"},"ismount":{".class":"SymbolTableNode","cross_ref":"posixpath.ismount","kind":"Gdef"},"join":{".class":"SymbolTableNode","cross_ref":"posixpath.join","kind":"Gdef"},"lexists":{".class":"SymbolTableNode","cross_ref":"posixpath.lexists","kind":"Gdef"},"normcase":{".class":"SymbolTableNode","cross_ref":"posixpath.normcase","kind":"Gdef"},"normpath":{".class":"SymbolTableNode","cross_ref":"posixpath.normpath","kind":"Gdef"},"pardir":{".class":"SymbolTableNode","cross_ref":"posixpath.pardir","kind":"Gdef"},"pathsep":{".class":"SymbolTableNode","cross_ref":"posixpath.pathsep","kind":"Gdef"},"realpath":{".class":"SymbolTableNode","cross_ref":"posixpath.realpath","kind":"Gdef"},"relpath":{".class":"SymbolTableNode","cross_ref":"posixpath.relpath","kind":"Gdef"},"samefile":{".class":"SymbolTableNode","cross_ref":"genericpath.samefile","kind":"Gdef"},"sameopenfile":{".class":"SymbolTableNode","cross_ref":"genericpath.sameopenfile","kind":"Gdef"},"samestat":{".class":"SymbolTableNode","cross_ref":"genericpath.samestat","kind":"Gdef"},"sep":{".class":"SymbolTableNode","cross_ref":"posixpath.sep","kind":"Gdef"},"split":{".class":"SymbolTableNode","cross_ref":"posixpath.split","kind":"Gdef"},"splitdrive":{".class":"SymbolTableNode","cross_ref":"posixpath.splitdrive","kind":"Gdef"},"splitext":{".class":"SymbolTableNode","cross_ref":"posixpath.splitext","kind":"Gdef"},"splitroot":{".class":"SymbolTableNode","cross_ref":"posixpath.splitroot","kind":"Gdef"},"supports_unicode_filenames":{".class":"SymbolTableNode","cross_ref":"posixpath.supports_unicode_filenames","kind":"Gdef"},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/os/path.pyi"}
```

.mypy_cache/3.12/os/path.meta.json
```
{"data_mtime":1767891128,"dep_lines":[1,7,1,1,1,1],"dep_prios":[10,5,5,30,30,30],"dependencies":["sys","posixpath","builtins","_frozen_importlib","abc","typing"],"hash":"34bb419f07129617e5c6e8405231794a2c12ca8b","id":"os.path","ignore_all":true,"interface_hash":"2bf874c2368e0dd571bf589f09ee8b709d580ff4","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/os/path.pyi","plugin_data":null,"size":186,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/sys/__init__.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/sys/__init__.meta.json
```
{"data_mtime":1767891128,"dep_lines":[3,5,477,2,4,6,7,8,9,1,1,1],"dep_prios":[5,5,10,5,5,5,5,5,5,30,30,30],"dependencies":["_typeshed.importlib","collections.abc","sys._monitoring","_typeshed","builtins","io","types","typing","typing_extensions","_frozen_importlib","_io","abc"],"hash":"136a19c3028a0080673e5416d508539bad4268e8","id":"sys","ignore_all":true,"interface_hash":"d0209a8115a6ae73f9e572a868470862d25d2e08","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/sys/__init__.pyi","plugin_data":null,"size":15906,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/sys/_monitoring.data.json
```
{".class":"MypyFile","_fullname":"sys._monitoring","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","Any":{".class":"SymbolTableNode","cross_ref":"typing.Any","kind":"Gdef","module_hidden":true,"module_public":false},"COVERAGE_ID":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.COVERAGE_ID","name":"COVERAGE_ID","type":"builtins.int"}},"Callable":{".class":"SymbolTableNode","cross_ref":"typing.Callable","kind":"Gdef","module_hidden":true,"module_public":false},"CodeType":{".class":"SymbolTableNode","cross_ref":"types.CodeType","kind":"Gdef","module_hidden":true,"module_public":false},"DEBUGGER_ID":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.DEBUGGER_ID","name":"DEBUGGER_ID","type":"builtins.int"}},"DISABLE":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.DISABLE","name":"DISABLE","type":"builtins.object"}},"MISSING":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.MISSING","name":"MISSING","type":"builtins.object"}},"OPTIMIZER_ID":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.OPTIMIZER_ID","name":"OPTIMIZER_ID","type":"builtins.int"}},"PROFILER_ID":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.PROFILER_ID","name":"PROFILER_ID","type":"builtins.int"}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"_events":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["builtins.object"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"sys._monitoring._events","name":"_events","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"sys._monitoring._events","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"sys._monitoring","mro":["sys._monitoring._events","builtins.object"],"names":{".class":"SymbolTable","BRANCH":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.BRANCH","name":"BRANCH","type":"builtins.int"}},"CALL":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.CALL","name":"CALL","type":"builtins.int"}},"C_RAISE":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.C_RAISE","name":"C_RAISE","type":"builtins.int"}},"C_RETURN":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.C_RETURN","name":"C_RETURN","type":"builtins.int"}},"EXCEPTION_HANDLED":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.EXCEPTION_HANDLED","name":"EXCEPTION_HANDLED","type":"builtins.int"}},"INSTRUCTION":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.INSTRUCTION","name":"INSTRUCTION","type":"builtins.int"}},"JUMP":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.JUMP","name":"JUMP","type":"builtins.int"}},"LINE":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.LINE","name":"LINE","type":"builtins.int"}},"NO_EVENTS":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.NO_EVENTS","name":"NO_EVENTS","type":"builtins.int"}},"PY_RESUME":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.PY_RESUME","name":"PY_RESUME","type":"builtins.int"}},"PY_RETURN":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.PY_RETURN","name":"PY_RETURN","type":"builtins.int"}},"PY_START":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.PY_START","name":"PY_START","type":"builtins.int"}},"PY_THROW":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.PY_THROW","name":"PY_THROW","type":"builtins.int"}},"PY_UNWIND":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.PY_UNWIND","name":"PY_UNWIND","type":"builtins.int"}},"PY_YIELD":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.PY_YIELD","name":"PY_YIELD","type":"builtins.int"}},"RAISE":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.RAISE","name":"RAISE","type":"builtins.int"}},"RERAISE":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.RERAISE","name":"RERAISE","type":"builtins.int"}},"STOP_ITERATION":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready"],"fullname":"sys._monitoring._events.STOP_ITERATION","name":"STOP_ITERATION","type":"builtins.int"}}},"self_type":null,"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"events":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"sys._monitoring.events","name":"events","type":"sys._monitoring._events"}},"free_tool_id":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":[null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sys._monitoring.free_tool_id","name":"free_tool_id","type":{".class":"CallableType","arg_kinds":[0],"arg_names":[null],"arg_types":["builtins.int"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"free_tool_id","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"get_events":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":[null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sys._monitoring.get_events","name":"get_events","type":{".class":"CallableType","arg_kinds":[0],"arg_names":[null],"arg_types":["builtins.int"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"get_events","ret_type":"builtins.int","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"get_local_events":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":[null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sys._monitoring.get_local_events","name":"get_local_events","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":[null,null],"arg_types":["builtins.int","types.CodeType"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"get_local_events","ret_type":"builtins.int","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"get_tool":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":[null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sys._monitoring.get_tool","name":"get_tool","type":{".class":"CallableType","arg_kinds":[0],"arg_names":[null],"arg_types":["builtins.int"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"get_tool","ret_type":{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":true},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"register_callback":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0],"arg_names":[null,null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sys._monitoring.register_callback","name":"register_callback","type":{".class":"CallableType","arg_kinds":[0,0,0],"arg_names":[null,null,null],"arg_types":["builtins.int","builtins.int",{".class":"UnionType","items":[{".class":"CallableType","arg_kinds":[2,4],"arg_names":[null,null],"arg_types":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2}],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":true,"name":null,"ret_type":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]},{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"register_callback","ret_type":{".class":"UnionType","items":[{".class":"CallableType","arg_kinds":[2,4],"arg_names":[null,null],"arg_types":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2}],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":true,"name":null,"ret_type":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":2},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]},{".class":"NoneType"}],"uses_pep604_syntax":true},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"restart_events":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[],"arg_names":[],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sys._monitoring.restart_events","name":"restart_events","type":{".class":"CallableType","arg_kinds":[],"arg_names":[],"arg_types":[],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"restart_events","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"set_events":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":[null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sys._monitoring.set_events","name":"set_events","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":[null,null],"arg_types":["builtins.int","builtins.int"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"set_events","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"set_local_events":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0],"arg_names":[null,null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sys._monitoring.set_local_events","name":"set_local_events","type":{".class":"CallableType","arg_kinds":[0,0,0],"arg_names":[null,null,null],"arg_types":["builtins.int","types.CodeType","builtins.int"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"set_local_events","ret_type":"builtins.int","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"use_tool_id":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":[null,null],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"sys._monitoring.use_tool_id","name":"use_tool_id","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":[null,null],"arg_types":["builtins.int","builtins.str"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"use_tool_id","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/sys/_monitoring.pyi"}
```

.mypy_cache/3.12/sys/_monitoring.meta.json
```
{"data_mtime":1767891128,"dep_lines":[8,9,10,1,1,1],"dep_prios":[5,5,5,5,30,30],"dependencies":["collections.abc","types","typing","builtins","_frozen_importlib","abc"],"hash":"6538719a3d28b7c044c8633b6b63602a46909534","id":"sys._monitoring","ignore_all":true,"interface_hash":"2e6e0e725b23ceaf1da62c8641e7d9c8b87570bb","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/sys/_monitoring.pyi","plugin_data":null,"size":1492,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/zipfile/__init__.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/zipfile/__init__.meta.json
```
{"data_mtime":1767891128,"dep_lines":[4,293,1,2,3,6,7,8,9,1,1,1,1,1],"dep_prios":[5,5,5,10,5,5,5,5,5,5,30,30,30,30],"dependencies":["collections.abc","zipfile._path","io","sys","_typeshed","os","types","typing","typing_extensions","builtins","_collections_abc","_frozen_importlib","_io","abc"],"hash":"8fc6699ae0c00ae6b83f2797cf0e4e82c9c29e8d","id":"zipfile","ignore_all":true,"interface_hash":"1b8099e3947a81abb54f0573215cb799da70bee4","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/zipfile/__init__.pyi","plugin_data":null,"size":12704,"suppressed":[],"version_id":"1.15.0"}
```

docs/oracle-questions-2026-01-08/actions/01-contracts-interfaces-ticket-surface.md
```
Direct answer (public surface changes; backwards-compat called out)

Clarify/document Action Pack execution semantics: steps run as bash -lc ..., and oraclepack’s “special handling” (flag injection/override validation) only applies to commands that begin with oracle (today). This is a user-facing CLI/TUI documentation surface change (README and/or oraclepack-tui.md-style docs). 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Dispatcher/command-detection contract expansion: update command detection from an oracle-anchored regex (noted as ^(\\s*)(oracle)\\b) so non-oracle tools (tm/task-master, codex, gemini) can be treated as first-class step commands for override/dispatch purposes. Back-compat constraint: preserve existing behavior for oracle ... commands. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Override validation behavior change (TUI/CI surface): today validation runs oracle --dry-run summary on detected oracle invocations and skips steps without oracle invocations; tickets imply extending or restructuring validation so steps containing tm/task-master, codex, gemini are not silently excluded. Back-compat constraint: do not regress the current oracle-only validation flow. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

ticket-action-pack.md content contract change: replace placeholder steps (explicitly 09–13 and 16) with headless gemini + non-interactive codex exec automation, while keeping the pack ingestible (single bash fence, 20-step structure). Back-compat constraint: keep Steps 01–07 semantics unchanged. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

New output artifact interface for the action workflow: introduce/standardize generated files under .oraclepack/ticketify/ (e.g., next.json, codex-implement.md, codex-verify.md and/or gemini-review.json, PR.md) as “expected outputs” of those steps. Back-compat constraint: paths must match the step examples; don’t move or rename without versioning. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Tool-availability/timeout behavior requirements become part of the pack’s operational contract: add command -v ... guards and documented “skip” behavior to avoid hard failures when codex/gemini are missing; also explicitly call out “interactive CLI blocks” risk. Back-compat constraint: default runs shouldn’t newly fail just because optional tools aren’t installed. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Taskify Action Pack generator surface: add an “agent-mode” option for taskify-generated packs (suggested mode=codex / mode=gemini) that swaps the existing autopilot entrypoint step with an agent implementation step, without changing the 20-step contract. Back-compat constraint: default mode should remain the current behavior; agent-mode must be opt-in. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

“Pack schema” remains a hard compatibility boundary: multiple tickets restate that the Action Pack must remain oraclepack-ingestible (single `bas
```

docs/oracle-questions-2026-01-08/actions/02-contracts-interfaces-integration-points.md
```
Direct answer (external integrations, required config/contract changes, failure/timeout, rollout)

Task Master CLI integration is assumed: Action Packs invoke task-master / tm for PRD parsing, complexity analysis, and task expansion; this implies the runtime environment must have Task Master installed and configured, and the pack writes/reads Task Master artifacts (e.g., .taskmaster/docs/tickets_prd.md, .oraclepack/ticketify/tm-complexity.json). 

Oraclepack_Compatibility_Issues

Codex CLI integration is implied for “implementation” and “verification”: placeholder steps (notably Step 10 and optionally Step 11) are intended to run codex exec non-interactively and emit .oraclepack/ticketify/codex-implement.md and .oraclepack/ticketify/codex-verify.md. 

Oraclepack_Compatibility_Issues

Gemini CLI integration is implied for “selection” and “PR drafting”: placeholder steps (notably Step 09 and Step 16, and optionally Step 11) are intended to run headless gemini and write .oraclepack/ticketify/next.json, .oraclepack/ticketify/PR.md, and optionally .oraclepack/ticketify/gemini-review.json. 

Oraclepack_Compatibility_Issues

Oracle CLI integration is the only integration that currently receives oraclepack’s special handling: oraclepack injects flags / performs validation only for commands beginning with oracle (regex anchored to ^(\\s*)(oracle)\\b), while tm/task-master, codex, gemini run as raw shell commands. 

Oraclepack_Compatibility_Issues

Required contract change (dispatcher/validation): extend oraclepack’s command detection + override/validation pipeline beyond oracle-prefixed commands so steps containing tm/task-master, codex, gemini are no longer excluded from override/validation purely due to prefix mismatch; must preserve existing oracle behavior. 

Oraclepack_Compatibility_Issues

Required pack-template change (ticketify Action Pack): replace the placeholder/echo-only steps (08–20) with real, headless commands in the suggested slots (09–13 and 16) and enforce deterministic output paths under .oraclepack/ticketify/ (e.g., next.json, codex-implement.md, codex-verify.md, gemini-review.json, PR.md). 

Oraclepack_Compatibility_Issues

Required generator change (taskify Action Packs): add an “agent-mode” switch (suggested mode=codex / mode=gemini) that swaps an existing step-slot (not an added step) “right after Task Master expands tasks,” keeping the 20-step contract intact. 

Oraclepack_Compatibility_Issues

Failure/timeout behavior implied by tickets: every step is executed as a literal bash -lc ... script; if a CLI is interactive it can block waiting for input, and if a binary is missing from PATH the step fails unless the step explicitly guards/skips via command -v ... checks. 

Oraclepack_Compatibility_Issues

Failure behavior implied by tickets: ROI filtering can skip steps that lack an ROI= annotation when a threshold > 0 is used (“ROI filter gotcha”), which can silently skip non-annotated automation steps unless you standardize ROI tags for them. 

Oraclepack_Compatibility_Issues

Minimal compat-safe rollout sequence: (1) document current semantics + failure modes (no behavior change), then (2) update ticket-action-pack.md placeholder steps using guarded command -v + non-interactive/headless flags (no oraclepack core change), then (3) introduce dispatcher/validation broadening behind an opt-in flag or “mode” to preserve default oracle-only semantics.

Risks/unknowns

The tickets explicitly note the spec gap: “exact desired behavior for applying overrides” to tm/task-master, codex, gemini (which flags, what validation) is not provided, so d
```

docs/oracle-questions-2026-01-08/actions/03-invariants-invariant-map.md
```
Direct answer (system invariants + where to enforce them)

Invariant: Action Packs must be “oraclepack-ingestible”: a single bash code fence containing numbered step headers # NN) (and the broader workflow expects a fixed step contract). Enforce in a pack parser/validator (structural validation before execution) and in pack generators/templates (to prevent emitting invalid shapes). 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Invariant: Step execution semantics are “literal shell”: each step is executed via bash -lc ..., in the project root; oraclepack does not change working directory to out_dir. Enforce by documenting as a non-changing contract, and by adding a “preflight” check in pack Step 01 if any later step assumes paths relative to out_dir. 

Oraclepack_Compatibility_Issues

Invariant: Oraclepack’s override/flag injection applies only to commands that begin with oracle (regex anchored to ^(\\s*)(oracle)\\b); tm/task-master, codex, gemini run directly and do not inherit oracle-specific transforms. Enforce in the override injection stage (explicitly scope the matcher to oracle unless/until dispatcher is extended) and in docs/TUI messaging to prevent incorrect user expectations. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Invariant: Override validation behavior in the TUI targets only detected oracle invocations (it runs oracle --dry-run summary and skips steps with no oracle invocations). Enforce in the TUI validation pipeline (make the “oracle-only validation” rule explicit) and ensure validate output clearly distinguishes “not validated (non-oracle)” vs “validated”. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Invariant: ROI filtering can skip steps that lack ROI= metadata when a threshold > 0 is used. Enforce in pack generation (always emit ROI metadata if packs are intended to be filtered) and in runtime (warn when filtering is enabled but steps have no ROI fields). 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Invariant: Placeholder steps do not “magically dispatch” external agents—Steps 08–20 are effectively notes unless the step body contains real commands; if you add codex/gemini, oraclepack will attempt to run them as-is. Enforce via template hygiene (placeholders clearly marked; “agent-mode” packs replace placeholders with real commands) and via validation/docs (set expectations: “no commands, nothing happens”). 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Invariant: Non-oracle tool availability and interactivity are execution blockers: missing binaries fail steps; interactive CLIs will block unless headless/non-interactive flags are used. Packs that include codex/gemini must include availability guards and skip behavior (e.g., command -v ...). Enforce inside the pack steps themselves (guards + deterministic skip semantics) and optionally in oraclepack preflight (detect missing binaries before running). 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Invariant: Certain steps are expected to produce specific on-disk artifacts (e.g., .oraclepack/ticketify/_tickets_index.json, _actions.json, _actions.md, .taskmaster/docs/tickets_prd.md, plus later .oraclepack/ticketify/next.json, codex-implement.md, codex-verify.md/gemini-review.json, PR.md). Enforce by (a) pack-level preflight asserting prerequisites exi_
```

docs/oracle-questions-2026-01-08/actions/04-invariants-validation-boundaries.md
```
Direct answer (validation boundaries that must exist; with minimal validation plan)

Pack structure boundary (parser-level): reject any “action pack” that is not oraclepack-ingestible: exactly one fenced bash block, and step headers in the # NN) form (sequential). This is explicitly treated as a global constraint in the ticket content and is the assumed execution contract. 

Oraclepack_Compatibility_Issues

 

oraclepack-llms-full

Execution semantics boundary (runner-level): treat every step body as literal shell executed via bash -lc … from the project root, with no special routing unless the command begins with oracle. This must be documented and enforced as a “you get what you wrote” boundary to prevent false assumptions about dispatching/wrapping non-oracle tools. 

Oraclepack_Compatibility_Issues

Oracle-only transform/override boundary (validator + injector-level): override injection and “override validation” must only apply to commands that begin with oracle (regex anchored to oracle per ticket), and steps without oracle invocations must not be assumed validated by oracle dry-runs. Validation must therefore (a) detect oracle invocations precisely, and (b) warn (or at least report) that non-oracle steps are outside oracle override validation. 

Oraclepack_Compatibility_Issues

Tooling availability boundary (pack authoring + runtime guard-level): because non-oracle CLIs (tm/task-master, codex, gemini) run directly, packs must either (a) require them explicitly (hard fail), or (b) guard with command -v … and implement “skip” behavior. The ticket explicitly calls out “missing binary on PATH fails” and “interactive blocks” as common failure modes; validation should catch missing guards for steps intended to be optional/headless. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Ticket parsing boundary (ticketify step-level): before any “ticketify” logic runs, validate .tickets/ exists (and contains readable ticket files) because missing .tickets/ is called out as a primary failure note; then validate the expected index artifact(s) are produced (e.g., .oraclepack/ticketify/_tickets_index.json). 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Artifact contract boundary (step-output-level): steps that claim to produce .oraclepack/ticketify/* outputs must be validated for deterministic paths and for actually writing the promised files (e.g., next.json, codex-implement.md, codex-verify.md, gemini-review.json, PR.md). The ticket’s acceptance criteria is already framed this way; validation should mirror it. 

Oraclepack_Compatibility_Issues

ROI filtering boundary (filter-level): if ROI-based filtering is enabled, steps without ROI= may be skipped; packs that rely on certain steps must include ROI tags (or validation must fail/warn when ROI thresholding would skip required steps). 

Oraclepack_Compatibility_Issues

Minimal validation plan (smallest set that covers the boundaries above):

Static pack validation: run oraclepack validate <pack.md> for representative packs (gold pack, ticket-action-pack, and a mixed-tool pack). 

oraclepack-llms-full

Fixture-based parser regression: validate packs with (a) multiple code fences, (b) missing/duplicated/unsorted # NN) headers, (c) non-sequential numbering, and confirm deterministic errors (prevents schema drift). 

oraclepack-llms-full

Mixed-tool step cove
```

docs/oracle-questions-2026-01-08/actions/05-caching-state-state-artifacts.md
```
Direct answer (1–10 bullets, evidence-cited)

Preserve the ticket discovery index: .oraclepack/ticketify/_tickets_index.json (produced by ticket-action-pack.md Step 01). It is explicitly called out as an output artifact and is the natural cache boundary for downstream “actions” inference. 

Oraclepack_Compatibility_Issues

Preserve the canonical actions outputs: _actions.json and _actions.md (produced by Step 02). These are explicitly named outputs; _actions.json is expected to follow a stable, machine-readable schema (metadata + up to 20 items) to support later automation. 

Oraclepack_Compatibility_Issues

 

oraclepack-llms-full

Preserve the Task Master PRD artifact: .taskmaster/docs/tickets_prd.md (produced by Step 03). This is explicitly named as a written output and is a key handoff artifact into Task Master parsing/expansion. 

Oraclepack_Compatibility_Issues

Preserve Task Master analysis/expansion artifacts, especially .oraclepack/ticketify/tm-complexity.json; and preserve tasks.json as the post-expansion state boundary (agent-mode insertion is specified “after Task Master expands tasks” when these exist). 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Preserve oraclepack run state and reporting outputs: ticket-action-pack.state.json and ticket-action-pack.report.json. These are explicitly named outputs and are the audit/resume boundary (the broader design expectation is “persist run state” + “machine-readable summary report” with stable schema/versioning). 

Oraclepack_Compatibility_Issues

 

oraclepack-llms-full

Add and preserve new headless “agent” artifacts under .oraclepack/ticketify/ with deterministic paths: next.json (Step 09), codex-implement.md (Step 10), codex-verify.md and/or gemini-review.json (Step 11), and PR.md (Step 16). These paths are hard requirements in the ticket’s acceptance criteria. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Preserve the pack’s ingestible shape as a compatibility constraint: action packs must remain “oraclepack-ingestible” (single bash fence, # NN) step headers), and taskify “agent-mode” must keep the “20-step contract intact” by swapping a step slot rather than adding steps. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Treat “project-root execution” as a stability requirement for artifact paths: steps run via bash -lc in the project root and oraclepack does not chdir to out_dir, so all preserved artifacts must be written/read using repo-root-relative deterministic paths (not relying on CWD changes). 

Oraclepack_Compatibility_Issues

Back-compat requirement for overrides/validation: oraclepack’s special injection/validation currently targets only commands beginning with oracle (regex anchored to ^(\\s*)(oracle)\\b), so any stateful Codex/Gemini/Task Master artifacts must not depend on oracle-specific overrides unless dispatcher logic is explicitly extended. 

Oraclepack_Compatibility_Issues

ROI metadata stability affects whether artifacts exist at all: ROI filtering may skip steps without ROI= when thresholds are used, so steps that must produce the preserved artifacts should keep ROI headers (and not become “placeholder/notes” steps) to prevent accidental non-execution. 

Oraclepack_Compatibility_Issues

 

Oraclepack_Compatibility_Issues

Risks/unknowns (bullets)

Exact schemas are not specified (in the ticket) for .oraclepack/ticketify/_tickets_index.json, .oraclepack/ticketify/tm-complexity.json, .oraclepack/ticketify/next.json, and the exact fields/versions of ticket-action-pack.state.json / .report.json; without these, schema drift ris

Oraclepack_Compatibility_Issues
```

docs/oracle-questions-2026-01-08/packs/actions.md
```
# Oracle Pack — oraclepack (Grouped Tickets Stage 1 — Direct Attach)

## Parsed args
- codebase_name: oraclepack
- out_dir: docs/oracle-questions-2026-01-08/actions
- oracle_cmd: oracle
- oracle_flags: --files-report
- extra_files: 
- ticket_root: .tickets
- ticket_glob: **/*.md
- ticket_paths: .tickets/actions/Enable Action Packs Dispatch.md,.tickets/actions/Improving Oraclepack Workflow.md,.tickets/actions/Oraclepack Action Pack Integration.md,.tickets/actions/Oraclepack Action Pack Issue.md,.tickets/actions/Oraclepack Action Packs.md,.tickets/actions/Oraclepack Compatibility Issues.md
- ticket_max_files: 6
- group_name: actions
- group_slug: actions
- mode: tickets-grouped-direct

Notes (contract):
- Exactly one fenced `bash` block in this document.
- No other ``` fences anywhere.
- Exactly 20 steps, numbered 01..20 in order.
- Step header: `# NN) ROI=... impact=... confidence=... effort=... horizon=... category=... reference=...`
- Every step includes: `--write-output "docs/oracle-questions-2026-01-08/actions/NN-<slug>.md"` (double quotes required).
- Steps must be self-contained and must not rely on shell variables created in previous steps.
- Each step must attach tickets directly (no `_tickets_bundle.md` dependency).
- Pack ends with a Coverage check section listing all 10 categories as OK or Missing(<step ids>).

```bash
set -euo pipefail

mkdir -p "docs/oracle-questions-2026-01-08/actions"

# 01) ROI=4.8 impact=6 confidence=0.80 effort=1 horizon=Immediate category=contracts/interfaces reference=actions

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/actions/Enable Action Packs Dispatch.md,.tickets/actions/Improving Oraclepack Workflow.md,.tickets/actions/Oraclepack Action Pack Integration.md,.tickets/actions/Oraclepack Action Pack Issue.md,.tickets/actions/Oraclepack Action Packs.md,.tickets/actions/Oraclepack Compatibility Issues.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'actions'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/actions/01-contracts-interfaces-ticket-surface.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #01  (ticket-driven, group: actions)

Reference: actions
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.8 (impact=6, confidence=0.80, effort=1)

Question:
Using the attached tickets as the primary context, list the public surface changes implied by the tickets (CLI/TUI/API/interfaces/contracts); call out backwards-compat constraints.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 02) ROI=4.6 impact=6 confidence=0.78 effort=1 horizon=Immediate category=contracts/interfaces reference=actions

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/actions/Enable Action Packs Dispatch.md,.tickets/actions/Improving Oraclepack Workflow.md,.tickets/actions/Oraclepack Action Pack Integration.md,.tickets/actions/Oraclepack Action Pack Issue.md,.tickets/actions/Oraclepack Action Packs.md,.tickets/actions/Oraclepack Compatibility Issues.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'actions'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/actions/02-contracts-interfaces-integration-points.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #02  (ticket-driven, group: actions)

Reference: actions
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.6 (impact=6, confidence=0.78, effort=1)

Question:
Using the attached tickets as the primary context, identify external integrations implied by the tickets; required config/contract changes; failure/timeout behavior; minimal compat-safe rollout.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 03) ROI=5.1 impact=7 confidence=0.74 effort=1 horizon=NearTerm category=invariants reference=actions

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/actions/Enable Action Packs Dispatch.md,.tickets/actions/Improving Oraclepack Workflow.md,.tickets/actions/Oraclepack Action Pack Integration.md,.tickets/actions/Oraclepack Action Pack Issue.md,.tickets/actions/Oraclepack Action Packs.md,.tickets/actions/Oraclepack Compatibility Issues.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'actions'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/actions/03-invariants-invariant-map.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #03  (ticket-driven, group: actions)

Reference: actions
Category: invariants
Horizon: NearTerm
ROI: 5.1 (impact=7, confidence=0.74, effort=1)

Question:
Using the attached tickets as the primary context, extract system invariants implied by tickets (inputs/outputs, pack schema rules, step execution rules) and where to enforce them.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 04) ROI=5.0 impact=7 confidence=0.72 effort=2 horizon=NearTerm category=invariants reference=actions

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/actions/Enable Action Packs Dispatch.md,.tickets/actions/Improving Oraclepack Workflow.md,.tickets/actions/Oraclepack Action Pack Integration.md,.tickets/actions/Oraclepack Action Pack Issue.md,.tickets/actions/Oraclepack Action Packs.md,.tickets/actions/Oraclepack Compatibility Issues.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'actions'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/actions/04-invariants-validation-boundaries.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #04  (ticket-driven, group: actions)

Reference: actions
Category: invariants
Horizon: NearTerm
ROI: 5.0 (impact=7, confidence=0.72, effort=2)

Question:
Using the attached tickets as the primary context, identify validation boundaries that must exist (ticket parsing, pack generation, pack validation); propose minimal validation plan.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 05) ROI=4.4 impact=6 confidence=0.78 effort=2 horizon=NearTerm category=caching/state reference=actions

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/actions/Enable Action Packs Dispatch.md,.tickets/actions/Improving Oraclepack Workflow.md,.tickets/actions/Oraclepack Action Pack Integration.md,.tickets/actions/Oraclepack Action Pack Issue.md,.tickets/actions/Oraclepack Action Packs.md,.tickets/actions/Oraclepack Compatibility Issues.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'actions'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/actions/05-caching-state-state-artifacts.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #05  (ticket-driven, group: actions)

Reference: actions
Category: caching/state
Horizon: NearTerm
ROI: 4.4 (impact=6, confidence=0.78, effort=2)

Question:
Using the attached tickets as the primary context, identify state/artifacts that must be produced and preserved; schema/format expectations; stability/back-compat requirements.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 06) ROI=4.2 impact=6 confidence=0.75 effort=2 horizon=NearTerm category=caching/state reference=actions

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/actions/Enable Action Packs Dispatch.md,.tickets/actions/Improving Oraclepack Workflow.md,.tickets/actions/Oraclepack Action Pack Integration.md,.tickets/actions/Oraclepack Action Pack Issue.md,.tickets/actions/Oraclepack Action Packs.md,.tickets/actions/Oraclepack Compatibility Issues.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'actions'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/actions/06-caching-state-cache-keys.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #06  (ticket-driven, group: actions)

Reference: actions
Category: caching/state
Horizon: NearTerm
ROI: 4.2 (impact=6, confidence=0.75, effort=2)

Question:
Using the attached tickets as the primary context, identify any caching opportunities/risks (discovery caches, pack outputs, oracle outputs); define cache keys, invalidation, and correctness risks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 07) ROI=4.3 impact=6 confidence=0.70 effort=2 horizon=MidTerm category=background jobs reference=actions

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/actions/Enable Action Packs Dispatch.md,.tickets/actions/Improving Oraclepack Workflow.md,.tickets/actions/Oraclepack Action Pack Integration.md,.tickets/actions/Oraclepack Action Pack Issue.md,.tickets/actions/Oraclepack Action Packs.md,.tickets/actions/Oraclepack Compatibility Issues.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'actions'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/actions/07-background-jobs-job-model.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #07  (ticket-driven, group: actions)

Reference: actions
Category: background jobs
Horizon: MidTerm
ROI: 4.3 (impact=6, confidence=0.70, effort=2)

Question:
Using the attached tickets as the primary context, identify any background/async work implied (jobs, queues, long-running operations); define responsibilities and interfaces.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 08) ROI=4.0 impact=6 confidence=0.68 effort=3 horizon=MidTerm category=background jobs reference=actions

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/actions/Enable Action Packs Dispatch.md,.tickets/actions/Improving Oraclepack Workflow.md,.tickets/actions/Oraclepack Action Pack Integration.md,.tickets/actions/Oraclepack Action Pack Issue.md,.tickets/actions/Oraclepack Action Packs.md,.tickets/actions/Oraclepack Compatibility Issues.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'actions'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/actions/08-background-jobs-queue-failure.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #08  (ticket-driven, group: actions)

Reference: actions
Category: background jobs
Horizon: MidTerm
ROI: 4.0 (impact=6, confidence=0.68, effort=3)

Question:
Using the attached tickets as the primary context, define how background failures are handled (retries, idempotency, poison messages); define observability hooks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 09) ROI=4.7 impact=7 confidence=0.76 effort=1 horizon=Immediate category=observability reference=actions

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/actions/Enable Action Packs Dispatch.md,.tickets/actions/Improving Oraclepack Workflow.md,.tickets/actions/Oraclepack Action Pack Integration.md,.tickets/actions/Oraclepack Action Pack Issue.md,.tickets/actions/Oraclepack Action Packs.md,.tickets/actions/Oraclepack Compatibility Issues.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'actions'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/actions/09-observability-logging-metrics.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #09  (ticket-driven, group: actions)

Reference: actions
Category: observability
Horizon: Immediate
ROI: 4.7 (impact=7, confidence=0.76, effort=1)

Question:
[TRUNCATED]
```

docs/oracle-questions-2026-01-08/packs/mcp.md
```
# Oracle Pack — oraclepack (Grouped Tickets Stage 1 — Direct Attach)

## Parsed args
- codebase_name: oraclepack
- out_dir: docs/oracle-questions-2026-01-08/mcp
- oracle_cmd: oracle
- oracle_flags: --files-report
- extra_files: 
- ticket_root: .tickets
- ticket_glob: **/*.md
- ticket_paths: .tickets/mcp/Expose Oraclepack as MCP.md,.tickets/mcp/MCP Server for Oraclepack.md,.tickets/mcp/gaps-still-not-covered.md,.tickets/mcp/gaps_part2-mcp-builder.md,.tickets/mcp/oraclepack-MCP.md,.tickets/mcp/oraclepack_mcp_server.md
- ticket_max_files: 6
- group_name: mcp
- group_slug: mcp
- mode: tickets-grouped-direct

Notes (contract):
- Exactly one fenced `bash` block in this document.
- No other ``` fences anywhere.
- Exactly 20 steps, numbered 01..20 in order.
- Step header: `# NN) ROI=... impact=... confidence=... effort=... horizon=... category=... reference=...`
- Every step includes: `--write-output "docs/oracle-questions-2026-01-08/mcp/NN-<slug>.md"` (double quotes required).
- Steps must be self-contained and must not rely on shell variables created in previous steps.
- Each step must attach tickets directly (no `_tickets_bundle.md` dependency).
- Pack ends with a Coverage check section listing all 10 categories as OK or Missing(<step ids>).

```bash
set -euo pipefail

mkdir -p "docs/oracle-questions-2026-01-08/mcp"

# 01) ROI=4.8 impact=6 confidence=0.80 effort=1 horizon=Immediate category=contracts/interfaces reference=mcp

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/mcp/Expose Oraclepack as MCP.md,.tickets/mcp/MCP Server for Oraclepack.md,.tickets/mcp/gaps-still-not-covered.md,.tickets/mcp/gaps_part2-mcp-builder.md,.tickets/mcp/oraclepack-MCP.md,.tickets/mcp/oraclepack_mcp_server.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'mcp'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/mcp/01-contracts-interfaces-ticket-surface.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #01  (ticket-driven, group: mcp)

Reference: mcp
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.8 (impact=6, confidence=0.80, effort=1)

Question:
Using the attached tickets as the primary context, list the public surface changes implied by the tickets (CLI/TUI/API/interfaces/contracts); call out backwards-compat constraints.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 02) ROI=4.6 impact=6 confidence=0.78 effort=1 horizon=Immediate category=contracts/interfaces reference=mcp

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/mcp/Expose Oraclepack as MCP.md,.tickets/mcp/MCP Server for Oraclepack.md,.tickets/mcp/gaps-still-not-covered.md,.tickets/mcp/gaps_part2-mcp-builder.md,.tickets/mcp/oraclepack-MCP.md,.tickets/mcp/oraclepack_mcp_server.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'mcp'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/mcp/02-contracts-interfaces-integration-points.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #02  (ticket-driven, group: mcp)

Reference: mcp
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.6 (impact=6, confidence=0.78, effort=1)

Question:
Using the attached tickets as the primary context, identify external integrations implied by the tickets; required config/contract changes; failure/timeout behavior; minimal compat-safe rollout.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 03) ROI=5.1 impact=7 confidence=0.74 effort=1 horizon=NearTerm category=invariants reference=mcp

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/mcp/Expose Oraclepack as MCP.md,.tickets/mcp/MCP Server for Oraclepack.md,.tickets/mcp/gaps-still-not-covered.md,.tickets/mcp/gaps_part2-mcp-builder.md,.tickets/mcp/oraclepack-MCP.md,.tickets/mcp/oraclepack_mcp_server.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'mcp'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/mcp/03-invariants-invariant-map.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #03  (ticket-driven, group: mcp)

Reference: mcp
Category: invariants
Horizon: NearTerm
ROI: 5.1 (impact=7, confidence=0.74, effort=1)

Question:
Using the attached tickets as the primary context, extract system invariants implied by tickets (inputs/outputs, pack schema rules, step execution rules) and where to enforce them.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 04) ROI=5.0 impact=7 confidence=0.72 effort=2 horizon=NearTerm category=invariants reference=mcp

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/mcp/Expose Oraclepack as MCP.md,.tickets/mcp/MCP Server for Oraclepack.md,.tickets/mcp/gaps-still-not-covered.md,.tickets/mcp/gaps_part2-mcp-builder.md,.tickets/mcp/oraclepack-MCP.md,.tickets/mcp/oraclepack_mcp_server.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'mcp'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/mcp/04-invariants-validation-boundaries.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #04  (ticket-driven, group: mcp)

Reference: mcp
Category: invariants
Horizon: NearTerm
ROI: 5.0 (impact=7, confidence=0.72, effort=2)

Question:
Using the attached tickets as the primary context, identify validation boundaries that must exist (ticket parsing, pack generation, pack validation); propose minimal validation plan.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 05) ROI=4.4 impact=6 confidence=0.78 effort=2 horizon=NearTerm category=caching/state reference=mcp

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/mcp/Expose Oraclepack as MCP.md,.tickets/mcp/MCP Server for Oraclepack.md,.tickets/mcp/gaps-still-not-covered.md,.tickets/mcp/gaps_part2-mcp-builder.md,.tickets/mcp/oraclepack-MCP.md,.tickets/mcp/oraclepack_mcp_server.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'mcp'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/mcp/05-caching-state-state-artifacts.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #05  (ticket-driven, group: mcp)

Reference: mcp
Category: caching/state
Horizon: NearTerm
ROI: 4.4 (impact=6, confidence=0.78, effort=2)

Question:
Using the attached tickets as the primary context, identify state/artifacts that must be produced and preserved; schema/format expectations; stability/back-compat requirements.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 06) ROI=4.2 impact=6 confidence=0.75 effort=2 horizon=NearTerm category=caching/state reference=mcp

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/mcp/Expose Oraclepack as MCP.md,.tickets/mcp/MCP Server for Oraclepack.md,.tickets/mcp/gaps-still-not-covered.md,.tickets/mcp/gaps_part2-mcp-builder.md,.tickets/mcp/oraclepack-MCP.md,.tickets/mcp/oraclepack_mcp_server.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'mcp'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/mcp/06-caching-state-cache-keys.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #06  (ticket-driven, group: mcp)

Reference: mcp
Category: caching/state
Horizon: NearTerm
ROI: 4.2 (impact=6, confidence=0.75, effort=2)

Question:
Using the attached tickets as the primary context, identify any caching opportunities/risks (discovery caches, pack outputs, oracle outputs); define cache keys, invalidation, and correctness risks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 07) ROI=4.3 impact=6 confidence=0.70 effort=2 horizon=MidTerm category=background jobs reference=mcp

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/mcp/Expose Oraclepack as MCP.md,.tickets/mcp/MCP Server for Oraclepack.md,.tickets/mcp/gaps-still-not-covered.md,.tickets/mcp/gaps_part2-mcp-builder.md,.tickets/mcp/oraclepack-MCP.md,.tickets/mcp/oraclepack_mcp_server.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'mcp'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/mcp/07-background-jobs-job-model.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #07  (ticket-driven, group: mcp)

Reference: mcp
Category: background jobs
Horizon: MidTerm
ROI: 4.3 (impact=6, confidence=0.70, effort=2)

Question:
Using the attached tickets as the primary context, identify any background/async work implied (jobs, queues, long-running operations); define responsibilities and interfaces.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 08) ROI=4.0 impact=6 confidence=0.68 effort=3 horizon=MidTerm category=background jobs reference=mcp

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/mcp/Expose Oraclepack as MCP.md,.tickets/mcp/MCP Server for Oraclepack.md,.tickets/mcp/gaps-still-not-covered.md,.tickets/mcp/gaps_part2-mcp-builder.md,.tickets/mcp/oraclepack-MCP.md,.tickets/mcp/oraclepack_mcp_server.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'mcp'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/mcp/08-background-jobs-queue-failure.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #08  (ticket-driven, group: mcp)

Reference: mcp
Category: background jobs
Horizon: MidTerm
ROI: 4.0 (impact=6, confidence=0.68, effort=3)

Question:
Using the attached tickets as the primary context, define how background failures are handled (retries, idempotency, poison messages); define observability hooks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 09) ROI=4.7 impact=7 confidence=0.76 effort=1 horizon=Immediate category=observability reference=mcp

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/mcp/Expose Oraclepack as MCP.md,.tickets/mcp/MCP Server for Oraclepack.md,.tickets/mcp/gaps-still-not-covered.md,.tickets/mcp/gaps_part2-mcp-builder.md,.tickets/mcp/oraclepack-MCP.md,.tickets/mcp/oraclepack_mcp_server.md".strip()
MAX = int("6")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'mcp'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/mcp/09-observability-logging-metrics.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #09  (ticket-driven, group: mcp)

Reference: mcp
Category: observability
Horizon: Immediate
ROI: 4.7 (impact=7, confidence=0.76, effort=1)

Question:
[TRUNCATED]
```

docs/oracle-questions-2026-01-08/packs/misc.md
```
# Oracle Pack — oraclepack (Grouped Tickets Stage 1 — Direct Attach)

## Parsed args
- codebase_name: oraclepack
- out_dir: docs/oracle-questions-2026-01-08/misc
- oracle_cmd: oracle
- oracle_flags: --files-report
- extra_files: 
- ticket_root: .tickets
- ticket_glob: **/*.md
- ticket_paths: .tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md
- ticket_max_files: 4
- group_name: misc
- group_slug: misc
- mode: tickets-grouped-direct

Notes (contract):
- Exactly one fenced `bash` block in this document.
- No other ``` fences anywhere.
- Exactly 20 steps, numbered 01..20 in order.
- Step header: `# NN) ROI=... impact=... confidence=... effort=... horizon=... category=... reference=...`
- Every step includes: `--write-output "docs/oracle-questions-2026-01-08/misc/NN-<slug>.md"` (double quotes required).
- Steps must be self-contained and must not rely on shell variables created in previous steps.
- Each step must attach tickets directly (no `_tickets_bundle.md` dependency).
- Pack ends with a Coverage check section listing all 10 categories as OK or Missing(<step ids>).

```bash
set -euo pipefail

mkdir -p "docs/oracle-questions-2026-01-08/misc"

# 01) ROI=4.8 impact=6 confidence=0.80 effort=1 horizon=Immediate category=contracts/interfaces reference=misc

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'misc'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/misc/01-contracts-interfaces-ticket-surface.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #01  (ticket-driven, group: misc)

Reference: misc
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.8 (impact=6, confidence=0.80, effort=1)

Question:
Using the attached tickets as the primary context, list the public surface changes implied by the tickets (CLI/TUI/API/interfaces/contracts); call out backwards-compat constraints.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 02) ROI=4.6 impact=6 confidence=0.78 effort=1 horizon=Immediate category=contracts/interfaces reference=misc

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'misc'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/misc/02-contracts-interfaces-integration-points.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #02  (ticket-driven, group: misc)

Reference: misc
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.6 (impact=6, confidence=0.78, effort=1)

Question:
Using the attached tickets as the primary context, identify external integrations implied by the tickets; required config/contract changes; failure/timeout behavior; minimal compat-safe rollout.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 03) ROI=5.1 impact=7 confidence=0.74 effort=1 horizon=NearTerm category=invariants reference=misc

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'misc'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/misc/03-invariants-invariant-map.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #03  (ticket-driven, group: misc)

Reference: misc
Category: invariants
Horizon: NearTerm
ROI: 5.1 (impact=7, confidence=0.74, effort=1)

Question:
Using the attached tickets as the primary context, extract system invariants implied by tickets (inputs/outputs, pack schema rules, step execution rules) and where to enforce them.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 04) ROI=5.0 impact=7 confidence=0.72 effort=2 horizon=NearTerm category=invariants reference=misc

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'misc'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/misc/04-invariants-validation-boundaries.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #04  (ticket-driven, group: misc)

Reference: misc
Category: invariants
Horizon: NearTerm
ROI: 5.0 (impact=7, confidence=0.72, effort=2)

Question:
Using the attached tickets as the primary context, identify validation boundaries that must exist (ticket parsing, pack generation, pack validation); propose minimal validation plan.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 05) ROI=4.4 impact=6 confidence=0.78 effort=2 horizon=NearTerm category=caching/state reference=misc

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'misc'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/misc/05-caching-state-state-artifacts.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #05  (ticket-driven, group: misc)

Reference: misc
Category: caching/state
Horizon: NearTerm
ROI: 4.4 (impact=6, confidence=0.78, effort=2)

Question:
Using the attached tickets as the primary context, identify state/artifacts that must be produced and preserved; schema/format expectations; stability/back-compat requirements.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 06) ROI=4.2 impact=6 confidence=0.75 effort=2 horizon=NearTerm category=caching/state reference=misc

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'misc'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/misc/06-caching-state-cache-keys.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #06  (ticket-driven, group: misc)

Reference: misc
Category: caching/state
Horizon: NearTerm
ROI: 4.2 (impact=6, confidence=0.75, effort=2)

Question:
Using the attached tickets as the primary context, identify any caching opportunities/risks (discovery caches, pack outputs, oracle outputs); define cache keys, invalidation, and correctness risks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 07) ROI=4.3 impact=6 confidence=0.70 effort=2 horizon=MidTerm category=background jobs reference=misc

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'misc'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/misc/07-background-jobs-job-model.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #07  (ticket-driven, group: misc)

Reference: misc
Category: background jobs
Horizon: MidTerm
ROI: 4.3 (impact=6, confidence=0.70, effort=2)

Question:
Using the attached tickets as the primary context, identify any background/async work implied (jobs, queues, long-running operations); define responsibilities and interfaces.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 08) ROI=4.0 impact=6 confidence=0.68 effort=3 horizon=MidTerm category=background jobs reference=misc

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'misc'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/misc/08-background-jobs-queue-failure.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #08  (ticket-driven, group: misc)

Reference: misc
Category: background jobs
Horizon: MidTerm
ROI: 4.0 (impact=6, confidence=0.68, effort=3)

Question:
Using the attached tickets as the primary context, define how background failures are handled (retries, idempotency, poison messages); define observability hooks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 09) ROI=4.7 impact=7 confidence=0.76 effort=1 horizon=Immediate category=observability reference=misc

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'misc'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/misc/09-observability-logging-metrics.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #09  (ticket-driven, group: misc)

Reference: misc
Category: observability
Horizon: Immediate
ROI: 4.7 (impact=7, confidence=0.76, effort=1)

Question:
Using the attached tickets as the primary context, define what logging/metrics must exist to debug pack generation + step execution; propose minimal instrumentation plan.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 10) ROI=4.5 impact=7 confidence=0.74 effort=2 horizon=Immediate category=observability reference=misc

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/Oraclepack File Storage.md,.tickets/Oraclepack Schema Approach.md,.tickets/Oraclepack bash fix.md,.tickets/Publish OraclePack MCP.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
[TRUNCATED]
```

docs/oracle-questions-2026-01-08/packs/other.md
```
# Oracle Pack — oraclepack (Grouped Tickets Stage 1 — Direct Attach)

## Parsed args
- codebase_name: oraclepack
- out_dir: docs/oracle-questions-2026-01-08/other
- oracle_cmd: oracle
- oracle_flags: --files-report
- extra_files: 
- ticket_root: .tickets
- ticket_glob: **/*.md
- ticket_paths: .tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md
- ticket_max_files: 4
- group_name: other
- group_slug: other
- mode: tickets-grouped-direct

Notes (contract):
- Exactly one fenced `bash` block in this document.
- No other ``` fences anywhere.
- Exactly 20 steps, numbered 01..20 in order.
- Step header: `# NN) ROI=... impact=... confidence=... effort=... horizon=... category=... reference=...`
- Every step includes: `--write-output "docs/oracle-questions-2026-01-08/other/NN-<slug>.md"` (double quotes required).
- Steps must be self-contained and must not rely on shell variables created in previous steps.
- Each step must attach tickets directly (no `_tickets_bundle.md` dependency).
- Pack ends with a Coverage check section listing all 10 categories as OK or Missing(<step ids>).

```bash
set -euo pipefail

mkdir -p "docs/oracle-questions-2026-01-08/other"

# 01) ROI=4.8 impact=6 confidence=0.80 effort=1 horizon=Immediate category=contracts/interfaces reference=other

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'other'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/other/01-contracts-interfaces-ticket-surface.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #01  (ticket-driven, group: other)

Reference: other
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.8 (impact=6, confidence=0.80, effort=1)

Question:
Using the attached tickets as the primary context, list the public surface changes implied by the tickets (CLI/TUI/API/interfaces/contracts); call out backwards-compat constraints.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 02) ROI=4.6 impact=6 confidence=0.78 effort=1 horizon=Immediate category=contracts/interfaces reference=other

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'other'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/other/02-contracts-interfaces-integration-points.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #02  (ticket-driven, group: other)

Reference: other
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.6 (impact=6, confidence=0.78, effort=1)

Question:
Using the attached tickets as the primary context, identify external integrations implied by the tickets; required config/contract changes; failure/timeout behavior; minimal compat-safe rollout.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 03) ROI=5.1 impact=7 confidence=0.74 effort=1 horizon=NearTerm category=invariants reference=other

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'other'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/other/03-invariants-invariant-map.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #03  (ticket-driven, group: other)

Reference: other
Category: invariants
Horizon: NearTerm
ROI: 5.1 (impact=7, confidence=0.74, effort=1)

Question:
Using the attached tickets as the primary context, extract system invariants implied by tickets (inputs/outputs, pack schema rules, step execution rules) and where to enforce them.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 04) ROI=5.0 impact=7 confidence=0.72 effort=2 horizon=NearTerm category=invariants reference=other

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'other'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/other/04-invariants-validation-boundaries.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #04  (ticket-driven, group: other)

Reference: other
Category: invariants
Horizon: NearTerm
ROI: 5.0 (impact=7, confidence=0.72, effort=2)

Question:
Using the attached tickets as the primary context, identify validation boundaries that must exist (ticket parsing, pack generation, pack validation); propose minimal validation plan.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 05) ROI=4.4 impact=6 confidence=0.78 effort=2 horizon=NearTerm category=caching/state reference=other

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'other'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/other/05-caching-state-state-artifacts.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #05  (ticket-driven, group: other)

Reference: other
Category: caching/state
Horizon: NearTerm
ROI: 4.4 (impact=6, confidence=0.78, effort=2)

Question:
Using the attached tickets as the primary context, identify state/artifacts that must be produced and preserved; schema/format expectations; stability/back-compat requirements.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 06) ROI=4.2 impact=6 confidence=0.75 effort=2 horizon=NearTerm category=caching/state reference=other

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'other'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/other/06-caching-state-cache-keys.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #06  (ticket-driven, group: other)

Reference: other
Category: caching/state
Horizon: NearTerm
ROI: 4.2 (impact=6, confidence=0.75, effort=2)

Question:
Using the attached tickets as the primary context, identify any caching opportunities/risks (discovery caches, pack outputs, oracle outputs); define cache keys, invalidation, and correctness risks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 07) ROI=4.3 impact=6 confidence=0.70 effort=2 horizon=MidTerm category=background jobs reference=other

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'other'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/other/07-background-jobs-job-model.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #07  (ticket-driven, group: other)

Reference: other
Category: background jobs
Horizon: MidTerm
ROI: 4.3 (impact=6, confidence=0.70, effort=2)

Question:
Using the attached tickets as the primary context, identify any background/async work implied (jobs, queues, long-running operations); define responsibilities and interfaces.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 08) ROI=4.0 impact=6 confidence=0.68 effort=3 horizon=MidTerm category=background jobs reference=other

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'other'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/other/08-background-jobs-queue-failure.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #08  (ticket-driven, group: other)

Reference: other
Category: background jobs
Horizon: MidTerm
ROI: 4.0 (impact=6, confidence=0.68, effort=3)

Question:
Using the attached tickets as the primary context, define how background failures are handled (retries, idempotency, poison messages); define observability hooks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 09) ROI=4.7 impact=7 confidence=0.76 effort=1 horizon=Immediate category=observability reference=other

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'other'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/other/09-observability-logging-metrics.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #09  (ticket-driven, group: other)

Reference: other
Category: observability
Horizon: Immediate
ROI: 4.7 (impact=7, confidence=0.76, effort=1)

Question:
Using the attached tickets as the primary context, define what logging/metrics must exist to debug pack generation + step execution; propose minimal instrumentation plan.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 10) ROI=4.5 impact=7 confidence=0.74 effort=2 horizon=Immediate category=observability reference=other

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/other/Oraclepack Pipeline Improvements.md,.tickets/other/Oraclepack Prompt Generator.md,.tickets/other/Oraclepack Workflow Enhancement.md,.tickets/other/Verbose Payload Rendering TUI.md".strip()
MAX = int("4")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
[TRUNCATED]
```

docs/oracle-questions-2026-01-08/packs/prd-tui.md
```
# Oracle Pack — oraclepack (Grouped Tickets Stage 1 — Direct Attach)

## Parsed args
- codebase_name: oraclepack
- out_dir: docs/oracle-questions-2026-01-08/prd-tui
- oracle_cmd: oracle
- oracle_flags: --files-report
- extra_files: 
- ticket_root: .tickets
- ticket_glob: **/*.md
- ticket_paths: .tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md
- ticket_max_files: 2
- group_name: PRD-TUI
- group_slug: prd-tui
- mode: tickets-grouped-direct

Notes (contract):
- Exactly one fenced `bash` block in this document.
- No other ``` fences anywhere.
- Exactly 20 steps, numbered 01..20 in order.
- Step header: `# NN) ROI=... impact=... confidence=... effort=... horizon=... category=... reference=...`
- Every step includes: `--write-output "docs/oracle-questions-2026-01-08/prd-tui/NN-<slug>.md"` (double quotes required).
- Steps must be self-contained and must not rely on shell variables created in previous steps.
- Each step must attach tickets directly (no `_tickets_bundle.md` dependency).
- Pack ends with a Coverage check section listing all 10 categories as OK or Missing(<step ids>).

```bash
set -euo pipefail

mkdir -p "docs/oracle-questions-2026-01-08/prd-tui"

# 01) ROI=4.8 impact=6 confidence=0.80 effort=1 horizon=Immediate category=contracts/interfaces reference=prd-tui

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md".strip()
MAX = int("2")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'PRD-TUI'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/prd-tui/01-contracts-interfaces-ticket-surface.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #01  (ticket-driven, group: PRD-TUI)

Reference: prd-tui
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.8 (impact=6, confidence=0.80, effort=1)

Question:
Using the attached tickets as the primary context, list the public surface changes implied by the tickets (CLI/TUI/API/interfaces/contracts); call out backwards-compat constraints.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 02) ROI=4.6 impact=6 confidence=0.78 effort=1 horizon=Immediate category=contracts/interfaces reference=prd-tui

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md".strip()
MAX = int("2")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'PRD-TUI'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/prd-tui/02-contracts-interfaces-integration-points.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #02  (ticket-driven, group: PRD-TUI)

Reference: prd-tui
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.6 (impact=6, confidence=0.78, effort=1)

Question:
Using the attached tickets as the primary context, identify external integrations implied by the tickets; required config/contract changes; failure/timeout behavior; minimal compat-safe rollout.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 03) ROI=5.1 impact=7 confidence=0.74 effort=1 horizon=NearTerm category=invariants reference=prd-tui

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md".strip()
MAX = int("2")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'PRD-TUI'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/prd-tui/03-invariants-invariant-map.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #03  (ticket-driven, group: PRD-TUI)

Reference: prd-tui
Category: invariants
Horizon: NearTerm
ROI: 5.1 (impact=7, confidence=0.74, effort=1)

Question:
Using the attached tickets as the primary context, extract system invariants implied by tickets (inputs/outputs, pack schema rules, step execution rules) and where to enforce them.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 04) ROI=5.0 impact=7 confidence=0.72 effort=2 horizon=NearTerm category=invariants reference=prd-tui

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md".strip()
MAX = int("2")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'PRD-TUI'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/prd-tui/04-invariants-validation-boundaries.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #04  (ticket-driven, group: PRD-TUI)

Reference: prd-tui
Category: invariants
Horizon: NearTerm
ROI: 5.0 (impact=7, confidence=0.72, effort=2)

Question:
Using the attached tickets as the primary context, identify validation boundaries that must exist (ticket parsing, pack generation, pack validation); propose minimal validation plan.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 05) ROI=4.4 impact=6 confidence=0.78 effort=2 horizon=NearTerm category=caching/state reference=prd-tui

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md".strip()
MAX = int("2")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'PRD-TUI'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/prd-tui/05-caching-state-state-artifacts.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #05  (ticket-driven, group: PRD-TUI)

Reference: prd-tui
Category: caching/state
Horizon: NearTerm
ROI: 4.4 (impact=6, confidence=0.78, effort=2)

Question:
Using the attached tickets as the primary context, identify state/artifacts that must be produced and preserved; schema/format expectations; stability/back-compat requirements.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 06) ROI=4.2 impact=6 confidence=0.75 effort=2 horizon=NearTerm category=caching/state reference=prd-tui

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md".strip()
MAX = int("2")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'PRD-TUI'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/prd-tui/06-caching-state-cache-keys.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #06  (ticket-driven, group: PRD-TUI)

Reference: prd-tui
Category: caching/state
Horizon: NearTerm
ROI: 4.2 (impact=6, confidence=0.75, effort=2)

Question:
Using the attached tickets as the primary context, identify any caching opportunities/risks (discovery caches, pack outputs, oracle outputs); define cache keys, invalidation, and correctness risks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 07) ROI=4.3 impact=6 confidence=0.70 effort=2 horizon=MidTerm category=background jobs reference=prd-tui

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md".strip()
MAX = int("2")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'PRD-TUI'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/prd-tui/07-background-jobs-job-model.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #07  (ticket-driven, group: PRD-TUI)

Reference: prd-tui
Category: background jobs
Horizon: MidTerm
ROI: 4.3 (impact=6, confidence=0.70, effort=2)

Question:
Using the attached tickets as the primary context, identify any background/async work implied (jobs, queues, long-running operations); define responsibilities and interfaces.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 08) ROI=4.0 impact=6 confidence=0.68 effort=3 horizon=MidTerm category=background jobs reference=prd-tui

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md".strip()
MAX = int("2")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'PRD-TUI'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/prd-tui/08-background-jobs-queue-failure.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #08  (ticket-driven, group: PRD-TUI)

Reference: prd-tui
Category: background jobs
Horizon: MidTerm
ROI: 4.0 (impact=6, confidence=0.68, effort=3)

Question:
Using the attached tickets as the primary context, define how background failures are handled (retries, idempotency, poison messages); define observability hooks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 09) ROI=4.7 impact=7 confidence=0.76 effort=1 horizon=Immediate category=observability reference=prd-tui

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md".strip()
MAX = int("2")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group 'PRD-TUI'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
oracle   --files-report   --write-output "docs/oracle-questions-2026-01-08/prd-tui/09-observability-logging-metrics.md"   "${ticket_args[@]}"      -p "$(cat <<'PROMPT'
Strategist question #09  (ticket-driven, group: PRD-TUI)

Reference: prd-tui
Category: observability
Horizon: Immediate
ROI: 4.7 (impact=7, confidence=0.76, effort=1)

Question:
Using the attached tickets as the primary context, define what logging/metrics must exist to debug pack generation + step execution; propose minimal instrumentation plan.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 10) ROI=4.5 impact=7 confidence=0.74 effort=2 horizon=Immediate category=observability reference=prd-tui

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = ".tickets"
TICKET_GLOB = "**/*.md"
TICKET_PATHS = ".tickets/PRD-TUI/Oraclepack TUI Integration.md,.tickets/PRD-TUI/PRD-generator URL routing.md".strip()
MAX = int("2")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
[TRUNCATED]
```

skills/oraclepack-pipeline-improver/assets/backlog-template.md
```
<!-- # path: oraclepack-pipeline-improver/assets/backlog-template.md -->
# Oraclepack Actionizer Backlog

Run:
- pack_id: TODO
- pack_hash: TODO
- generated_at: TODO

## Summary

- Total tasks: TODO
- Actionable: TODO
- Blocked: TODO
- Conflicts: TODO

## P0 (do first)

### <task_id> — <title>
- Status: actionable | blocked | conflict | noop
- Category: TODO
- Reference: TODO
- Expected artifacts: TODO
- Actions:
  - TODO
- Evidence:
  - Paths: TODO
  - Symbols: TODO
  - Commands: TODO
- Done when:
  - TODO

## P1

### <task_id> — <title>
- (same fields)

## Blocked / needs evidence

### <task_id> — <title>
- Missing inputs:
  - TODO
- Next smallest experiment (one action):
  - TODO

## Conflicts / needs resolution

### <task_id> — <title>
- Conflicting statements:
  - TODO
- What evidence resolves this:
  - TODO
- Proposed resolution (clearly marked as Proposed):
  - TODO
```

skills/oraclepack-pipeline-improver/assets/change-plan-template.md
```
<!-- # path: oraclepack-pipeline-improver/assets/change-plan-template.md -->
# Oraclepack Change Plan

Run:
- pack_id: TODO
- pack_hash: TODO
- generated_at: TODO

## Principles

- Smallest shippable increments first.
- Every step has an acceptance check.
- Unknowns are explicit; no guessing.

## Phase 0 — Guardrails (validate + safety)

1) Implement/confirm strict validation (validate --strict --json)
- Scope:
  - TODO
- Acceptance:
  - TODO (e.g., rejects non-20 packs; emits JSON summary)
- Tests:
  - TODO (fixtures for invalid packs)

2) Path safety for output writing
- Scope:
  - TODO
- Acceptance:
  - TODO (rejects .. traversal / absolute escape)
- Tests:
  - TODO

## Phase 1 — Deterministic runs (run dir + manifests + resume)

3) Stable run dir + run.json / steps.json
- Scope:
  - TODO
- Acceptance:
  - TODO (creates .oraclepack/runs/<pack_id>/..., stable naming)
- Tests:
  - TODO

4) Resume default + --rerun semantics
- Scope:
  - TODO
- Acceptance:
  - TODO (interrupt + rerun skips completed via hashes)
- Tests:
  - TODO

## Phase 2 — Reliability (concurrency + retries + optional caching)

5) Concurrency cap
- Scope:
  - TODO
- Acceptance:
  - TODO (never exceeds N parallel calls)

6) Retry/backoff on transient errors
- Scope:
  - TODO
- Acceptance:
  - TODO (bounded retries; recorded in steps.json)

7) Optional caching (if enabled)
- Scope:
  - TODO
- Acceptance:
  - TODO (unchanged inputs cause zero provider calls)

## Phase 3 — Actionizer (Stage 3)

8) Implement actionize command and artifacts
- Scope:
  - normalized.jsonl + backlog.md + change-plan.md
- Acceptance:
  - TODO (byte-identical output on rerun with unchanged inputs)

## CI integration (optional)

9) Add CI mode wiring (run --ci --non-interactive --json-log; actionize --ci)
- Policy thresholds:
  - TODO/Unknown
- Acceptance:
  - TODO (exit codes match policy)
```

skills/oraclepack-pipeline-improver/assets/normalized.example.jsonl
```
{"pack_id":"2026-01-05__nogit__deadbeef","pack_hash":"deadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeef","step_id":"07","task_id":"t_deadbeef_07_a1b2c3d4","title":"Define authorization boundary for server routes","status":"blocked","category":"permissions","reference":"src/server/auth/**","expected_artifacts":["src/server/auth/**","src/routes/**"],"actions":["Locate existing auth middleware/guards and document intended boundary","Add route guard checks or middleware wiring where missing"],"evidence":{"paths":["src/server/auth/**","src/routes/**"],"symbols":[],"commands":["ck --regex auth|permission|role src/server src/routes"]},"notes":["Auth wiring not evidenced in provided inputs"],"missing_inputs":["Repo paths containing current auth middleware or route guards (e.g., src/server/auth/**)","CLI help output for oraclepack validate/run/actionize (if already exists)"]}
{"pack_id":"2026-01-05__nogit__deadbeef","pack_hash":"deadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeef","step_id":"13","task_id":"t_deadbeef_13_e5f6a7b8","title":"Bound upload persistence metadata and retention policy","status":"actionable","category":"caching/state","reference":"src/server/persistence/sessionUploads.server.ts","expected_artifacts":["src/server/persistence/**","docs/plans/**"],"actions":["Add explicit retention policy + max entries/size controls","Ensure metadata captured is sufficient for downstream analysis"],"evidence":{"paths":["src/server/persistence/sessionUploads.server.ts"],"symbols":["saveSessionUpload"],"commands":["ck --regex saveSessionUpload src"]},"notes":[],"missing_inputs":[]}
```

skills/oraclepack-pipeline-improver/references/actionizer-spec.md
```
<!-- # path: oraclepack-pipeline-improver/references/actionizer-spec.md -->
# Stage 3 “Actionizer” spec (proposed)

Goal: deterministically convert the 20 outputs of a run into actionable engineering work artifacts, without duplicating work on reruns.

## Inputs

- `.oraclepack/runs/<pack_id>/run.json`
- `.oraclepack/runs/<pack_id>/steps.json`
- `.oraclepack/runs/<pack_id>/outputs/*`

## Processing pipeline (deterministic)

1) **Load** run + steps + outputs
- If any output is missing, mark that step as `missing_output` in normalization.

2) **Normalize** each step output into a stable record
- Extract (when present):
  - question metadata (QuestionId/Category/Reference/ExpectedArtifacts),
  - recommended actions,
  - evidence anchors (paths, symbols, commands),
  - unknowns / missing inputs.
- Classify:
  - `actionable` (clear tasks),
  - `blocked` (missing evidence prevents action),
  - `conflict` (contradictory requirements/answers),
  - `noop` (no action required).

3) **Deduplicate** tasks across steps
- Use stable task IDs derived from `pack_hash` + a stable task key (e.g., normalized title + target path).
- Reruns must produce byte-identical outputs when inputs unchanged.

4) **Generate** three core artifacts:
- `normalized.jsonl` (machine-readable records)
- `backlog.md` (human-prioritized tasks)
- `change-plan.md` (ordered implementation plan, smallest-first)

5) Optional exports:
- `github-issues.json` (issue objects; exact schema TODO/Unknown)
- `taskmaster.json` (taskmaster-style import; exact schema TODO/Unknown)

## Output files

### A) `actionizer/normalized.jsonl`

One JSON object per line.

**Proposed record fields:**
- `pack_id` (string)
- `pack_hash` (string)
- `step_id` (string `"01"`..`"20"`)
- `task_id` (string; stable)
- `title` (string)
- `status` (enum: `actionable` | `blocked` | `conflict` | `noop`)
- `category` (string | null)
- `reference` (string | null)
- `expected_artifacts` (string[] | null)
- `actions` (string[]) — concrete “do X” items
- `evidence` (object)
  - `paths` (string[])
  - `symbols` (string[])
  - `commands` (string[])
- `notes` (string[])
- `missing_inputs` (string[])

### B) `actionizer/backlog.md`

Use assets/backlog-template.md as the base.

Rules:
- Group by category (if present), else by subsystem (inferred from reference paths).
- Include blocked/conflict items explicitly with “what evidence is needed”.

### C) `actionizer/change-plan.md`

Use assets/change-plan-template.md as the base.

Rules:
- Ordered, smallest shippable increments first.
- Each step includes acceptance criteria and “done when…” checks.
- If CI gating thresholds exist, include them; else mark TODO.

## Handling blocked/conflict outputs

- `blocked` must include a **single next smallest experiment** (one action) to obtain missing evidence.
- `conflict` must include:
  - conflicting statements,
  - what file/path/log is needed to resolve,
  - a proposed resolution strategy (flagged as Proposed).

## Idempotency / stability requirements

- Stable IDs (required):
  - deterministic function of `pack_hash` + `step_id` + normalized title (or similar stable key).
- Reruns:
  - must not duplicate tasks,
  - must regenerate byte-identical artifacts if inputs unchanged.
```

skills/oraclepack-pipeline-improver/references/cli-contract.md
```
<!-- # path: oraclepack-pipeline-improver/references/cli-contract.md -->
# oraclepack CLI contract (proposed)

This document is the target CLI behavior to implement. If the current repo differs, treat that as **Observed** and this as **Proposed**.

## Commands

### 1) `oraclepack validate`

**Goal:** Deterministically validate a pack file and (optionally) emit machine-readable results.

**Proposed:**
- `oraclepack validate <pack.md> [--strict] [--json]`

**--strict checks (proposed minimum):**
- Exactly **20** oracle invocations.
- No schema drift vs expected pack format (**exact schema rules: TODO/Unknown** unless provided).
- Each question has required fields present (as enforceable in current schema; else **TODO**).
- Stable ordering checks (if applicable): ROI desc, effort asc (only if the pack uses those fields; else skip).

**--json output (proposed):**
- Print a single JSON object to stdout (or to a specified file if supported; **TODO**).
- Include `ok: boolean`, `errors: []`, `warnings: []`, and per-question metadata when parseable.

### 2) `oraclepack run`

**Goal:** Execute the 20 steps into a deterministic run directory with resumable semantics.

**Proposed:**
- `oraclepack run <pack.md> [--max-parallel N] [--resume] [--rerun all|failed|01,03,07] [--ci] [--non-interactive] [--json-log]`

**Run dir (proposed):**
- Create: `.oraclepack/runs/<pack_id>/`
- Emit at least:
  - `.oraclepack/runs/<pack_id>/run.json`
  - `.oraclepack/runs/<pack_id>/steps.json`
  - `.oraclepack/runs/<pack_id>/outputs/` (20 files; naming convention below)
  - `.oraclepack/runs/<pack_id>/logs/` (optional)

**pack_id (proposed):**
- `YYYY-MM-DD__<gitshort>__<packhash8>`
- If git SHA unavailable: use `nogit` for `<gitshort>`.

**Output naming (proposed):**
- Prefer deterministic: `outputs/01.md` ... `outputs/20.md`
- If a stable QuestionId exists: optionally include in filename, but do not break determinism.

**Resume/rerun (proposed):**
- Resume is default if the run dir already exists:
  - skip steps already marked `ok` with matching output hash.
- `--rerun failed` reruns only failed steps.
- `--rerun all` reruns all steps.
- `--rerun 01,03,07` reruns specified step IDs.

**Concurrency (proposed):**
- `--max-parallel N` bounds parallel provider calls.
- Optional: per-provider caps via config (**TODO/Unknown**: config format).

**Transient errors (proposed):**
- Implement exponential backoff + jitter on retryable errors (e.g., 429/503) up to a retry budget.
- Persist retry counts/outcomes into `steps.json`.

### 3) `oraclepack actionize`

**Goal:** Convert run outputs into actionable engineering work artifacts.

**Proposed:**
- `oraclepack actionize --run-dir .oraclepack/runs/<pack_id> [--ci]`

**Inputs:**
- `run.json`, `steps.json`
- `outputs/` (20 outputs)

**Outputs:**
- `.oraclepack/runs/<pack_id>/actionizer/normalized.jsonl`
- `.oraclepack/runs/<pack_id>/actionizer/backlog.md`
- `.oraclepack/runs/<pack_id>/actionizer/change-plan.md`
- Optional:
  - `.oraclepack/runs/<pack_id>/actionizer/github-issues.json`
  - `.oraclepack/runs/<pack_id>/actionizer/taskmaster.json`

## CI mode (proposed)

- `oraclepack run --ci --non-interactive --json-log`
- `oraclepack actionize --ci`

**Behavior (proposed):**
- No TUI interaction.
- Structured logs enabled (JSONL or JSON objects; **TODO/Unknown** exact format).
- Exit codes are policy-driven:
  - validation failures → non-zero
  - run failures exceeding retry budget → non-zero
  - optional policy thresholds (completion rate, action yield) → **TODO/Unknown** threshold values.

## Security / path safety (proposed)

- Prevent any output flag (including legacy `--write-output` if present) from writing outside the intended run directory.
- Reject path traversal (e.g., `..`) and absolute paths when writing within `.oraclepack/runs/<pack_id>/...`.
```

skills/oraclepack-pipeline-improver/references/run-manifest-spec.md
```
<!-- # path: oraclepack-pipeline-improver/references/run-manifest-spec.md -->
# Run manifest spec (proposed)

This defines the minimum content for run artifacts to enable traceability, resume/rerun, and Stage 3 processing.

## `.oraclepack/runs/<pack_id>/run.json`

**Required fields (proposed minimum):**
- `pack_id` (string)
- `pack_path` (string)
- `pack_hash` (string; full hash)
- `created_at` (RFC3339 string)
- `git_sha` (string | null)
- `oraclepack_version` (string | TODO if not available)
- `oracle_version` (string | TODO if not available)
- `max_parallel` (number | null)
- `ci` (boolean)
- `providers` (object | TODO if not available)
- `models` (object | TODO if not available)

**Notes:**
- If any value cannot be derived, set it to `null` and record a `warnings[]` entry rather than inventing it.

## `.oraclepack/runs/<pack_id>/steps.json`

Represent steps as an array of 20 items ordered by `step_id`.

**Per-step fields (proposed minimum):**
- `step_id` (string `"01"`..`"20"`)
- `question_id` (string | null) — if present in the pack/prompt metadata
- `category` (string | null)
- `reference` (string | null)
- `invocation_hash` (string) — hash of canonical invocation inputs (prompt + attachments + provider/model knobs)
- `output_path` (string)
- `output_hash` (string | null)
- `status` (enum: `pending` | `ok` | `failed` | `skipped`)
- `attempts` (number)
- `last_error` (string | null)
- `started_at` (RFC3339 string | null)
- `finished_at` (RFC3339 string | null)

## Hashing (proposed)

### `pack_hash`
- Compute from a canonical representation of the pack file:
  - normalize line endings,
  - remove non-semantic whitespace if safe (TODO/Unknown: exact pack grammar),
  - hash the resulting bytes.

### `invocation_hash`
- Compute from:
  - prompt text (including embedded mini-metadata),
  - attachment file contents (hash of contents, not just paths),
  - provider + model identifiers,
  - deterministic knobs (temperature, etc.) if applicable.

If attachment content hashing cannot be performed, record **Unknown/TODO** and do not enable caching based on incomplete inputs.
```

skills/oraclepack-pipeline-improver/references/stage1-prompt-metadata.md
```
<!-- # path: oraclepack-pipeline-improver/references/stage1-prompt-metadata.md -->
# Stage 1 prompt-embedded metadata (proposed)

Goal: improve downstream parsing for Stage 2/3 without changing the oracle pack schema.

## Constraints

- Do not change the pack’s structural schema unless an explicit migration path is provided.
- Embed metadata inside the prompt text (the `-p` payload) in a parseable, consistent format.

## Recommended metadata block (inside the prompt)

Add at the *very top* of each prompt:

```

[oraclepack-meta]
QuestionId: 07
Category: permissions
Reference: src/server/auth/middleware.ts
ExpectedArtifacts:

* src/server/auth/**
* docs/plans/...
  [/oraclepack-meta]

```

## Parsing rules (deterministic)

- The block starts with `[oraclepack-meta]` and ends with `[/oraclepack-meta]`.
- Keys are case-sensitive as shown.
- Multi-line lists are allowed for `ExpectedArtifacts`.
- If any key is missing, treat it as `null` and continue.

## Minimal required keys (recommended)

- QuestionId
- Category
- Reference
- ExpectedArtifacts (optional but recommended)

If the Stage 1 generator cannot produce these, it should write `Unknown` values explicitly rather than omitting keys.
```

skills/oraclepack-tickets-pack-common/scripts/validate_pack.py
```
import argparse
import re
import sys
from dataclasses import dataclass
from pathlib import Path, PurePosixPath
from typing import Dict, List, Tuple

ALLOWED_CATEGORIES = [
    "contracts/interfaces",
    "invariants",
    "caching/state",
    "background jobs",
    "observability",
    "permissions",
    "migrations",
    "UX flows",
    "failure modes",
    "feature flags",
]

REQUIRED_HEADER_KEYS = [
    "ROI",
    "impact",
    "confidence",
    "effort",
    "horizon",
    "category",
    "reference",
]


@dataclass(frozen=True)
class Step:
    n: str
    header_line: str
    block_lines: List[str]


def _fail(errors: List[str]) -> None:
    for e in errors:
        print(f"[ERROR] {e}", file=sys.stderr)
    sys.exit(1)


def _read_text(path: Path) -> str:
    return path.read_text(encoding="utf-8", errors="replace")


def _extract_single_bash_fence(lines: List[str]) -> Tuple[int, int, List[str], List[str]]:
    start = None
    for i, ln in enumerate(lines):
        if ln.strip().lower() == "```bash":
            if start is not None:
                raise ValueError("Multiple ```bash fences found; expected exactly one.")
            start = i

    if start is None:
        raise ValueError("No ```bash fence found; expected exactly one.")

    end = None
    for i in range(start + 1, len(lines)):
        if lines[i].strip() == "```":
            end = i
            break

    if end is None:
        raise ValueError("No closing ``` found for the ```bash fence.")

    fence_lines = [ln.rstrip("\n") for ln in lines[start + 1 : end]]
    outside_lines = [ln.rstrip("\n") for i, ln in enumerate(lines) if i < start or i > end]
    return start, end, fence_lines, outside_lines


def _parse_steps(fence_lines: List[str]) -> List[Step]:
    header_re = re.compile(r"^#\s*(\d{2})\)\s+")
    header_idxs: List[Tuple[int, str]] = []
    for i, ln in enumerate(fence_lines):
        m = header_re.match(ln)
        if m:
            header_idxs.append((i, m.group(1)))

    if not header_idxs:
        raise ValueError("No step headers found inside bash fence.")

    steps: List[Step] = []
    for idx, (start_i, n) in enumerate(header_idxs):
        end_i = header_idxs[idx + 1][0] if idx + 1 < len(header_idxs) else len(fence_lines)
        block = fence_lines[start_i:end_i]
        steps.append(Step(n=n, header_line=block[0], block_lines=block))
    return steps


def _parse_header_kv(header_line: str) -> Dict[str, str]:
    out: Dict[str, str] = {}
    tokens = header_line.strip().split()
    i = 0
    while i < len(tokens):
        tok = tokens[i]
        if "=" not in tok:
            i += 1
            continue
        key, val = tok.split("=", 1)
        if key in REQUIRED_HEADER_KEYS:
            if key == "category" and i + 1 < len(tokens):
                # Allow two-word categories like "background jobs" in headers.
                nxt = tokens[i + 1]
                if (val, nxt) in {
                    ("background", "jobs"),
                    ("UX", "flows"),
                    ("failure", "modes"),
                    ("feature", "flags"),
                }:
                    val = f"{val} {nxt}"
            out[key] = val
        i += 1
    return out


def _validate_header(step: Step, errors: List[str]) -> None:
    m = re.match(r"^#\s*(\d{2})\)\s+", step.header_line)
    if not m:
        errors.append(f"Step {step.n}: invalid header format (expected '# NN) ...').")
        return
    if m.group(1) != step.n:
        errors.append(f"Step {step.n}: header number mismatch (found {m.group(1)}).")

    kv = _parse_header_kv(step.header_line)
    for req in REQUIRED_HEADER_KEYS:
        if req not in kv:
            errors.append(f"Step {step.n}: header missing required token {req}=...")

    cat = kv.get("category")
    if cat is not None and cat not in ALLOWED_CATEGORIES:
        errors.append(
            f"Step {step.n}: category must be one of {ALLOWED_CATEGORIES}; got '{cat}'."
        )


def _validate_write_output(step: Step, errors: List[str]) -> None:
    joined = "\n".join(step.block_lines)

    m = re.search(r'(?<!\S)--write-output(?!\S)\s+"([^"]+)"', joined)
    if not m:
        errors.append(f"Step {step.n}: missing --write-output \"...\".")
        return

    out_path = m.group(1)
    if out_path.startswith("/") or out_path.startswith("~"):
        errors.append(f"Step {step.n}: --write-output must not be absolute: {out_path}")
        return

    p = PurePosixPath(out_path)
    if any(part == ".." for part in p.parts):
        errors.append(f"Step {step.n}: --write-output must not contain '..': {out_path}")

    if re.search(rf"(^|/){re.escape(step.n)}-", out_path) is None:
        errors.append(f"Step {step.n}: --write-output must include '{step.n}-' in filename: {out_path}")

    if not out_path.endswith(".md"):
        errors.append(f"Step {step.n}: --write-output must end with .md: {out_path}")


def _validate_ticket_bundle_reference(step: Step, errors: List[str]) -> None:
    joined = "\n".join(step.block_lines)

    if "_tickets_bundle" not in joined:
        errors.append(
            f"Step {step.n}: must reference the ticket bundle (expected '_tickets_bundle' in step block)."
        )

    if re.search(r'(?<!\S)(-f|--file)(?!\S)\s+"[^"\n]*_tickets_bundle[^"\n]*"', joined) is None:
        errors.append(
            f"Step {step.n}: must attach the ticket bundle via -f/--file \"..._tickets_bundle...\"."
        )


def _validate_answer_format(step: Step, errors: List[str]) -> None:
    hay = "\n".join(step.block_lines).lower()
    required = [
        "answer format:",
        "direct answer",
        "risks/unknowns",
        "next smallest concrete experiment",
        "if evidence is insufficient",
        "missing file/path pattern",
    ]
    missing = [s for s in required if s not in hay]
    if missing:
        errors.append(f"Step {step.n}: prompt missing required Answer format components: {missing}")


def _validate_category_counts(steps: List[Step], errors: List[str]) -> None:
    counts: Dict[str, List[str]] = {c: [] for c in ALLOWED_CATEGORIES}
    for st in steps:
        kv = _parse_header_kv(st.header_line)
        cat = kv.get("category")
        if cat in counts:
            counts[cat].append(st.n)

    bad = []
    for cat, ids in counts.items():
        if len(ids) != 2:
            bad.append(f"{cat}={len(ids)} (steps={ids})")
    if bad:
        errors.append(
            "Category distribution must be exactly 2 steps per category (20 total). Problems: "
            + ", ".join(bad)
        )


def _validate_step_numbers(steps: List[Step], errors: List[str]) -> None:
    nums = [st.n for st in steps]
    if nums != [f"{i:02d}" for i in range(1, 21)]:
        errors.append(f"Step numbering must be 01..20 in order; got {nums}.")


def _validate_coverage_check(outside_lines: List[str], errors: List[str]) -> None:
    text = "\n".join(outside_lines)
    m = re.search(r"^##\s+Coverage check\s*$", text, flags=re.IGNORECASE | re.MULTILINE)
    if m is None:
        errors.append('Missing "## Coverage check" section (must be outside the bash fence).')
        return

    after = text[m.end() :]
    for cat in ALLOWED_CATEGORIES:
        pat = rf"^\s*[-*]\s+{re.escape(cat)}\s*:\s*(OK|Missing\([^)]*\))\s*$"
        if re.search(pat, after, flags=re.MULTILINE) is None:
            errors.append(f'Coverage check missing/invalid line for category: "{cat}"')


def _validate_bash_hazards(step: Step, errors: List[str]) -> None:
    lines = step.block_lines[1:]
    for i, ln in enumerate(lines):
        s = ln.strip()

        if s == "\\":
            errors.append(f"Step {step.n}: contains a bare '\\\\' line (orphan backslash).")

        if s.startswith("#"):
            j = i - 1
            while j >= 0 and not lines[j].strip():
                j -= 1
            if j >= 0 and lines[j].rstrip().endswith("\\"):
                errors.append(
                    f"Step {step.n}: comment line appears immediately after a '\\'-continued line (comment-in-continuation hazard)."
                )

        if s.startswith("-p "):
            j = i - 1
            while j >= 0 and not lines[j].strip():
                j -= 1
            if j < 0 or not lines[j].rstrip().endswith("\\"):
                errors.append(
                    f"Step {step.n}: '-p ...' line is not attached to a continued command (detached -p hazard)."
                )


def validate_pack(path: Path, require_bundle: bool) -> None:
    raw = _read_text(path)
    lines = raw.splitlines(True)

    errors: List[str] = []

    try:
        _start, _end, fence, outside = _extract_single_bash_fence(lines)
    except Exception as e:
        _fail([str(e)])

    steps = _parse_steps(fence)

    if len(steps) != 20:
        errors.append(f"Expected exactly 20 steps; found {len(steps)}.")
    else:
        _validate_step_numbers(steps, errors)

    for step in steps:
        _validate_header(step, errors)
        _validate_write_output(step, errors)
        _validate_answer_format(step, errors)
        _validate_bash_hazards(step, errors)
        if require_bundle:
            _validate_ticket_bundle_reference(step, errors)

    _validate_category_counts(steps, errors)
    _validate_coverage_check(outside, errors)

    if errors:
        _fail(errors)

    print("[OK] Pack validates against tickets Stage-1 contract.")


def main() -> None:
    p = argparse.ArgumentParser(description="Validate oraclepack Stage-1 ticket packs.")
    p.add_argument("pack_path", help="Path to the Markdown pack file")
    p.add_argument(
        "--mode",
        choices=["bundle", "direct"],
        default="direct",
        help="Validation mode: bundle requires _tickets_bundle attachments",
    )
    args = p.parse_args()

    path = Path(args.pack_path)
    if not path.exists():
        _fail([f"File not found: {path}"])

    validate_pack(path, require_bundle=args.mode == "bundle")


if __name__ == "__main__":
    main()
```

skills/oraclepack-tickets-pack/references/attachment-minimization.md
```
# Attachment minimization rules (Tickets Stage 1 packs)

Objective: keep oracle calls fast, portable, and deterministic by attaching the minimum evidence per step.

## Hard limits

- Default **native attachments**: **0–2 per step** (`-f/--file`).
- In tickets packs, the ticket bundle (`ticket_bundle_path`) is typically **the first native attachment**.
- If you need more than 2 native attachments, the step is not scoped tightly enough: split or reduce.

## extra_files (literal append)

- If `extra_files` is provided, it must be appended **literally** to every oracle command.
- It may contain additional `-f/--file` flags.
- To keep linting reliable and preserve the “native attachments ≤2” rule:
  - place `extra_files` on its own line in each command,
  - preceded by a comment line containing: `extra_files appended literally`.

This lets `scripts/lint_attachments.py` treat that line as “extra” and not part of the native attachment count.

## What to attach (rule of thumb)

For each step, prefer:
1) Ticket bundle: `-f "<ticket_bundle_path>"`
2) One repo file that best supports the question:
   - a definition/contract file (types, schemas, CLI/TUI surface), OR
   - a use-site/enforcement file

If you can’t pick confidently:
- attach only the ticket bundle
- set `reference=Unknown`
- ensure the prompt requests the exact missing file/path pattern(s) to attach next

## Avoid these attachment anti-patterns

- Attaching entire directories when one file is enough.
- Attaching duplicates.
- Attaching generated/lock files unless the ticket explicitly requires it.
- Attaching secrets.
```

skills/oraclepack-tickets-pack/references/ticket-bundling.md
```
# Ticket bundling (deterministic)

Objective: create a single Markdown file (`ticket_bundle_path`) that provides stable, minimal, high-signal context for all 20 oracle steps.

## Inputs

- `ticket_root` (default `.tickets`)
- `ticket_glob` (default `**/*.md`, relative to `ticket_root`)
- `ticket_paths` (optional; comma-separated explicit files; if present, ignore `ticket_glob`)
- `ticket_bundle_path` (default `<out_dir>/_tickets_bundle.md`)

## Deterministic selection rules

1) If `ticket_paths` is non-empty:
- Split on commas, trim whitespace.
- Use that list exactly.
- Sort lexicographically by path string.

2) Else:
- If `ticket_root` does not exist: select nothing.
- Glob `ticket_root/ticket_glob`.
- Sort lexicographically by path string.

Hard rule: do not use timestamps, mtimes, file sizes, or “newest” semantics.

## Bundle format

The bundle should include:

1) Header:
- codebase name (if available)
- the selection rules and resolved values:
  - ticket_root, ticket_glob, ticket_paths (or “(none)”)
  - ordering: lexicographic by path

2) Per-ticket sections (in lex order):
- ticket title (best-effort):
  - first Markdown heading (`# ...`) if present, else first non-empty line, else “Untitled”
- ticket path
- key sections or excerpt:
  - if ticket content is small, include full content
  - otherwise include common sections when present (examples):
    - Description / Context / Problem
    - Proposal / Solution
    - Acceptance Criteria
    - Repro steps / Expected / Actual
    - Notes / Links
  - and include a “[... truncated ...]” marker when partial

## Failure handling requirements

If `ticket_root` is missing OR no tickets matched:
- Still create `ticket_bundle_path`.
- Include a **WARNING** section explaining:
  - what was attempted (root + glob or explicit paths)
  - that the bundle is empty
  - that Step 01 should request which ticket paths to attach next (exact missing file/path pattern(s))

## Why bundling exists

- Ensures every step uses the same primary evidence.
- Reduces per-step attachments (bundle is 1 attachment).
- Improves determinism and portability of oracle calls.
```

skills/oraclepack-tickets-pack/references/tickets-pack-template.md
```
# Oracle Pack — {{codebase_name}} (Tickets Stage 1)

## Parsed args
- codebase_name: {{codebase_name}}
- out_dir: {{out_dir}}
- oracle_cmd: {{oracle_cmd}}
- oracle_flags: {{oracle_flags}}
- extra_files: {{extra_files}}
- ticket_root: {{ticket_root}}
- ticket_glob: {{ticket_glob}}
- ticket_paths: {{ticket_paths}}
- ticket_bundle_path: {{ticket_bundle_path}}
- mode: {{mode}}

Notes (contract):
- Exactly one fenced `bash` block in this document.
- No other ``` fences anywhere.
- Exactly 20 steps, numbered 01..20 in order.
- Step header: `# NN) ROI=... impact=... confidence=... effort=... horizon=... category=... reference=...`
- Every step includes: `--write-output "{{out_dir}}/NN-<slug>.md"` (double quotes required).
- Steps must be self-contained and must not rely on shell variables created in previous steps.
- Pack ends with a Coverage check section listing all 10 categories as OK or Missing(<step ids>).

```bash
# Prelude (allowed inside the single bash fence)
# - Creates out_dir deterministically
# - Builds ticket_bundle_path deterministically from ticket_root/ticket_glob OR ticket_paths
# - Uses lexicographic ordering only (no mtime/timestamps)

set -euo pipefail

mkdir -p "{{out_dir}}"

python3 - <<'PY'
from __future__ import annotations

import os
from pathlib import Path

CODEBASE_NAME = "{{codebase_name}}"
OUT_DIR = "{{out_dir}}"
TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
BUNDLE_PATH = "{{ticket_bundle_path}}"

root = Path(TICKET_ROOT)

def read_text(p: Path) -> str:
    try:
        return p.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return p.read_text(encoding="utf-8", errors="replace")

def title_from_md(text: str) -> str:
    for ln in text.splitlines():
        s = ln.strip()
        if s.startswith("#"):
            return s.lstrip("#").strip()[:160] or "Untitled"
    for ln in text.splitlines():
        s = ln.strip()
        if s:
            return s[:160]
    return "Untitled"

def select_key_sections(text: str) -> str:
    # Heuristic: if small, include all; else include common ticket sections + top excerpt.
    lines = text.splitlines()
    if len(text) <= 8000 and len(lines) <= 250:
        return text

    keep = []
    wanted = {"description", "context", "problem", "proposal", "solution", "acceptance criteria", "ac", "steps", "repro", "expected", "actual", "notes", "links"}
    i = 0
    while i < len(lines):
        ln = lines[i]
        s = ln.strip()
        if s.startswith("##"):
            hdr = s.lstrip("#").strip().lower()
            if hdr in wanted:
                keep.append(ln)
                i += 1
                # capture until next heading
                while i < len(lines) and not lines[i].lstrip().startswith("#"):
                    keep.append(lines[i])
                    i += 1
                continue
        i += 1

    # Fallback excerpt if no sections matched
    if not any(l.strip() for l in keep):
        excerpt = "\n".join(lines[:200])
        return excerpt + "\n\n[... truncated ...]\n"
    return "\n".join(keep) + "\n\n[... truncated ...]\n"

def resolve_ticket_files() -> list[Path]:
    if TICKET_PATHS:
        items = [p.strip() for p in TICKET_PATHS.split(",") if p.strip()]
        return sorted([Path(p) for p in items], key=lambda p: str(p))
    if not root.exists():
        return []
    return sorted(list(root.glob(TICKET_GLOB)), key=lambda p: str(p))

tickets = resolve_ticket_files()

bundle_lines = []
bundle_lines.append(f"# Tickets bundle — {CODEBASE_NAME}")
bundle_lines.append("")
bundle_lines.append("## Selection rules (deterministic)")
bundle_lines.append(f"- ticket_root: {TICKET_ROOT}")
bundle_lines.append(f"- ticket_glob: {TICKET_GLOB}")
bundle_lines.append(f"- ticket_paths: {TICKET_PATHS or '(none)'}")
bundle_lines.append("- ordering: lexicographic by path")
bundle_lines.append("")

if not tickets:
    bundle_lines.append("## WARNING")
    if TICKET_PATHS:
        bundle_lines.append("- No tickets were found from ticket_paths (check paths).")
    else:
        bundle_lines.append("- ticket_root missing or no tickets matched the glob.")
    bundle_lines.append("- This bundle is empty; Step 01 should request which ticket paths to attach next.")
    bundle_lines.append("")

for p in tickets:
    try:
        txt = read_text(p)
    except Exception as e:
        txt = f"[ERROR reading file: {e}]"
    title = title_from_md(txt)
    body = select_key_sections(txt)
    bundle_lines.append(f"## {title}")
    bundle_lines.append(f"- path: {p}")
    bundle_lines.append("")
    bundle_lines.append(body)
    bundle_lines.append("")
    bundle_lines.append("---")
    bundle_lines.append("")

out_path = Path(BUNDLE_PATH)
out_path.parent.mkdir(parents=True, exist_ok=True)
out_path.write_text("\n".join(bundle_lines).rstrip() + "\n", encoding="utf-8")

print(f"OK: wrote ticket bundle: {out_path}")
PY

# 01) ROI=4.8 impact=6 confidence=0.80 effort=1 horizon=Immediate category=contracts/interfaces reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/01-contracts-interfaces-ticket-surface.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #01  (ticket-driven)

Reference: Unknown
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.8 (impact=6, confidence=0.80, effort=1)

Question:
Using the ticket bundle as the primary context, list the public surface changes implied by the tickets (CLI/TUI/API/interfaces/contracts). For each implied change:
- describe the new/changed interface shape
- identify the most likely code areas involved
- call out any backwards-compatibility constraints that must be preserved.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 02) ROI=4.6 impact=6 confidence=0.78 effort=1 horizon=Immediate category=contracts/interfaces reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/02-contracts-interfaces-integration-points.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #02  (ticket-driven)

Reference: Unknown
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.6 (impact=6, confidence=0.78, effort=1)

Question:
Using the ticket bundle as the primary context, identify any external integrations implied by the tickets (e.g., calling new agents/tools, new CLIs, new services). For each:
- what contract/config must be added or changed?
- what failure/timeout behavior should be defined?
- what should be the minimal “compat-safe” rollout approach?

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 03) ROI=5.2 impact=7 confidence=0.75 effort=2 horizon=NearTerm category=invariants reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/03-invariants-correctness-guardrails.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #03  (ticket-driven)

Reference: Unknown
Category: invariants
Horizon: NearTerm
ROI: 5.2 (impact=7, confidence=0.75, effort=2)

Question:
From the tickets, derive the key correctness invariants that must hold while implementing them (e.g., “runner-ingestible pack constraints”, “no schema drift”, “no unsafe paths”). For each invariant:
- define it precisely
- state how to enforce it (validation, linting, runtime checks)
- identify where it should live in the codebase (by file/path patterns if evidence is missing).

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 04) ROI=5.0 impact=7 confidence=0.72 effort=2 horizon=NearTerm category=invariants reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/04-invariants-validation-boundaries.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #04  (ticket-driven)

Reference: Unknown
Category: invariants
Horizon: NearTerm
ROI: 5.0 (impact=7, confidence=0.72, effort=2)

Question:
Using the tickets, identify validation boundaries that must exist (ticket parsing, pack generation, pack validation). Where could invalid inputs slip through (missing tickets, malformed headers, extra fences)? Propose a minimal validation plan that preserves backward compatibility.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 05) ROI=4.4 impact=6 confidence=0.78 effort=2 horizon=NearTerm category=caching/state reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/05-caching-state-ticket-artifacts.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #05  (ticket-driven)

Reference: Unknown
Category: caching/state
Horizon: NearTerm
ROI: 4.4 (impact=6, confidence=0.78, effort=2)

Question:
Based on the tickets, what state/artifacts must be produced and preserved (ticket bundle, generated pack, validator outputs, runner outputs)? Identify any schema/format expectations that must remain backward compatible and how to keep them stable.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 06) ROI=4.1 impact=5 confidence=0.80 effort=2 horizon=NearTerm category=caching/state reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/06-caching-state-determinism-consistency.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #06  (ticket-driven)

Reference: Unknown
Category: caching/state
Horizon: NearTerm
ROI: 4.1 (impact=5, confidence=0.80, effort=2)

Question:
Using the tickets, identify determinism risks (non-deterministic ticket selection, unstable ordering, environment-dependent paths). Propose a minimal deterministic selection and bundling approach and how to test it.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 07) ROI=3.6 impact=5 confidence=0.70 effort=3 horizon=NearTerm category=background jobs reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/07-background-jobs-ticket-implications.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #07  (ticket-driven)

Reference: Unknown
Category: background jobs
Horizon: NearTerm
ROI: 3.6 (impact=5, confidence=0.70, effort=3)

Question:
Do any tickets imply background processing, worker modes, scheduled validation, or CI pipelines (e.g., generating packs from tickets in CI)? If yes, define:
- trigger mechanism
- inputs/outputs
- retries/idempotency constraints
If no, explicitly confirm based on the ticket bundle.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 08) ROI=3.9 impact=5 confidence=0.72 effort=3 horizon=NearTerm category=background jobs reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/08-background-jobs-reliability-controls.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #08  (ticket-driven)

Reference: Unknown
Category: background jobs
Horizon: NearTerm
ROI: 3.9 (impact=5, confidence=0.72, effort=3)

Question:
If tickets imply background/CI execution, what reliability controls are required (concurrency limits, backoff, reprocessing, artifact retention)? Tie each control to a specific ticket requirement and suggest minimal implementation points.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 09) ROI=4.7 impact=6 confidence=0.82 effort=2 horizon=Immediate category=observability reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/09-observability-required-signals.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #09  (ticket-driven)

Reference: Unknown
Category: observability
Horizon: Immediate
ROI: 4.7 (impact=6, confidence=0.82, effort=2)

Question:
From the tickets, define the minimum observability required for implementing and operating ticketed changes (logs, warnings, structured outputs, correlation/run IDs). What signals must be emitted on:
- missing tickets
- validation failures
- unsafe path detection
- runner ingestion failures?

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 10) ROI=4.5 impact=6 confidence=0.80 effort=2 horizon=Immediate category=observability reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/10-observability-gaps-and-metrics.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #10  (ticket-driven)

Reference: Unknown
Category: observability
Horizon: Immediate
ROI: 4.5 (impact=6, confidence=0.80, effort=2)

Question:
Using the ticket bundle, identify observability gaps that would block shipping the ticketed work safely (missing structured errors, missing per-step diagnostics, missing coverage/mismatch reporting). Recommend the smallest additions with high debugging value.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 11) ROI=5.0 impact=7 confidence=0.76 effort=2 horizon=Immediate category=permissions reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/11-permissions-security-constraints.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #11  (ticket-driven)

Reference: Unknown
Category: permissions
Horizon: Immediate
ROI: 5.0 (impact=7, confidence=0.76, effort=2)

Question:
From the tickets, determine what security/permissions constraints must exist (e.g., exec gating, tool invocation restrictions, file access restrictions, safe write paths). Define “who can do what” minimally and where enforcement should live.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 12) ROI=4.8 impact=7 confidence=0.74 effort=2 horizon=Immediate category=permissions reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/12-permissions-enforcement-chokepoints.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #12  (ticket-driven)

Reference: Unknown
Category: permissions
Horizon: Immediate
ROI: 4.8 (impact=7, confidence=0.74, effort=2)

Question:
Using the tickets, identify where permissions must be enforced (CLI command gating, TUI actions, runner execution, filesystem writes). Call out bypass risks and propose the minimal enforcement chokepoints and tests.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 13) ROI=4.2 impact=6 confidence=0.72 effort=3 horizon=NearTerm category=migrations reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/13-migrations-schema-changes.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #13  (ticket-driven)

Reference: Unknown
Category: migrations
Horizon: NearTerm
ROI: 4.2 (impact=6, confidence=0.72, effort=3)

Question:
Do tickets imply schema/version changes (pack schema, state/report schema, actions artifacts)? Identify what can change vs must remain backward-compatible, and propose a minimal migration strategy (if any).

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 14) ROI=4.0 impact=6 confidence=0.70 effort=3 horizon=NearTerm category=migrations reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/14-migrations-compat-guardrails.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #14  (ticket-driven)

Reference: Unknown
Category: migrations
Horizon: NearTerm
ROI: 4.0 (impact=6, confidence=0.70, effort=3)

Question:
Using the ticket bundle, define the compatibility expectations (backward/forward, rolling upgrades, mixed versions). Where are the risky edges, and what guardrails/tests should be required before shipping ticketed changes?

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 15) ROI=4.6 impact=6 confidence=0.80 effort=2 horizon=NearTerm category=UX flows reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/15-ux-flows-ticketed-user-journeys.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #15  (ticket-driven)

Reference: Unknown
Category: UX flows
Horizon: NearTerm
ROI: 4.6 (impact=6, confidence=0.80, effort=2)

Question:
From the ticket bundle, identify which user/operator flows are affected (TUI flows, CLI flows, non-interactive mode). For each flow:
- outline steps and state transitions
- identify key UX requirements implied by tickets
- call out compatibility constraints with existing workflows.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

[TRUNCATED]
```

skills/oraclepack-tickets-pack/scripts/lint_attachments.py
```
import argparse
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple


@dataclass
class Step:
    n: str
    header: str
    lines: List[str]


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return path.read_text(encoding="utf-8", errors="replace")


def _extract_bash_fence(lines: List[str]) -> List[str]:
    fence_idxs = [i for i, ln in enumerate(lines) if ln.startswith("```")]
    if len(fence_idxs) != 2:
        raise ValueError(f"Expected exactly one fenced block (2 fence lines). Found {len(fence_idxs)}.")
    open_i, close_i = fence_idxs
    if lines[open_i].rstrip("\n") != "```bash":
        raise ValueError("Opening fence must be exactly ```bash.")
    if lines[close_i].rstrip("\n") != "```":
        raise ValueError("Closing fence must be exactly ```.")
    return [ln.rstrip("\n") for ln in lines[open_i + 1 : close_i]]


def _parse_steps(fence_lines: List[str]) -> List[Step]:
    header_re = re.compile(r"^#\s*(\d{2})\)\s+")
    header_idxs: List[Tuple[int, str]] = []
    for i, ln in enumerate(fence_lines):
        m = header_re.match(ln)
        if m:
            header_idxs.append((i, m.group(1)))

    if not header_idxs:
        raise ValueError("No step headers found inside bash fence.")

    steps: List[Step] = []
    for idx, (start_i, n) in enumerate(header_idxs):
        end_i = header_idxs[idx + 1][0] if idx + 1 < len(header_idxs) else len(fence_lines)
        block = fence_lines[start_i:end_i]
        steps.append(Step(n=n, header=block[0], lines=block))
    return steps


def _count_native_attachments(step: Step) -> int:
    """
    Counts -f/--file occurrences excluding:
      - comment lines
      - the literal extra_files line (immediately following the marker comment)
    """
    count = 0
    ignore_next_nonempty = False

    for ln in step.lines[1:]:
        s = ln.strip()
        if not s:
            continue

        # Detect extra_files marker comment; ignore next non-empty line.
        if s.startswith("#") and "extra_files appended literally" in s.lower():
            ignore_next_nonempty = True
            continue

        if ignore_next_nonempty:
            # Skip counting attachments on the extra_files line itself.
            ignore_next_nonempty = False
            continue

        if s.startswith("#"):
            continue

        count += len(re.findall(r"(?<!\S)(-f|--file)(?!\S)", ln))
    return count

def lint(path: Path) -> None:
    raw = _read_text(path)
    lines = raw.splitlines(True)
    fence = _extract_bash_fence(lines)
    steps = _parse_steps(fence)

    errors: List[str] = []
    for step in steps:
        native = _count_native_attachments(step)
        if native > 2:
            errors.append(
                f"Step {step.n}: has {native} native attachments; must be <= 2 (ticket bundle + at most one repo file)."
            )

    if errors:
        for e in errors:
            print(f"[ERROR] {e}", file=sys.stderr)
        sys.exit(1)

    print("[OK] Attachment lint passed (native attachments <= 2 per step; extra_files line excluded).")

def main() -> None:
    p = argparse.ArgumentParser(
        description="Lint ticket-driven oraclepack Stage-1 packs for native attachments (<=2 per step, excluding literal extra_files line)."
    )
    p.add_argument("pack_path", help="Path to the Markdown pack file")
    args = p.parse_args()

    path = Path(args.pack_path)
    if not path.exists():
        print(f"[ERROR] File not found: {path}", file=sys.stderr)
        sys.exit(1)

    lint(path)


if __name__ == "__main__":
    main()
```

skills/oraclepack-tickets-pack/scripts/validate_pack.py
```
import argparse
import re
import sys
from dataclasses import dataclass
from pathlib import Path, PurePosixPath
from typing import Dict, List, Tuple


ALLOWED_CATEGORIES = [
    "contracts/interfaces",
    "invariants",
    "caching/state",
    "background jobs",
    "observability",
    "permissions",
    "migrations",
    "UX flows",
    "failure modes",
    "feature flags",
]

# Required header tokens, in strict order.
HEADER_TOKEN_ORDER = [
    "ROI=",
    "impact=",
    "confidence=",
    "effort=",
    "horizon=",
    "category=",
    "reference=",
]


@dataclass
class Step:
    n: str
    header_line_no: int  # 1-based within fence
    header_line: str
    block_lines: List[str]


def _fail(errors: List[str]) -> None:
    for e in errors:
        print(f"[ERROR] {e}", file=sys.stderr)
    sys.exit(1)


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return path.read_text(encoding="utf-8", errors="replace")


def _extract_single_bash_fence(lines: List[str]) -> Tuple[int, int, List[str], List[str]]:
    """
    Enforces:
      - exactly one fenced code block labeled bash
      - no other fences anywhere
      - opening fence line must be exactly ```bash
      - closing fence line must be exactly ```
    """
    fence_locs = [i for i, ln in enumerate(lines) if re.match(r"^```", ln)]
    if len(fence_locs) != 2:
        # Show all fence-like lines to help debugging.
        details = []
        for i, ln in enumerate(lines):
            if re.match(r"^```", ln):
                details.append(f"line {i+1}: {ln.rstrip()}")
        raise ValueError(
            f"Expected exactly one fenced code block (2 fence lines), found {len(fence_locs)} fence line(s). "
            + ("Fences: " + "; ".join(details) if details else "")
        )

    open_i, close_i = fence_locs
    if lines[open_i].rstrip("\n") != "```bash":
        raise ValueError("Opening fence must be exactly ```bash on its own line (no spaces).")
    if lines[close_i].rstrip("\n") != "```":
        raise ValueError("Closing fence must be exactly ``` on its own line (no spaces).")
    if close_i <= open_i:
        raise ValueError("Closing fence appears before opening fence.")

    fence_lines = lines[open_i + 1 : close_i]
    outside_lines = lines[:open_i] + lines[close_i + 1 :]
    return open_i, close_i, fence_lines, outside_lines


def _parse_steps(fence_lines: List[str]) -> List[Step]:
    header_re = re.compile(r"^#\s*(\d{2})\)\s+")
    header_idxs: List[Tuple[int, str]] = []
    for i, ln in enumerate(fence_lines):
        m = header_re.match(ln)
        if m:
            header_idxs.append((i, m.group(1)))

    if len(header_idxs) != 20:
        raise ValueError(f"Expected exactly 20 step headers inside bash fence, found {len(header_idxs)}.")

    expected = [f"{i:02d}" for i in range(1, 21)]
    got = [n for _, n in header_idxs]
    if got != expected:
        raise ValueError(f"Step numbering must be sequential 01..20. Got: {got}")

    steps: List[Step] = []
    for idx, (start_i, n) in enumerate(header_idxs):
        end_i = header_idxs[idx + 1][0] if idx + 1 < len(header_idxs) else len(fence_lines)
        block = fence_lines[start_i:end_i]
        steps.append(
            Step(
                n=n,
                header_line_no=start_i + 1,
                header_line=block[0].rstrip("\n"),
                block_lines=[b.rstrip("\n") for b in block],
            )
        )
    return steps


def _header_token_positions(header: str) -> Dict[str, int]:
    pos: Dict[str, int] = {}
    for t in HEADER_TOKEN_ORDER:
        pos[t] = header.find(t)
    return pos


def _parse_category_value(header: str) -> str:
    if "category=" not in header:
        return ""
    after = header.split("category=", 1)[1]
    # Category ends at the start of " reference=" (strict contract).
    end = after.find(" reference=")
    if end == -1:
        # As a fallback, try other token starts, though contract expects reference= last.
        for token in [" ROI=", " impact=", " confidence=", " effort=", " horizon="]:
            p = after.find(token)
            if p != -1:
                end = p if end == -1 else min(end, p)
    if end == -1:
        cat = after.strip()
    else:
        cat = after[:end].strip()
    return cat


def _has_nonempty_scalar(header: str, key: str) -> bool:
    # scalar value ends at next whitespace
    m = re.search(rf"\b{re.escape(key)}=([^\s]+)", header)
    return bool(m and m.group(1).strip())


def _validate_header(step: Step, errors: List[str]) -> None:
    header = step.header_line

    # Strict start.
    if not re.match(rf"^#\s*{re.escape(step.n)}\)\s+", header):
        errors.append(f"Step {step.n}: header must start with '# {step.n})'. Got: {header}")

    # Tokens must appear in strict order.
    pos = _header_token_positions(header)
    for t, p in pos.items():
        if p == -1:
            errors.append(f"Step {step.n}: missing required token '{t}' in header: {header}")

    # Order check (only if all present).
    if all(p != -1 for p in pos.values()):
        last = -1
        for t in HEADER_TOKEN_ORDER:
            if pos[t] <= last:
                errors.append(
                    f"Step {step.n}: token '{t}' is out of order in header. "
                    f"Expected order: {' '.join(HEADER_TOKEN_ORDER)}. Got: {header}"
                )
                break
            last = pos[t]

    # Non-empty values.
    if not _has_nonempty_scalar(header, "ROI"):
        errors.append(f"Step {step.n}: missing/empty ROI= value in header: {header}")
    for k in ["impact", "confidence", "effort", "horizon", "reference"]:
        if not _has_nonempty_scalar(header, k):
            errors.append(f"Step {step.n}: missing/empty {k}= value in header: {header}")

    cat_val = _parse_category_value(header)
    if not cat_val:
        errors.append(f"Step {step.n}: missing/empty category= value in header: {header}")
    elif cat_val not in ALLOWED_CATEGORIES:
        errors.append(
            f"Step {step.n}: invalid category='{cat_val}'. Must be one of: {ALLOWED_CATEGORIES}. Header: {header}"
        )


def _validate_write_output(step: Step, errors: List[str]) -> None:
    joined = "\n".join(step.block_lines)
    # Strict: must use double quotes exactly: --write-output "<path>"
    m = re.search(r'--write-output\s+"([^"]+)"', joined)
    if not m:
        errors.append(f"Step {step.n}: missing --write-output \"...\" (double-quoted) in step block.")
        return

    out_path = m.group(1)

    # Disallow variable expansions in write paths.
    if "$" in out_path or "`" in out_path:
        errors.append(f"Step {step.n}: --write-output path must not contain shell expansions. Got: {out_path}")

    # Disallow absolute writes (and home shortcuts).
    if out_path.startswith("/") or out_path.startswith("~"):
        errors.append(f"Step {step.n}: --write-output path must be relative (no absolute/home paths). Got: {out_path}")

    # Disallow traversal.
    if re.search(r"(^|/)\.\.(/|$)", out_path):
        errors.append(f"Step {step.n}: --write-output path must not contain '..' traversal. Got: {out_path}")

    # Basic shape: <out_dir>/<nn>-<slug>.md
    if "/" not in out_path:
        errors.append(f"Step {step.n}: --write-output path must contain a directory component. Got: {out_path}")
        return

    filename = out_path.split("/")[-1]
    if not filename.startswith(f"{step.n}-"):
        errors.append(f"Step {step.n}: --write-output filename must start with '{step.n}-'. Got: {filename}")
    if not filename.endswith(".md"):
        errors.append(f"Step {step.n}: --write-output filename must end with '.md'. Got: {filename}")

    # Extra guard: ensure PurePosixPath doesn't include '..' (covers odd strings like 'a/../b').
    try:
        parts = PurePosixPath(out_path).parts
        if ".." in parts:
            errors.append(f"Step {step.n}: --write-output path contains '..' segment (unsafe). Got: {out_path}")
    except Exception:
        # Non-fatal; already handled by regex.
        pass


def _validate_ticket_bundle_reference(step: Step, errors: List[str]) -> None:
    joined = "\n".join(step.block_lines)

    # Require the bundle to be mentioned/attached.
    if "_tickets_bundle" not in joined:
        errors.append(
            f"Step {step.n}: must reference the ticket bundle (expected '_tickets_bundle' in step block)."
        )

    # Require a file attachment pointing to the bundle, double-quoted for stability.
    if re.search(r'(?<!\S)(-f|--file)(?!\S)\s+"[^"\n]*_tickets_bundle[^"\n]*"', joined) is None:
        errors.append(
            f"Step {step.n}: must attach the ticket bundle via -f/--file \"..._tickets_bundle...\"."
        )


def _validate_answer_format(step: Step, errors: List[str]) -> None:
    hay = "\n".join(step.block_lines).lower()
    required = [
        "answer format:",
        "direct answer",
        "risks/unknowns",
        "next smallest concrete experiment",
        "if evidence is insufficient",
        "missing file/path pattern",
    ]
    missing = [s for s in required if s not in hay]
    if missing:
        errors.append(f"Step {step.n}: prompt missing required Answer format components: {missing}")


def _validate_category_counts(steps: List[Step], errors: List[str]) -> None:
    counts: Dict[str, List[str]] = {c: [] for c in ALLOWED_CATEGORIES}
    for st in steps:
        cat = _parse_category_value(st.header_line)
        if cat in counts:
            counts[cat].append(st.n)

    bad = []
    for cat, ids in counts.items():
        if len(ids) != 2:
            bad.append(f"{cat}={len(ids)} (steps={ids})")
    if bad:
        errors.append(
            "Category distribution must be exactly 2 steps per category (20 total). Problems: " + ", ".join(bad)
        )


def _validate_coverage_check(outside_lines: List[str], errors: List[str]) -> None:
    text = "\n".join(outside_lines)
    m = re.search(r"^##\s+Coverage check\s*$", text, flags=re.IGNORECASE | re.MULTILINE)
    if m is None:
        errors.append('Missing "## Coverage check" section (must be outside the bash fence).')
        return

    after = text[m.end() :]
    for cat in ALLOWED_CATEGORIES:
        # Require a line like: "- <cat>: OK" OR "- <cat>: Missing(01,02)"
        pat = rf"^\s*[-*]\s+{re.escape(cat)}\s*:\s*(OK|Missing\([^)]*\))\s*$"
        if re.search(pat, after, flags=re.MULTILINE) is None:
            errors.append(f'Coverage check missing/invalid line for category: "{cat}"')


def validate_pack(path: Path) -> None:
    raw = _read_text(path)
    lines = raw.splitlines(True)

    try:
        _, _, fence_lines, outside_lines = _extract_single_bash_fence(lines)
    except ValueError as e:
        _fail([str(e)])

    try:
        steps = _parse_steps(fence_lines)
    except ValueError as e:
        _fail([str(e)])

    errors: List[str] = []
    for st in steps:
        _validate_header(st, errors)
        _validate_write_output(st, errors)
        _validate_ticket_bundle_reference(st, errors)
        _validate_answer_format(st, errors)

    _validate_category_counts(steps, errors)
    _validate_coverage_check(outside_lines, errors)

    if errors:
        _fail(errors)

    print("[OK] Pack validates against tickets Stage-1 contract.")

def main() -> None:
    p = argparse.ArgumentParser(
        description="Validate a ticket-driven oraclepack Stage-1 pack (single bash fence, 20 steps, strict headers/tokens, safe write paths, ticket bundle references, coverage check)."
    )
    p.add_argument("pack_path", help="Path to the Markdown pack file")
    args = p.parse_args()

    path = Path(args.pack_path)
    if not path.exists():
        _fail([f"File not found: {path}"])

    validate_pack(path)


if __name__ == "__main__":
    main()
```

.config/mcp/mcp-builder/reference/evaluation.md
```
# MCP Server Evaluation Guide

## Overview

This document provides guidance on creating comprehensive evaluations for MCP servers. Evaluations test whether LLMs can effectively use your MCP server to answer realistic, complex questions using only the tools provided.

---

## Quick Reference

### Evaluation Requirements

- Create 10 human-readable questions
- Questions must be READ-ONLY, INDEPENDENT, NON-DESTRUCTIVE
- Each question requires multiple tool calls (potentially dozens)
- Answers must be single, verifiable values
- Answers must be STABLE (won't change over time)

### Output Format

```xml
<evaluation>
   <qa_pair>
      <question>Your question here</question>
      <answer>Single verifiable answer</answer>
   </qa_pair>
</evaluation>
```

---

## Purpose of Evaluations

The measure of quality of an MCP server is NOT how well or comprehensively the server implements tools, but how well these implementations (input/output schemas, docstrings/descriptions, functionality) enable LLMs with no other context and access ONLY to the MCP servers to answer realistic and difficult questions.

## Evaluation Overview

Create 10 human-readable questions requiring ONLY READ-ONLY, INDEPENDENT, NON-DESTRUCTIVE, and IDEMPOTENT operations to answer. Each question should be:

- Realistic
- Clear and concise
- Unambiguous
- Complex, requiring potentially dozens of tool calls or steps
- Answerable with a single, verifiable value that you identify in advance

## Question Guidelines

### Core Requirements

1. **Questions MUST be independent**
   - Each question should NOT depend on the answer to any other question
   - Should not assume prior write operations from processing another question

2. **Questions MUST require ONLY NON-DESTRUCTIVE AND IDEMPOTENT tool use**
   - Should not instruct or require modifying state to arrive at the correct answer

3. **Questions must be REALISTIC, CLEAR, CONCISE, and COMPLEX**
   - Must require another LLM to use multiple (potentially dozens of) tools or steps to answer

### Complexity and Depth

4. **Questions must require deep exploration**
   - Consider multi-hop questions requiring multiple sub-questions and sequential tool calls
   - Each step should benefit from information found in previous questions

5. **Questions may require extensive paging**
   - May need paging through multiple pages of results
   - May require querying old data (1-2 years out-of-date) to find niche information
   - The questions must be DIFFICULT

6. **Questions must require deep understanding**
   - Rather than surface-level knowledge
   - May pose complex ideas as True/False questions requiring evidence
   - May use multiple-choice format where LLM must search different hypotheses

7. **Questions must not be solvable with straightforward keyword search**
   - Do not include specific keywords from the target content
   - Use synonyms, related concepts, or paraphrases
   - Require multiple searches, analyzing multiple related items, extracting context, then deriving the answer

### Tool Testing

8. **Questions should stress-test tool return values**
   - May elicit tools returning large JSON objects or lists, overwhelming the LLM
   - Should require understanding multiple modalities of data:
     - IDs and names
     - Timestamps and datetimes (months, days, years, seconds)
     - File IDs, names, extensions, and mimetypes
     - URLs, GIDs, etc.
   - Should probe the tool's ability to return all useful forms of data

9. **Questions should MOSTLY reflect real human use cases**
   - The kinds of information retrieval tasks that HUMANS assisted by an LLM would care about

10. **Questions may require dozens of tool calls**
    - This challenges LLMs with limited context
    - Encourages MCP server tools to reduce information returned

11. **Include ambiguous questions**
    - May be ambiguous OR require difficult decisions on which tools to call
    - Force the LLM to potentially make mistakes or misinterpret
    - Ensure that despite AMBIGUITY, there is STILL A SINGLE VERIFIABLE ANSWER

### Stability

12. **Questions must be designed so the answer DOES NOT CHANGE**
    - Do not ask questions that rely on "current state" which is dynamic
    - For example, do not count:
      - Number of reactions to a post
      - Number of replies to a thread
      - Number of members in a channel

13. **DO NOT let the MCP server RESTRICT the kinds of questions you create**
    - Create challenging and complex questions
    - Some may not be solvable with the available MCP server tools
    - Questions may require specific output formats (datetime vs. epoch time, JSON vs. MARKDOWN)
    - Questions may require dozens of tool calls to complete

## Answer Guidelines

### Verification

1. **Answers must be VERIFIABLE via direct string comparison**
   - If the answer can be re-written in many formats, clearly specify the output format in the QUESTION
   - Examples: "Use YYYY/MM/DD.", "Respond True or False.", "Answer A, B, C, or D and nothing else."
   - Answer should be a single VERIFIABLE value such as:
     - User ID, user name, display name, first name, last name
     - Channel ID, channel name
     - Message ID, string
     - URL, title
     - Numerical quantity
     - Timestamp, datetime
     - Boolean (for True/False questions)
     - Email address, phone number
     - File ID, file name, file extension
     - Multiple choice answer
   - Answers must not require special formatting or complex, structured output
   - Answer will be verified using DIRECT STRING COMPARISON

### Readability

2. **Answers should generally prefer HUMAN-READABLE formats**
   - Examples: names, first name, last name, datetime, file name, message string, URL, yes/no, true/false, a/b/c/d
   - Rather than opaque IDs (though IDs are acceptable)
   - The VAST MAJORITY of answers should be human-readable

### Stability

3. **Answers must be STABLE/STATIONARY**
   - Look at old content (e.g., conversations that have ended, projects that have launched, questions answered)
   - Create QUESTIONS based on "closed" concepts that will always return the same answer
   - Questions may ask to consider a fixed time window to insulate from non-stationary answers
   - Rely on context UNLIKELY to change
   - Example: if finding a paper name, be SPECIFIC enough so answer is not confused with papers published later

4. **Answers must be CLEAR and UNAMBIGUOUS**
   - Questions must be designed so there is a single, clear answer
   - Answer can be derived from using the MCP server tools

### Diversity

5. **Answers must be DIVERSE**
   - Answer should be a single VERIFIABLE value in diverse modalities and formats
   - User concept: user ID, user name, display name, first name, last name, email address, phone number
   - Channel concept: channel ID, channel name, channel topic
   - Message concept: message ID, message string, timestamp, month, day, year

6. **Answers must NOT be complex structures**
   - Not a list of values
   - Not a complex object
   - Not a list of IDs or strings
   - Not natural language text
   - UNLESS the answer can be straightforwardly verified using DIRECT STRING COMPARISON
   - And can be realistically reproduced
   - It should be unlikely that an LLM would return the same list in any other order or format

## Evaluation Process

### Step 1: Documentation Inspection

Read the documentation of the target API to understand:

- Available endpoints and functionality
- If ambiguity exists, fetch additional information from the web
- Parallelize this step AS MUCH AS POSSIBLE
- Ensure each subagent is ONLY examining documentation from the file system or on the web

### Step 2: Tool Inspection

List the tools available in the MCP server:

- Inspect the MCP server directly
- Understand input/output schemas, docstrings, and descriptions
- WITHOUT calling the tools themselves at this stage

### Step 3: Developing Understanding

Repeat steps 1 & 2 until you have a good understanding:

- Iterate multiple times
- Think about the kinds of tasks you want to create
- Refine your understanding
- At NO stage should you READ the code of the MCP server implementation itself
- Use your intuition and understanding to create reasonable, realistic, but VERY challenging tasks

### Step 4: Read-Only Content Inspection

After understanding the API and tools, USE the MCP server tools:

- Inspect content using READ-ONLY and NON-DESTRUCTIVE operations ONLY
- Goal: identify specific content (e.g., users, channels, messages, projects, tasks) for creating realistic questions
- Should NOT call any tools that modify state
- Will NOT read the code of the MCP server implementation itself
- Parallelize this step with individual sub-agents pursuing independent explorations
- Ensure each subagent is only performing READ-ONLY, NON-DESTRUCTIVE, and IDEMPOTENT operations
- BE CAREFUL: SOME TOOLS may return LOTS OF DATA which would cause you to run out of CONTEXT
- Make INCREMENTAL, SMALL, AND TARGETED tool calls for exploration
- In all tool call requests, use the `limit` parameter to limit results (<10)
- Use pagination

### Step 5: Task Generation

After inspecting the content, create 10 human-readable questions:

- An LLM should be able to answer these with the MCP server
- Follow all question and answer guidelines above

## Output Format

Each QA pair consists of a question and an answer. The output should be an XML file with this structure:

```xml
<evaluation>
   <qa_pair>
      <question>Find the project created in Q2 2024 with the highest number of completed tasks. What is the project name?</question>
      <answer>Website Redesign</answer>
   </qa_pair>
   <qa_pair>
      <question>Search for issues labeled as "bug" that were closed in March 2024. Which user closed the most issues? Provide their username.</question>
      <answer>sarah_dev</answer>
   </qa_pair>
   <qa_pair>
      <question>Look for pull requests that modified files in the /api directory and were merged between January 1 and January 31, 2024. How many different contributors worked on these PRs?</question>
      <answer>7</answer>
   </qa_pair>
   <qa_pair>
      <question>Find the repository with the most stars that was created before 2023. What is the repository name?</question>
      <answer>data-pipeline</answer>
   </qa_pair>
</evaluation>
```

## Evaluation Examples

### Good Questions

**Example 1: Multi-hop question requiring deep exploration (GitHub MCP)**

```xml
<qa_pair>
   <question>Find the repository that was archived in Q3 2023 and had previously been the most forked project in the organization. What was the primary programming language used in that repository?</question>
   <answer>Python</answer>
</qa_pair>
```

This question is good because:

- Requires multiple searches to find archived repositories
- Needs to identify which had the most forks before archival
- Requires examining repository details for the language
- Answer is a simple, verifiable value
- Based on historical (closed) data that won't change

**Example 2: Requires understanding context without keyword matching (Project Management MCP)**

```xml
<qa_pair>
   <question>Locate the initiative focused on improving customer onboarding that was completed in late 2023. The project lead created a retrospective document after completion. What was the lead's role title at that time?</question>
   <answer>Product Manager</answer>
</qa_pair>
```

This question is good because:

- Doesn't use specific project name ("initiative focused on improving customer onboarding")
- Requires finding completed projects from specific timeframe
- Needs to identify the project lead and their role
- Requires understanding context from retrospective documents
- Answer is human-readable and stable
- Based on completed work (won't change)

**Example 3: Complex aggregation requiring multiple steps (Issue Tracker MCP)**

```xml
<qa_pair>
   <question>Among all bugs reported in January 2024 that were marked as critical priority, which assignee resolved the highest percentage of their assigned bugs within 48 hours? Provide the assignee's username.</question>
   <answer>alex_eng</answer>
</qa_pair>
```

This question is good because:

- Requires filtering bugs by date, priority, and status
- Needs to group by assignee and calculate resolution rates
- Requires understanding timestamps to determine 48-hour windows
- Tests pagination (potentially many bugs to process)
- Answer is a single username
- Based on historical data from specific time period

**Example 4: Requires synthesis across multiple data types (CRM MCP)**

```xml
<qa_pair>
   <question>Find the account that upgraded from the Starter to Enterprise plan in Q4 2023 and had the highest annual contract value. What industry does this account operate in?</question>
   <answer>Healthcare</answer>
</qa_pair>
```

This question is good because:

- Requires understanding subscription tier changes
- Needs to identify upgrade events in specific timeframe
- Requires comparing contract values
- Must access account industry information
- Answer is simple and verifiable
- Based on completed historical transactions

### Poor Questions

**Example 1: Answer changes over time**

```xml
<qa_pair>
   <question>How many open issues are currently assigned to the engineering team?</question>
   <answer>47</answer>
</qa_pair>
```

This question is poor because:

- The answer will change as issues are created, closed, or reassigned
- Not based on stable/stationary data
- Relies on "current state" which is dynamic

**Example 2: Too easy with keyword search**

```xml
<qa_pair>
   <question>Find the pull request with title "Add authentication feature" and tell me who created it.</question>
   <answer>developer123</answer>
</qa_pair>
```

This question is poor because:

- Can be solved with a straightforward keyword search for exact title
- Doesn't require deep exploration or understanding
- No synthesis or analysis needed

**Example 3: Ambiguous answer format**

```xml
<qa_pair>
   <question>List all the repositories that have Python as their primary language.</question>
   <answer>repo1, repo2, repo3, data-pipeline, ml-tools</answer>
</qa_pair>
```

This question is poor because:

- Answer is a list that could be returned in any order
- Difficult to verify with direct string comparison
- LLM might format differently (JSON array, comma-separated, newline-separated)
- Better to ask for a specific aggregate (count) or superlative (most stars)

## Verification Process

After creating evaluations:

1. **Examine the XML file** to understand the schema
2. **Load each task instruction** and in parallel using the MCP server and tools, identify the correct answer by attempting to solve the task YOURSELF
3. **Flag any operations** that require WRITE or DESTRUCTIVE operations
4. **Accumulate all CORRECT answers** and replace any incorrect answers in the document
5. **Remove any `<qa_pair>`** that require WRITE or DESTRUCTIVE operations

Remember to parallelize solving tasks to avoid running out of context, then accumulate all answers and make changes to the file at the end.

## Tips for Creating Quality Evaluations

1. **Think Hard and Plan Ahead** before generating tasks
2. **Parallelize Where Opportunity Arises** to speed up the process and manage context
3. **Focus on Realistic Use Cases** that humans would actually want to accomplish
4. **Create Challenging Questions** that test the limits of the MCP server's capabilities
5. **Ensure Stability** by using historical data and closed concepts
6. **Verify Answers** by solving the questions yourself using the MCP server tools
7. **Iterate and Refine** based on what you learn during the process

---

# Running Evaluations

After creating your evaluation file, you can use the provided evaluation harness to test your MCP server.

## Setup

1. **Install Dependencies**

   ```bash
   pip install -r scripts/requirements.txt
   ```

   Or install manually:

   ```bash
   pip install anthropic mcp
   ```

2. **Set API Key**

   ```bash
   export ANTHROPIC_API_KEY=your_api_key_here
   ```

## Evaluation File Format

Evaluation files use XML format with `<qa_pair>` elements:

```xml
<evaluation>
   <qa_pair>
      <question>Find the project created in Q2 2024 with the highest number of completed tasks. What is the project name?</question>
      <answer>Website Redesign</answer>
   </qa_pair>
   <qa_pair>
      <question>Search for issues labeled as "bug" that were closed in March 2024. Which user closed the most issues? Provide their username.</question>
      <answer>sarah_dev</answer>
   </qa_pair>
</evaluation>
```

## Running Evaluations

The evaluation script (`scripts/evaluation.py`) supports three transport types:

**Important:**

- **stdio transport**: The evaluation script automatically launches and manages the MCP server process for you. Do not run the server manually.
- **sse/http transports**: You must start the MCP server separately before running the evaluation. The script connects to the already-running server at the specified URL.

### 1. Local STDIO Server

For locally-run MCP servers (script launches the server automatically):

```bash
python scripts/evaluation.py \
  -t stdio \
  -c python \
  -a my_mcp_server.py \
  evaluation.xml
```

With environment variables:

```bash
python scripts/evaluation.py \
  -t stdio \
  -c python \
  -a my_mcp_server.py \
  -e API_KEY=abc123 \
  -e DEBUG=true \
  evaluation.xml
```

### 2. Server-Sent Events (SSE)

For SSE-based MCP servers (you must start the server first):

```bash
python scripts/evaluation.py \
  -t sse \
  -u https://example.com/mcp \
  -H "Authorization: Bearer token123" \
  -H "X-Custom-Header: value" \
  evaluation.xml
```

### 3. HTTP (Streamable HTTP)

For HTTP-based MCP servers (you must start the server first):

```bash
python scripts/evaluation.py \
  -t http \
  -u https://example.com/mcp \
  -H "Authorization: Bearer token123" \
  evaluation.xml
```

## Command-Line Options

```
usage: evaluation.py [-h] [-t {stdio,sse,http}] [-m MODEL] [-c COMMAND]
                     [-a ARGS [ARGS ...]] [-e ENV [ENV ...]] [-u URL]
                     [-H HEADERS [HEADERS ...]] [-o OUTPUT]
                     eval_file

positional arguments:
  eval_file             Path to evaluation XML file

optional arguments:
  -h, --help            Show help message
  -t, --transport       Transport type: stdio, sse, or http (default: stdio)
  -m, --model           codex model to use (default: codex-3-7-sonnet-20250219)
  -o, --output          Output file for report (default: print to stdout)

stdio options:
  -c, --command         Command to run MCP server (e.g., python, node)
  -a, --args            Arguments for the command (e.g., server.py)
  -e, --env             Environment variables in KEY=VALUE format

sse/http options:
  -u, --url             MCP server URL
  -H, --header          HTTP headers in 'Key: Value' format
```

## Output

The evaluation script generates a detailed report including:

- **Summary Statistics**:
  - Accuracy (correct/total)
  - Average task duration
  - Average tool calls per task
  - Total tool calls

- **Per-Task Results**:
  - Prompt and expected response
  - Actual response from the agent
  - Whether the answer was correct (✅/❌)
  - Duration and tool call details
  - Agent's summary of its approach
  - Agent's feedback on the tools

### Save Report to File

```bash
python scripts/evaluation.py \
  -t stdio \
  -c python \
  -a my_server.py \
  -o evaluation_report.md \
  evaluation.xml
```

## Complete Example Workflow

Here's a complete example of creating and running an evaluation:

1. **Create your evaluation file** (`my_evaluation.xml`):

```xml
<evaluation>
   <qa_pair>
      <question>Find the user who created the most issues in January 2024. What is their username?</question>
      <answer>alice_developer</answer>
   </qa_pair>
   <qa_pair>
      <question>Among all pull requests merged in Q1 2024, which repository had the highest number? Provide the repository name.</question>
      <answer>backend-api</answer>
   </qa_pair>
   <qa_pair>
      <question>Find the project that was completed in December 2023 and had the longest duration from start to finish. How many days did it take?</question>
      <answer>127</answer>
   </qa_pair>
</evaluation>
```

2. **Install dependencies**:

```bash
pip install -r scripts/requirements.txt
export ANTHROPIC_API_KEY=your_api_key
```

3. **Run evaluation**:

```bash
python scripts/evaluation.py \
  -t stdio \
  -c python \
  -a github_mcp_server.py \
  -e GITHUB_TOKEN=ghp_xxx \
  -o github_eval_report.md \
  my_evaluation.xml
```

4. **Review the report** in `github_eval_report.md` to:
   - See which questions passed/failed
   - Read the agent's feedback on your tools
   - Identify areas for improvement
   - Iterate on your MCP server design

## Troubleshooting

### Connection Errors

If you get connection errors:

- **STDIO**: Verify the command and arguments are correct
- **SSE/HTTP**: Check the URL is accessible and headers are correct
- Ensure any required API keys are set in environment variables or headers

### Low Accuracy

If many evaluations fail:

- Review the agent's feedback for each task
- Check if tool descriptions are clear and comprehensive
- Verify input parameters are well-documented
[TRUNCATED]
```

.config/mcp/mcp-builder/reference/mcp_best_practices.md
```
# MCP Server Best Practices

## Quick Reference

### Server Naming
- **Python**: `{service}_mcp` (e.g., `slack_mcp`)
- **Node/TypeScript**: `{service}-mcp-server` (e.g., `slack-mcp-server`)

### Tool Naming
- Use snake_case with service prefix
- Format: `{service}_{action}_{resource}`
- Example: `slack_send_message`, `github_create_issue`

### Response Formats
- Support both JSON and Markdown formats
- JSON for programmatic processing
- Markdown for human readability

### Pagination
- Always respect `limit` parameter
- Return `has_more`, `next_offset`, `total_count`
- Default to 20-50 items

### Transport
- **Streamable HTTP**: For remote servers, multi-client scenarios
- **stdio**: For local integrations, command-line tools
- Avoid SSE (deprecated in favor of streamable HTTP)

---

## Server Naming Conventions

Follow these standardized naming patterns:

**Python**: Use format `{service}_mcp` (lowercase with underscores)
- Examples: `slack_mcp`, `github_mcp`, `jira_mcp`

**Node/TypeScript**: Use format `{service}-mcp-server` (lowercase with hyphens)
- Examples: `slack-mcp-server`, `github-mcp-server`, `jira-mcp-server`

The name should be general, descriptive of the service being integrated, easy to infer from the task description, and without version numbers.

---

## Tool Naming and Design

### Tool Naming

1. **Use snake_case**: `search_users`, `create_project`, `get_channel_info`
2. **Include service prefix**: Anticipate that your MCP server may be used alongside other MCP servers
   - Use `slack_send_message` instead of just `send_message`
   - Use `github_create_issue` instead of just `create_issue`
3. **Be action-oriented**: Start with verbs (get, list, search, create, etc.)
4. **Be specific**: Avoid generic names that could conflict with other servers

### Tool Design

- Tool descriptions must narrowly and unambiguously describe functionality
- Descriptions must precisely match actual functionality
- Provide tool annotations (readOnlyHint, destructiveHint, idempotentHint, openWorldHint)
- Keep tool operations focused and atomic

---

## Response Formats

All tools that return data should support multiple formats:

### JSON Format (`response_format="json"`)
- Machine-readable structured data
- Include all available fields and metadata
- Consistent field names and types
- Use for programmatic processing

### Markdown Format (`response_format="markdown"`, typically default)
- Human-readable formatted text
- Use headers, lists, and formatting for clarity
- Convert timestamps to human-readable format
- Show display names with IDs in parentheses
- Omit verbose metadata

---

## Pagination

For tools that list resources:

- **Always respect the `limit` parameter**
- **Implement pagination**: Use `offset` or cursor-based pagination
- **Return pagination metadata**: Include `has_more`, `next_offset`/`next_cursor`, `total_count`
- **Never load all results into memory**: Especially important for large datasets
- **Default to reasonable limits**: 20-50 items is typical

Example pagination response:
```json
{
  "total": 150,
  "count": 20,
  "offset": 0,
  "items": [...],
  "has_more": true,
  "next_offset": 20
}
```

---

## Transport Options

### Streamable HTTP

**Best for**: Remote servers, web services, multi-client scenarios

**Characteristics**:
- Bidirectional communication over HTTP
- Supports multiple simultaneous clients
- Can be deployed as a web service
- Enables server-to-client notifications

**Use when**:
- Serving multiple clients simultaneously
- Deploying as a cloud service
- Integration with web applications

### stdio

**Best for**: Local integrations, command-line tools

**Characteristics**:
- Standard input/output stream communication
- Simple setup, no network configuration needed
- Runs as a subprocess of the client

**Use when**:
- Building tools for local development environments
- Integrating with desktop applications
- Single-user, single-session scenarios

**Note**: stdio servers should NOT log to stdout (use stderr for logging)

### Transport Selection

| Criterion | stdio | Streamable HTTP |
|-----------|-------|-----------------|
| **Deployment** | Local | Remote |
| **Clients** | Single | Multiple |
| **Complexity** | Low | Medium |
| **Real-time** | No | Yes |

---

## Security Best Practices

### Authentication and Authorization

**OAuth 2.1**:
- Use secure OAuth 2.1 with certificates from recognized authorities
- Validate access tokens before processing requests
- Only accept tokens specifically intended for your server

**API Keys**:
- Store API keys in environment variables, never in code
- Validate keys on server startup
- Provide clear error messages when authentication fails

### Input Validation

- Sanitize file paths to prevent directory traversal
- Validate URLs and external identifiers
- Check parameter sizes and ranges
- Prevent command injection in system calls
- Use schema validation (Pydantic/Zod) for all inputs

### Error Handling

- Don't expose internal errors to clients
- Log security-relevant errors server-side
- Provide helpful but not revealing error messages
- Clean up resources after errors

### DNS Rebinding Protection

For streamable HTTP servers running locally:
- Enable DNS rebinding protection
- Validate the `Origin` header on all incoming connections
- Bind to `127.0.0.1` rather than `0.0.0.0`

---

## Tool Annotations

Provide annotations to help clients understand tool behavior:

| Annotation | Type | Default | Description |
|-----------|------|---------|-------------|
| `readOnlyHint` | boolean | false | Tool does not modify its environment |
| `destructiveHint` | boolean | true | Tool may perform destructive updates |
| `idempotentHint` | boolean | false | Repeated calls with same args have no additional effect |
| `openWorldHint` | boolean | true | Tool interacts with external entities |

**Important**: Annotations are hints, not security guarantees. Clients should not make security-critical decisions based solely on annotations.

---

## Error Handling

- Use standard JSON-RPC error codes
- Report tool errors within result objects (not protocol-level errors)
- Provide helpful, specific error messages with suggested next steps
- Don't expose internal implementation details
- Clean up resources properly on errors

Example error handling:
```typescript
try {
  const result = performOperation();
  return { content: [{ type: "text", text: result }] };
} catch (error) {
  return {
    isError: true,
    content: [{
      type: "text",
      text: `Error: ${error.message}. Try using filter='active_only' to reduce results.`
    }]
  };
}
```

---

## Testing Requirements

Comprehensive testing should cover:

- **Functional testing**: Verify correct execution with valid/invalid inputs
- **Integration testing**: Test interaction with external systems
- **Security testing**: Validate auth, input sanitization, rate limiting
- **Performance testing**: Check behavior under load, timeouts
- **Error handling**: Ensure proper error reporting and cleanup

---

## Documentation Requirements

- Provide clear documentation of all tools and capabilities
- Include working examples (at least 3 per major feature)
- Document security considerations
- Specify required permissions and access levels
- Document rate limits and performance characteristics
```

.config/mcp/mcp-builder/reference/node_mcp_server.md
```
# Node/TypeScript MCP Server Implementation Guide

## Overview

This document provides Node/TypeScript-specific best practices and examples for implementing MCP servers using the MCP TypeScript SDK. It covers project structure, server setup, tool registration patterns, input validation with Zod, error handling, and complete working examples.

---

## Quick Reference

### Key Imports
```typescript
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StreamableHTTPServerTransport } from "@modelcontextprotocol/sdk/server/streamableHttp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import express from "express";
import { z } from "zod";
```

### Server Initialization
```typescript
const server = new McpServer({
  name: "service-mcp-server",
  version: "1.0.0"
});
```

### Tool Registration Pattern
```typescript
server.registerTool(
  "tool_name",
  {
    title: "Tool Display Name",
    description: "What the tool does",
    inputSchema: { param: z.string() },
    outputSchema: { result: z.string() }
  },
  async ({ param }) => {
    const output = { result: `Processed: ${param}` };
    return {
      content: [{ type: "text", text: JSON.stringify(output) }],
      structuredContent: output // Modern pattern for structured data
    };
  }
);
```

---

## MCP TypeScript SDK

The official MCP TypeScript SDK provides:
- `McpServer` class for server initialization
- `registerTool` method for tool registration
- Zod schema integration for runtime input validation
- Type-safe tool handler implementations

**IMPORTANT - Use Modern APIs Only:**
- **DO use**: `server.registerTool()`, `server.registerResource()`, `server.registerPrompt()`
- **DO NOT use**: Old deprecated APIs such as `server.tool()`, `server.setRequestHandler(ListToolsRequestSchema, ...)`, or manual handler registration
- The `register*` methods provide better type safety, automatic schema handling, and are the recommended approach

See the MCP SDK documentation in the references for complete details.

## Server Naming Convention

Node/TypeScript MCP servers must follow this naming pattern:
- **Format**: `{service}-mcp-server` (lowercase with hyphens)
- **Examples**: `github-mcp-server`, `jira-mcp-server`, `stripe-mcp-server`

The name should be:
- General (not tied to specific features)
- Descriptive of the service/API being integrated
- Easy to infer from the task description
- Without version numbers or dates

## Project Structure

Create the following structure for Node/TypeScript MCP servers:

```
{service}-mcp-server/
├── package.json
├── tsconfig.json
├── README.md
├── src/
│   ├── index.ts          # Main entry point with McpServer initialization
│   ├── types.ts          # TypeScript type definitions and interfaces
│   ├── tools/            # Tool implementations (one file per domain)
│   ├── services/         # API clients and shared utilities
│   ├── schemas/          # Zod validation schemas
│   └── constants.ts      # Shared constants (API_URL, CHARACTER_LIMIT, etc.)
└── dist/                 # Built JavaScript files (entry point: dist/index.js)
```

## Tool Implementation

### Tool Naming

Use snake_case for tool names (e.g., "search_users", "create_project", "get_channel_info") with clear, action-oriented names.

**Avoid Naming Conflicts**: Include the service context to prevent overlaps:
- Use "slack_send_message" instead of just "send_message"
- Use "github_create_issue" instead of just "create_issue"
- Use "asana_list_tasks" instead of just "list_tasks"

### Tool Structure

Tools are registered using the `registerTool` method with the following requirements:
- Use Zod schemas for runtime input validation and type safety
- The `description` field must be explicitly provided - JSDoc comments are NOT automatically extracted
- Explicitly provide `title`, `description`, `inputSchema`, and `annotations`
- The `inputSchema` must be a Zod schema object (not a JSON schema)
- Type all parameters and return values explicitly

```typescript
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { z } from "zod";

const server = new McpServer({
  name: "example-mcp",
  version: "1.0.0"
});

// Zod schema for input validation
const UserSearchInputSchema = z.object({
  query: z.string()
    .min(2, "Query must be at least 2 characters")
    .max(200, "Query must not exceed 200 characters")
    .describe("Search string to match against names/emails"),
  limit: z.number()
    .int()
    .min(1)
    .max(100)
    .default(20)
    .describe("Maximum results to return"),
  offset: z.number()
    .int()
    .min(0)
    .default(0)
    .describe("Number of results to skip for pagination"),
  response_format: z.nativeEnum(ResponseFormat)
    .default(ResponseFormat.MARKDOWN)
    .describe("Output format: 'markdown' for human-readable or 'json' for machine-readable")
}).strict();

// Type definition from Zod schema
type UserSearchInput = z.infer<typeof UserSearchInputSchema>;

server.registerTool(
  "example_search_users",
  {
    title: "Search Example Users",
    description: `Search for users in the Example system by name, email, or team.

This tool searches across all user profiles in the Example platform, supporting partial matches and various search filters. It does NOT create or modify users, only searches existing ones.

Args:
  - query (string): Search string to match against names/emails
  - limit (number): Maximum results to return, between 1-100 (default: 20)
  - offset (number): Number of results to skip for pagination (default: 0)
  - response_format ('markdown' | 'json'): Output format (default: 'markdown')

Returns:
  For JSON format: Structured data with schema:
  {
    "total": number,           // Total number of matches found
    "count": number,           // Number of results in this response
    "offset": number,          // Current pagination offset
    "users": [
      {
        "id": string,          // User ID (e.g., "U123456789")
        "name": string,        // Full name (e.g., "John Doe")
        "email": string,       // Email address
        "team": string,        // Team name (optional)
        "active": boolean      // Whether user is active
      }
    ],
    "has_more": boolean,       // Whether more results are available
    "next_offset": number      // Offset for next page (if has_more is true)
  }

Examples:
  - Use when: "Find all marketing team members" -> params with query="team:marketing"
  - Use when: "Search for John's account" -> params with query="john"
  - Don't use when: You need to create a user (use example_create_user instead)

Error Handling:
  - Returns "Error: Rate limit exceeded" if too many requests (429 status)
  - Returns "No users found matching '<query>'" if search returns empty`,
    inputSchema: UserSearchInputSchema,
    annotations: {
      readOnlyHint: true,
      destructiveHint: false,
      idempotentHint: true,
      openWorldHint: true
    }
  },
  async (params: UserSearchInput) => {
    try {
      // Input validation is handled by Zod schema
      // Make API request using validated parameters
      const data = await makeApiRequest<any>(
        "users/search",
        "GET",
        undefined,
        {
          q: params.query,
          limit: params.limit,
          offset: params.offset
        }
      );

      const users = data.users || [];
      const total = data.total || 0;

      if (!users.length) {
        return {
          content: [{
            type: "text",
            text: `No users found matching '${params.query}'`
          }]
        };
      }

      // Prepare structured output
      const output = {
        total,
        count: users.length,
        offset: params.offset,
        users: users.map((user: any) => ({
          id: user.id,
          name: user.name,
          email: user.email,
          ...(user.team ? { team: user.team } : {}),
          active: user.active ?? true
        })),
        has_more: total > params.offset + users.length,
        ...(total > params.offset + users.length ? {
          next_offset: params.offset + users.length
        } : {})
      };

      // Format text representation based on requested format
      let textContent: string;
      if (params.response_format === ResponseFormat.MARKDOWN) {
        const lines = [`# User Search Results: '${params.query}'`, "",
          `Found ${total} users (showing ${users.length})`, ""];
        for (const user of users) {
          lines.push(`## ${user.name} (${user.id})`);
          lines.push(`- **Email**: ${user.email}`);
          if (user.team) lines.push(`- **Team**: ${user.team}`);
          lines.push("");
        }
        textContent = lines.join("\n");
      } else {
        textContent = JSON.stringify(output, null, 2);
      }

      return {
        content: [{ type: "text", text: textContent }],
        structuredContent: output // Modern pattern for structured data
      };
    } catch (error) {
      return {
        content: [{
          type: "text",
          text: handleApiError(error)
        }]
      };
    }
  }
);
```

## Zod Schemas for Input Validation

Zod provides runtime type validation:

```typescript
import { z } from "zod";

// Basic schema with validation
const CreateUserSchema = z.object({
  name: z.string()
    .min(1, "Name is required")
    .max(100, "Name must not exceed 100 characters"),
  email: z.string()
    .email("Invalid email format"),
  age: z.number()
    .int("Age must be a whole number")
    .min(0, "Age cannot be negative")
    .max(150, "Age cannot be greater than 150")
}).strict();  // Use .strict() to forbid extra fields

// Enums
enum ResponseFormat {
  MARKDOWN = "markdown",
  JSON = "json"
}

const SearchSchema = z.object({
  response_format: z.nativeEnum(ResponseFormat)
    .default(ResponseFormat.MARKDOWN)
    .describe("Output format")
});

// Optional fields with defaults
const PaginationSchema = z.object({
  limit: z.number()
    .int()
    .min(1)
    .max(100)
    .default(20)
    .describe("Maximum results to return"),
  offset: z.number()
    .int()
    .min(0)
    .default(0)
    .describe("Number of results to skip")
});
```

## Response Format Options

Support multiple output formats for flexibility:

```typescript
enum ResponseFormat {
  MARKDOWN = "markdown",
  JSON = "json"
}

const inputSchema = z.object({
  query: z.string(),
  response_format: z.nativeEnum(ResponseFormat)
    .default(ResponseFormat.MARKDOWN)
    .describe("Output format: 'markdown' for human-readable or 'json' for machine-readable")
});
```

**Markdown format**:
- Use headers, lists, and formatting for clarity
- Convert timestamps to human-readable format
- Show display names with IDs in parentheses
- Omit verbose metadata
- Group related information logically

**JSON format**:
- Return complete, structured data suitable for programmatic processing
- Include all available fields and metadata
- Use consistent field names and types

## Pagination Implementation

For tools that list resources:

```typescript
const ListSchema = z.object({
  limit: z.number().int().min(1).max(100).default(20),
  offset: z.number().int().min(0).default(0)
});

async function listItems(params: z.infer<typeof ListSchema>) {
  const data = await apiRequest(params.limit, params.offset);

  const response = {
    total: data.total,
    count: data.items.length,
    offset: params.offset,
    items: data.items,
    has_more: data.total > params.offset + data.items.length,
    next_offset: data.total > params.offset + data.items.length
      ? params.offset + data.items.length
      : undefined
  };

  return JSON.stringify(response, null, 2);
}
```

## Character Limits and Truncation

Add a CHARACTER_LIMIT constant to prevent overwhelming responses:

```typescript
// At module level in constants.ts
export const CHARACTER_LIMIT = 25000;  // Maximum response size in characters

async function searchTool(params: SearchInput) {
  let result = generateResponse(data);

  // Check character limit and truncate if needed
  if (result.length > CHARACTER_LIMIT) {
    const truncatedData = data.slice(0, Math.max(1, data.length / 2));
    response.data = truncatedData;
    response.truncated = true;
    response.truncation_message =
      `Response truncated from ${data.length} to ${truncatedData.length} items. ` +
      `Use 'offset' parameter or add filters to see more results.`;
    result = JSON.stringify(response, null, 2);
  }

  return result;
}
```

## Error Handling

Provide clear, actionable error messages:

```typescript
import axios, { AxiosError } from "axios";

function handleApiError(error: unknown): string {
  if (error instanceof AxiosError) {
    if (error.response) {
      switch (error.response.status) {
        case 404:
          return "Error: Resource not found. Please check the ID is correct.";
        case 403:
          return "Error: Permission denied. You don't have access to this resource.";
        case 429:
          return "Error: Rate limit exceeded. Please wait before making more requests.";
        default:
          return `Error: API request failed with status ${error.response.status}`;
      }
    } else if (error.code === "ECONNABORTED") {
      return "Error: Request timed out. Please try again.";
    }
  }
  return `Error: Unexpected error occurred: ${error instanceof Error ? error.message : String(error)}`;
}
```

## Shared Utilities

Extract common functionality into reusable functions:

```typescript
// Shared API request function
async function makeApiRequest<T>(
  endpoint: string,
  method: "GET" | "POST" | "PUT" | "DELETE" = "GET",
  data?: any,
  params?: any
): Promise<T> {
  try {
    const response = await axios({
      method,
      url: `${API_BASE_URL}/${endpoint}`,
      data,
      params,
      timeout: 30000,
      headers: {
        "Content-Type": "application/json",
        "Accept": "application/json"
      }
    });
    return response.data;
  } catch (error) {
    throw error;
  }
}
```

## Async/Await Best Practices

Always use async/await for network requests and I/O operations:

```typescript
// Good: Async network request
async function fetchData(resourceId: string): Promise<ResourceData> {
  const response = await axios.get(`${API_URL}/resource/${resourceId}`);
  return response.data;
}

// Bad: Promise chains
function fetchData(resourceId: string): Promise<ResourceData> {
  return axios.get(`${API_URL}/resource/${resourceId}`)
    .then(response => response.data);  // Harder to read and maintain
}
```

## TypeScript Best Practices

1. **Use Strict TypeScript**: Enable strict mode in tsconfig.json
2. **Define Interfaces**: Create clear interface definitions for all data structures
3. **Avoid `any`**: Use proper types or `unknown` instead of `any`
4. **Zod for Runtime Validation**: Use Zod schemas to validate external data
5. **Type Guards**: Create type guard functions for complex type checking
6. **Error Handling**: Always use try-catch with proper error type checking
7. **Null Safety**: Use optional chaining (`?.`) and nullish coalescing (`??`)

```typescript
// Good: Type-safe with Zod and interfaces
interface UserResponse {
  id: string;
  name: string;
  email: string;
  team?: string;
  active: boolean;
}

const UserSchema = z.object({
  id: z.string(),
  name: z.string(),
  email: z.string().email(),
  team: z.string().optional(),
  active: z.boolean()
});

type User = z.infer<typeof UserSchema>;

async function getUser(id: string): Promise<User> {
  const data = await apiCall(`/users/${id}`);
  return UserSchema.parse(data);  // Runtime validation
}

// Bad: Using any
async function getUser(id: string): Promise<any> {
  return await apiCall(`/users/${id}`);  // No type safety
}
```

## Package Configuration

### package.json

```json
{
  "name": "{service}-mcp-server",
  "version": "1.0.0",
  "description": "MCP server for {Service} API integration",
  "type": "module",
  "main": "dist/index.js",
  "scripts": {
    "start": "node dist/index.js",
    "dev": "tsx watch src/index.ts",
    "build": "tsc",
    "clean": "rm -rf dist"
  },
  "engines": {
    "node": ">=18"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.6.1",
    "axios": "^1.7.9",
    "zod": "^3.23.8"
  },
  "devDependencies": {
    "@types/node": "^22.10.0",
    "tsx": "^4.19.2",
    "typescript": "^5.7.2"
  }
}
```

### tsconfig.json

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "Node16",
    "moduleResolution": "Node16",
    "lib": ["ES2022"],
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "allowSyntheticDefaultImports": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
```

## Complete Example

```typescript
#!/usr/bin/env node
/**
 * MCP Server for Example Service.
 *
 * This server provides tools to interact with Example API, including user search,
 * project management, and data export capabilities.
 */

import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";
import axios, { AxiosError } from "axios";

// Constants
const API_BASE_URL = "https://api.example.com/v1";
const CHARACTER_LIMIT = 25000;

// Enums
enum ResponseFormat {
  MARKDOWN = "markdown",
  JSON = "json"
}

// Zod schemas
const UserSearchInputSchema = z.object({
  query: z.string()
    .min(2, "Query must be at least 2 characters")
    .max(200, "Query must not exceed 200 characters")
    .describe("Search string to match against names/emails"),
  limit: z.number()
    .int()
    .min(1)
    .max(100)
    .default(20)
    .describe("Maximum results to return"),
  offset: z.number()
    .int()
    .min(0)
    .default(0)
    .describe("Number of results to skip for pagination"),
  response_format: z.nativeEnum(ResponseFormat)
    .default(ResponseFormat.MARKDOWN)
    .describe("Output format: 'markdown' for human-readable or 'json' for machine-readable")
}).strict();

type UserSearchInput = z.infer<typeof UserSearchInputSchema>;

// Shared utility functions
async function makeApiRequest<T>(
  endpoint: string,
  method: "GET" | "POST" | "PUT" | "DELETE" = "GET",
  data?: any,
  params?: any
): Promise<T> {
  try {
    const response = await axios({
      method,
      url: `${API_BASE_URL}/${endpoint}`,
      data,
      params,
      timeout: 30000,
      headers: {
        "Content-Type": "application/json",
        "Accept": "application/json"
      }
    });
    return response.data;
  } catch (error) {
    throw error;
  }
}

function handleApiError(error: unknown): string {
  if (error instanceof AxiosError) {
    if (error.response) {
      switch (error.response.status) {
        case 404:
          return "Error: Resource not found. Please check the ID is correct.";
        case 403:
          return "Error: Permission denied. You don't have access to this resource.";
        case 429:
          return "Error: Rate limit exceeded. Please wait before making more requests.";
        default:
          return `Error: API request failed with status ${error.response.status}`;
      }
    } else if (error.code === "ECONNABORTED") {
      return "Error: Request timed out. Please try again.";
    }
  }
  return `Error: Unexpected error occurred: ${error instanceof Error ? error.message : String(error)}`;
}

// Create MCP server instance
const server = new McpServer({
  name: "example-mcp",
  version: "1.0.0"
});

// Register tools
server.registerTool(
  "example_search_users",
  {
    title: "Search Example Users",
    description: `[Full description as shown above]`,
    inputSchema: UserSearchInputSchema,
    annotations: {
      readOnlyHint: true,
      destructiveHint: false,
      idempotentHint: true,
      openWorldHint: true
    }
  },
  async (params: UserSearchInput) => {
    // Implementation as shown above
  }
);

// Main function
// For stdio (local):
async function runStdio() {
  if (!process.env.EXAMPLE_API_KEY) {
    console.error("ERROR: EXAMPLE_API_KEY environment variable is required");
    process.exit(1);
  }

  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error("MCP server running via stdio");
}

// For streamable HTTP (remote):
async function runHTTP() {
  if (!process.env.EXAMPLE_API_KEY) {
    console.error("ERROR: EXAMPLE_API_KEY environment variable is required");
    process.exit(1);
  }

  const app = express();
  app.use(express.json());

  app.post('/mcp', async (req, res) => {
    const transport = new StreamableHTTPServerTransport({
      sessionIdGenerator: undefined,
      enableJsonResponse: true
    });
    res.on('close', () => transport.close());
    await server.connect(transport);
    await transport.handleRequest(req, res, req.body);
  });

  const port = parseInt(process.env.PORT || '3000');
  app.listen(port, () => {
    console.error(`MCP server running on http://localhost:${port}/mcp`);
  });
}

// Choose transport based on environment
const transport = process.env.TRANSPORT || 'stdio';
if (transport === 'http') {
  runHTTP().catch(error => {
    console.error("Server error:", error);
    process.exit(1);
  });
} else {
  runStdio().catch(error => {
    console.error("Server error:", error);
    process.exit(1);
  });
}
```

---

## Advanced MCP Features

### Resource Registration

Expose data as resources for efficient, URI-based access:

```typescript
import { ResourceTemplate } from "@modelcontextprotocol/sdk/types.js";

// Register a resource with URI template
server.registerResource(
  {
    uri: "file://documents/{name}",
    name: "Document Resource",
    description: "Access documents by name",
    mimeType: "text/plain"
  },
  async (uri: string) => {
    // Extract parameter from URI
    const match = uri.match(/^file:\/\/documents\/(.+)$/);
    if (!match) {
      throw new Error("Invalid URI format");
    }

    const documentName = match[1];
    const content = await loadDocument(documentName);

    return {
      contents: [{
        uri,
        mimeType: "text/plain",
        text: content
      }]
    };
  }
);

// List available resources dynamically
server.registerResourceList(async () => {
  const documents = await getAvailableDocuments();
  return {
    resources: documents.map(doc => ({
      uri: `file://documents/${doc.name}`,
      name: doc.name,
      mimeType: "text/plain",
      description: doc.description
    }))
  };
});
```

**When to use Resources vs Tools:**
- **Resources**: For data access with simple URI-based parameters
- **Tools**: For complex operations requiring validation and business logic
- **Resources**: When data is relatively static or template-based
- **Tools**: When operations have side effects or complex workflows

### Transport Options

The TypeScript SDK supports two main transport mechanisms:

#### Streamable HTTP (Recommended for Remote Servers)

```typescript
import { StreamableHTTPServerTransport } from "@modelcontextprotocol/sdk/server/streamableHttp.js";
import express from "express";

const app = express();
app.use(express.json());

app.post('/mcp', async (req, res) => {
  // Create new transport for each request (stateless, prevents request ID collisions)
  const transport = new StreamableHTTPServerTransport({
    sessionIdGenerator: undefined,
    enableJsonResponse: true
  });

  res.on('close', () => transport.close());

  await server.connect(transport);
  await transport.handleRequest(req, res, req.body);
});

app.listen(3000);
```

#### stdio (For Local Integrations)

```typescript
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

const transport = new StdioServerTransport();
await server.connect(transport);
```

**Transport selection:**
- **Streamable HTTP**: Web services, remote access, multiple clients
- **stdio**: Command-line tools, local development, subprocess integration

### Notification Support

Notify clients when server state changes:

```typescript
// Notify when tools list changes
server.notification({
  method: "notifications/tools/list_changed"
});

// Notify when resources change
server.notification({
  method: "notifications/resources/list_changed"
});
```

Use notifications sparingly - only when server capabilities genuinely change.

---

## Code Best Practices

### Code Composability and Reusability

Your implementation MUST prioritize composability and code reuse:

1. **Extract Common Functionality**:
   - Create reusable helper functions for operations used across multiple tools
   - Build shared API clients for HTTP requests instead of duplicating code
   - Centralize error handling logic in utility functions
[TRUNCATED]
```

.config/mcp/mcp-builder/reference/python_mcp_server.md
```
# Python MCP Server Implementation Guide

## Overview

This document provides Python-specific best practices and examples for implementing MCP servers using the MCP Python SDK. It covers server setup, tool registration patterns, input validation with Pydantic, error handling, and complete working examples.

---

## Quick Reference

### Key Imports
```python
from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel, Field, field_validator, ConfigDict
from typing import Optional, List, Dict, Any
from enum import Enum
import httpx
```

### Server Initialization
```python
mcp = FastMCP("service_mcp")
```

### Tool Registration Pattern
```python
@mcp.tool(name="tool_name", annotations={...})
async def tool_function(params: InputModel) -> str:
    # Implementation
    pass
```

---

## MCP Python SDK and FastMCP

The official MCP Python SDK provides FastMCP, a high-level framework for building MCP servers. It provides:
- Automatic description and inputSchema generation from function signatures and docstrings
- Pydantic model integration for input validation
- Decorator-based tool registration with `@mcp.tool`

**For complete SDK documentation, use WebFetch to load:**
`https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`

## Server Naming Convention

Python MCP servers must follow this naming pattern:
- **Format**: `{service}_mcp` (lowercase with underscores)
- **Examples**: `github_mcp`, `jira_mcp`, `stripe_mcp`

The name should be:
- General (not tied to specific features)
- Descriptive of the service/API being integrated
- Easy to infer from the task description
- Without version numbers or dates

## Tool Implementation

### Tool Naming

Use snake_case for tool names (e.g., "search_users", "create_project", "get_channel_info") with clear, action-oriented names.

**Avoid Naming Conflicts**: Include the service context to prevent overlaps:
- Use "slack_send_message" instead of just "send_message"
- Use "github_create_issue" instead of just "create_issue"
- Use "asana_list_tasks" instead of just "list_tasks"

### Tool Structure with FastMCP

Tools are defined using the `@mcp.tool` decorator with Pydantic models for input validation:

```python
from pydantic import BaseModel, Field, ConfigDict
from mcp.server.fastmcp import FastMCP

# Initialize the MCP server
mcp = FastMCP("example_mcp")

# Define Pydantic model for input validation
class ServiceToolInput(BaseModel):
    '''Input model for service tool operation.'''
    model_config = ConfigDict(
        str_strip_whitespace=True,  # Auto-strip whitespace from strings
        validate_assignment=True,    # Validate on assignment
        extra='forbid'              # Forbid extra fields
    )

    param1: str = Field(..., description="First parameter description (e.g., 'user123', 'project-abc')", min_length=1, max_length=100)
    param2: Optional[int] = Field(default=None, description="Optional integer parameter with constraints", ge=0, le=1000)
    tags: Optional[List[str]] = Field(default_factory=list, description="List of tags to apply", max_items=10)

@mcp.tool(
    name="service_tool_name",
    annotations={
        "title": "Human-Readable Tool Title",
        "readOnlyHint": True,     # Tool does not modify environment
        "destructiveHint": False,  # Tool does not perform destructive operations
        "idempotentHint": True,    # Repeated calls have no additional effect
        "openWorldHint": False     # Tool does not interact with external entities
    }
)
async def service_tool_name(params: ServiceToolInput) -> str:
    '''Tool description automatically becomes the 'description' field.

    This tool performs a specific operation on the service. It validates all inputs
    using the ServiceToolInput Pydantic model before processing.

    Args:
        params (ServiceToolInput): Validated input parameters containing:
            - param1 (str): First parameter description
            - param2 (Optional[int]): Optional parameter with default
            - tags (Optional[List[str]]): List of tags

    Returns:
        str: JSON-formatted response containing operation results
    '''
    # Implementation here
    pass
```

## Pydantic v2 Key Features

- Use `model_config` instead of nested `Config` class
- Use `field_validator` instead of deprecated `validator`
- Use `model_dump()` instead of deprecated `dict()`
- Validators require `@classmethod` decorator
- Type hints are required for validator methods

```python
from pydantic import BaseModel, Field, field_validator, ConfigDict

class CreateUserInput(BaseModel):
    model_config = ConfigDict(
        str_strip_whitespace=True,
        validate_assignment=True
    )

    name: str = Field(..., description="User's full name", min_length=1, max_length=100)
    email: str = Field(..., description="User's email address", pattern=r'^[\w\.-]+@[\w\.-]+\.\w+$')
    age: int = Field(..., description="User's age", ge=0, le=150)

    @field_validator('email')
    @classmethod
    def validate_email(cls, v: str) -> str:
        if not v.strip():
            raise ValueError("Email cannot be empty")
        return v.lower()
```

## Response Format Options

Support multiple output formats for flexibility:

```python
from enum import Enum

class ResponseFormat(str, Enum):
    '''Output format for tool responses.'''
    MARKDOWN = "markdown"
    JSON = "json"

class UserSearchInput(BaseModel):
    query: str = Field(..., description="Search query")
    response_format: ResponseFormat = Field(
        default=ResponseFormat.MARKDOWN,
        description="Output format: 'markdown' for human-readable or 'json' for machine-readable"
    )
```

**Markdown format**:
- Use headers, lists, and formatting for clarity
- Convert timestamps to human-readable format (e.g., "2024-01-15 10:30:00 UTC" instead of epoch)
- Show display names with IDs in parentheses (e.g., "@john.doe (U123456)")
- Omit verbose metadata (e.g., show only one profile image URL, not all sizes)
- Group related information logically

**JSON format**:
- Return complete, structured data suitable for programmatic processing
- Include all available fields and metadata
- Use consistent field names and types

## Pagination Implementation

For tools that list resources:

```python
class ListInput(BaseModel):
    limit: Optional[int] = Field(default=20, description="Maximum results to return", ge=1, le=100)
    offset: Optional[int] = Field(default=0, description="Number of results to skip for pagination", ge=0)

async def list_items(params: ListInput) -> str:
    # Make API request with pagination
    data = await api_request(limit=params.limit, offset=params.offset)

    # Return pagination info
    response = {
        "total": data["total"],
        "count": len(data["items"]),
        "offset": params.offset,
        "items": data["items"],
        "has_more": data["total"] > params.offset + len(data["items"]),
        "next_offset": params.offset + len(data["items"]) if data["total"] > params.offset + len(data["items"]) else None
    }
    return json.dumps(response, indent=2)
```

## Error Handling

Provide clear, actionable error messages:

```python
def _handle_api_error(e: Exception) -> str:
    '''Consistent error formatting across all tools.'''
    if isinstance(e, httpx.HTTPStatusError):
        if e.response.status_code == 404:
            return "Error: Resource not found. Please check the ID is correct."
        elif e.response.status_code == 403:
            return "Error: Permission denied. You don't have access to this resource."
        elif e.response.status_code == 429:
            return "Error: Rate limit exceeded. Please wait before making more requests."
        return f"Error: API request failed with status {e.response.status_code}"
    elif isinstance(e, httpx.TimeoutException):
        return "Error: Request timed out. Please try again."
    return f"Error: Unexpected error occurred: {type(e).__name__}"
```

## Shared Utilities

Extract common functionality into reusable functions:

```python
# Shared API request function
async def _make_api_request(endpoint: str, method: str = "GET", **kwargs) -> dict:
    '''Reusable function for all API calls.'''
    async with httpx.AsyncClient() as client:
        response = await client.request(
            method,
            f"{API_BASE_URL}/{endpoint}",
            timeout=30.0,
            **kwargs
        )
        response.raise_for_status()
        return response.json()
```

## Async/Await Best Practices

Always use async/await for network requests and I/O operations:

```python
# Good: Async network request
async def fetch_data(resource_id: str) -> dict:
    async with httpx.AsyncClient() as client:
        response = await client.get(f"{API_URL}/resource/{resource_id}")
        response.raise_for_status()
        return response.json()

# Bad: Synchronous request
def fetch_data(resource_id: str) -> dict:
    response = requests.get(f"{API_URL}/resource/{resource_id}")  # Blocks
    return response.json()
```

## Type Hints

Use type hints throughout:

```python
from typing import Optional, List, Dict, Any

async def get_user(user_id: str) -> Dict[str, Any]:
    data = await fetch_user(user_id)
    return {"id": data["id"], "name": data["name"]}
```

## Tool Docstrings

Every tool must have comprehensive docstrings with explicit type information:

```python
async def search_users(params: UserSearchInput) -> str:
    '''
    Search for users in the Example system by name, email, or team.

    This tool searches across all user profiles in the Example platform,
    supporting partial matches and various search filters. It does NOT
    create or modify users, only searches existing ones.

    Args:
        params (UserSearchInput): Validated input parameters containing:
            - query (str): Search string to match against names/emails (e.g., "john", "@example.com", "team:marketing")
            - limit (Optional[int]): Maximum results to return, between 1-100 (default: 20)
            - offset (Optional[int]): Number of results to skip for pagination (default: 0)

    Returns:
        str: JSON-formatted string containing search results with the following schema:

        Success response:
        {
            "total": int,           # Total number of matches found
            "count": int,           # Number of results in this response
            "offset": int,          # Current pagination offset
            "users": [
                {
                    "id": str,      # User ID (e.g., "U123456789")
                    "name": str,    # Full name (e.g., "John Doe")
                    "email": str,   # Email address (e.g., "john@example.com")
                    "team": str     # Team name (e.g., "Marketing") - optional
                }
            ]
        }

        Error response:
        "Error: <error message>" or "No users found matching '<query>'"

    Examples:
        - Use when: "Find all marketing team members" -> params with query="team:marketing"
        - Use when: "Search for John's account" -> params with query="john"
        - Don't use when: You need to create a user (use example_create_user instead)
        - Don't use when: You have a user ID and need full details (use example_get_user instead)

    Error Handling:
        - Input validation errors are handled by Pydantic model
        - Returns "Error: Rate limit exceeded" if too many requests (429 status)
        - Returns "Error: Invalid API authentication" if API key is invalid (401 status)
        - Returns formatted list of results or "No users found matching 'query'"
    '''
```

## Complete Example

See below for a complete Python MCP server example:

```python
#!/usr/bin/env python3
'''
MCP Server for Example Service.

This server provides tools to interact with Example API, including user search,
project management, and data export capabilities.
'''

from typing import Optional, List, Dict, Any
from enum import Enum
import httpx
from pydantic import BaseModel, Field, field_validator, ConfigDict
from mcp.server.fastmcp import FastMCP

# Initialize the MCP server
mcp = FastMCP("example_mcp")

# Constants
API_BASE_URL = "https://api.example.com/v1"

# Enums
class ResponseFormat(str, Enum):
    '''Output format for tool responses.'''
    MARKDOWN = "markdown"
    JSON = "json"

# Pydantic Models for Input Validation
class UserSearchInput(BaseModel):
    '''Input model for user search operations.'''
    model_config = ConfigDict(
        str_strip_whitespace=True,
        validate_assignment=True
    )

    query: str = Field(..., description="Search string to match against names/emails", min_length=2, max_length=200)
    limit: Optional[int] = Field(default=20, description="Maximum results to return", ge=1, le=100)
    offset: Optional[int] = Field(default=0, description="Number of results to skip for pagination", ge=0)
    response_format: ResponseFormat = Field(default=ResponseFormat.MARKDOWN, description="Output format")

    @field_validator('query')
    @classmethod
    def validate_query(cls, v: str) -> str:
        if not v.strip():
            raise ValueError("Query cannot be empty or whitespace only")
        return v.strip()

# Shared utility functions
async def _make_api_request(endpoint: str, method: str = "GET", **kwargs) -> dict:
    '''Reusable function for all API calls.'''
    async with httpx.AsyncClient() as client:
        response = await client.request(
            method,
            f"{API_BASE_URL}/{endpoint}",
            timeout=30.0,
            **kwargs
        )
        response.raise_for_status()
        return response.json()

def _handle_api_error(e: Exception) -> str:
    '''Consistent error formatting across all tools.'''
    if isinstance(e, httpx.HTTPStatusError):
        if e.response.status_code == 404:
            return "Error: Resource not found. Please check the ID is correct."
        elif e.response.status_code == 403:
            return "Error: Permission denied. You don't have access to this resource."
        elif e.response.status_code == 429:
            return "Error: Rate limit exceeded. Please wait before making more requests."
        return f"Error: API request failed with status {e.response.status_code}"
    elif isinstance(e, httpx.TimeoutException):
        return "Error: Request timed out. Please try again."
    return f"Error: Unexpected error occurred: {type(e).__name__}"

# Tool definitions
@mcp.tool(
    name="example_search_users",
    annotations={
        "title": "Search Example Users",
        "readOnlyHint": True,
        "destructiveHint": False,
        "idempotentHint": True,
        "openWorldHint": True
    }
)
async def example_search_users(params: UserSearchInput) -> str:
    '''Search for users in the Example system by name, email, or team.

    [Full docstring as shown above]
    '''
    try:
        # Make API request using validated parameters
        data = await _make_api_request(
            "users/search",
            params={
                "q": params.query,
                "limit": params.limit,
                "offset": params.offset
            }
        )

        users = data.get("users", [])
        total = data.get("total", 0)

        if not users:
            return f"No users found matching '{params.query}'"

        # Format response based on requested format
        if params.response_format == ResponseFormat.MARKDOWN:
            lines = [f"# User Search Results: '{params.query}'", ""]
            lines.append(f"Found {total} users (showing {len(users)})")
            lines.append("")

            for user in users:
                lines.append(f"## {user['name']} ({user['id']})")
                lines.append(f"- **Email**: {user['email']}")
                if user.get('team'):
                    lines.append(f"- **Team**: {user['team']}")
                lines.append("")

            return "\n".join(lines)

        else:
            # Machine-readable JSON format
            import json
            response = {
                "total": total,
                "count": len(users),
                "offset": params.offset,
                "users": users
            }
            return json.dumps(response, indent=2)

    except Exception as e:
        return _handle_api_error(e)

if __name__ == "__main__":
    mcp.run()
```

---

## Advanced FastMCP Features

### Context Parameter Injection

FastMCP can automatically inject a `Context` parameter into tools for advanced capabilities like logging, progress reporting, resource reading, and user interaction:

```python
from mcp.server.fastmcp import FastMCP, Context

mcp = FastMCP("example_mcp")

@mcp.tool()
async def advanced_search(query: str, ctx: Context) -> str:
    '''Advanced tool with context access for logging and progress.'''

    # Report progress for long operations
    await ctx.report_progress(0.25, "Starting search...")

    # Log information for debugging
    await ctx.log_info("Processing query", {"query": query, "timestamp": datetime.now()})

    # Perform search
    results = await search_api(query)
    await ctx.report_progress(0.75, "Formatting results...")

    # Access server configuration
    server_name = ctx.fastmcp.name

    return format_results(results)

@mcp.tool()
async def interactive_tool(resource_id: str, ctx: Context) -> str:
    '''Tool that can request additional input from users.'''

    # Request sensitive information when needed
    api_key = await ctx.elicit(
        prompt="Please provide your API key:",
        input_type="password"
    )

    # Use the provided key
    return await api_call(resource_id, api_key)
```

**Context capabilities:**
- `ctx.report_progress(progress, message)` - Report progress for long operations
- `ctx.log_info(message, data)` / `ctx.log_error()` / `ctx.log_debug()` - Logging
- `ctx.elicit(prompt, input_type)` - Request input from users
- `ctx.fastmcp.name` - Access server configuration
- `ctx.read_resource(uri)` - Read MCP resources

### Resource Registration

Expose data as resources for efficient, template-based access:

```python
@mcp.resource("file://documents/{name}")
async def get_document(name: str) -> str:
    '''Expose documents as MCP resources.

    Resources are useful for static or semi-static data that doesn't
    require complex parameters. They use URI templates for flexible access.
    '''
    document_path = f"./docs/{name}"
    with open(document_path, "r") as f:
        return f.read()

@mcp.resource("config://settings/{key}")
async def get_setting(key: str, ctx: Context) -> str:
    '''Expose configuration as resources with context.'''
    settings = await load_settings()
    return json.dumps(settings.get(key, {}))
```

**When to use Resources vs Tools:**
- **Resources**: For data access with simple parameters (URI templates)
- **Tools**: For complex operations with validation and business logic

### Structured Output Types

FastMCP supports multiple return types beyond strings:

```python
from typing import TypedDict
from dataclasses import dataclass
from pydantic import BaseModel

# TypedDict for structured returns
class UserData(TypedDict):
    id: str
    name: str
    email: str

@mcp.tool()
async def get_user_typed(user_id: str) -> UserData:
    '''Returns structured data - FastMCP handles serialization.'''
    return {"id": user_id, "name": "John Doe", "email": "john@example.com"}

# Pydantic models for complex validation
class DetailedUser(BaseModel):
    id: str
    name: str
    email: str
    created_at: datetime
    metadata: Dict[str, Any]

@mcp.tool()
async def get_user_detailed(user_id: str) -> DetailedUser:
    '''Returns Pydantic model - automatically generates schema.'''
    user = await fetch_user(user_id)
    return DetailedUser(**user)
```

### Lifespan Management

Initialize resources that persist across requests:

```python
from contextlib import asynccontextmanager

@asynccontextmanager
async def app_lifespan():
    '''Manage resources that live for the server's lifetime.'''
    # Initialize connections, load config, etc.
    db = await connect_to_database()
    config = load_configuration()

    # Make available to all tools
    yield {"db": db, "config": config}

    # Cleanup on shutdown
    await db.close()

mcp = FastMCP("example_mcp", lifespan=app_lifespan)

@mcp.tool()
async def query_data(query: str, ctx: Context) -> str:
    '''Access lifespan resources through context.'''
    db = ctx.request_context.lifespan_state["db"]
    results = await db.query(query)
    return format_results(results)
```

### Transport Options

FastMCP supports two main transport mechanisms:

```python
# stdio transport (for local tools) - default
if __name__ == "__main__":
    mcp.run()

# Streamable HTTP transport (for remote servers)
if __name__ == "__main__":
    mcp.run(transport="streamable_http", port=8000)
```

**Transport selection:**
- **stdio**: Command-line tools, local integrations, subprocess execution
- **Streamable HTTP**: Web services, remote access, multiple clients

---

## Code Best Practices

### Code Composability and Reusability

Your implementation MUST prioritize composability and code reuse:

1. **Extract Common Functionality**:
   - Create reusable helper functions for operations used across multiple tools
   - Build shared API clients for HTTP requests instead of duplicating code
   - Centralize error handling logic in utility functions
   - Extract business logic into dedicated functions that can be composed
   - Extract shared markdown or JSON field selection & formatting functionality

2. **Avoid Duplication**:
   - NEVER copy-paste similar code between tools
   - If you find yourself writing similar logic twice, extract it into a function
   - Common operations like pagination, filtering, field selection, and formatting should be shared
   - Authentication/authorization logic should be centralized

### Python-Specific Best Practices

1. **Use Type Hints**: Always include type annotations for function parameters and return values
2. **Pydantic Models**: Define clear Pydantic models for all input validation
3. **Avoid Manual Validation**: Let Pydantic handle input validation with constraints
4. **Proper Imports**: Group imports (standard library, third-party, local)
5. **Error Handling**: Use specific exception types (httpx.HTTPStatusError, not generic Exception)
6. **Async Context Managers**: Use `async with` for resources that need cleanup
7. **Constants**: Define module-level constants in UPPER_CASE

## Quality Checklist

Before finalizing your Python MCP server implementation, ensure:

### Strategic Design
- [ ] Tools enable complete workflows, not just API endpoint wrappers
- [ ] Tool names reflect natural task subdivisions
- [ ] Response formats optimize for agent context efficiency
- [ ] Human-readable identifiers used where appropriate
- [ ] Error messages guide agents toward correct usage

### Implementation Quality
- [ ] FOCUSED IMPLEMENTATION: Most important and valuable tools implemented
- [ ] All tools have descriptive names and documentation
- [ ] Return types are consistent across similar operations
- [ ] Error handling is implemented for all external calls
- [ ] Server name follows format: `{service}_mcp`
- [ ] All network operations use async/await
- [ ] Common functionality is extracted into reusable functions
- [ ] Error messages are clear, actionable, and educational
- [ ] Outputs are properly validated and formatted

### Tool Configuration
- [ ] All tools implement 'name' and 'annotations' in the decorator
- [ ] Annotations correctly set (readOnlyHint, destructiveHint, idempotentHint, openWorldHint)
- [ ] All tools use Pydantic BaseModel for input validation with Field() definitions
- [ ] All Pydantic Fields have explicit types and descriptions with constraints
- [ ] All tools have comprehensive docstrings with explicit input/output types
- [ ] Docstrings include complete schema structure for dict/JSON returns
- [ ] Pydantic models handle input validation (no manual validation needed)

### Advanced Features (where applicable)
[TRUNCATED]
```

skills/oraclepack-tickets-pack-grouped/references/attachment-minimization.md
```
# Attachment minimization rules (Grouped Tickets Stage 1 — Direct Attach)

Objective: keep each group pack focused and portable.

## Ticket attachments

- Ticket files are attached directly in each step via `${ticket_args[@]}`.
- Use `group_max_files` (default 25) to bound per-pack ticket count.
- If a group is larger than the cap, split into multiple packs (part 1..N).

## Non-ticket attachments (repo evidence)

- Keep explicit non-ticket attachments to **0–1 per step**.
- Prefer a single high-signal file that clarifies contracts or a key code path.

## extra_files (literal append)

- If `extra_files` is provided, append it literally to every oracle command.
- It may include additional `-f/--file` flags.
- Place `extra_files` on its own line with a comment:
  - `# extra_files appended literally`

```

skills/oraclepack-tickets-pack-grouped/references/ticket-grouping.md
```
# Ticket grouping (deterministic, inferred)

Objective: split tickets into focused topic/domain groups and generate one pack per group.

## Inputs

- `ticket_root` (default `.tickets`)
- `ticket_glob` (default `**/*.md`, relative to `ticket_root`)
- `ticket_paths` (optional; comma-separated explicit files; if present, ignore `ticket_glob`)
- `group_mode` (default `subdir+infer`)
- `group_min_score` (default `0.08`)
- `group_max_files` (default `25`; max tickets per pack; >0)
- `group_max_chars` (default `200000`; max total chars per pack; >0)
- `dedupe_mode` (default `report`; one of `off`, `report`, `prune`, `merge`)
- `dedupe_jaccard` (default `0.55`)
- `dedupe_overlap_hi` (default `0.80`)
- `dedupe_overlap_lo` (default `0.70`)
- `dedupe_delta_min` (default `0.15`)
- `dedupe_body_chars` (default `2000`)

## Deterministic grouping rules

1) Collect tickets:
- If `ticket_paths` is non-empty: split on commas, trim whitespace, use exactly that list.
- Else: glob `ticket_root/ticket_glob`.
- Always sort lexicographically by path string.

2) Detect possible duplicates (if `dedupe_mode != off`):
- Signature: filename stem + first heading + first `dedupe_body_chars` chars.
- Compute `jaccard` + `overlap` between tickets.
- Duplicate edge rule:
  - `overlap >= dedupe_overlap_hi` OR (`jaccard >= dedupe_jaccard` AND `overlap >= dedupe_overlap_lo`)
- Connected components become duplicate clusters.
- Canonical: largest content length; tie-break lexicographic.
- Delta vs redundant:
  - delta if unique token ratio >= `dedupe_delta_min` OR heading differs materially.
  - redundant otherwise.

3) Seed groups by subdir:
- For any path under `ticket_root/<group>/...`, assign to group `<group>`.
- Tickets directly under `ticket_root/` are "loose".

4) Infer loose tickets into groups (if any groups exist):
- Build a token set for each group from:
  - group name tokens
  - ticket filenames (stem tokens)
  - first Markdown heading line (if present)
- For each loose ticket, compute Jaccard overlap score with each group token set.
- If `max_score >= group_min_score`, assign to the best group (stable tie-break by group name).
- Otherwise, assign to `misc`.

5) If no groups exist:
- Put all tickets into a single group named `root`.

6) Merge duplicates into primary group:
- `report`: attach all tickets in the cluster to the canonical’s group.
- `prune`: attach canonical + delta only; drop redundant from attachments.
- `merge`: create `out_dir/_ticket_merges/cluster-XXXX.md` and attach only the merged file.
- Emit `_dupes_possible.json`, `_duplicates.json`, and `_dedupe_plan.json`.

7) Split oversized groups:
- If a group exceeds `group_max_files` or `group_max_chars`, split into parts (1..N)
  in sorted order, chunked deterministically.

Hard rule: do not use mtimes, file sizes, or external ML services.

## Required outputs

- `_groups.json`: mapping of group -> list of ticket paths (lexicographic order)
- Pack file per group (and part), each self-contained and direct-attach
- `manifest.json`: groups with pack path + attached vs original ticket lists
```

skills/oraclepack-tickets-pack-grouped/references/tickets-pack-template-bundle.md
```
# Oracle Pack — {{codebase_name}} (Tickets Stage 1)

## Parsed args
- codebase_name: {{codebase_name}}
- out_dir: {{out_dir}}
- oracle_cmd: {{oracle_cmd}}
- oracle_flags: {{oracle_flags}}
- extra_files: {{extra_files}}
- ticket_root: {{ticket_root}}
- ticket_glob: {{ticket_glob}}
- ticket_paths: {{ticket_paths}}
- ticket_bundle_path: {{ticket_bundle_path}}
- mode: {{mode}}

Notes (contract):
- Exactly one fenced `bash` block in this document.
- No other ``` fences anywhere.
- Exactly 20 steps, numbered 01..20 in order.
- Step header: `# NN) ROI=... impact=... confidence=... effort=... horizon=... category=... reference=...`
- Every step includes: `--write-output "{{out_dir}}/NN-<slug>.md"` (double quotes required).
- Steps must be self-contained and must not rely on shell variables created in previous steps.
- `## Coverage check` MUST be outside the bash fence (after the closing ```).

```bash
# Prelude (allowed inside the single bash fence)
# - Creates out_dir deterministically
# - Builds ticket_bundle_path deterministically from ticket_root/ticket_glob OR ticket_paths
# - Uses lexicographic ordering only (no mtime/timestamps)

set -euo pipefail

mkdir -p "{{out_dir}}"

python3 - <<'PY'
from __future__ import annotations

import sys
from pathlib import Path

CODEBASE_NAME = "{{codebase_name}}"
OUT_DIR = Path("{{out_dir}}")
TICKET_ROOT = Path("{{ticket_root}}")
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS_RAW = "{{ticket_paths}}".strip()
BUNDLE_PATH = Path("{{ticket_bundle_path}}")

def _read_text(p: Path) -> str:
    return p.read_text(encoding="utf-8", errors="replace")

def _title_from_md(text: str) -> str:
    for ln in text.splitlines():
        s = ln.strip()
        if s.startswith("# "):
            return s[2:].strip() or "Untitled"
    for ln in text.splitlines():
        s = ln.strip()
        if s:
            return s[:80]
    return "Untitled"

def _select_paths() -> list[Path]:
    if TICKET_PATHS_RAW:
        items = [Path(x.strip()) for x in TICKET_PATHS_RAW.split(",") if x.strip()]
        items = sorted(items, key=lambda p: str(p))
        return items

    if not TICKET_ROOT.exists():
        return []

    items = sorted(TICKET_ROOT.glob(TICKET_GLOB), key=lambda p: str(p))
    return items

paths = _select_paths()

BUNDLE_PATH.parent.mkdir(parents=True, exist_ok=True)

lines: list[str] = []
lines.append(f"# Tickets Bundle — {CODEBASE_NAME if CODEBASE_NAME else 'Unknown'}")
lines.append("")
lines.append("## Selection")
lines.append(f"- ticket_root: {TICKET_ROOT}")
lines.append(f"- ticket_glob: {TICKET_GLOB}")
lines.append(f"- ticket_paths: {TICKET_PATHS_RAW if TICKET_PATHS_RAW else '(none)'}")
lines.append("- ordering: lexicographic by path")
lines.append("")

if not paths:
    warn = (
        "## WARNING: No tickets found\n\n"
        "No ticket files were selected.\n\n"
        "What was attempted:\n"
        f"- ticket_root: {TICKET_ROOT}\n"
        f"- ticket_glob: {TICKET_GLOB}\n"
        f"- ticket_paths: {TICKET_PATHS_RAW if TICKET_PATHS_RAW else '(none)'}\n\n"
        "Next: provide explicit ticket_paths or create tickets under ticket_root.\n"
    )
    lines.append(warn)
    print(f"[WARN] No tickets selected; bundle will contain only WARNING.", file=sys.stderr)
else:
    lines.append("## Tickets")
    lines.append("")
    for p in paths:
        lines.append("---")
        lines.append(f"### {_title_from_md(_read_text(p))}")
        lines.append(f"- path: {p}")
        lines.append("")
        try:
            txt = _read_text(p)
        except Exception as e:
            lines.append(f"[ERROR reading file: {e}]")
            lines.append("")
            continue

        # Simple truncation policy: keep first 4000 chars if large.
        if len(txt) > 4000:
            lines.append(txt[:4000])
            lines.append("\n[... truncated ...]\n")
        else:
            lines.append(txt)

        lines.append("")

BUNDLE_PATH.write_text("\n".join(lines).rstrip() + "\n", encoding="utf-8")
print(f"[OK] Wrote ticket bundle: {BUNDLE_PATH}")
PY

# 01) ROI=8.0 impact=9 confidence=0.9 effort=1 horizon=Immediate category=contracts/interfaces reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/01-contracts-interfaces-surface.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #01
Category: contracts/interfaces

Using the attached tickets bundle as the primary evidence, identify the primary public interface(s) implied by the tickets (CLI commands, APIs, file contracts, or user workflows).
For each interface:
- list key inputs/outputs
- list the exact files/modules likely defining it (if unknown, say Unknown)

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 02) ROI=7.8 impact=8 confidence=0.9 effort=1 horizon=Immediate category=contracts/interfaces reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/02-contracts-interfaces-dependencies.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #02
Category: contracts/interfaces

From the attached tickets bundle, infer which external dependencies/services the system must integrate with (CLIs, APIs, SaaS, databases).
For each dependency:
- what contract is required (auth, endpoints, file formats)
- what configuration surface is implied

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 03) ROI=7.6 impact=8 confidence=0.85 effort=2 horizon=Immediate category=invariants reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/03-invariants-must-always-hold.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #03
Category: invariants

Based on the attached tickets bundle, list the invariants that must always hold (data constraints, ordering constraints, security invariants, idempotency).
For each invariant:
- what breaks if violated
- where it should be enforced (layer/module; if unknown, Unknown)

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 04) ROI=7.2 impact=8 confidence=0.8 effort=2 horizon=Immediate category=invariants reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/04-invariants-input-validation.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #04
Category: invariants

Using the attached tickets bundle, identify what inputs must be validated (CLI args, config fields, payloads, file paths).
For each input:
- validation rules implied
- failure message/behavior implied

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 05) ROI=7.0 impact=7 confidence=0.85 effort=2 horizon=Near category=caching/state reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/05-caching-state-state-model.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #05
Category: caching/state

From the attached tickets bundle, infer what state must be persisted or cached (files, DB, in-memory, remote).
For each state item:
- read/write lifecycle
- consistency model implied
- failure recovery requirements

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 06) ROI=6.8 impact=7 confidence=0.8 effort=2 horizon=Near category=caching/state reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/06-caching-state-cache-invalidation.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #06
Category: caching/state

Using the attached tickets bundle, identify caching risks: staleness, invalidation, keying, or race conditions implied by the tickets.
Propose a minimal caching strategy consistent with the tickets.

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 07) ROI=6.9 impact=8 confidence=0.75 effort=3 horizon=Near category=background jobs reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/07-background-jobs-what-runs-async.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #07
Category: background jobs

From the attached tickets bundle, determine what work should run asynchronously/background (schedulers, queues, cron, long-running tasks).
For each job:
- trigger
- inputs/outputs
- retry/backoff requirements

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 08) ROI=6.6 impact=7 confidence=0.75 effort=3 horizon=Near category=background jobs reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/08-background-jobs-idempotency.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #08
Category: background jobs

Using the attached tickets bundle, list the idempotency and concurrency constraints implied for background jobs.
Recommend minimal safeguards (dedupe keys, locks, at-least-once handling) aligned with tickets.

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 09) ROI=7.4 impact=8 confidence=0.8 effort=2 horizon=Immediate category=observability reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/09-observability-logs-metrics-traces.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #09
Category: observability

From the attached tickets bundle, infer required observability: logs, metrics, traces, and user-visible diagnostics.
List:
- what to log/measure
- cardinality risks
- minimal dashboards/alerts implied

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 10) ROI=7.0 impact=7 confidence=0.8 effort=2 horizon=Near category=observability reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/10-observability-error-taxonomy.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #10
Category: observability

Using the attached tickets bundle, define an error taxonomy consistent with ticket failure modes:
- user errors vs system errors
- retryable vs non-retryable
- how errors should surface (CLI exit codes, UI states, logs)

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 11) ROI=7.6 impact=9 confidence=0.75 effort=3 horizon=Immediate category=permissions reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/11-permissions-authz-model.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #11
Category: permissions

From the attached tickets bundle, infer the permissions model (roles, capabilities, scopes).
List:
- what operations require permissions
- how permissions are granted/revoked
- audit requirements implied

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 12) ROI=7.0 impact=8 confidence=0.75 effort=3 horizon=Near category=permissions reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/12-permissions-secret-handling.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #12
Category: permissions

Using the attached tickets bundle, identify sensitive data/secret handling needs.
Recommend:
- where secrets come from (env, files, vault)
- redaction rules
- least-privilege defaults

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 13) ROI=7.2 impact=8 confidence=0.8 effort=2 horizon=Near category=migrations reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/13-migrations-data-changes.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #13
Category: migrations

From the attached tickets bundle, infer any data/schema/config migrations needed.
For each migration:
- trigger/versioning
- rollout plan
- rollback strategy

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 14) ROI=6.8 impact=7 confidence=0.8 effort=2 horizon=Near category=migrations reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/14-migrations-compatibility.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #14
Category: migrations

Using the attached tickets bundle, identify backwards/forwards compatibility requirements during migration windows.
Recommend minimal compatibility shims or staged rollout steps.

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 15) ROI=7.4 impact=8 confidence=0.8 effort=2 horizon=Immediate category=UX flows reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/15-ux-flows-primary-journeys.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #15
Category: UX flows

From the attached tickets bundle, map the primary user journeys implied by tickets.
For each journey:
- entry points
- steps/screens/commands
- success criteria and user feedback

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 16) ROI=6.9 impact=7 confidence=0.8 effort=2 horizon=Near category=UX flows reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/16-ux-flows-edge-cases.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #16
Category: UX flows

Using the attached tickets bundle, list UX edge cases and failure UX:
- partial completion
- retries
- cancellation
- timeouts
- conflict resolution

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 17) ROI=7.8 impact=9 confidence=0.8 effort=2 horizon=Immediate category=failure modes reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/17-failure-modes-top-risks.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #17
Category: failure modes

From the attached tickets bundle, enumerate the most likely failure modes.
For each failure mode:
- detection signal
- mitigation
- user-visible behavior

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 18) ROI=7.0 impact=8 confidence=0.75 effort=3 horizon=Near category=failure modes reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/18-failure-modes-test-plan.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #18
Category: failure modes

Using the attached tickets bundle, propose a minimal test plan that covers the highest-risk failure modes.
Include:
- unit vs integration coverage split
- fixtures/mocks needed
- one smallest test to write first

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 19) ROI=7.3 impact=8 confidence=0.8 effort=2 horizon=Near category=feature flags reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/19-feature-flags-needed.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #19
Category: feature flags

From the attached tickets bundle, infer where feature flags or staged rollouts are needed.
For each flag:
- what it gates
- default value
- sunset plan

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 20) ROI=6.8 impact=7 confidence=0.8 effort=2 horizon=Near category=feature flags reference=Unknown
{{oracle_cmd}} {{oracle_flags}} \
  --write-output "{{out_dir}}/20-feature-flags-observability.md" \
  -f "{{ticket_bundle_path}}" {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #20
Category: feature flags

Using the attached tickets bundle, propose how to observe/validate a flagged rollout:
- success metrics
- rollback triggers
- logging/alert changes while enabled

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"
```

## Coverage check

*   contracts/interfaces: OK
*   invariants: OK
*   caching/state: OK
*   background jobs: OK
*   observability: OK
*   permissions: OK
*   migrations: OK
*   UX flows: OK
*   failure modes: OK
*   feature flags: OK

```
```

skills/oraclepack-tickets-pack-grouped/references/tickets-pack-template.md
```
# Oracle Pack — {{codebase_name}} (Grouped Tickets Stage 1 — Direct Attach)

## Parsed args
- codebase_name: {{codebase_name}}
- out_dir: {{out_dir}}
- oracle_cmd: {{oracle_cmd}}
- oracle_flags: {{oracle_flags}}
- extra_files: {{extra_files}}
- ticket_root: {{ticket_root}}
- ticket_glob: {{ticket_glob}}
- ticket_paths: {{ticket_paths}}
- ticket_max_files: {{ticket_max_files}}
- group_name: {{group_name}}
- group_slug: {{group_slug}}
- mode: {{mode}}

Notes (contract):
- Exactly one fenced `bash` block in this document.
- No other ``` fences anywhere.
- Exactly 20 steps, numbered 01..20 in order.
- Step header: `# NN) ROI=... impact=... confidence=... effort=... horizon=... category=... reference=...`
- Every step includes: `--write-output "{{out_dir}}/NN-<slug>.md"` (double quotes required).
- Steps must be self-contained and must not rely on shell variables created in previous steps.
- Each step must attach tickets directly (no `_tickets_bundle.md` dependency).
- Pack ends with a Coverage check section listing all 10 categories as OK or Missing(<step ids>).

```bash
set -euo pipefail

mkdir -p "{{out_dir}}"

# 01) ROI=4.8 impact=6 confidence=0.80 effort=1 horizon=Immediate category=contracts/interfaces reference={{group_slug}}

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
MAX = int("{{ticket_max_files}}")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group '{{group_name}}'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
{{oracle_cmd}}   {{oracle_flags}}   --write-output "{{out_dir}}/01-contracts-interfaces-ticket-surface.md"   "${ticket_args[@]}"   {{extra_files}}   -p "$(cat <<'PROMPT'
Strategist question #01  (ticket-driven, group: {{group_name}})

Reference: {{group_slug}}
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.8 (impact=6, confidence=0.80, effort=1)

Question:
Using the attached tickets as the primary context, list the public surface changes implied by the tickets (CLI/TUI/API/interfaces/contracts); call out backwards-compat constraints.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 02) ROI=4.6 impact=6 confidence=0.78 effort=1 horizon=Immediate category=contracts/interfaces reference={{group_slug}}

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
MAX = int("{{ticket_max_files}}")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group '{{group_name}}'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
{{oracle_cmd}}   {{oracle_flags}}   --write-output "{{out_dir}}/02-contracts-interfaces-integration-points.md"   "${ticket_args[@]}"   {{extra_files}}   -p "$(cat <<'PROMPT'
Strategist question #02  (ticket-driven, group: {{group_name}})

Reference: {{group_slug}}
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.6 (impact=6, confidence=0.78, effort=1)

Question:
Using the attached tickets as the primary context, identify external integrations implied by the tickets; required config/contract changes; failure/timeout behavior; minimal compat-safe rollout.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 03) ROI=5.1 impact=7 confidence=0.74 effort=1 horizon=NearTerm category=invariants reference={{group_slug}}

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
MAX = int("{{ticket_max_files}}")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group '{{group_name}}'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
{{oracle_cmd}}   {{oracle_flags}}   --write-output "{{out_dir}}/03-invariants-invariant-map.md"   "${ticket_args[@]}"   {{extra_files}}   -p "$(cat <<'PROMPT'
Strategist question #03  (ticket-driven, group: {{group_name}})

Reference: {{group_slug}}
Category: invariants
Horizon: NearTerm
ROI: 5.1 (impact=7, confidence=0.74, effort=1)

Question:
Using the attached tickets as the primary context, extract system invariants implied by tickets (inputs/outputs, pack schema rules, step execution rules) and where to enforce them.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 04) ROI=5.0 impact=7 confidence=0.72 effort=2 horizon=NearTerm category=invariants reference={{group_slug}}

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
MAX = int("{{ticket_max_files}}")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group '{{group_name}}'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
{{oracle_cmd}}   {{oracle_flags}}   --write-output "{{out_dir}}/04-invariants-validation-boundaries.md"   "${ticket_args[@]}"   {{extra_files}}   -p "$(cat <<'PROMPT'
Strategist question #04  (ticket-driven, group: {{group_name}})

Reference: {{group_slug}}
Category: invariants
Horizon: NearTerm
ROI: 5.0 (impact=7, confidence=0.72, effort=2)

Question:
Using the attached tickets as the primary context, identify validation boundaries that must exist (ticket parsing, pack generation, pack validation); propose minimal validation plan.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 05) ROI=4.4 impact=6 confidence=0.78 effort=2 horizon=NearTerm category=caching/state reference={{group_slug}}

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
MAX = int("{{ticket_max_files}}")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group '{{group_name}}'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
{{oracle_cmd}}   {{oracle_flags}}   --write-output "{{out_dir}}/05-caching-state-state-artifacts.md"   "${ticket_args[@]}"   {{extra_files}}   -p "$(cat <<'PROMPT'
Strategist question #05  (ticket-driven, group: {{group_name}})

Reference: {{group_slug}}
Category: caching/state
Horizon: NearTerm
ROI: 4.4 (impact=6, confidence=0.78, effort=2)

Question:
Using the attached tickets as the primary context, identify state/artifacts that must be produced and preserved; schema/format expectations; stability/back-compat requirements.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 06) ROI=4.2 impact=6 confidence=0.75 effort=2 horizon=NearTerm category=caching/state reference={{group_slug}}

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
MAX = int("{{ticket_max_files}}")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group '{{group_name}}'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
{{oracle_cmd}}   {{oracle_flags}}   --write-output "{{out_dir}}/06-caching-state-cache-keys.md"   "${ticket_args[@]}"   {{extra_files}}   -p "$(cat <<'PROMPT'
Strategist question #06  (ticket-driven, group: {{group_name}})

Reference: {{group_slug}}
Category: caching/state
Horizon: NearTerm
ROI: 4.2 (impact=6, confidence=0.75, effort=2)

Question:
Using the attached tickets as the primary context, identify any caching opportunities/risks (discovery caches, pack outputs, oracle outputs); define cache keys, invalidation, and correctness risks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 07) ROI=4.3 impact=6 confidence=0.70 effort=2 horizon=MidTerm category=background jobs reference={{group_slug}}

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
MAX = int("{{ticket_max_files}}")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group '{{group_name}}'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
{{oracle_cmd}}   {{oracle_flags}}   --write-output "{{out_dir}}/07-background-jobs-job-model.md"   "${ticket_args[@]}"   {{extra_files}}   -p "$(cat <<'PROMPT'
Strategist question #07  (ticket-driven, group: {{group_name}})

Reference: {{group_slug}}
Category: background jobs
Horizon: MidTerm
ROI: 4.3 (impact=6, confidence=0.70, effort=2)

Question:
Using the attached tickets as the primary context, identify any background/async work implied (jobs, queues, long-running operations); define responsibilities and interfaces.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 08) ROI=4.0 impact=6 confidence=0.68 effort=3 horizon=MidTerm category=background jobs reference={{group_slug}}

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
MAX = int("{{ticket_max_files}}")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group '{{group_name}}'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
{{oracle_cmd}}   {{oracle_flags}}   --write-output "{{out_dir}}/08-background-jobs-queue-failure.md"   "${ticket_args[@]}"   {{extra_files}}   -p "$(cat <<'PROMPT'
Strategist question #08  (ticket-driven, group: {{group_name}})

Reference: {{group_slug}}
Category: background jobs
Horizon: MidTerm
ROI: 4.0 (impact=6, confidence=0.68, effort=3)

Question:
Using the attached tickets as the primary context, define how background failures are handled (retries, idempotency, poison messages); define observability hooks.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 09) ROI=4.7 impact=7 confidence=0.76 effort=1 horizon=Immediate category=observability reference={{group_slug}}

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
MAX = int("{{ticket_max_files}}")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group '{{group_name}}'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
{{oracle_cmd}}   {{oracle_flags}}   --write-output "{{out_dir}}/09-observability-logging-metrics.md"   "${ticket_args[@]}"   {{extra_files}}   -p "$(cat <<'PROMPT'
Strategist question #09  (ticket-driven, group: {{group_name}})

Reference: {{group_slug}}
Category: observability
Horizon: Immediate
ROI: 4.7 (impact=7, confidence=0.76, effort=1)

Question:
Using the attached tickets as the primary context, define what logging/metrics must exist to debug pack generation + step execution; propose minimal instrumentation plan.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 10) ROI=4.5 impact=7 confidence=0.74 effort=2 horizon=Immediate category=observability reference={{group_slug}}

# tickets attached directly (deterministic; self-contained)
mapfile -t __tickets < <(python3 - <<'PY'
from __future__ import annotations
from pathlib import Path

TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
MAX = int("{{ticket_max_files}}")

root = Path(TICKET_ROOT)

def lex_sorted(ps):
    return sorted((str(p) for p in ps), key=lambda s: s)

if TICKET_PATHS:
    tickets = [Path(p.strip()) for p in TICKET_PATHS.split(",") if p.strip()]
else:
    tickets = list(root.glob(TICKET_GLOB)) if root.exists() else []

tickets = [Path(p) for p in lex_sorted(tickets)]
if MAX and MAX > 0:
    tickets = tickets[:MAX]

for p in tickets:
    print(str(p))
PY
)

ticket_args=()
for p in "${__tickets[@]}"; do
  ticket_args+=(-f "$p")
done

if [ "${#ticket_args[@]}" -eq 0 ]; then
  echo "WARNING: no tickets resolved for group '{{group_name}}'." >&2
fi

# extra_files appended literally (may be empty; may include -f/--file):
{{oracle_cmd}}   {{oracle_flags}}   --write-output "{{out_dir}}/10-observability-tracing.md"   "${ticket_args[@]}"   {{extra_files}}   -p "$(cat <<'PROMPT'
Strategist question #10  (ticket-driven, group: {{group_name}})

Reference: {{group_slug}}
Category: observability
Horizon: Immediate
ROI: 4.5 (impact=7, confidence=0.74, effort=2)

Question:
Using the attached tickets as the primary context, define tracing/correlation strategy across pack steps and downstream tools; identify required IDs and propagation.

Constraints: None
Non-goals: None

Answer format:
[TRUNCATED]
```

skills/oraclepack-tickets-pack-grouped/scripts/generate_grouped_packs.py
```
#!/usr/bin/env python3
from __future__ import annotations

import datetime as _dt
import math
import json
import re
import sys
from pathlib import Path
from typing import Dict, Iterable, List, Tuple

STOPWORDS = {
    "the", "and", "for", "with", "from", "this", "that", "into", "over", "under", "when",
    "then", "than", "else", "only", "must", "should", "could", "would", "will", "shall",
    "ticket", "tickets", "oraclepack", "oracle", "pack", "packs",
}


def _parse_kv_args(argv: List[str]) -> Dict[str, str]:
    args: Dict[str, str] = {}
    for raw in argv:
        if "=" not in raw:
            continue
        k, v = raw.split("=", 1)
        args[k.strip()] = v.strip()
    return args


def _today() -> str:
    return _dt.date.today().isoformat()


def _slugify(s: str) -> str:
    s = s.strip().lower()
    s = re.sub(r"[^a-z0-9]+", "-", s)
    s = re.sub(r"-+", "-", s).strip("-")
    return s or "group"


def _tokenize(text: str) -> List[str]:
    text = text.lower()
    text = re.sub(r"[^a-z0-9]+", " ", text)
    toks = [t for t in text.split() if len(t) >= 3 and t not in STOPWORDS]
    return toks


def _normalize_title(text: str) -> str:
    text = text.strip().lower()
    text = re.sub(r"[^a-z0-9]+", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text


def _read_heading(path: Path) -> str:
    try:
        for line in path.read_text(encoding="utf-8", errors="replace").splitlines():
            if line.startswith("#"):
                return line.lstrip("#").strip()
    except FileNotFoundError:
        return ""
    return ""


def _collect_ticket_paths(ticket_root: str, ticket_glob: str, ticket_paths: str) -> List[Path]:
    if ticket_paths:
        parts = [p.strip() for p in ticket_paths.split(",") if p.strip()]
        return [Path(p) for p in parts]
    root = Path(ticket_root)
    if not root.exists():
        return []
    return [Path(p) for p in root.glob(ticket_glob)]


def _read_signature(path: Path, max_lines: int = 40) -> Tuple[str, str]:
    heading = ""
    lines: List[str] = []
    try:
        for line in path.read_text(encoding="utf-8", errors="replace").splitlines():
            if not heading and line.startswith("#"):
                heading = line.lstrip("#").strip()
            if line.strip():
                lines.append(line.strip())
            if len(lines) >= max_lines:
                break
    except FileNotFoundError:
        pass
    return heading, " ".join(lines)


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8", errors="replace")
    except FileNotFoundError:
        return ""


def _group_by_subdir(paths: Iterable[Path], ticket_root: str) -> Tuple[Dict[str, List[Path]], List[Path]]:
    root = Path(ticket_root)
    groups: Dict[str, List[Path]] = {}
    loose: List[Path] = []
    for p in paths:
        try:
            rel = p.relative_to(root)
        except ValueError:
            loose.append(p)
            continue
        if len(rel.parts) >= 2:
            key = rel.parts[0]
            groups.setdefault(key, []).append(p)
        else:
            loose.append(p)
    return groups, loose


def _group_tokens(group_name: str, paths: Iterable[Path]) -> set:
    tokens = set(_tokenize(group_name))
    for p in paths:
        tokens.update(_tokenize(p.stem))
        tokens.update(_tokenize(_read_heading(p)))
    return tokens


def _ticket_tokens(p: Path) -> set:
    toks = set(_tokenize(p.stem))
    heading, snippet = _read_signature(p)
    toks.update(_tokenize(heading))
    toks.update(_tokenize(snippet))
    return toks


def _signature_tokens(p: Path, body_chars: int) -> set:
    heading = _read_heading(p)
    body = _read_text(p)
    body = body[:body_chars]
    toks = set(_tokenize(p.stem))
    toks.update(_tokenize(heading))
    toks.update(_tokenize(body))
    return toks


def _jaccard(a: set, b: set) -> float:
    if not a or not b:
        return 0.0
    inter = a.intersection(b)
    union = a.union(b)
    return float(len(inter)) / float(len(union))


def _overlap(a: set, b: set) -> float:
    if not a or not b:
        return 0.0
    inter = a.intersection(b)
    denom = min(len(a), len(b))
    if denom == 0:
        return 0.0
    return float(len(inter)) / float(denom)


def _clusters_from_edges(nodes: List[str], edges: Dict[str, List[str]]) -> List[List[str]]:
    seen = set()
    clusters: List[List[str]] = []
    for n in nodes:
        if n in seen:
            continue
        stack = [n]
        comp = []
        seen.add(n)
        while stack:
            cur = stack.pop()
            comp.append(cur)
            for nxt in edges.get(cur, []):
                if nxt not in seen:
                    seen.add(nxt)
                    stack.append(nxt)
        clusters.append(sorted(comp))
    return clusters


def _dedupe_clusters(
    paths: List[Path],
    body_chars: int,
    jaccard_hi: float,
    overlap_hi: float,
    overlap_lo: float,
    delta_min: float,
) -> Tuple[List[List[str]], Dict[str, str], Dict[str, Dict[str, object]], Dict[Tuple[str, str], Dict[str, float]]]:
    tokens: Dict[str, set] = {}
    sizes: Dict[str, int] = {}
    titles: Dict[str, str] = {}
    for p in paths:
        key = str(p)
        tokens[key] = _signature_tokens(p, body_chars)
        sizes[key] = len(_read_text(p))
        titles[key] = _normalize_title(_read_heading(p))

    nodes = sorted(tokens.keys())
    edges: Dict[str, List[str]] = {n: [] for n in nodes}
    pair_scores: Dict[Tuple[str, str], Dict[str, float]] = {}

    for i, a in enumerate(nodes):
        for b in nodes[i + 1 :]:
            jac = _jaccard(tokens[a], tokens[b])
            ov = _overlap(tokens[a], tokens[b])
            pair_scores[(a, b)] = {"jaccard": jac, "overlap": ov}
            if ov >= overlap_hi or (jac >= jaccard_hi and ov >= overlap_lo):
                edges[a].append(b)
                edges[b].append(a)

    clusters = _clusters_from_edges(nodes, edges)
    cluster_meta: Dict[str, Dict[str, object]] = {}
    dup_map: Dict[str, str] = {}

    for idx, members in enumerate(clusters, start=1):
        if len(members) == 1:
            continue
        # canonical: largest content length, then lexicographic
        canon = sorted(
            members,
            key=lambda m: (-sizes.get(m, 0), m),
        )[0]
        deltas: List[str] = []
        redundant: List[str] = []
        for m in members:
            if m == canon:
                continue
            unique = tokens[m] - tokens[canon]
            unique_ratio = float(len(unique)) / float(max(1, len(tokens[m])))
            heading_diff = titles.get(m, "") != titles.get(canon, "")
            if unique_ratio >= delta_min or heading_diff:
                deltas.append(m)
            else:
                redundant.append(m)
            dup_map[m] = canon

        cluster_meta[str(idx)] = {
            "canonical": canon,
            "members": members,
            "deltas": sorted(deltas),
            "redundant": sorted(redundant),
        }

    return clusters, dup_map, cluster_meta, pair_scores


def _infer_groups(
    groups: Dict[str, List[Path]],
    loose: List[Path],
    min_score: float,
) -> Dict[str, List[Path]]:
    if not groups:
        return {"root": list(loose)}

    group_tokens = {k: _group_tokens(k, v) for k, v in groups.items()}
    for p in loose:
        tokens = _ticket_tokens(p)
        best = None
        best_score = -1.0
        for name in sorted(group_tokens.keys()):
            score = _jaccard(tokens, group_tokens[name])
            if score > best_score:
                best_score = score
                best = name
        if best is not None and best_score >= min_score:
            groups.setdefault(best, []).append(p)
        else:
            groups.setdefault("misc", []).append(p)
    return groups


def _chunk(paths: List[Path], size: int) -> List[List[Path]]:
    if size <= 0:
        return [paths]
    return [paths[i : i + size] for i in range(0, len(paths), size)]


def _chunk_by_limits(
    paths: List[Path],
    max_files: int,
    max_chars: int,
) -> List[List[Path]]:
    if max_files <= 0 and max_chars <= 0:
        return [paths]
    chunks: List[List[Path]] = []
    cur: List[Path] = []
    cur_chars = 0
    for p in paths:
        size = len(_read_text(p))
        if cur:
            if (max_files > 0 and len(cur) >= max_files) or (
                max_chars > 0 and cur_chars + size > max_chars
            ):
                chunks.append(cur)
                cur = []
                cur_chars = 0
        cur.append(p)
        cur_chars += size
    if cur:
        chunks.append(cur)
    return chunks


def _render_template(template: str, mapping: Dict[str, str]) -> str:
    out = template
    for key, val in mapping.items():
        out = out.replace("{{" + key + "}}", val)
    unresolved = sorted(set(re.findall(r"\{\{([^}]+)\}\}", out)))
    if unresolved:
        raise ValueError(f"Unresolved template placeholders: {unresolved}")
    return out


def _write_merge_file(
    out_dir: Path,
    cluster_id: str,
    canonical: str,
    deltas: List[str],
    redundant: List[str],
    body_chars: int,
) -> Path:
    merge_dir = out_dir / "_ticket_merges"
    merge_dir.mkdir(parents=True, exist_ok=True)
    path = merge_dir / f"cluster-{int(cluster_id):04d}.md"

    def _cap(text: str) -> str:
        if len(text) <= body_chars:
            return text
        return text[:body_chars] + "\n[... truncated ...]\n"

    lines: List[str] = []
    lines.append(f"# Ticket Merge Cluster {cluster_id}")
    lines.append("")
    lines.append("## Canonical")
    lines.append(f"- path: {canonical}")
    lines.append("")
    lines.append(_cap(_read_text(Path(canonical))))
    lines.append("")

    members = deltas + redundant
    if members:
        lines.append("## Also reported in")
        for m in members:
            lines.append(f"- {m}")
        lines.append("")

    if deltas:
        lines.append("## Unique details from related tickets")
        for m in deltas:
            text = _read_text(Path(m))
            toks = _signature_tokens(Path(m), body_chars)
            canon_toks = _signature_tokens(Path(canonical), body_chars)
            unique = toks - canon_toks
            sel: List[str] = []
            for ln in text.splitlines():
                lnt = _tokenize(ln)
                if any(t in unique for t in lnt):
                    sel.append(ln)
                if len(sel) >= 60:
                    break
            lines.append(f"### {m}")
            if sel:
                lines.extend(sel)
            else:
                lines.append("(no unique lines detected within cap)")
            lines.append("")

    path.write_text("\n".join(lines), encoding="utf-8")
    return path


def main() -> int:
    if len(sys.argv) == 1:
        print("Select how to run:")
        print("1) Use defaults (no args)")
        print("2) Provide custom args (show usage)")
        choice = input("Enter choice [1-2]: ").strip() or "1"
        if choice == "2":
            print("Usage: generate_grouped_packs.py key=value [key=value ...]")
            return 0

    args = _parse_kv_args(sys.argv[1:])
    codebase_name = args.get("codebase_name", "Unknown")
    out_dir = args.get("out_dir", f"docs/oracle-questions-{_today()}")
    oracle_cmd = args.get("oracle_cmd", "oracle")
    oracle_flags = args.get("oracle_flags", "--files-report")
    extra_files = args.get("extra_files", "")
    ticket_root = args.get("ticket_root", ".tickets")
    ticket_glob = args.get("ticket_glob", "**/*.md")
    ticket_paths = args.get("ticket_paths", "")
    ticket_max_files = args.get("ticket_max_files", "25")
    group_mode = args.get("group_mode", "subdir+infer")
    group_min_score = float(args.get("group_min_score", "0.08"))
    group_max_files = int(args.get("group_max_files", "25"))
    group_max_chars = int(args.get("group_max_chars", "200000"))
    dedupe_mode = args.get("dedupe_mode", "report")
    dedupe_jaccard = float(args.get("dedupe_jaccard", "0.55"))
    dedupe_overlap_hi = float(args.get("dedupe_overlap_hi", "0.80"))
    dedupe_overlap_lo = float(args.get("dedupe_overlap_lo", "0.70"))
    dedupe_delta_min = float(args.get("dedupe_delta_min", "0.15"))
    dedupe_body_chars = int(args.get("dedupe_body_chars", "2000"))
    mode = args.get("mode", "tickets-grouped-direct")

    template_path = Path(__file__).resolve().parent.parent / "references" / "tickets-pack-template.md"
    template = template_path.read_text(encoding="utf-8")

    paths = _collect_ticket_paths(ticket_root, ticket_glob, ticket_paths)
    paths = sorted((str(p) for p in paths))
    paths = [Path(p) for p in paths]

    original_paths = list(paths)
    dup_map: Dict[str, str] = {}
    cluster_meta: Dict[str, Dict[str, object]] = {}
    dup_pairs: Dict[Tuple[str, str], Dict[str, float]] = {}
    if dedupe_mode != "off":
        _clusters, dup_map, cluster_meta, dup_pairs = _dedupe_clusters(
            paths,
            body_chars=dedupe_body_chars,
            jaccard_hi=dedupe_jaccard,
            overlap_hi=dedupe_overlap_hi,
            overlap_lo=dedupe_overlap_lo,
            delta_min=dedupe_delta_min,
        )

    # Build grouping base: canonical tickets + singletons
    canonical_set = {meta["canonical"] for meta in cluster_meta.values()}
    dup_set = set(dup_map.keys())
    base_paths: List[Path] = []
    for p in paths:
        sp = str(p)
        if sp in dup_set:
            continue
        base_paths.append(p)

    groups: Dict[str, List[Path]] = {}
    loose: List[Path] = []
    if "subdir" in group_mode:
        groups, loose = _group_by_subdir(base_paths, ticket_root)
    else:
        loose = list(base_paths)

    if "infer" in group_mode:
        groups = _infer_groups(groups, loose, group_min_score)
    else:
        groups.setdefault("misc", []).extend(loose)

    dedupe_plan: Dict[str, Dict[str, object]] = {}
    merge_files: Dict[str, str] = {}
    if cluster_meta:
        primary_to_group: Dict[str, str] = {}
        for gname in groups:
            for p in groups[gname]:
                primary_to_group[str(p)] = gname

        for cluster_id, meta in sorted(cluster_meta.items(), key=lambda x: int(x[0])):
            canonical = meta["canonical"]
            deltas = list(meta["deltas"])
            redundant = list(meta["redundant"])
            gname = primary_to_group.get(canonical, "misc")

            if dedupe_mode == "merge":
                merge_path = _write_merge_file(
                    Path(out_dir),
                    cluster_id=cluster_id,
                    canonical=canonical,
                    deltas=deltas,
                    redundant=redundant,
                    body_chars=dedupe_body_chars,
                )
                merge_files[canonical] = str(merge_path)
                # Replace canonical in group with merge file
                groups[gname] = [p for p in groups[gname] if str(p) != canonical]
                groups[gname].append(merge_path)
            else:
                # report/prune: append related tickets to canonical group
                keep = deltas if dedupe_mode == "prune" else deltas + redundant
                for p in keep:
                    groups.setdefault(gname, []).append(Path(p))

            dedupe_plan[cluster_id] = {
                "canonical": canonical,
                "group": gname,
                "deltas": sorted(deltas),
                "redundant": sorted(redundant),
                "mode": dedupe_mode,
            }

    # Ensure stable order
    for k in sorted(groups.keys()):
        groups[k] = sorted((str(p) for p in groups[k]))
        groups[k] = [Path(p) for p in groups[k]]

    original_set = {str(p) for p in original_paths}
    assignment: Dict[str, str] = {}
    for gname, gpaths in groups.items():
        for p in gpaths:
            sp = str(p)
            if sp in original_set:
                if sp in assignment:
                    raise SystemExit(f"[ERROR] Ticket assigned to multiple groups: {sp}")
                assignment[sp] = gname

    for meta in dedupe_plan.values():
        gname = meta["group"]
        for sp in [meta["canonical"]] + meta["deltas"] + meta["redundant"]:
            if sp not in assignment:
                assignment[sp] = gname

    missing = sorted(original_set - set(assignment.keys()))
    if missing:
        raise SystemExit(f"[ERROR] Tickets missing group assignment: {missing}")

    base_out = Path(out_dir)
    packs_dir = base_out / "packs"
    packs_dir.mkdir(parents=True, exist_ok=True)

    grouping_report: Dict[str, List[str]] = {}
    manifest_groups: List[Dict[str, object]] = []
    group_originals: Dict[str, List[str]] = {g: [] for g in groups.keys()}
    for ticket, gname in assignment.items():
        group_originals.setdefault(gname, []).append(ticket)
    for group_name in sorted(groups.keys()):
        group_paths = groups[group_name]
        grouping_report[group_name] = [str(p) for p in group_paths]

        parts = _chunk_by_limits(group_paths, group_max_files, group_max_chars)
        for idx, part in enumerate(parts, start=1):
            part_suffix = f"-part-{idx:02d}" if len(parts) > 1 else ""
            group_slug = _slugify(group_name + part_suffix)

            pack_out_dir = str(base_out / group_slug)
            pack_file = packs_dir / f"{group_slug}.md"

            mapping = {
                "codebase_name": codebase_name,
                "out_dir": pack_out_dir,
                "oracle_cmd": oracle_cmd,
                "oracle_flags": oracle_flags,
                "extra_files": extra_files,
                "ticket_root": ticket_root,
                "ticket_glob": ticket_glob,
                "ticket_paths": ",".join(str(p) for p in part),
                "ticket_max_files": str(min(len(part), max(1, group_max_files))),
                "group_name": group_name,
                "group_slug": group_slug,
                "mode": mode,
            }

            content = _render_template(template, mapping)
            pack_file.write_text(content, encoding="utf-8")

            manifest_groups.append(
                {
                    "group": group_name,
                    "slug": group_slug,
                    "part": idx,
                    "pack_path": str(pack_file),
                    "out_dir": pack_out_dir,
                    "attached_paths": [str(p) for p in part],
                    "original_tickets": sorted(group_originals.get(group_name, [])),
                }
            )

    (base_out / "_groups.json").write_text(
        json.dumps(grouping_report, indent=2, sort_keys=True),
        encoding="utf-8",
    )

    if dup_map:
        (base_out / "_duplicates.json").write_text(
            json.dumps(dup_map, indent=2, sort_keys=True),
            encoding="utf-8",
        )

    if dedupe_plan:
        (base_out / "_dedupe_plan.json").write_text(
            json.dumps(dedupe_plan, indent=2, sort_keys=True),
            encoding="utf-8",
        )

    if cluster_meta:
        pairs_out = [
            {"a": a, "b": b, **scores} for (a, b), scores in sorted(dup_pairs.items())
        ]
        (base_out / "_dupes_possible.json").write_text(
            json.dumps({"clusters": cluster_meta, "pairs": pairs_out}, indent=2, sort_keys=True),
            encoding="utf-8",
        )

    (base_out / "manifest.json").write_text(
        json.dumps({"groups": manifest_groups}, indent=2, sort_keys=True),
        encoding="utf-8",
    )

    print(f"[OK] wrote packs to: {packs_dir}")
    print(f"[OK] wrote grouping map: {base_out / '_groups.json'}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
```

skills/oraclepack-tickets-pack-grouped/scripts/lint_attachments.py
```
import argparse
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple


@dataclass
class Step:
    n: str
    lines: List[str]


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return path.read_text(encoding="utf-8", errors="replace")


def _extract_bash_fence(lines: List[str]) -> List[str]:
    fence_idxs = [i for i, ln in enumerate(lines) if ln.startswith("```")]
    if len(fence_idxs) != 2:
        raise ValueError(f"Expected exactly one fenced block (2 fence lines). Found {len(fence_idxs)}.")
    open_i, close_i = fence_idxs
    if lines[open_i].rstrip("\n") != "```bash":
        raise ValueError("Opening fence must be exactly ```bash.")
    if lines[close_i].rstrip("\n") != "```":
        raise ValueError("Closing fence must be exactly ```.")
    return [ln.rstrip("\n") for ln in lines[open_i + 1 : close_i]]


def _parse_steps(fence_lines: List[str]) -> List[Step]:
    header_re = re.compile(r"^#\s*(\d{2})\)\s+")
    header_idxs: List[Tuple[int, str]] = []
    for i, ln in enumerate(fence_lines):
        m = header_re.match(ln)
        if m:
            header_idxs.append((i, m.group(1)))

    if not header_idxs:
        raise ValueError("No step headers found inside bash fence.")

    steps: List[Step] = []
    for idx, (start_i, n) in enumerate(header_idxs):
        end_i = header_idxs[idx + 1][0] if idx + 1 < len(header_idxs) else len(fence_lines)
        steps.append(Step(n=n, lines=fence_lines[start_i:end_i]))
    return steps


def lint(path: Path) -> None:
    raw = _read_text(path)
    lines = raw.splitlines(True)
    fence = _extract_bash_fence(lines)
    steps = _parse_steps(fence)

    errors: List[str] = []
    for step in steps:
        joined = "\n".join(step.lines)

        if "_tickets_bundle" in joined:
            errors.append(f"Step {step.n}: found '_tickets_bundle' reference (direct-ticket packs must not use bundle).")

        if re.search(r"mapfile\s+-t\s+__tickets\s+<\s+<\(", joined) is None:
            errors.append(f"Step {step.n}: missing mapfile ticket discovery stanza.")

        if re.search(r"ticket_args=\(\)", joined) is None or re.search(r"ticket_args\+\=\(\s*(-f|--file)\b", joined) is None:
            errors.append(f"Step {step.n}: missing ticket_args builder (ticket_args+=(-f \"$p\")).")

        if re.search(r"\$\{ticket_args\[@\]\}", joined) is None:
            errors.append(f"Step {step.n}: missing ${'{'}ticket_args[@]{'}'} usage in oracle invocation.")

        # Heuristic: ensure we did not hardcode a non-existent bundle path.
        if re.search(r'(?<!\S)(-f|--file)(?!\S)\s+"[^"\n]*_tickets_bundle', joined):
            errors.append(f"Step {step.n}: contains a hardcoded _tickets_bundle attachment.")

    if errors:
        for e in errors:
            print(f"[ERROR] {e}", file=sys.stderr)
        sys.exit(1)

    print("[OK] Direct-ticket lint passed.")


def main() -> None:
    p = argparse.ArgumentParser(description="Lint ticket-driven Stage-1 packs (direct-ticket mode).")
    p.add_argument("pack_path", help="Path to the Markdown pack file")
    args = p.parse_args()

    path = Path(args.pack_path)
    if not path.exists():
        print(f"[ERROR] File not found: {path}", file=sys.stderr)
        sys.exit(1)

    lint(path)


if __name__ == "__main__":
    main()
```

skills/oraclepack-tickets-pack-grouped/scripts/render_group_packs.py
```
#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
import re
from pathlib import Path
from typing import Dict


def _render_template(template: str, mapping: Dict[str, str]) -> str:
    out = template
    for key, val in mapping.items():
        out = out.replace("{{" + key + "}}", val)
    unresolved = sorted(set(re.findall(r"\{\{([^}]+)\}\}", out)))
    if unresolved:
        raise ValueError(f"Unresolved template placeholders: {unresolved}")
    return out


def main() -> int:
    if len(sys.argv) == 1:
        print("Select how to run:")
        print("1) Use defaults (no args)")
        print("2) Provide custom args (show usage)")
        choice = input("Enter choice [1-2]: ").strip() or "1"
        if choice == "2":
            print("Usage: render_group_packs.py --manifest manifest.json --out-dir out")
            return 0

    p = argparse.ArgumentParser(description="Render group-specific bundle packs from manifest.")
    p.add_argument("--manifest", default="manifest.json")
    p.add_argument("--out-dir", default="docs/oracle-questions-sharded")
    p.add_argument("--template", default="/home/user/.codex/skills/oraclepack-tickets-pack-grouped/references/tickets-pack-template-bundle.md")
    p.add_argument("--codebase-name", default="Unknown")
    p.add_argument("--oracle-cmd", default="oracle")
    p.add_argument("--oracle-flags", default="--files-report")
    p.add_argument("--extra-files", default="")
    p.add_argument("--ticket-root", default=".tickets")
    p.add_argument("--ticket-glob", default="**/*.md")
    p.add_argument("--mode", default="tickets-bundle")
    args = p.parse_args()

    manifest_path = Path(args.manifest)
    if not manifest_path.exists():
        raise SystemExit(f"[ERROR] manifest not found: {manifest_path}")

    manifest = json.loads(manifest_path.read_text(encoding="utf-8"))
    template = Path(args.template).read_text(encoding="utf-8")

    out_dir = Path(args.out_dir)
    packs_dir = out_dir / "packs"
    packs_dir.mkdir(parents=True, exist_ok=True)

    for group in manifest.get("groups", []):
        slug = group["slug"]
        tickets = group["tickets"]
        pack_dir = packs_dir / slug
        pack_dir.mkdir(parents=True, exist_ok=True)

        pack_path = pack_dir / f"oracle-pack_{slug}.md"
        bundle_path = pack_dir / f"tickets_bundle_{slug}.md"
        out_run_dir = pack_dir / "out"

        mapping = {
            "codebase_name": args.codebase_name,
            "out_dir": str(out_run_dir),
            "oracle_cmd": args.oracle_cmd,
            "oracle_flags": args.oracle_flags,
            "extra_files": args.extra_files,
            "ticket_root": args.ticket_root,
            "ticket_glob": args.ticket_glob,
            "ticket_paths": ",".join(tickets),
            "ticket_bundle_path": str(bundle_path),
            "mode": args.mode,
        }

        content = _render_template(template, mapping)
        pack_path.write_text(content, encoding="utf-8")
        group["pack_path"] = str(pack_path)

    manifest_path.write_text(json.dumps(manifest, indent=2, sort_keys=True), encoding="utf-8")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
```

skills/oraclepack-tickets-pack-grouped/scripts/shard_tickets.py
```
#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
import math
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Tuple

STOPWORDS = {
    "the", "and", "for", "with", "from", "this", "that", "into", "over", "under", "when",
    "then", "than", "else", "only", "must", "should", "could", "would", "will", "shall",
    "ticket", "tickets", "oraclepack", "oracle", "pack", "packs",
}

SECTION_KEYS = {"summary", "acceptance", "criteria", "background", "context"}


@dataclass
class Ticket:
    path: Path
    text: str
    tokens: List[str]
    vector: List[float]


def _tokenize(text: str) -> List[str]:
    text = text.lower()
    text = re.sub(r"[^a-z0-9]+", " ", text)
    return [t for t in text.split() if len(t) >= 3 and t not in STOPWORDS]


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8", errors="replace")
    except FileNotFoundError:
        return ""


def _extract_repr(text: str, stem: str, max_chars: int) -> str:
    lines = text.splitlines()
    heading = ""
    sections: List[str] = []
    capture = False
    for line in lines:
        s = line.strip()
        if not heading and s.startswith("#"):
            heading = s.lstrip("#").strip()
        if s.startswith("#"):
            key = s.lstrip("#").strip().lower()
            capture = any(k in key for k in SECTION_KEYS)
            continue
        if capture and s:
            sections.append(s)
        if len(" ".join(sections)) >= max_chars:
            break
    body = " ".join(sections)
    base = " ".join([stem, heading, body])
    return base[:max_chars]


def _tfidf_vectors(texts: List[str]) -> Tuple[List[List[float]], List[str]]:
    docs = [
        [tok for tok in _tokenize(t)]
        for t in texts
    ]
    vocab: Dict[str, int] = {}
    df: Dict[str, int] = {}
    for toks in docs:
        seen = set()
        for tok in toks:
            if tok not in vocab:
                vocab[tok] = len(vocab)
            if tok not in seen:
                df[tok] = df.get(tok, 0) + 1
                seen.add(tok)

    n_docs = len(docs)
    idf = [0.0] * len(vocab)
    for tok, idx in vocab.items():
        idf[idx] = math.log((1 + n_docs) / (1 + df.get(tok, 1))) + 1.0

    vectors: List[List[float]] = []
    for toks in docs:
        tf: Dict[int, float] = {}
        for tok in toks:
            tf[vocab[tok]] = tf.get(vocab[tok], 0.0) + 1.0
        vec = [0.0] * len(vocab)
        for idx, count in tf.items():
            vec[idx] = count * idf[idx]
        # L2 normalize
        norm = math.sqrt(sum(v * v for v in vec)) or 1.0
        vec = [v / norm for v in vec]
        vectors.append(vec)

    inv_vocab = [None] * len(vocab)
    for tok, idx in vocab.items():
        inv_vocab[idx] = tok
    return vectors, inv_vocab


def _cosine(a: List[float], b: List[float]) -> float:
    return sum(x * y for x, y in zip(a, b))


def _centroid(vectors: List[List[float]]) -> List[float]:
    if not vectors:
        return []
    dim = len(vectors[0])
    out = [0.0] * dim
    for v in vectors:
        for i, val in enumerate(v):
            out[i] += val
    n = float(len(vectors)) or 1.0
    out = [v / n for v in out]
    norm = math.sqrt(sum(v * v for v in out)) or 1.0
    return [v / norm for v in out]


def _kmeans_split(vectors: List[List[float]], k: int, iters: int = 10) -> List[List[int]]:
    if k <= 1:
        return [list(range(len(vectors)))]
    # deterministic init: first k vectors
    centroids = [vectors[i][:] for i in range(k)]
    for _ in range(iters):
        clusters = [[] for _ in range(k)]
        for idx, v in enumerate(vectors):
            best = 0
            best_score = -1.0
            for c_idx, c in enumerate(centroids):
                score = _cosine(v, c)
                if score > best_score:
                    best_score = score
                    best = c_idx
            clusters[best].append(idx)
        new_centroids = []
        for cluster in clusters:
            if cluster:
                new_centroids.append(_centroid([vectors[i] for i in cluster]))
            else:
                new_centroids.append(centroids[len(new_centroids)])
        centroids = new_centroids
    return clusters


def main() -> int:
    if len(sys.argv) == 1:
        print("Select how to run:")
        print("1) Use defaults (no args)")
        print("2) Provide custom args (show usage)")
        choice = input("Enter choice [1-2]: ").strip() or "1"
        if choice == "2":
            print("Usage: shard_tickets.py --ticket-root .tickets --out-dir out")
            return 0

    p = argparse.ArgumentParser(description="Shard tickets into topic/domain groups.")
    p.add_argument("--ticket-root", default=".tickets")
    p.add_argument("--ticket-glob", default="**/*.md")
    p.add_argument("--ticket-paths", default="")
    p.add_argument("--out-dir", default="docs/oracle-questions-sharded")
    p.add_argument("--min-sim", type=float, default=0.15)
    p.add_argument("--max-group-size", type=int, default=25)
    p.add_argument("--min-group-size", type=int, default=1)
    p.add_argument("--max-bundle-chars", type=int, default=200000)
    p.add_argument("--repr-chars", type=int, default=2000)
    p.add_argument("--use-llm-for-ambiguous", action="store_true")
    args = p.parse_args()

    ticket_root = Path(args.ticket_root)
    if args.ticket_paths:
        paths = [Path(p.strip()) for p in args.ticket_paths.split(",") if p.strip()]
    else:
        paths = sorted(ticket_root.glob(args.ticket_glob), key=lambda p: str(p)) if ticket_root.exists() else []

    texts: List[str] = []
    tickets: List[Ticket] = []
    for pth in paths:
        txt = _read_text(pth)
        rep = _extract_repr(txt, pth.stem, args.repr_chars)
        texts.append(rep)

    vectors, vocab = _tfidf_vectors(texts)
    for pth, txt, vec in zip(paths, texts, vectors):
        tickets.append(Ticket(path=pth, text=txt, tokens=_tokenize(txt), vector=vec))

    groups: Dict[str, List[int]] = {}
    loose: List[int] = []
    for idx, t in enumerate(tickets):
        try:
            rel = t.path.relative_to(ticket_root)
        except ValueError:
            loose.append(idx)
            continue
        if len(rel.parts) >= 2:
            g = rel.parts[0]
            groups.setdefault(g, []).append(idx)
        else:
            loose.append(idx)

    # Compute centroids for subdir groups
    centroids: Dict[str, List[float]] = {}
    for g, idxs in groups.items():
        centroids[g] = _centroid([tickets[i].vector for i in idxs])

    # Assign loose tickets by similarity
    reasons: Dict[int, Dict[str, object]] = {}
    for idx in loose:
        best_g = None
        best_sim = -1.0
        for g, c in centroids.items():
            sim = _cosine(tickets[idx].vector, c)
            if sim > best_sim:
                best_sim = sim
                best_g = g
        if best_g is not None and best_sim >= args.min_sim:
            groups.setdefault(best_g, []).append(idx)
            reasons[idx] = {"assigned_to": best_g, "sim": best_sim, "reason": "tfidf"}
        else:
            groups.setdefault("misc", []).append(idx)
            reasons[idx] = {
                "assigned_to": "misc",
                "sim": best_sim,
                "reason": "ambiguous" if not args.use_llm_for_ambiguous else "ambiguous_llm_needed",
            }

    # Merge small groups
    if args.min_group_size > 1 and len(groups) > 1:
        for g in sorted(list(groups.keys())):
            if g == "misc":
                continue
            if len(groups[g]) < args.min_group_size:
                # merge into nearest group
                g_centroid = _centroid([tickets[i].vector for i in groups[g]])
                best_g = None
                best_sim = -1.0
                for og, c in centroids.items():
                    if og == g:
                        continue
                    sim = _cosine(g_centroid, c)
                    if sim > best_sim:
                        best_sim = sim
                        best_g = og
                if best_g:
                    groups.setdefault(best_g, []).extend(groups[g])
                    del groups[g]

    # Split large groups using deterministic kmeans
    final_groups: Dict[str, List[int]] = {}
    for g in sorted(groups.keys()):
        idxs = groups[g]
        idxs_sorted = sorted(idxs, key=lambda i: str(tickets[i].path))
        total_chars = sum(len(_read_text(tickets[i].path)) for i in idxs_sorted)
        k = max(
            1,
            math.ceil(len(idxs_sorted) / max(1, args.max_group_size)),
            math.ceil(total_chars / max(1, args.max_bundle_chars)),
        )
        if k <= 1:
            final_groups[g] = idxs_sorted
            continue
        clusters = _kmeans_split([tickets[i].vector for i in idxs_sorted], k)
        part = 1
        for cluster in clusters:
            if not cluster:
                continue
            slug = f"{g}-part-{part:02d}"
            final_groups[slug] = [idxs_sorted[i] for i in cluster]
            part += 1

    # Build manifest
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    manifest_groups = []
    for g in sorted(final_groups.keys()):
        idxs = final_groups[g]
        vecs = [tickets[i].vector for i in idxs]
        centroid = _centroid(vecs)
        top_terms = []
        for i, score in sorted(enumerate(centroid), key=lambda x: -x[1])[:8]:
            if score <= 0:
                continue
            top_terms.append(vocab[i])
        sims = []
        for i in idxs:
            sims.append(_cosine(tickets[i].vector, centroid))
        conf = sum(sims) / float(len(sims)) if sims else 0.0

        manifest_groups.append(
            {
                "slug": g,
                "tickets": [str(tickets[i].path) for i in idxs],
                "keywords": top_terms,
                "confidence": conf,
            }
        )

    manifest = {"groups": manifest_groups}
    (out_dir / "manifest.json").write_text(json.dumps(manifest, indent=2, sort_keys=True), encoding="utf-8")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
```

skills/oraclepack-tickets-pack-grouped/scripts/validate_pack.py
```
from pathlib import Path
import runpy

COMMON = Path(__file__).resolve().parents[2] / "oraclepack-tickets-pack-common" / "scripts" / "validate_pack.py"
if not COMMON.exists():
    raise SystemExit(f"[ERROR] Shared validator not found: {COMMON}")

runpy.run_path(str(COMMON), run_name="__main__")
```

skills/oraclepack-tickets-pack-grouped/scripts/validate_shards.py
```
#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
import subprocess
from pathlib import Path
from typing import Dict


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8", errors="replace")
    except FileNotFoundError:
        return ""


def main() -> int:
    if len(sys.argv) == 1:
        print("Select how to run:")
        print("1) Use defaults (no args)")
        print("2) Provide custom args (show usage)")
        choice = input("Enter choice [1-2]: ").strip() or "1"
        if choice == "2":
            print("Usage: validate_shards.py --manifest manifest.json")
            return 0

    p = argparse.ArgumentParser(description="Validate sharded packs manifest.")
    p.add_argument("--manifest", default="manifest.json")
    p.add_argument("--max-bundle-chars", type=int, default=200000)
    p.add_argument(
        "--validator",
        default="/home/user/.codex/skills/oraclepack-tickets-pack-common/scripts/validate_pack.py",
    )
    args = p.parse_args()

    manifest_path = Path(args.manifest)
    if not manifest_path.exists():
        raise SystemExit(f"[ERROR] manifest not found: {manifest_path}")

    manifest = json.loads(manifest_path.read_text(encoding="utf-8"))
    counts: Dict[str, int] = {}

    for group in manifest.get("groups", []):
        for t in group.get("tickets", []):
            counts[t] = counts.get(t, 0) + 1

    bad = [t for t, c in counts.items() if c != 1]
    if bad:
        raise SystemExit(f"[ERROR] Tickets assigned !=1 times: {bad}")

    for group in manifest.get("groups", []):
        pack_path = Path(group.get("pack_path", ""))
        if not pack_path.exists():
            raise SystemExit(f"[ERROR] pack missing: {pack_path}")

        # validate pack
        subprocess.run(
            [
                "python3",
                args.validator,
                "--mode",
                "bundle",
                str(pack_path),
            ],
            check=True,
        )

        # size check
        total = 0
        for t in group.get("tickets", []):
            total += len(_read_text(Path(t)))
        if total > args.max_bundle_chars:
            raise SystemExit(
                f"[ERROR] group '{group.get('slug')}' exceeds max bundle chars: {total} > {args.max_bundle_chars}"
            )

    print("[OK] Sharded packs manifest validated.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
```

.config/mcp/oraclepack-gold-pack/references/attachment-minimization.md
```
# Attachment minimization rules (Stage 1 packs)

Objective: keep oracle calls fast, portable, and deterministic by attaching the minimum evidence per step.

## Hard limits

- Default: **0–2 attachments per step** (`-f/--file`).
- If you need more than 2, the step is not scoped tightly enough: split or reduce.
- Any `extra_files` the user provides must be appended **literally** (do not reinterpret), but you should still keep the step’s own attachments ≤2.

## What to attach (rule of thumb)

For a given step, prefer:
1) One file that *defines* the concept (contract/schema/config/type)
2) One file that *enforces/uses* the concept (handler/service/policy)

If you can’t find both confidently, attach only the “definition” file.

## Common attachment choices by category (patterns, not requirements)

Use these as **patterns** to recognize likely candidates in a repo; do not assume these paths exist.

- contracts/interfaces:
  - route registration, API schema/spec, public type definitions, CLI command registry

- invariants:
  - domain model definitions, validation layer, schema types, critical service functions that enforce rules

- caching/state:
  - cache client config, state container/store, session manager, any TTL/invalidation logic

- background jobs:
  - worker entrypoint, job registry, scheduler configuration, queue client config

- observability:
  - logger initialization/config, metrics/tracing setup, middleware that injects correlation ids

- permissions:
  - authn/authz middleware, policy definitions, role/scope mapping, guard functions

- migrations:
  - migrations folder index, migration runner config, schema definition file (if present)

- UX flows:
  - key UI/router flow code, top-level workflow orchestrator, controller/handler representing the flow

- failure modes:
  - error handling utilities, retry/backoff config, boundary middleware, circuit breaker wrappers (if any)

- feature flags:
  - flag config/registry, evaluation hook, rollout/targeting logic

## If you cannot find good attachments

- Attach nothing or only 1 file.
- Set `reference=Unknown`.
- Make the prompt request “exact missing file/path pattern(s) to attach next.”

## Avoid these attachment anti-patterns

- Attaching entire directories when one file is enough.
- Attaching multiple duplicates (e.g., the same config in three copies).
- Attaching generated/lock files unless the question is explicitly about them.
- Attaching secrets.
```

.config/mcp/oraclepack-gold-pack/references/inference-first-discovery.md
```
# Inference-first discovery (Stage 1 packs)

Goal: pick the *right* 1–2 attachments per step without over-attaching, by inferring repo shape from a small set of anchors.

## Principles

- Prefer **evidence** (actual files) over assumptions.
- Start broad with **cheap, high-signal** files; only then zoom in.
- If a file/path doesn’t exist: record `Unknown` and continue.
- Keep steps self-contained: each step should succeed without relying on shared shell setup.

## Deterministic discovery order

1) **Repo identity + entrypoints**
- `README*` (first ~200 lines)
- top-level manifests (language/framework/package)
- main entrypoints (server start, CLI main, app bootstrap) if obvious from tree

2) **Configuration + environment**
- example config files
- `.env.example` or equivalent (if present)
- CI config files (to infer build/test and deploy steps)

3) **Public surface**
- routing tables / controllers / handlers
- schema/contract definitions (API specs, message schemas, type definitions)
- CLI command registration (if applicable)

4) **Data + jobs + operations**
- data models and storage adapters
- migrations directory (if present)
- background job definitions and worker entrypoints (if present)
- logging/metrics/tracing configuration (if present)

## Turning discovery into step-specific attachments

For each planned step:
- Choose 1 “definition” file (where the thing is declared).
- Optionally choose 1 “use-site” file (where the thing is used/enforced).
- If you can’t confidently pick: attach fewer files and use `reference=Unknown`.

Then write the prompt so the oracle can request missing artifact patterns when needed.

## What to do when evidence is insufficient

- Set `reference=Unknown` in the step header.
- In the prompt, explicitly ask for:
  - “the exact missing file/path pattern(s) to attach next”
- Keep attachments minimal; do not guess file paths.
```

.config/mcp/oraclepack-gold-pack/references/oracle-pack-template.md
```
# Oracle Pack — {{codebase_name}} (Gold Stage 1)

## Parsed args
- codebase_name: {{codebase_name}}
- constraints: {{constraints}}
- non_goals: {{non_goals}}
- team_size: {{team_size}}
- deadline: {{deadline}}
- out_dir: {{out_dir}}
- oracle_cmd: {{oracle_cmd}}
- oracle_flags: {{oracle_flags}}
- engine: {{engine}}
- model: {{model}}
- extra_files: {{extra_files}}

Notes:
- Template is the **contract**. Keep the pack runner-ingestible.
- Exactly one fenced `bash` block in this whole document.
- Exactly 20 steps, numbered `01..20`.
- Each step includes: `ROI= impact= confidence= effort= horizon= category= reference=`
- Categories must be exactly the fixed set used in Coverage check.

## Commands
```bash
# Optional preflight pattern:
# - Add `--dry-run summary` to preview what will be sent, and keep `--files-report` enabled when available.

# 01) ROI=... impact=... confidence=... effort=... horizon=Immediate category=contracts/interfaces reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/01-contracts-interfaces-surface.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #01

Reference: Unknown
Category: contracts/interfaces
Horizon: Immediate
ROI: ... (impact=..., confidence=..., effort=...)

Question:
Identify the primary public interface(s) of this system (API endpoints, CLI commands, public SDK surface, event contracts). For each, list the key request/response (or input/output) shapes and where they are defined in the code.

Rationale (one sentence):
We need a trustworthy map of the system’s “outside-facing contract” before deeper planning.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 02) ROI=... impact=... confidence=... effort=... horizon=Immediate category=contracts/interfaces reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/02-contracts-interfaces-integration.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #02

Reference: Unknown
Category: contracts/interfaces
Horizon: Immediate
ROI: ... (impact=..., confidence=..., effort=...)

Question:
What are the top integration points with external systems (databases, queues, third-party APIs, SSO, storage), and what contract(s) or config declare them? Provide the minimal list of files/locations that define each integration.

Rationale (one sentence):
Integration boundaries drive risk, deployment needs, and test strategy.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–6 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 03) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=invariants reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/03-invariants-domain.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #03

Reference: Unknown
Category: invariants
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
List the system’s most important invariants (business rules, correctness properties, “must always be true” conditions). For each, show where it is enforced (or where it should be enforced but currently is not).

Rationale (one sentence):
Invariants define correctness and are the backbone of reliable changes.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 04) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=invariants reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/04-invariants-validation.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #04

Reference: Unknown
Category: invariants
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
Where does validation happen (input validation, schema validation, domain validation)? Identify the validation boundaries and the most likely gaps that could cause inconsistent state.

Rationale (one sentence):
Knowing validation boundaries prevents regressions and reduces security/correctness risk.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 05) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=caching/state reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/05-caching-state-layers.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #05

Reference: Unknown
Category: caching/state
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
What stateful components exist (in-memory state, caches, sessions, client-side state, persisted state)? For each, describe lifecycle, invalidation/expiry, and where it is implemented.

Rationale (one sentence):
State and caching are common sources of subtle bugs and performance issues.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 06) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=caching/state reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/06-caching-state-consistency.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #06

Reference: Unknown
Category: caching/state
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
Identify the top consistency risks between caches/state layers and the source of truth (stale reads, write skew, missing invalidation). Where are the knobs/configs for cache behavior?

Rationale (one sentence):
Consistency failure modes often surface as “random bugs” and are expensive to debug.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 07) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=background jobs reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/07-background-jobs-discovery.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #07

Reference: Unknown
Category: background jobs
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
What background jobs/workers/scheduled tasks exist? For each, identify trigger mechanism, payload, retries, idempotency, and where it is defined.

Rationale (one sentence):
Background work affects reliability, cost, and operational complexity.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 08) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=background jobs reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/08-background-jobs-reliability.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #08

Reference: Unknown
Category: background jobs
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
Where are the main reliability controls for background work (dead-lettering, backoff, concurrency limits, reprocessing), and what is missing or inconsistent?

Rationale (one sentence):
Reliability controls prevent incident loops and data corruption.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 09) ROI=... impact=... confidence=... effort=... horizon=Immediate category=observability reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/09-observability-signals.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #09

Reference: Unknown
Category: observability
Horizon: Immediate
ROI: ... (impact=..., confidence=..., effort=...)

Question:
What observability signals exist (logs/metrics/traces/events), and what are the primary identifiers for correlating a request/job across components? Point to the code/config that defines them.

Rationale (one sentence):
You can’t operate or improve what you can’t measure or debug quickly.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 10) ROI=... impact=... confidence=... effort=... horizon=Immediate category=observability reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/10-observability-gaps.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #10

Reference: Unknown
Category: observability
Horizon: Immediate
ROI: ... (impact=..., confidence=..., effort=...)

Question:
Where are the biggest observability gaps (missing logs around key decisions, missing metrics for SLOs, missing trace spans)? Recommend the smallest additions that would most improve debugging.

Rationale (one sentence):
Targeted observability improvements compound across all future changes.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 11) ROI=... impact=... confidence=... effort=... horizon=Immediate category=permissions reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/11-permissions-model.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #11

Reference: Unknown
Category: permissions
Horizon: Immediate
ROI: ... (impact=..., confidence=..., effort=...)

Question:
What is the permission model (roles/scopes/claims/ACLs), and where is it defined? Provide the minimal set of files that encode “who can do what.”

Rationale (one sentence):
Permission rules are a high-risk area with security and product impact.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 12) ROI=... impact=... confidence=... effort=... horizon=Immediate category=permissions reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/12-permissions-enforcement.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #12

Reference: Unknown
Category: permissions
Horizon: Immediate
ROI: ... (impact=..., confidence=..., effort=...)

Question:
Where are permissions enforced (middleware/guards/policies/service-layer checks), and where are likely bypass risks? Identify the enforcement chokepoints and any inconsistent patterns.

Rationale (one sentence):
Enforcement consistency prevents privilege escalation and policy drift.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 13) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=migrations reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/13-migrations-schema.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #13

Reference: Unknown
Category: migrations
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
How are schema/config migrations handled (DB migrations, data backfills, versioned configs)? Identify the tooling, directories, and how migrations are applied in CI/deploy.

Rationale (one sentence):
Migration mechanics are critical for safe releases and rollbacks.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 14) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=migrations reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/14-migrations-compat.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #14

Reference: Unknown
Category: migrations
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
What are the backward/forward compatibility expectations during migrations (rolling deploys, dual-read/dual-write, feature-flagged schema use)? Identify where compatibility is ensured or currently risky.

Rationale (one sentence):
Compatibility strategy prevents outages during deployments.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–8 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 15) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=UX flows reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/15-ux-flows-primary.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #15

Reference: Unknown
Category: UX flows
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
What are the primary user flows (or primary operator workflows) and their steps? Map each to the main components/modules involved, and note the key state transitions.

Rationale (one sentence):
Flow maps reveal critical paths and help prioritize work with user impact.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 16) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=UX flows reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/16-ux-flows-edgecases.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #16

Reference: Unknown
Category: UX flows
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
For the primary flows, what are the top edge cases and “gotchas” (validation failures, partial completion, retries, timeouts)? Identify where these cases are handled and where they are missing.

Rationale (one sentence):
Edge-case handling is where many UX and reliability issues originate.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 17) ROI=... impact=... confidence=... effort=... horizon=Immediate category=failure modes reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/17-failure-modes-taxonomy.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #17

Reference: Unknown
Category: failure modes
Horizon: Immediate
ROI: ... (impact=..., confidence=..., effort=...)

Question:
What is the failure-mode taxonomy of this system (timeouts, retries, partial failures, inconsistent state, dependency failures)? Identify where failures are classified/handled and what is surfaced to users/operators.

Rationale (one sentence):
Explicit failure handling prevents incidents and reduces user-facing errors.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 18) ROI=... impact=... confidence=... effort=... horizon=Immediate category=failure modes reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/18-failure-modes-resilience.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #18

Reference: Unknown
Category: failure modes
Horizon: Immediate
ROI: ... (impact=..., confidence=..., effort=...)

Question:
What resilience mechanisms exist (circuit breakers, bulkheads, retries with jitter, rate limiting, graceful degradation)? Where are they configured, and which critical path lacks them?

Rationale (one sentence):
Resilience patterns determine real-world reliability under stress.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 19) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=feature flags reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/19-feature-flags-inventory.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #19

Reference: Unknown
Category: feature flags
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
What feature-flag system exists (or how are conditional rollouts handled)? Inventory the flags (or equivalents) and identify where flags are defined, evaluated, and documented.

Rationale (one sentence):
Flags enable safe rollout and experimentation and reduce release risk.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 20) ROI=... impact=... confidence=... effort=... horizon=NearTerm category=feature flags reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/20-feature-flags-rollout.md" \
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #20

Reference: Unknown
Category: feature flags
Horizon: NearTerm
ROI: ... (impact=..., confidence=..., effort=...)

Question:
Describe the flag/rollout lifecycle (how flags are created, tested, ramped, monitored, and retired). Identify the minimum guardrails needed to prevent “flag debt.”

Rationale (one sentence):
A disciplined rollout lifecycle reduces long-term complexity and operational risk.

Constraints: {{constraints}}
Non-goals: {{non_goals}}

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"
```

Coverage check
--------------

Mark each as `OK` or `Missing(<which step ids>)`:

*   contracts/interfaces: OK

*   invariants: OK

*   caching/state: OK

*   background jobs: OK

*   observability: OK

*   permissions: OK

*   migrations: OK

*   UX flows: OK

*   failure modes: OK

*   feature flags: OK
```

.config/mcp/oraclepack-gold-pack/references/oracle-scratch-format.md
```
# Oracle scratch playbook (NOT a pack format)

This document is for **manual debugging / one-off oracle runs**. It is **not** runner-ingestible oraclepack pack format.

## When to use scratch vs pack

Use the **pack** (`references/oracle-pack-template.md`) when:
- You need a strict 20-step Stage-1 pack for oraclepack ingestion.
- You want deterministic execution and validation via `scripts/validate_pack.py`.

Use **scratch** when:
- You need a single oracle call to explore something quickly.
- You are iterating on prompt wording before committing it into the pack.
- You want to test attachment choices with `--dry-run`.

## Scratch workflow

1) Start with one focused question.
2) Attach 0–2 high-signal files.
3) Use a quoted heredoc prompt to avoid shell-escaping issues.
4) If results are weak, add *one* more attachment (or refine the question).

## Pack-adjacent scratch example (single run)

Example pattern (edit paths/flags to match your environment):

- Uses the quoted heredoc prompt style.
- Shows the optional `--dry-run summary` style (if supported).

```bash
# (optional) preview:
# oracle --dry-run summary --files-report -f "README.md" -p "$(cat <<'PROMPT'
# Explain the repo’s main entrypoint and how requests flow through the system.
# If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
# PROMPT
# )"

oracle \
  --files-report \
  -f "README.md" \
  -p "$(cat <<'PROMPT'
Goal: Understand the repo’s main entrypoints and primary request flow.

Answer format:
1) Direct answer (bullets, evidence-cited)
2) Risks/unknowns
3) Next smallest concrete experiment (one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"
```

## Promoting scratch into the pack

When a scratch run looks good:
- Convert it into a numbered step in the pack.
- Add the strict header tokens (`ROI= impact= confidence= effort= horizon= category= reference=`).
- Add `--write-output "{{out_dir}}/NN-<slug>.md"`.
- Ensure category is one of the fixed 10 and update Coverage check accordingly.

```
```

.config/mcp/mcp-builder/scripts/connections.py
```
"""Lightweight connection handling for MCP servers."""

from abc import ABC, abstractmethod
from contextlib import AsyncExitStack
from typing import Any

from mcp import ClientSession, StdioServerParameters
from mcp.client.sse import sse_client
from mcp.client.stdio import stdio_client
from mcp.client.streamable_http import streamablehttp_client


class MCPConnection(ABC):
    """Base class for MCP server connections."""

    def __init__(self):
        self.session = None
        self._stack = None

    @abstractmethod
    def _create_context(self):
        """Create the connection context based on connection type."""

    async def __aenter__(self):
        """Initialize MCP server connection."""
        self._stack = AsyncExitStack()
        await self._stack.__aenter__()

        try:
            ctx = self._create_context()
            result = await self._stack.enter_async_context(ctx)

            if len(result) == 2:
                read, write = result
            elif len(result) == 3:
                read, write, _ = result
            else:
                raise ValueError(f"Unexpected context result: {result}")

            session_ctx = ClientSession(read, write)
            self.session = await self._stack.enter_async_context(session_ctx)
            await self.session.initialize()
            return self
        except BaseException:
            await self._stack.__aexit__(None, None, None)
            raise

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Clean up MCP server connection resources."""
        if self._stack:
            await self._stack.__aexit__(exc_type, exc_val, exc_tb)
        self.session = None
        self._stack = None

    async def list_tools(self) -> list[dict[str, Any]]:
        """Retrieve available tools from the MCP server."""
        response = await self.session.list_tools()
        return [
            {
                "name": tool.name,
                "description": tool.description,
                "input_schema": tool.inputSchema,
            }
            for tool in response.tools
        ]

    async def call_tool(self, tool_name: str, arguments: dict[str, Any]) -> Any:
        """Call a tool on the MCP server with provided arguments."""
        result = await self.session.call_tool(tool_name, arguments=arguments)
        return result.content


class MCPConnectionStdio(MCPConnection):
    """MCP connection using standard input/output."""

    def __init__(self, command: str, args: list[str] = None, env: dict[str, str] = None):
        super().__init__()
        self.command = command
        self.args = args or []
        self.env = env

    def _create_context(self):
        return stdio_client(
            StdioServerParameters(command=self.command, args=self.args, env=self.env)
        )


class MCPConnectionSSE(MCPConnection):
    """MCP connection using Server-Sent Events."""

    def __init__(self, url: str, headers: dict[str, str] = None):
        super().__init__()
        self.url = url
        self.headers = headers or {}

    def _create_context(self):
        return sse_client(url=self.url, headers=self.headers)


class MCPConnectionHTTP(MCPConnection):
    """MCP connection using Streamable HTTP."""

    def __init__(self, url: str, headers: dict[str, str] = None):
        super().__init__()
        self.url = url
        self.headers = headers or {}

    def _create_context(self):
        return streamablehttp_client(url=self.url, headers=self.headers)


def create_connection(
    transport: str,
    command: str = None,
    args: list[str] = None,
    env: dict[str, str] = None,
    url: str = None,
    headers: dict[str, str] = None,
) -> MCPConnection:
    """Factory function to create the appropriate MCP connection.

    Args:
        transport: Connection type ("stdio", "sse", or "http")
        command: Command to run (stdio only)
        args: Command arguments (stdio only)
        env: Environment variables (stdio only)
        url: Server URL (sse and http only)
        headers: HTTP headers (sse and http only)

    Returns:
        MCPConnection instance
    """
    transport = transport.lower()

    if transport == "stdio":
        if not command:
            raise ValueError("Command is required for stdio transport")
        return MCPConnectionStdio(command=command, args=args, env=env)

    elif transport == "sse":
        if not url:
            raise ValueError("URL is required for sse transport")
        return MCPConnectionSSE(url=url, headers=headers)

    elif transport in ["http", "streamable_http", "streamable-http"]:
        if not url:
            raise ValueError("URL is required for http transport")
        return MCPConnectionHTTP(url=url, headers=headers)

    else:
        raise ValueError(f"Unsupported transport type: {transport}. Use 'stdio', 'sse', or 'http'")
```

.config/mcp/mcp-builder/scripts/evaluation.py
```
"""MCP Server Evaluation Harness

This script evaluates MCP servers by running test questions against them using codex-cli.
"""

import argparse
import asyncio
import json
import re
import sys
import time
import traceback
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Any

from anthropic import Anthropic

from connections import create_connection

EVALUATION_PROMPT = """You are an AI assistant with access to tools.

When given a task, you MUST:
1. Use the available tools to complete the task
2. Provide summary of each step in your approach, wrapped in <summary> tags
3. Provide feedback on the tools provided, wrapped in <feedback> tags
4. Provide your final response, wrapped in <response> tags

Summary Requirements:
- In your <summary> tags, you must explain:
  - The steps you took to complete the task
  - Which tools you used, in what order, and why
  - The inputs you provided to each tool
  - The outputs you received from each tool
  - A summary for how you arrived at the response

Feedback Requirements:
- In your <feedback> tags, provide constructive feedback on the tools:
  - Comment on tool names: Are they clear and descriptive?
  - Comment on input parameters: Are they well-documented? Are required vs optional parameters clear?
  - Comment on descriptions: Do they accurately describe what the tool does?
  - Comment on any errors encountered during tool usage: Did the tool fail to execute? Did the tool return too many tokens?
  - Identify specific areas for improvement and explain WHY they would help
  - Be specific and actionable in your suggestions

Response Requirements:
- Your response should be concise and directly address what was asked
- Always wrap your final response in <response> tags
- If you cannot solve the task return <response>NOT_FOUND</response>
- For numeric responses, provide just the number
- For IDs, provide just the ID
- For names or text, provide the exact text requested
- Your response should go last"""


def parse_evaluation_file(file_path: Path) -> list[dict[str, Any]]:
    """Parse XML evaluation file with qa_pair elements."""
    try:
        tree = ET.parse(file_path)
        root = tree.getroot()
        evaluations = []

        for qa_pair in root.findall(".//qa_pair"):
            question_elem = qa_pair.find("question")
            answer_elem = qa_pair.find("answer")

            if question_elem is not None and answer_elem is not None:
                evaluations.append({
                    "question": (question_elem.text or "").strip(),
                    "answer": (answer_elem.text or "").strip(),
                })

        return evaluations
    except Exception as e:
        print(f"Error parsing evaluation file {file_path}: {e}")
        return []


def extract_xml_content(text: str, tag: str) -> str | None:
    """Extract content from XML tags."""
    pattern = rf"<{tag}>(.*?)</{tag}>"
    matches = re.findall(pattern, text, re.DOTALL)
    return matches[-1].strip() if matches else None


async def agent_loop(
    client: Anthropic,
    model: str,
    question: str,
    tools: list[dict[str, Any]],
    connection: Any,
) -> tuple[str, dict[str, Any]]:
    """Run the agent loop with MCP tools."""
    messages = [{"role": "user", "content": question}]

    response = await asyncio.to_thread(
        client.messages.create,
        model=model,
        max_tokens=4096,
        system=EVALUATION_PROMPT,
        messages=messages,
        tools=tools,
    )

    messages.append({"role": "assistant", "content": response.content})

    tool_metrics = {}

    while response.stop_reason == "tool_use":
        tool_use = next(block for block in response.content if block.type == "tool_use")
        tool_name = tool_use.name
        tool_input = tool_use.input

        tool_start_ts = time.time()
        try:
            tool_result = await connection.call_tool(tool_name, tool_input)
            tool_response = json.dumps(tool_result) if isinstance(tool_result, (dict, list)) else str(tool_result)
        except Exception as e:
            tool_response = f"Error executing tool {tool_name}: {str(e)}\n"
            tool_response += traceback.format_exc()
        tool_duration = time.time() - tool_start_ts

        if tool_name not in tool_metrics:
            tool_metrics[tool_name] = {"count": 0, "durations": []}
        tool_metrics[tool_name]["count"] += 1
        tool_metrics[tool_name]["durations"].append(tool_duration)

        messages.append({
            "role": "user",
            "content": [{
                "type": "tool_result",
                "tool_use_id": tool_use.id,
                "content": tool_response,
            }]
        })

        response = await asyncio.to_thread(
            client.messages.create,
            model=model,
            max_tokens=4096,
            system=EVALUATION_PROMPT,
            messages=messages,
            tools=tools,
        )
        messages.append({"role": "assistant", "content": response.content})

    response_text = next(
        (block.text for block in response.content if hasattr(block, "text")),
        None,
    )
    return response_text, tool_metrics


async def evaluate_single_task(
    client: Anthropic,
    model: str,
    qa_pair: dict[str, Any],
    tools: list[dict[str, Any]],
    connection: Any,
    task_index: int,
) -> dict[str, Any]:
    """Evaluate a single QA pair with the given tools."""
    start_time = time.time()

    print(f"Task {task_index + 1}: Running task with question: {qa_pair['question']}")
    response, tool_metrics = await agent_loop(client, model, qa_pair["question"], tools, connection)

    response_value = extract_xml_content(response, "response")
    summary = extract_xml_content(response, "summary")
    feedback = extract_xml_content(response, "feedback")

    duration_seconds = time.time() - start_time

    return {
        "question": qa_pair["question"],
        "expected": qa_pair["answer"],
        "actual": response_value,
        "score": int(response_value == qa_pair["answer"]) if response_value else 0,
        "total_duration": duration_seconds,
        "tool_calls": tool_metrics,
        "num_tool_calls": sum(len(metrics["durations"]) for metrics in tool_metrics.values()),
        "summary": summary,
        "feedback": feedback,
    }


REPORT_HEADER = """
# Evaluation Report

## Summary

- **Accuracy**: {correct}/{total} ({accuracy:.1f}%)
- **Average Task Duration**: {average_duration_s:.2f}s
- **Average Tool Calls per Task**: {average_tool_calls:.2f}
- **Total Tool Calls**: {total_tool_calls}

---
"""

TASK_TEMPLATE = """
### Task {task_num}

**Question**: {question}
**Ground Truth Answer**: `{expected_answer}`
**Actual Answer**: `{actual_answer}`
**Correct**: {correct_indicator}
**Duration**: {total_duration:.2f}s
**Tool Calls**: {tool_calls}

**Summary**
{summary}

**Feedback**
{feedback}

---
"""


async def run_evaluation(
    eval_path: Path,
    connection: Any,
    model: str = "codex-cli-3-7-sonnet-20250219",
) -> str:
    """Run evaluation with MCP server tools."""
    print("🚀 Starting Evaluation")

    client = Anthropic()

    tools = await connection.list_tools()
    print(f"📋 Loaded {len(tools)} tools from MCP server")

    qa_pairs = parse_evaluation_file(eval_path)
    print(f"📋 Loaded {len(qa_pairs)} evaluation tasks")

    results = []
    for i, qa_pair in enumerate(qa_pairs):
        print(f"Processing task {i + 1}/{len(qa_pairs)}")
        result = await evaluate_single_task(client, model, qa_pair, tools, connection, i)
        results.append(result)

    correct = sum(r["score"] for r in results)
    accuracy = (correct / len(results)) * 100 if results else 0
    average_duration_s = sum(r["total_duration"] for r in results) / len(results) if results else 0
    average_tool_calls = sum(r["num_tool_calls"] for r in results) / len(results) if results else 0
    total_tool_calls = sum(r["num_tool_calls"] for r in results)

    report = REPORT_HEADER.format(
        correct=correct,
        total=len(results),
        accuracy=accuracy,
        average_duration_s=average_duration_s,
        average_tool_calls=average_tool_calls,
        total_tool_calls=total_tool_calls,
    )

    report += "".join([
        TASK_TEMPLATE.format(
            task_num=i + 1,
            question=qa_pair["question"],
            expected_answer=qa_pair["answer"],
            actual_answer=result["actual"] or "N/A",
            correct_indicator="✅" if result["score"] else "❌",
            total_duration=result["total_duration"],
            tool_calls=json.dumps(result["tool_calls"], indent=2),
            summary=result["summary"] or "N/A",
            feedback=result["feedback"] or "N/A",
        )
        for i, (qa_pair, result) in enumerate(zip(qa_pairs, results))
    ])

    return report


def parse_headers(header_list: list[str]) -> dict[str, str]:
    """Parse header strings in format 'Key: Value' into a dictionary."""
    headers = {}
    if not header_list:
        return headers

    for header in header_list:
        if ":" in header:
            key, value = header.split(":", 1)
            headers[key.strip()] = value.strip()
        else:
            print(f"Warning: Ignoring malformed header: {header}")
    return headers


def parse_env_vars(env_list: list[str]) -> dict[str, str]:
    """Parse environment variable strings in format 'KEY=VALUE' into a dictionary."""
    env = {}
    if not env_list:
        return env

    for env_var in env_list:
        if "=" in env_var:
            key, value = env_var.split("=", 1)
            env[key.strip()] = value.strip()
        else:
            print(f"Warning: Ignoring malformed environment variable: {env_var}")
    return env


async def main():
    parser = argparse.ArgumentParser(
        description="Evaluate MCP servers using test questions",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Evaluate a local stdio MCP server
  python evaluation.py -t stdio -c python -a my_server.py eval.xml

  # Evaluate an SSE MCP server
  python evaluation.py -t sse -u https://example.com/mcp -H "Authorization: Bearer token" eval.xml

  # Evaluate an HTTP MCP server with custom model
  python evaluation.py -t http -u https://example.com/mcp -m codex-cli-3-5-sonnet-20241022 eval.xml
        """,
    )

    parser.add_argument("eval_file", type=Path, help="Path to evaluation XML file")
    parser.add_argument("-t", "--transport", choices=["stdio", "sse", "http"], default="stdio", help="Transport type (default: stdio)")
    parser.add_argument("-m", "--model", default="codex-cli-3-7-sonnet-20250219", help="codex-cli model to use (default: codex-cli-3-7-sonnet-20250219)")

    stdio_group = parser.add_argument_group("stdio options")
    stdio_group.add_argument("-c", "--command", help="Command to run MCP server (stdio only)")
    stdio_group.add_argument("-a", "--args", nargs="+", help="Arguments for the command (stdio only)")
    stdio_group.add_argument("-e", "--env", nargs="+", help="Environment variables in KEY=VALUE format (stdio only)")

    remote_group = parser.add_argument_group("sse/http options")
    remote_group.add_argument("-u", "--url", help="MCP server URL (sse/http only)")
    remote_group.add_argument("-H", "--header", nargs="+", dest="headers", help="HTTP headers in 'Key: Value' format (sse/http only)")

    parser.add_argument("-o", "--output", type=Path, help="Output file for evaluation report (default: stdout)")

    args = parser.parse_args()

    if not args.eval_file.exists():
        print(f"Error: Evaluation file not found: {args.eval_file}")
        sys.exit(1)

    headers = parse_headers(args.headers) if args.headers else None
    env_vars = parse_env_vars(args.env) if args.env else None

    try:
        connection = create_connection(
            transport=args.transport,
            command=args.command,
            args=args.args,
            env=env_vars,
            url=args.url,
            headers=headers,
        )
    except ValueError as e:
        print(f"Error: {e}")
        sys.exit(1)

    print(f"🔗 Connecting to MCP server via {args.transport}...")

    async with connection:
        print("✅ Connected successfully")
        report = await run_evaluation(args.eval_file, connection, args.model)

        if args.output:
            args.output.write_text(report)
            print(f"\n✅ Report saved to {args.output}")
        else:
            print("\n" + report)


if __name__ == "__main__":
    asyncio.run(main())
```

.config/mcp/mcp-builder/scripts/example_evaluation.xml
```
<evaluation>
   <qa_pair>
      <question>Calculate the compound interest on $10,000 invested at 5% annual interest rate, compounded monthly for 3 years. What is the final amount in dollars (rounded to 2 decimal places)?</question>
      <answer>11614.72</answer>
   </qa_pair>
   <qa_pair>
      <question>A projectile is launched at a 45-degree angle with an initial velocity of 50 m/s. Calculate the total distance (in meters) it has traveled from the launch point after 2 seconds, assuming g=9.8 m/s². Round to 2 decimal places.</question>
      <answer>87.25</answer>
   </qa_pair>
   <qa_pair>
      <question>A sphere has a volume of 500 cubic meters. Calculate its surface area in square meters. Round to 2 decimal places.</question>
      <answer>304.65</answer>
   </qa_pair>
   <qa_pair>
      <question>Calculate the population standard deviation of this dataset: [12, 15, 18, 22, 25, 30, 35]. Round to 2 decimal places.</question>
      <answer>7.61</answer>
   </qa_pair>
   <qa_pair>
      <question>Calculate the pH of a solution with a hydrogen ion concentration of 3.5 × 10^-5 M. Round to 2 decimal places.</question>
      <answer>4.46</answer>
   </qa_pair>
</evaluation>
```

.config/mcp/mcp-builder/scripts/requirements.txt
```
anthropic>=0.39.0
mcp>=1.1.0
```

.config/mcp/oraclepack-gold-pack/scripts/lint_attachments.py
```
# path: oraclepack-gold-pack/scripts/lint_attachments.py
import argparse
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple


@dataclass
class Step:
    n: str
    header: str
    lines: List[str]


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return path.read_text(encoding="utf-8", errors="replace")


def _extract_bash_fence(lines: List[str]) -> List[str]:
    fence_idxs = [i for i, ln in enumerate(lines) if ln.startswith("```")]
    if len(fence_idxs) != 2:
        raise ValueError(f"Expected exactly one fenced block (2 fence lines). Found {len(fence_idxs)}.")
    open_i, close_i = fence_idxs
    if lines[open_i].rstrip("\n") != "```bash":
        raise ValueError("Opening fence must be exactly ```bash.")
    if lines[close_i].rstrip("\n") != "```":
        raise ValueError("Closing fence must be exactly ```.")
    return [ln.rstrip("\n") for ln in lines[open_i + 1 : close_i]]


def _parse_steps(fence_lines: List[str]) -> List[Step]:
    header_re = re.compile(r"^#\s*(\d{2})\)\s+")
    header_idxs: List[Tuple[int, str]] = []
    for i, ln in enumerate(fence_lines):
        m = header_re.match(ln)
        if m:
            header_idxs.append((i, m.group(1)))

    if not header_idxs:
        raise ValueError("No step headers found inside bash fence.")

    steps: List[Step] = []
    for idx, (start_i, n) in enumerate(header_idxs):
        end_i = header_idxs[idx + 1][0] if idx + 1 < len(header_idxs) else len(fence_lines)
        block = fence_lines[start_i:end_i]
        steps.append(Step(n=n, header=block[0], lines=block))
    return steps


def _count_attachments(step: Step) -> int:
    count = 0
    for ln in step.lines[1:]:
        s = ln.strip()
        if not s or s.startswith("#"):
            continue
        # Count occurrences in non-comment lines
        count += len(re.findall(r"(?<!\S)(-f|--file)(?!\S)", ln))
    return count


def _is_unknown_reference(step: Step) -> bool:
    # Step header token format contains reference=...
    m = re.search(r"\breference=([^\s]+)", step.header)
    if not m:
        return False
    val = m.group(1).strip()
    return val.lower() == "unknown"


def _has_missing_artifact_request(step: Step) -> bool:
    hay = "\n".join(step.lines).lower()
    # Accept several common phrasings, keep it simple and robust.
    patterns = [
        r"missing file/path pattern",
        r"missing file.*pattern",
        r"attach next",
        r"name the exact missing.*pattern",
    ]
    return any(re.search(p, hay) for p in patterns)

def lint(path: Path) -> None:
    raw = _read_text(path)
    lines = raw.splitlines(True)
    fence = _extract_bash_fence(lines)
    steps = _parse_steps(fence)

    errors: List[str] = []
    for step in steps:
        attachments = _count_attachments(step)
        if attachments > 2:
            errors.append(f"Step {step.n}: has {attachments} attachments; must be <= 2 (minimal attachments rule).")

        if _is_unknown_reference(step) and not _has_missing_artifact_request(step):
            errors.append(
                f"Step {step.n}: reference=Unknown but prompt does not request missing file/path pattern(s) to attach next."
            )

    if errors:
        for e in errors:
            print(f"[ERROR] {e}", file=sys.stderr)
        sys.exit(1)

    print("[OK] Attachment lint passed (<=2 attachments per step; Unknown-reference prompts request missing patterns).")

def main() -> None:
    p = argparse.ArgumentParser(description="Lint oraclepack Stage-1 gold pack attachments (<=2 per step) and Unknown-reference prompt behavior.")
    p.add_argument("pack_path", help="Path to the Markdown pack file")
    args = p.parse_args()

    path = Path(args.pack_path)
    if not path.exists():
        print(f"[ERROR] File not found: {path}", file=sys.stderr)
        sys.exit(1)

    lint(path)


if __name__ == "__main__":
    main()
```

.config/mcp/oraclepack-gold-pack/scripts/validate_pack.py
```
# path: oraclepack-gold-pack/scripts/validate_pack.py
import argparse
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple, Optional, Dict


ALLOWED_CATEGORIES = [
    "contracts/interfaces",
    "invariants",
    "caching/state",
    "background jobs",
    "observability",
    "permissions",
    "migrations",
    "UX flows",
    "failure modes",
    "feature flags",
]

REQUIRED_TOKENS = [
    "ROI=",
    "impact=",
    "confidence=",
    "effort=",
    "horizon=",
    "category=",
    "reference=",
]


@dataclass
class Step:
    n: str
    header_line_no: int
    header_line: str
    block_lines: List[str]


def _fail(errors: List[str]) -> None:
    for e in errors:
        print(f"[ERROR] {e}", file=sys.stderr)
    sys.exit(1)


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        # fallback
        return path.read_text(encoding="utf-8", errors="replace")


def _extract_single_bash_fence(lines: List[str]) -> Tuple[int, int, List[str], List[str]]:
    """
    Enforces:
      - exactly two fence lines in entire document
      - first fence line must be exactly ```bash
      - closing fence line must be exactly ```
    Returns: (open_idx, close_idx, fence_lines, outside_lines)
    """
    fence_idxs = [i for i, ln in enumerate(lines) if ln.startswith("```")]

    if len(fence_idxs) != 2:
        raise ValueError(
            f"Expected exactly 1 fenced code block (2 fence lines), found {len(fence_idxs)} fence line(s)."
        )

    open_idx, close_idx = fence_idxs
    if lines[open_idx].rstrip("\n") != "```bash":
        raise ValueError("Opening fence must be exactly ```bash (no extra tokens/spaces).")
    if lines[close_idx].rstrip("\n") != "```":
        raise ValueError("Closing fence must be exactly ``` (no extra tokens/spaces).")
    if close_idx <= open_idx:
        raise ValueError("Closing fence appears before opening fence.")

    fence_lines = lines[open_idx + 1 : close_idx]
    outside_lines = lines[:open_idx] + lines[close_idx + 1 :]
    return open_idx, close_idx, fence_lines, outside_lines


def _parse_steps(fence_lines: List[str]) -> List[Step]:
    header_re = re.compile(r"^#\s*(\d{2})\s+")
    header_idxs: List[Tuple[int, str]] = []
    for i, ln in enumerate(fence_lines):
        m = header_re.match(ln)
        if m:
            header_idxs.append((i, m.group(1)))

    if len(header_idxs) != 20:
        raise ValueError(f"Expected exactly 20 step headers inside bash fence, found {len(header_idxs)}.")

    expected = [f"{i:02d}" for i in range(1, 21)]
    got = [n for _, n in header_idxs]
    if got != expected:
        raise ValueError(f"Step numbering must be sequential 01..20. Got: {got}")

    steps: List[Step] = []
    for idx, (start_i, n) in enumerate(header_idxs):
        end_i = header_idxs[idx + 1][0] if idx + 1 < len(header_idxs) else len(fence_lines)
        block = fence_lines[start_i:end_i]
        steps.append(
            Step(
                n=n,
                header_line_no=start_i + 1,  # 1-based within fence
                header_line=block[0].rstrip("\n"),
                block_lines=[b.rstrip("\n") for b in block],
            )
        )
    return steps


def _validate_header(step: Step, errors: List[str]) -> None:
    header = step.header_line

    for tok in REQUIRED_TOKENS:
        if tok not in header:
            errors.append(f"Step {step.n}: missing required token '{tok}' in header: {header}")

    # ensure each token has a value (non-empty, non-space)
    for key in ["ROI", "impact", "confidence", "effort", "horizon", "category", "reference"]:
        m = re.search(rf"\b{re.escape(key)}=([^\s]+)", header)
        if not m:
            errors.append(f"Step {step.n}: header missing/empty '{key}=' value: {header}")

    cat_m = re.search(r"\bcategory=([^\s]+(?:\s+[^\s]+)?)", header)
    # Category can contain a space (e.g., "background jobs", "UX flows", "failure modes", "feature flags")
    # The regex above captures up to two words; handle 2-word categories explicitly by matching allowed set.
    if cat_m:
        # Extract by checking allowed set presence after 'category='
        after = header.split("category=", 1)[1]
        # category value ends at next token start or end of line
        end = len(after)
        for token in [" reference=", " ROI=", " impact=", " confidence=", " effort=", " horizon="]:
            pos = after.find(token)
            if pos != -1:
                end = min(end, pos)
        cat_val = after[:end].strip()
        if cat_val not in ALLOWED_CATEGORIES:
            errors.append(
                f"Step {step.n}: invalid category='{cat_val}'. Must be one of: {ALLOWED_CATEGORIES}"
            )
    else:
        errors.append(f"Step {step.n}: could not parse category=... from header: {header}")


def _validate_write_output(step: Step, errors: List[str]) -> None:
    # Find first --write-output in the step block
    joined = "\n".join(step.block_lines)
    m = re.search(r'--write-output\s+(["(\S+)"|"(\S+)"|(\S+)])', joined)
    if not m:
        errors.append(f"Step {step.n}: missing --write-output in step block.")
        return

    path = m.group(2) or m.group(3) or m.group(4) or ""
    if "/" not in path:
        errors.append(
            f"Step {step.n}: --write-output path must look like <out_dir>/{step.n}-<slug>.md; got: {path}"
        )
        return

    filename = path.split("/")[-1]
    if not filename.startswith(f"{step.n}-"):
        errors.append(
            f"Step {step.n}: --write-output filename must start with '{step.n}-'; got: {filename}"
        )
    if not filename.endswith(".md"):
        errors.append(f"Step {step.n}: --write-output filename must end with .md; got: {filename}")


def _validate_coverage_check(outside_lines: List[str], errors: List[str]) -> None:
    text = "\n".join(outside_lines)
    # Require a "Coverage check" heading (case-insensitive)
    if re.search(r"^##\s+Coverage check\s*$", text, flags=re.IGNORECASE | re.MULTILINE) is None:
        errors.append('Missing "## Coverage check" section (must be outside the bash fence).')
        return

    # Ensure every category appears as "<category>:` somewhere after the heading
    # Find slice after the heading
    m = re.search(r"^##\s+Coverage check\s*$", text, flags=re.IGNORECASE | re.MULTILINE)
    assert m is not None
    after = text[m.end() :]

    missing = []
    for cat in ALLOWED_CATEGORIES:
        # Escape special chars (/, etc.)
        if re.search(rf"^\s*[*-]\s+{re.escape(cat)}\s*:", after, flags=re.MULTILINE) is None:
            missing.append(cat)
    if missing:
        errors.append(f'Coverage check missing category lines for: {missing}')


def validate_pack(path: Path) -> None:
    errors: List[str] = []
    raw = _read_text(path)
    lines = raw.splitlines(True)

    try:
        _, _, fence_lines, outside_lines = _extract_single_bash_fence(lines)
    except ValueError as e:
        _fail([str(e)])

    try:
        steps = _parse_steps(fence_lines)
    except ValueError as e:
        _fail([str(e)])

    for step in steps:
        _validate_header(step, errors)
        _validate_write_output(step, errors)

    _validate_coverage_check(outside_lines, errors)

    if errors:
        _fail(errors)

    print("[OK] Pack validates against gold Stage-1 contract.")


def main() -> None:
    p = argparse.ArgumentParser(
        description="Validate an oraclepack Stage-1 gold pack (single bash fence, 20 steps, strict headers, coverage check)."
    )
    p.add_argument("pack_path", help="Path to the Markdown pack file")
    args = p.parse_args()

    path = Path(args.pack_path)
    if not path.exists():
        _fail([f"File not found: {path}"])

    validate_pack(path)


if __name__ == "__main__":
    main()
```

.config/skills/oraclepack-pipeline-improver/assets/backlog-template.md
```
<!-- # path: oraclepack-pipeline-improver/assets/backlog-template.md -->
# Oraclepack Actionizer Backlog

Run:
- pack_id: TODO
- pack_hash: TODO
- generated_at: TODO

## Summary

- Total tasks: TODO
- Actionable: TODO
- Blocked: TODO
- Conflicts: TODO

## P0 (do first)

### <task_id> — <title>
- Status: actionable | blocked | conflict | noop
- Category: TODO
- Reference: TODO
- Expected artifacts: TODO
- Actions:
  - TODO
- Evidence:
  - Paths: TODO
  - Symbols: TODO
  - Commands: TODO
- Done when:
  - TODO

## P1

### <task_id> — <title>
- (same fields)

## Blocked / needs evidence

### <task_id> — <title>
- Missing inputs:
  - TODO
- Next smallest experiment (one action):
  - TODO

## Conflicts / needs resolution

### <task_id> — <title>
- Conflicting statements:
  - TODO
- What evidence resolves this:
  - TODO
- Proposed resolution (clearly marked as Proposed):
  - TODO
```

.config/skills/oraclepack-pipeline-improver/assets/change-plan-template.md
```
<!-- # path: oraclepack-pipeline-improver/assets/change-plan-template.md -->
# Oraclepack Change Plan

Run:
- pack_id: TODO
- pack_hash: TODO
- generated_at: TODO

## Principles

- Smallest shippable increments first.
- Every step has an acceptance check.
- Unknowns are explicit; no guessing.

## Phase 0 — Guardrails (validate + safety)

1) Implement/confirm strict validation (validate --strict --json)
- Scope:
  - TODO
- Acceptance:
  - TODO (e.g., rejects non-20 packs; emits JSON summary)
- Tests:
  - TODO (fixtures for invalid packs)

2) Path safety for output writing
- Scope:
  - TODO
- Acceptance:
  - TODO (rejects .. traversal / absolute escape)
- Tests:
  - TODO

## Phase 1 — Deterministic runs (run dir + manifests + resume)

3) Stable run dir + run.json / steps.json
- Scope:
  - TODO
- Acceptance:
  - TODO (creates .oraclepack/runs/<pack_id>/..., stable naming)
- Tests:
  - TODO

4) Resume default + --rerun semantics
- Scope:
  - TODO
- Acceptance:
  - TODO (interrupt + rerun skips completed via hashes)
- Tests:
  - TODO

## Phase 2 — Reliability (concurrency + retries + optional caching)

5) Concurrency cap
- Scope:
  - TODO
- Acceptance:
  - TODO (never exceeds N parallel calls)

6) Retry/backoff on transient errors
- Scope:
  - TODO
- Acceptance:
  - TODO (bounded retries; recorded in steps.json)

7) Optional caching (if enabled)
- Scope:
  - TODO
- Acceptance:
  - TODO (unchanged inputs cause zero provider calls)

## Phase 3 — Actionizer (Stage 3)

8) Implement actionize command and artifacts
- Scope:
  - normalized.jsonl + backlog.md + change-plan.md
- Acceptance:
  - TODO (byte-identical output on rerun with unchanged inputs)

## CI integration (optional)

9) Add CI mode wiring (run --ci --non-interactive --json-log; actionize --ci)
- Policy thresholds:
  - TODO/Unknown
- Acceptance:
  - TODO (exit codes match policy)
```

.config/skills/oraclepack-pipeline-improver/assets/normalized.example.jsonl
```
{"pack_id":"2026-01-05__nogit__deadbeef","pack_hash":"deadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeef","step_id":"07","task_id":"t_deadbeef_07_a1b2c3d4","title":"Define authorization boundary for server routes","status":"blocked","category":"permissions","reference":"src/server/auth/**","expected_artifacts":["src/server/auth/**","src/routes/**"],"actions":["Locate existing auth middleware/guards and document intended boundary","Add route guard checks or middleware wiring where missing"],"evidence":{"paths":["src/server/auth/**","src/routes/**"],"symbols":[],"commands":["ck --regex auth|permission|role src/server src/routes"]},"notes":["Auth wiring not evidenced in provided inputs"],"missing_inputs":["Repo paths containing current auth middleware or route guards (e.g., src/server/auth/**)","CLI help output for oraclepack validate/run/actionize (if already exists)"]}
{"pack_id":"2026-01-05__nogit__deadbeef","pack_hash":"deadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeef","step_id":"13","task_id":"t_deadbeef_13_e5f6a7b8","title":"Bound upload persistence metadata and retention policy","status":"actionable","category":"caching/state","reference":"src/server/persistence/sessionUploads.server.ts","expected_artifacts":["src/server/persistence/**","docs/plans/**"],"actions":["Add explicit retention policy + max entries/size controls","Ensure metadata captured is sufficient for downstream analysis"],"evidence":{"paths":["src/server/persistence/sessionUploads.server.ts"],"symbols":["saveSessionUpload"],"commands":["ck --regex saveSessionUpload src"]},"notes":[],"missing_inputs":[]}
```

.config/mcp/oraclepack-taskify/references/determinism-and-safety.md
```
# Determinism and safety guardrails

## Determinism rules

- Always select inputs by prefix ordering:
  - exactly one match for each: `01-*.md` … `20-*.md`
- If any prefix is missing or has multiple matches, exit non-zero with a precise error.
- Keep generated JSON normalized:
  - items sorted by id ascending (01..20)
  - stable ordering for arrays
- Keep output paths explicit and stable:
  - do not rely on shared environment variables across steps
  - each step re-declares its constants

## Safety rules

- No interactive prompts in the Action Pack.
- Fail fast when prerequisites are missing:
  - `task-master` (or override)
  - `oracle` (or override)
  - `tm` only in autopilot mode (default)
- Always `mkdir -p` parent directories before writing files.
- Avoid destructive operations:
  - do not delete
  - do not force push
  - do not commit to main/master in autopilot mode
- Autopilot mode:
  - require a clean working tree
  - if on main/master, create a new work branch before starting autopilot
  - write a state file to support resumption

## Failure behavior

- Prefer explicit, early errors over partial or ambiguous outputs.
- If Task Master output paths differ from defaults, print warnings but keep the pack deterministic.
```

.config/mcp/oraclepack-taskify/references/task-master-cli-cheatsheet.md
```
# Task Master CLI cheatsheet (minimal)

This skill assumes only these Task Master commands:

## Parse PRD into tasks

- `task-master parse-prd <prd_path>`
- If tag scoping is supported in your setup, the Action Pack attempts:
  - `task-master parse-prd <prd_path> --tag <tag>`
  - and falls back to the untagged command if the flag is not accepted.

## Analyze complexity

- `task-master analyze-complexity --output <out_dir>/tm-complexity.json`

## Expand tasks

- `task-master expand --all`

## Autopilot (default mode behavior)

- The Action Pack attempts: `tm autopilot` (via `tm_cmd`, default `tm`)
- If your `tm` tool does not support autopilot, run Stage 3 with `mode=backlog` or `mode=pipelines`.

Notes:
- The Action Pack checks for `.taskmaster/tasks.json` or `tasks.json` after parsing, but Task Master may be configured differently. If neither file exists, the pack prints a warning.
```

.config/mcp/oraclepack-taskify/references/workflow-overview.md
```
# Stage 3 (oraclepack-taskify) — Workflow overview

## What this stage solves

Stage 1 produces a 20-question oracle pack.
Stage 2 runs oraclepack and produces 20 answer files.

Stage 2 outputs are answers, not work. Stage 3 creates the deterministic bridge from answers to executable planning artifacts and (by default) starts a guarded autopilot to begin implementation.

## Inputs

- A completed oraclepack output directory containing exactly:
  - `01-*.md` … `20-*.md` (one file per prefix)
- Optional additional files to improve synthesis fidelity (extra attachments)

## Primary output (this skill generates)

- An “Action Pack” markdown file at:
  - default: `docs/oracle-actions-pack-YYYY-MM-DD.md`
  - override: `pack_path=...`

The Action Pack is designed to be executed as a deterministic pipeline.

## Artifacts the Action Pack produces when executed

- Canonical actions:
  - `<out_dir>/_actions.json` (machine-consumable)
  - `<out_dir>/_actions.md` (human summary)
- PRD/spec suitable for Task Master:
  - `.taskmaster/docs/oracle-actions-prd.md`
- Task Master outputs:
  - tasks created/expanded by `task-master`
  - complexity report: `<out_dir>/tm-complexity.json`
- Optional:
  - pipelines doc: `docs/oracle-actions-pipelines.md` (pipelines mode)
  - autopilot entrypoint + state file (autopilot mode, default)

## Execution modes

- backlog: actions → PRD → tasks
- pipelines: backlog + pipelines generation
- autopilot (default): backlog + guarded autopilot entrypoint
```

.config/mcp/oraclepack-taskify/assets/action-pack-template.md
```
# Oraclepack Stage 3 — Action Pack (Taskify)

Generated: {{pack_date}}

Parsed args (resolved):
- out_dir: {{out_dir}}
- pack_path: {{pack_path}}
- actions_json: {{actions_json}}
- actions_md: {{actions_md}}
- prd_path: {{prd_path}}
- tag: {{tag}}
- mode: {{mode}}
- top_n: {{top_n}}
- oracle_cmd: {{oracle_cmd}}
- task_master_cmd: {{task_master_cmd}}
- tm_cmd: {{tm_cmd}}
- extra_files: (embedded where applicable)

This document must contain exactly one bash code fence, and no other code fences.

```bash
# 01) Preflight: verify inputs and tools (fail fast)
set -euo pipefail

OUT_DIR="{{out_dir}}"
MODE="{{mode}}"
TASK_MASTER_CMD="{{task_master_cmd}}"
ORACLE_CMD="{{oracle_cmd}}"
TM_CMD="{{tm_cmd}}"

if [ ! -d "${OUT_DIR}" ]; then
  echo "ERROR: out_dir does not exist: ${OUT_DIR}" >&2
  exit 2
fi

shopt -s nullglob
for n in 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20; do
  matches=( "${OUT_DIR}/${n}-"*.md )
  if [ "${#matches[@]}" -eq 0 ]; then
    echo "ERROR: missing oracle output for prefix ${n}: expected ${OUT_DIR}/${n}-*.md" >&2
    exit 3
  fi
  if [ "${#matches[@]}" -gt 1 ]; then
    echo "ERROR: multiple oracle outputs for prefix ${n}; expected exactly one file." >&2
    printf '%s\n' "${matches[@]}" >&2
    exit 4
  fi
done

if ! command -v "${TASK_MASTER_CMD%% *}" >/dev/null 2>&1; then
  echo "ERROR: required tool missing: ${TASK_MASTER_CMD%% *} (from task_master_cmd='${TASK_MASTER_CMD}')" >&2
  exit 10
fi

if ! command -v "${ORACLE_CMD%% *}" >/dev/null 2>&1; then
  echo "ERROR: required tool missing: ${ORACLE_CMD%% *} (from oracle_cmd='${ORACLE_CMD}')" >&2
  exit 11
fi

if [ "${MODE}" = "autopilot" ]; then
  if ! command -v "${TM_CMD%% *}" >/dev/null 2>&1; then
    echo "ERROR: autopilot mode requires tm_cmd, but tool missing: ${TM_CMD%% *} (from tm_cmd='${TM_CMD}')" >&2
    echo "HINT: rerun Stage 3 with mode=backlog if you only want tasks generated." >&2
    exit 12
  fi
fi

mkdir -p "$(dirname "{{actions_json}}")" "$(dirname "{{actions_md}}")" "$(dirname "{{prd_path}}")" "docs" "${OUT_DIR}"

cat > "${OUT_DIR}/_actions.schema.md" <<'SCHEMA'
# Canonical Actions JSON Schema (human-readable)

This file describes the required structure of `_actions.json` produced in Step 02.

## Root object

- `metadata` (object, required)
  - `generated_at` (string, ISO-8601 recommended)
  - `pack_date` (string, YYYY-MM-DD)
  - `source_out_dir` (string)
  - `repo` (object)
    - `name` (string, optional)
    - `root` (string, optional)
    - `head_sha` (string, optional)
  - `tooling` (object)
    - `oracle_cmd` (string)
    - `task_master_cmd` (string)
  - `top_n` (number)

- `items` (array, required; max 20)
  - Each item is normalized and must include:

## Item fields (required unless marked optional)

- `id` (string): "01".."20"
- `source_file` (string): the exact answer file path used for this item
- `category` (string): a stable label (e.g., `contracts/interfaces`, `permissions`, `observability`, etc.)
- `priority_score` (number): higher means more important (can be ROI if available)
- `recommended_next_action` (string): a single imperative sentence
- `missing_artifacts` (array of strings): file/path globs to locate or create
- `acceptance_criteria` (array of strings): testable, objective conditions
- `risk_notes` (array of strings): specific risks/unknowns, no generic filler
- `estimated_effort` (string): one of `XS|S|M|L|XL` (or a short consistent scale)

## Optional item fields

- `dependencies` (array of strings): other `id` values that should precede this item

## Normalization rules

- Keep `items` sorted by `id` ascending (01..20), regardless of priority.
- Keep all arrays stably ordered (most important first; ties by lexical order).
- Do not include code fences in any string values.
SCHEMA

cat > "${OUT_DIR}/_prd_synthesis_prompt.md" <<'PROMPT'
See the canonical prompt text in the skill asset: assets/prd-synthesis-prompt.md.

This repo-local copy exists for traceability and to keep the Action Pack portable.
PROMPT

echo "OK: Preflight passed."
echo "OK: Inputs: ${OUT_DIR}/01-*.md .. ${OUT_DIR}/20-*.md"
echo "OK: Mode: ${MODE}"


# 02) Synthesize canonical actions JSON + summary MD
set -euo pipefail

OUT_DIR="{{out_dir}}"
ACTIONS_JSON="{{actions_json}}"
ACTIONS_MD="{{actions_md}}"

shopt -s nullglob
oracle_file_flags=()
for n in 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20; do
  matches=( "${OUT_DIR}/${n}-"*.md )
  if [ "${#matches[@]}" -ne 1 ]; then
    echo "ERROR: expected exactly one match for ${OUT_DIR}/${n}-*.md, got ${#matches[@]}" >&2
    printf '%s\n' "${matches[@]:-}" >&2
    exit 20
  fi
  oracle_file_flags+=( -f "${matches[0]}" )
done

# Extra attachments (auto-expanded at pack generation time)
# (If none, this section is empty)
{{EXTRA_FILES_LINES}}

mkdir -p "$(dirname "${ACTIONS_JSON}")" "$(dirname "${ACTIONS_MD}")"

{{oracle_cmd}} \
  --write-output "${ACTIONS_JSON}" \
  "${oracle_file_flags[@]}" \
  -p "$(cat <<'PROMPT'
You are producing a SINGLE JSON document and nothing else.

Task: Normalize 20 oraclepack answer files into a canonical actionable plan.

Hard requirements:
- Output MUST be valid JSON (no markdown, no prose, no code fences).
- Output MUST follow the schema described below.
- Output MUST be deterministic in ordering:
  - items sorted by id ascending: 01..20
  - arrays use stable ordering (highest priority first; ties lexical)
- Extract only actionable work. Do not invent repo facts. If evidence is missing, record it in missing_artifacts/risk_notes explicitly.

Schema (summarized):
Root object:
- metadata: { generated_at, pack_date, source_out_dir, repo?, tooling?, top_n }
- items: array (max 20)
Each item:
- id: "01".."20"
- source_file: string
- category: string
- priority_score: number
- recommended_next_action: string (single imperative sentence)
- missing_artifacts: string[]
- acceptance_criteria: string[] (testable)
- risk_notes: string[]
- estimated_effort: "XS"|"S"|"M"|"L"|"XL"
- dependencies?: string[] of ids

Repo/run context:
- pack_date: {{pack_date}}
- source_out_dir: {{out_dir}}
- top_n: {{top_n}}
- tag: {{tag}}

Output hygiene:
- Do not include backticks or fenced code blocks anywhere.
- Keep strings concise and specific.

Now produce the JSON.
PROMPT
)"

{{oracle_cmd}} \
  --write-output "${ACTIONS_MD}" \
  -f "${ACTIONS_JSON}" \
  -p "$(cat <<'PROMPT'
Write a human-readable Markdown summary of the canonical actions JSON.

Hard requirements:
- Output MUST be Markdown text with headings/bullets only (no code fences).
- Keep ordering aligned with items id ascending (01..20).
- Include:
  - short executive summary (5–10 bullets)
  - top {{top_n}} prioritized list (with id, title inferred from recommended_next_action, category, and why)
  - per-item: recommended_next_action + acceptance_criteria bullets + missing_artifacts bullets
- Do not invent facts; reflect only what is present in the JSON.

Now write the summary Markdown.
PROMPT
)"

echo "OK: Wrote ${ACTIONS_JSON}"
echo "OK: Wrote ${ACTIONS_MD}"


# 03) Generate PRD for Task Master
set -euo pipefail

ACTIONS_JSON="{{actions_json}}"
PRD_PATH="{{prd_path}}"

mkdir -p "$(dirname "${PRD_PATH}")"

{{oracle_cmd}} \
  --write-output "${PRD_PATH}" \
  -f "${ACTIONS_JSON}" \
  -p "$(cat <<'PROMPT'
Write a Task Master-compatible PRD (Markdown) derived from the canonical actions JSON.

Hard requirements:
- Output MUST be Markdown (no code fences).
- Be dependency-aware (use dependencies if present; otherwise infer minimal dependencies cautiously).
- Prioritize focus: select the top N items by priority_score (N = TOP_N), but keep a traceability appendix mapping all ids 01..20.
- Every selected item must become an implementation-ready PRD section with:
  - Goal
  - Scope
  - Non-goals
  - Constraints
  - Acceptance criteria (testable)
  - Risks/unknowns
  - Dependencies (explicit)
- Use the tag value "{{tag}}" in the PRD text where helpful for grouping.

Constants:
- TOP_N={{top_n}}
- TAG={{tag}}

Now produce the PRD.
PROMPT
)"

echo "OK: Wrote ${PRD_PATH}"


# 04) Task Master: parse PRD into tasks
set -euo pipefail

PRD_PATH="{{prd_path}}"
TASK_MASTER_CMD="{{task_master_cmd}}"
TAG="{{tag}}"

if "${TASK_MASTER_CMD}" parse-prd "${PRD_PATH}" --tag "${TAG}" 2>/dev/null; then
  echo "OK: task-master parse-prd (tagged) succeeded."
else
  echo "INFO: task-master parse-prd did not accept --tag; retrying without tag."
  "${TASK_MASTER_CMD}" parse-prd "${PRD_PATH}"
fi

if [ -f ".taskmaster/tasks.json" ]; then
  echo "OK: Found .taskmaster/tasks.json"
elif [ -f "tasks.json" ]; then
  echo "OK: Found tasks.json"
else
  echo "WARN: tasks.json not found at .taskmaster/tasks.json or tasks.json. Check your Task Master configuration/output path."
fi


# 05) Task Master: analyze complexity and save report
set -euo pipefail

TASK_MASTER_CMD="{{task_master_cmd}}"
OUT_DIR="{{out_dir}}"

mkdir -p "${OUT_DIR}"

"${TASK_MASTER_CMD}" analyze-complexity --output "${OUT_DIR}/tm-complexity.json"
echo "OK: Wrote ${OUT_DIR}/tm-complexity.json"


# 06) Task Master: expand tasks
set -euo pipefail

TASK_MASTER_CMD="{{task_master_cmd}}"

"${TASK_MASTER_CMD}" expand --all
echo "OK: Expanded tasks."


# 07) Pipelines (pipelines mode only): generate deterministic pipelines from tasks.json
set -euo pipefail

MODE="{{mode}}"

if [ "${MODE}" != "pipelines" ]; then
  echo "SKIP: mode=${MODE} (pipelines step runs only when mode=pipelines)."
else
  tasks_path=""
  if [ -f ".taskmaster/tasks.json" ]; then
    tasks_path=".taskmaster/tasks.json"
  elif [ -f "tasks.json" ]; then
    tasks_path="tasks.json"
  else
    echo "ERROR: tasks.json not found; cannot generate pipelines." >&2
    exit 70
  fi

  mkdir -p "docs"

  {{oracle_cmd}} \
    --write-output "docs/oracle-actions-pipelines.md" \
    -f "${tasks_path}" \
    -p "$(cat <<'PROMPT'
Generate deterministic command pipelines from tasks.json.

Hard requirements:
- Output MUST be Markdown (no code fences).
- Include 3–6 pipelines, each a numbered list of shell commands.
- Each pipeline must be tests-first and avoid destructive operations.
- Commands should be generic and repo-agnostic (no invented scripts).
- Include a short “resume strategy” section explaining how to re-run pipelines safely.

Now write docs/oracle-actions-pipelines.md content.
PROMPT
)"

  echo "OK: Wrote docs/oracle-actions-pipelines.md"
fi


# 08) Autopilot (autopilot mode only): branch safety + guarded entrypoint
set -euo pipefail

MODE="{{mode}}"
TM_CMD="{{tm_cmd}}"
OUT_DIR="{{out_dir}}"
PACK_DATE="{{pack_date}}"
TAG="{{tag}}"

if [ "${MODE}" != "autopilot" ]; then
  echo "SKIP: mode=${MODE} (autopilot step runs only when mode=autopilot)."
else
  if ! command -v git >/dev/null 2>&1; then
    echo "ERROR: autopilot mode requires git on PATH." >&2
    exit 80
  fi

  if ! git rev-parse --is-inside-work-tree >/dev/null 2>&1; then
    echo "ERROR: not inside a git work tree; autopilot mode requires a git repo." >&2
    exit 81
  fi

  if ! git diff --quiet || ! git diff --cached --quiet; then
    echo "ERROR: working tree not clean. Commit/stash before autopilot." >&2
    exit 82
  fi

  current_branch="$(git rev-parse --abbrev-ref HEAD)"
  if [ "${current_branch}" = "main" ] || [ "${current_branch}" = "master" ]; then
    new_branch="oraclepack/${PACK_DATE}-${TAG}"
    echo "INFO: on default-like branch (${current_branch}); creating work branch: ${new_branch}"
    git checkout -b "${new_branch}"
  else
    echo "OK: current branch is ${current_branch}"
  fi

  mkdir -p "${OUT_DIR}"
  cat > "${OUT_DIR}/tm-autopilot.state.json" <<STATE
{"pack_date":"${PACK_DATE}","tag":"${TAG}","mode":"autopilot","notes":"State file created by Stage-3 Action Pack. Autopilot tooling should resume from this file if supported."}
STATE

  echo "OK: Wrote ${OUT_DIR}/tm-autopilot.state.json"
  echo "INFO: Starting autopilot via: ${TM_CMD} autopilot"
  echo "INFO: If your tm tool uses a different subcommand, edit this step accordingly."

  if ! "${TM_CMD}" --help 2>&1 | grep -qi "autopilot"; then
    echo "ERROR: '${TM_CMD}' does not advertise 'autopilot' in --help output." >&2
    echo "HINT: rerun Stage 3 with mode=backlog if you only want tasks generated." >&2
    exit 83
  fi

  "${TM_CMD}" autopilot
fi
```
```

.config/mcp/oraclepack-taskify/assets/actions-json-schema.md
```
# Canonical Actions JSON Schema (human-readable)

This schema defines the required structure of the canonical actions file:

- Default path: `<out_dir>/_actions.json`

## Root object

The root MUST be a JSON object with:

### metadata (required)

- `generated_at` (string): generation timestamp (ISO-8601 recommended)
- `pack_date` (string): `YYYY-MM-DD`
- `source_out_dir` (string): the oraclepack output dir used (e.g., `oracle-out`)
- `repo` (object, optional):
  - `name` (string, optional)
  - `root` (string, optional)
  - `head_sha` (string, optional)
- `tooling` (object, optional):
  - `oracle_cmd` (string)
  - `task_master_cmd` (string)
- `top_n` (number): the top-N focus value used to build PRD/pipelines

### items (required; max 20)

`items` MUST be an array with up to 20 objects. Each item MUST include:

- `id` (string): `"01"`..`"20"`
- `source_file` (string): the specific answer file used for this item
- `category` (string): stable label describing the domain area
- `priority_score` (number): higher means higher priority (can be ROI if present)
- `recommended_next_action` (string): single imperative sentence
- `missing_artifacts` (array of strings): file/path globs or concrete paths
- `acceptance_criteria` (array of strings): testable, objective conditions
- `risk_notes` (array of strings): risks/unknowns grounded in evidence gaps
- `estimated_effort` (string): use a consistent scale such as `XS|S|M|L|XL`

Optional:

- `dependencies` (array of strings): other ids (e.g., `["03","07"]`) that should precede this item

## Normalization rules

- Items MUST be sorted by `id` ascending (`01..20`) for machine stability.
- Within each item:
  - `missing_artifacts`, `acceptance_criteria`, and `risk_notes` MUST be stably ordered.
- Do not include fenced code blocks in any string values.
```

.config/mcp/oraclepack-taskify/assets/prd-synthesis-prompt.md
```
# Stage 3 Synthesis Prompts (exact text)

Use these prompts verbatim in the Action Pack.

## Prompt A — Canonical actions JSON (_actions.json)

You are producing a SINGLE JSON document and nothing else.

Task: Normalize 20 oraclepack answer files into a canonical actionable plan.

Hard requirements:
- Output MUST be valid JSON (no markdown, no prose, no code fences).
- Output MUST follow the schema described below.
- Output MUST be deterministic in ordering:
  - items sorted by id ascending: 01..20
  - arrays use stable ordering (highest priority first; ties lexical)
- Extract only actionable work. Do not invent repo facts. If evidence is missing, record it in missing_artifacts/risk_notes explicitly.

Schema (summarized):
Root object:
- metadata: { generated_at, pack_date, source_out_dir, repo?, tooling?, top_n }
- items: array (max 20)
Each item:
- id: "01".."20"
- source_file: string
- category: string
- priority_score: number
- recommended_next_action: string (single imperative sentence)
- missing_artifacts: string[]
- acceptance_criteria: string[] (testable)
- risk_notes: string[]
- estimated_effort: "XS"|"S"|"M"|"L"|"XL"
- dependencies?: string[] of ids

Output hygiene:
- Do not include backticks or fenced code blocks anywhere.
- Keep strings concise and specific.

## Prompt B — Task Master PRD (oracle-actions-prd.md)

Write a Task Master-compatible PRD (Markdown) derived from the canonical actions JSON.

Hard requirements:
- Output MUST be Markdown (no code fences).
- Be dependency-aware (use dependencies if present; otherwise infer minimal dependencies cautiously).
- Prioritize focus: select the top N items by priority_score (N = TOP_N), but keep a traceability appendix mapping all ids 01..20.
- Every selected item must become an implementation-ready PRD section with:
  - Goal
  - Scope
  - Non-goals
  - Constraints
  - Acceptance criteria (testable)
  - Risks/unknowns
  - Dependencies (explicit)

Hygiene:
- Do not invent scripts/paths; use missing_artifacts when you need the repo to supply something.
- Keep acceptance criteria objective and testable.
```

.config/mcp/oraclepack-taskify/scripts/detect-oracle-outputs.sh
```
#!/usr/bin/env bash
set -euo pipefail

out_dir="${1:-oracle-out}"

if [[ ! -d "${out_dir}" ]]; then
  echo "ERROR: out_dir does not exist: ${out_dir}" >&2
  exit 2
fi

shopt -s nullglob

for n in 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20; do
  matches=( "${out_dir}/${n}-"*.md )
  if [[ "${#matches[@]}" -eq 0 ]]; then
    echo "ERROR: missing output for prefix ${n}: expected ${out_dir}/${n}-*.md" >&2
    exit 3
  fi
  if [[ "${#matches[@]}" -gt 1 ]]; then
    echo "ERROR: multiple outputs for prefix ${n}; expected exactly one file." >&2
    printf '%s\n' "${matches[@]}" >&2
    exit 4
  fi
  printf '%s\n' "${matches[0]}"
done
```

.config/mcp/oraclepack-taskify/scripts/validate-action-pack.sh
```
#!/usr/bin/env bash
set -euo pipefail

pack_path="${1:-}"
if [[ -z "${pack_path}" ]]; then
  echo "Usage: validate-action-pack.sh <path/to/oracle-actions-pack.md>" >&2
  exit 2
fi

if [[ ! -f "${pack_path}" ]]; then
  echo "ERROR: file not found: ${pack_path}" >&2
  exit 3
fi

# Rule: exactly one bash fence, and no other fences.
bash_fence_count="$(grep -cE '^[[:space:]]*```bash[[:space:]]*$' "${pack_path}" || true)"
any_fence_count="$(grep -cE '^[[:space:]]*```' "${pack_path}" || true)"

if [[ "${bash_fence_count}" -ne 1 ]]; then
  echo "ERROR: expected exactly one '```bash' fence; found ${bash_fence_count}" >&2
  exit 10
fi

if [[ "${any_fence_count}" -ne 2 ]]; then
  echo "ERROR: expected exactly 2 total fences (start+end); found ${any_fence_count}" >&2
  echo "Fences found:" >&2
  grep -nE '^[[:space:]]*```' "${pack_path}" >&2 || true
  exit 11
fi

# Extract lines within the bash fence and validate step headers.
in_bash=0
headers=()
while IFS= read -r line; do
  if [[ "${line}" =~ ^[[:space:]]*```bash[[:space:]]*$ ]]; then
    in_bash=1
    continue
  fi
  if [[ "${line}" =~ ^[[:space:]]*```[[:space:]]*$ ]]; then
    in_bash=0
    continue
  fi
  if [[ "${in_bash}" -eq 1 ]]; then
    if [[ "${line}" =~ ^#\ ([0-9]{2})\) ]]; then
      headers+=( "${BASH_REMATCH[1]}" )
    fi
  fi
done < "${pack_path}"

if [[ "${#headers[@]}" -lt 1 ]]; then
  echo "ERROR: no step headers found inside bash fence (expected '# NN)')" >&2
  exit 20
fi

# Validate strict sequential: 01..N with no gaps and no duplicates.
seen=""
expected=1
for h in "${headers[@]}"; do
  # Check duplicates
  if [[ " ${seen} " == *" ${h} "* ]]; then
    echo "ERROR: duplicate step header: ${h}" >&2
    exit 21
  fi
  seen="${seen} ${h}"

  exp="$(printf '%02d' "${expected}")"
  if [[ "${h}" != "${exp}" ]]; then
    echo "ERROR: non-sequential step header. Expected ${exp}, got ${h}" >&2
    echo "All headers: ${headers[*]}" >&2
    exit 22
  fi
  expected=$((expected + 1))
done

echo "OK: Action Pack validation passed."
```

.config/skills/oraclepack-pipeline-improver/references/actionizer-spec.md
```
<!-- # path: oraclepack-pipeline-improver/references/actionizer-spec.md -->
# Stage 3 “Actionizer” spec (proposed)

Goal: deterministically convert the 20 outputs of a run into actionable engineering work artifacts, without duplicating work on reruns.

## Inputs

- `.oraclepack/runs/<pack_id>/run.json`
- `.oraclepack/runs/<pack_id>/steps.json`
- `.oraclepack/runs/<pack_id>/outputs/*`

## Processing pipeline (deterministic)

1) **Load** run + steps + outputs
- If any output is missing, mark that step as `missing_output` in normalization.

2) **Normalize** each step output into a stable record
- Extract (when present):
  - question metadata (QuestionId/Category/Reference/ExpectedArtifacts),
  - recommended actions,
  - evidence anchors (paths, symbols, commands),
  - unknowns / missing inputs.
- Classify:
  - `actionable` (clear tasks),
  - `blocked` (missing evidence prevents action),
  - `conflict` (contradictory requirements/answers),
  - `noop` (no action required).

3) **Deduplicate** tasks across steps
- Use stable task IDs derived from `pack_hash` + a stable task key (e.g., normalized title + target path).
- Reruns must produce byte-identical outputs when inputs unchanged.

4) **Generate** three core artifacts:
- `normalized.jsonl` (machine-readable records)
- `backlog.md` (human-prioritized tasks)
- `change-plan.md` (ordered implementation plan, smallest-first)

5) Optional exports:
- `github-issues.json` (issue objects; exact schema TODO/Unknown)
- `taskmaster.json` (taskmaster-style import; exact schema TODO/Unknown)

## Output files

### A) `actionizer/normalized.jsonl`

One JSON object per line.

**Proposed record fields:**
- `pack_id` (string)
- `pack_hash` (string)
- `step_id` (string `"01"`..`"20"`)
- `task_id` (string; stable)
- `title` (string)
- `status` (enum: `actionable` | `blocked` | `conflict` | `noop`)
- `category` (string | null)
- `reference` (string | null)
- `expected_artifacts` (string[] | null)
- `actions` (string[]) — concrete “do X” items
- `evidence` (object)
  - `paths` (string[])
  - `symbols` (string[])
  - `commands` (string[])
- `notes` (string[])
- `missing_inputs` (string[])

### B) `actionizer/backlog.md`

Use assets/backlog-template.md as the base.

Rules:
- Group by category (if present), else by subsystem (inferred from reference paths).
- Include blocked/conflict items explicitly with “what evidence is needed”.

### C) `actionizer/change-plan.md`

Use assets/change-plan-template.md as the base.

Rules:
- Ordered, smallest shippable increments first.
- Each step includes acceptance criteria and “done when…” checks.
- If CI gating thresholds exist, include them; else mark TODO.

## Handling blocked/conflict outputs

- `blocked` must include a **single next smallest experiment** (one action) to obtain missing evidence.
- `conflict` must include:
  - conflicting statements,
  - what file/path/log is needed to resolve,
  - a proposed resolution strategy (flagged as Proposed).

## Idempotency / stability requirements

- Stable IDs (required):
  - deterministic function of `pack_hash` + `step_id` + normalized title (or similar stable key).
- Reruns:
  - must not duplicate tasks,
  - must regenerate byte-identical artifacts if inputs unchanged.
```

.config/skills/oraclepack-pipeline-improver/references/cli-contract.md
```
<!-- # path: oraclepack-pipeline-improver/references/cli-contract.md -->
# oraclepack CLI contract (proposed)

This document is the target CLI behavior to implement. If the current repo differs, treat that as **Observed** and this as **Proposed**.

## Commands

### 1) `oraclepack validate`

**Goal:** Deterministically validate a pack file and (optionally) emit machine-readable results.

**Proposed:**
- `oraclepack validate <pack.md> [--strict] [--json]`

**--strict checks (proposed minimum):**
- Exactly **20** oracle invocations.
- No schema drift vs expected pack format (**exact schema rules: TODO/Unknown** unless provided).
- Each question has required fields present (as enforceable in current schema; else **TODO**).
- Stable ordering checks (if applicable): ROI desc, effort asc (only if the pack uses those fields; else skip).

**--json output (proposed):**
- Print a single JSON object to stdout (or to a specified file if supported; **TODO**).
- Include `ok: boolean`, `errors: []`, `warnings: []`, and per-question metadata when parseable.

### 2) `oraclepack run`

**Goal:** Execute the 20 steps into a deterministic run directory with resumable semantics.

**Proposed:**
- `oraclepack run <pack.md> [--max-parallel N] [--resume] [--rerun all|failed|01,03,07] [--ci] [--non-interactive] [--json-log]`

**Run dir (proposed):**
- Create: `.oraclepack/runs/<pack_id>/`
- Emit at least:
  - `.oraclepack/runs/<pack_id>/run.json`
  - `.oraclepack/runs/<pack_id>/steps.json`
  - `.oraclepack/runs/<pack_id>/outputs/` (20 files; naming convention below)
  - `.oraclepack/runs/<pack_id>/logs/` (optional)

**pack_id (proposed):**
- `YYYY-MM-DD__<gitshort>__<packhash8>`
- If git SHA unavailable: use `nogit` for `<gitshort>`.

**Output naming (proposed):**
- Prefer deterministic: `outputs/01.md` ... `outputs/20.md`
- If a stable QuestionId exists: optionally include in filename, but do not break determinism.

**Resume/rerun (proposed):**
- Resume is default if the run dir already exists:
  - skip steps already marked `ok` with matching output hash.
- `--rerun failed` reruns only failed steps.
- `--rerun all` reruns all steps.
- `--rerun 01,03,07` reruns specified step IDs.

**Concurrency (proposed):**
- `--max-parallel N` bounds parallel provider calls.
- Optional: per-provider caps via config (**TODO/Unknown**: config format).

**Transient errors (proposed):**
- Implement exponential backoff + jitter on retryable errors (e.g., 429/503) up to a retry budget.
- Persist retry counts/outcomes into `steps.json`.

### 3) `oraclepack actionize`

**Goal:** Convert run outputs into actionable engineering work artifacts.

**Proposed:**
- `oraclepack actionize --run-dir .oraclepack/runs/<pack_id> [--ci]`

**Inputs:**
- `run.json`, `steps.json`
- `outputs/` (20 outputs)

**Outputs:**
- `.oraclepack/runs/<pack_id>/actionizer/normalized.jsonl`
- `.oraclepack/runs/<pack_id>/actionizer/backlog.md`
- `.oraclepack/runs/<pack_id>/actionizer/change-plan.md`
- Optional:
  - `.oraclepack/runs/<pack_id>/actionizer/github-issues.json`
  - `.oraclepack/runs/<pack_id>/actionizer/taskmaster.json`

## CI mode (proposed)

- `oraclepack run --ci --non-interactive --json-log`
- `oraclepack actionize --ci`

**Behavior (proposed):**
- No TUI interaction.
- Structured logs enabled (JSONL or JSON objects; **TODO/Unknown** exact format).
- Exit codes are policy-driven:
  - validation failures → non-zero
  - run failures exceeding retry budget → non-zero
  - optional policy thresholds (completion rate, action yield) → **TODO/Unknown** threshold values.

## Security / path safety (proposed)

- Prevent any output flag (including legacy `--write-output` if present) from writing outside the intended run directory.
- Reject path traversal (e.g., `..`) and absolute paths when writing within `.oraclepack/runs/<pack_id>/...`.
```

.config/skills/oraclepack-pipeline-improver/references/run-manifest-spec.md
```
<!-- # path: oraclepack-pipeline-improver/references/run-manifest-spec.md -->
# Run manifest spec (proposed)

This defines the minimum content for run artifacts to enable traceability, resume/rerun, and Stage 3 processing.

## `.oraclepack/runs/<pack_id>/run.json`

**Required fields (proposed minimum):**
- `pack_id` (string)
- `pack_path` (string)
- `pack_hash` (string; full hash)
- `created_at` (RFC3339 string)
- `git_sha` (string | null)
- `oraclepack_version` (string | TODO if not available)
- `oracle_version` (string | TODO if not available)
- `max_parallel` (number | null)
- `ci` (boolean)
- `providers` (object | TODO if not available)
- `models` (object | TODO if not available)

**Notes:**
- If any value cannot be derived, set it to `null` and record a `warnings[]` entry rather than inventing it.

## `.oraclepack/runs/<pack_id>/steps.json`

Represent steps as an array of 20 items ordered by `step_id`.

**Per-step fields (proposed minimum):**
- `step_id` (string `"01"`..`"20"`)
- `question_id` (string | null) — if present in the pack/prompt metadata
- `category` (string | null)
- `reference` (string | null)
- `invocation_hash` (string) — hash of canonical invocation inputs (prompt + attachments + provider/model knobs)
- `output_path` (string)
- `output_hash` (string | null)
- `status` (enum: `pending` | `ok` | `failed` | `skipped`)
- `attempts` (number)
- `last_error` (string | null)
- `started_at` (RFC3339 string | null)
- `finished_at` (RFC3339 string | null)

## Hashing (proposed)

### `pack_hash`
- Compute from a canonical representation of the pack file:
  - normalize line endings,
  - remove non-semantic whitespace if safe (TODO/Unknown: exact pack grammar),
  - hash the resulting bytes.

### `invocation_hash`
- Compute from:
  - prompt text (including embedded mini-metadata),
  - attachment file contents (hash of contents, not just paths),
  - provider + model identifiers,
  - deterministic knobs (temperature, etc.) if applicable.

If attachment content hashing cannot be performed, record **Unknown/TODO** and do not enable caching based on incomplete inputs.
```

.config/skills/oraclepack-pipeline-improver/references/stage1-prompt-metadata.md
```
<!-- # path: oraclepack-pipeline-improver/references/stage1-prompt-metadata.md -->
# Stage 1 prompt-embedded metadata (proposed)

Goal: improve downstream parsing for Stage 2/3 without changing the oracle pack schema.

## Constraints

- Do not change the pack’s structural schema unless an explicit migration path is provided.
- Embed metadata inside the prompt text (the `-p` payload) in a parseable, consistent format.

## Recommended metadata block (inside the prompt)

Add at the *very top* of each prompt:

```

[oraclepack-meta]
QuestionId: 07
Category: permissions
Reference: src/server/auth/middleware.ts
ExpectedArtifacts:

* src/server/auth/**
* docs/plans/...
  [/oraclepack-meta]

```

## Parsing rules (deterministic)

- The block starts with `[oraclepack-meta]` and ends with `[/oraclepack-meta]`.
- Keys are case-sensitive as shown.
- Multi-line lists are allowed for `ExpectedArtifacts`.
- If any key is missing, treat it as `null` and continue.

## Minimal required keys (recommended)

- QuestionId
- Category
- Reference
- ExpectedArtifacts (optional but recommended)

If the Stage 1 generator cannot produce these, it should write `Unknown` values explicitly rather than omitting keys.
```

.config/skills/oraclepack-tickets-pack/scripts/lint_attachments.py
```
import argparse
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple


@dataclass
class Step:
    n: str
    header: str
    lines: List[str]


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return path.read_text(encoding="utf-8", errors="replace")


def _extract_bash_fence(lines: List[str]) -> List[str]:
    fence_idxs = [i for i, ln in enumerate(lines) if ln.startswith("```")]
    if len(fence_idxs) != 2:
        raise ValueError(f"Expected exactly one fenced block (2 fence lines). Found {len(fence_idxs)}.")
    open_i, close_i = fence_idxs
    if lines[open_i].rstrip("\n") != "```bash":
        raise ValueError("Opening fence must be exactly ```bash.")
    if lines[close_i].rstrip("\n") != "```":
        raise ValueError("Closing fence must be exactly ```.")
    return [ln.rstrip("\n") for ln in lines[open_i + 1 : close_i]]


def _parse_steps(fence_lines: List[str]) -> List[Step]:
    header_re = re.compile(r"^#\s*(\d{2})\)\s+")
    header_idxs: List[Tuple[int, str]] = []
    for i, ln in enumerate(fence_lines):
        m = header_re.match(ln)
        if m:
            header_idxs.append((i, m.group(1)))

    if not header_idxs:
        raise ValueError("No step headers found inside bash fence.")

    steps: List[Step] = []
    for idx, (start_i, n) in enumerate(header_idxs):
        end_i = header_idxs[idx + 1][0] if idx + 1 < len(header_idxs) else len(fence_lines)
        block = fence_lines[start_i:end_i]
        steps.append(Step(n=n, header=block[0], lines=block))
    return steps


def _count_native_attachments(step: Step) -> int:
    """
    Counts -f/--file occurrences excluding:
      - comment lines
      - the literal extra_files line (immediately following the marker comment)
    """
    count = 0
    ignore_next_nonempty = False

    for ln in step.lines[1:]:
        s = ln.strip()
        if not s:
            continue

        # Detect extra_files marker comment; ignore next non-empty line.
        if s.startswith("#") and "extra_files appended literally" in s.lower():
            ignore_next_nonempty = True
            continue

        if ignore_next_nonempty:
            # Skip counting attachments on the extra_files line itself.
            ignore_next_nonempty = False
            continue

        if s.startswith("#"):
            continue

        count += len(re.findall(r"(?<!\S)(-f|--file)(?!\S)", ln))
    return count

def lint(path: Path) -> None:
    raw = _read_text(path)
    lines = raw.splitlines(True)
    fence = _extract_bash_fence(lines)
    steps = _parse_steps(fence)

    errors: List[str] = []
    for step in steps:
        native = _count_native_attachments(step)
        if native > 2:
            errors.append(
                f"Step {step.n}: has {native} native attachments; must be <= 2 (ticket bundle + at most one repo file)."
            )

    if errors:
        for e in errors:
            print(f"[ERROR] {e}", file=sys.stderr)
        sys.exit(1)

    print("[OK] Attachment lint passed (native attachments <= 2 per step; extra_files line excluded).")

def main() -> None:
    p = argparse.ArgumentParser(
        description="Lint ticket-driven oraclepack Stage-1 packs for native attachments (<=2 per step, excluding literal extra_files line)."
    )
    p.add_argument("pack_path", help="Path to the Markdown pack file")
    args = p.parse_args()

    path = Path(args.pack_path)
    if not path.exists():
        print(f"[ERROR] File not found: {path}", file=sys.stderr)
        sys.exit(1)

    lint(path)


if __name__ == "__main__":
    main()
```

.config/skills/oraclepack-tickets-pack/scripts/validate_pack.py
```
import argparse
import re
import sys
from dataclasses import dataclass
from pathlib import Path, PurePosixPath
from typing import Dict, List, Tuple


ALLOWED_CATEGORIES = [
    "contracts/interfaces",
    "invariants",
    "caching/state",
    "background jobs",
    "observability",
    "permissions",
    "migrations",
    "UX flows",
    "failure modes",
    "feature flags",
]

# Required header tokens, in strict order.
HEADER_TOKEN_ORDER = [
    "ROI=",
    "impact=",
    "confidence=",
    "effort=",
    "horizon=",
    "category=",
    "reference=",
]


@dataclass
class Step:
    n: str
    header_line_no: int  # 1-based within fence
    header_line: str
    block_lines: List[str]


def _fail(errors: List[str]) -> None:
    for e in errors:
        print(f"[ERROR] {e}", file=sys.stderr)
    sys.exit(1)


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return path.read_text(encoding="utf-8", errors="replace")


def _extract_single_bash_fence(lines: List[str]) -> Tuple[int, int, List[str], List[str]]:
    """
    Enforces:
      - exactly one fenced code block labeled bash
      - no other fences anywhere
      - opening fence line must be exactly ```bash
      - closing fence line must be exactly ```
    """
    fence_locs = [i for i, ln in enumerate(lines) if re.match(r"^```", ln)]
    if len(fence_locs) != 2:
        # Show all fence-like lines to help debugging.
        details = []
        for i, ln in enumerate(lines):
            if re.match(r"^```", ln):
                details.append(f"line {i+1}: {ln.rstrip()}")
        raise ValueError(
            f"Expected exactly one fenced code block (2 fence lines), found {len(fence_locs)} fence line(s). "
            + ("Fences: " + "; ".join(details) if details else "")
        )

    open_i, close_i = fence_locs
    if lines[open_i].rstrip("\n") != "```bash":
        raise ValueError("Opening fence must be exactly ```bash on its own line (no spaces).")
    if lines[close_i].rstrip("\n") != "```":
        raise ValueError("Closing fence must be exactly ``` on its own line (no spaces).")
    if close_i <= open_i:
        raise ValueError("Closing fence appears before opening fence.")

    fence_lines = lines[open_i + 1 : close_i]
    outside_lines = lines[:open_i] + lines[close_i + 1 :]
    return open_i, close_i, fence_lines, outside_lines


def _parse_steps(fence_lines: List[str]) -> List[Step]:
    header_re = re.compile(r"^#\s*(\d{2})\)\s+")
    header_idxs: List[Tuple[int, str]] = []
    for i, ln in enumerate(fence_lines):
        m = header_re.match(ln)
        if m:
            header_idxs.append((i, m.group(1)))

    if len(header_idxs) != 20:
        raise ValueError(f"Expected exactly 20 step headers inside bash fence, found {len(header_idxs)}.")

    expected = [f"{i:02d}" for i in range(1, 21)]
    got = [n for _, n in header_idxs]
    if got != expected:
        raise ValueError(f"Step numbering must be sequential 01..20. Got: {got}")

    steps: List[Step] = []
    for idx, (start_i, n) in enumerate(header_idxs):
        end_i = header_idxs[idx + 1][0] if idx + 1 < len(header_idxs) else len(fence_lines)
        block = fence_lines[start_i:end_i]
        steps.append(
            Step(
                n=n,
                header_line_no=start_i + 1,
                header_line=block[0].rstrip("\n"),
                block_lines=[b.rstrip("\n") for b in block],
            )
        )
    return steps


def _header_token_positions(header: str) -> Dict[str, int]:
    pos: Dict[str, int] = {}
    for t in HEADER_TOKEN_ORDER:
        pos[t] = header.find(t)
    return pos


def _parse_category_value(header: str) -> str:
    if "category=" not in header:
        return ""
    after = header.split("category=", 1)[1]
    # Category ends at the start of " reference=" (strict contract).
    end = after.find(" reference=")
    if end == -1:
        # As a fallback, try other token starts, though contract expects reference= last.
        for token in [" ROI=", " impact=", " confidence=", " effort=", " horizon="]:
            p = after.find(token)
            if p != -1:
                end = p if end == -1 else min(end, p)
    if end == -1:
        cat = after.strip()
    else:
        cat = after[:end].strip()
    return cat


def _has_nonempty_scalar(header: str, key: str) -> bool:
    # scalar value ends at next whitespace
    m = re.search(rf"\b{re.escape(key)}=([^\s]+)", header)
    return bool(m and m.group(1).strip())


def _validate_header(step: Step, errors: List[str]) -> None:
    header = step.header_line

    # Strict start.
    if not re.match(rf"^#\s*{re.escape(step.n)}\)\s+", header):
        errors.append(f"Step {step.n}: header must start with '# {step.n})'. Got: {header}")

    # Tokens must appear in strict order.
    pos = _header_token_positions(header)
    for t, p in pos.items():
        if p == -1:
            errors.append(f"Step {step.n}: missing required token '{t}' in header: {header}")

    # Order check (only if all present).
    if all(p != -1 for p in pos.values()):
        last = -1
        for t in HEADER_TOKEN_ORDER:
            if pos[t] <= last:
                errors.append(
                    f"Step {step.n}: token '{t}' is out of order in header. "
                    f"Expected order: {' '.join(HEADER_TOKEN_ORDER)}. Got: {header}"
                )
                break
            last = pos[t]

    # Non-empty values.
    if not _has_nonempty_scalar(header, "ROI"):
        errors.append(f"Step {step.n}: missing/empty ROI= value in header: {header}")
    for k in ["impact", "confidence", "effort", "horizon", "reference"]:
        if not _has_nonempty_scalar(header, k):
            errors.append(f"Step {step.n}: missing/empty {k}= value in header: {header}")

    cat_val = _parse_category_value(header)
    if not cat_val:
        errors.append(f"Step {step.n}: missing/empty category= value in header: {header}")
    elif cat_val not in ALLOWED_CATEGORIES:
        errors.append(
            f"Step {step.n}: invalid category='{cat_val}'. Must be one of: {ALLOWED_CATEGORIES}. Header: {header}"
        )


def _validate_write_output(step: Step, errors: List[str]) -> None:
    joined = "\n".join(step.block_lines)
    # Strict: must use double quotes exactly: --write-output "<path>"
    m = re.search(r'--write-output\s+"([^"]+)"', joined)
    if not m:
        errors.append(f"Step {step.n}: missing --write-output \"...\" (double-quoted) in step block.")
        return

    out_path = m.group(1)

    # Disallow variable expansions in write paths.
    if "$" in out_path or "`" in out_path:
        errors.append(f"Step {step.n}: --write-output path must not contain shell expansions. Got: {out_path}")

    # Disallow absolute writes (and home shortcuts).
    if out_path.startswith("/") or out_path.startswith("~"):
        errors.append(f"Step {step.n}: --write-output path must be relative (no absolute/home paths). Got: {out_path}")

    # Disallow traversal.
    if re.search(r"(^|/)\.\.(/|$)", out_path):
        errors.append(f"Step {step.n}: --write-output path must not contain '..' traversal. Got: {out_path}")

    # Basic shape: <out_dir>/<nn>-<slug>.md
    if "/" not in out_path:
        errors.append(f"Step {step.n}: --write-output path must contain a directory component. Got: {out_path}")
        return

    filename = out_path.split("/")[-1]
    if not filename.startswith(f"{step.n}-"):
        errors.append(f"Step {step.n}: --write-output filename must start with '{step.n}-'. Got: {filename}")
    if not filename.endswith(".md"):
        errors.append(f"Step {step.n}: --write-output filename must end with '.md'. Got: {filename}")

    # Extra guard: ensure PurePosixPath doesn't include '..' (covers odd strings like 'a/../b').
    try:
        parts = PurePosixPath(out_path).parts
        if ".." in parts:
            errors.append(f"Step {step.n}: --write-output path contains '..' segment (unsafe). Got: {out_path}")
    except Exception:
        # Non-fatal; already handled by regex.
        pass


def _validate_ticket_bundle_reference(step: Step, errors: List[str]) -> None:
    joined = "\n".join(step.block_lines)

    # Require the bundle to be mentioned/attached.
    if "_tickets_bundle" not in joined:
        errors.append(
            f"Step {step.n}: must reference the ticket bundle (expected '_tickets_bundle' in step block)."
        )

    # Require a file attachment pointing to the bundle, double-quoted for stability.
    if re.search(r'(?<!\S)(-f|--file)(?!\S)\s+"[^"\n]*_tickets_bundle[^"\n]*"', joined) is None:
        errors.append(
            f"Step {step.n}: must attach the ticket bundle via -f/--file \"..._tickets_bundle...\"."
        )


def _validate_answer_format(step: Step, errors: List[str]) -> None:
    hay = "\n".join(step.block_lines).lower()
    required = [
        "answer format:",
        "direct answer",
        "risks/unknowns",
        "next smallest concrete experiment",
        "if evidence is insufficient",
        "missing file/path pattern",
    ]
    missing = [s for s in required if s not in hay]
    if missing:
        errors.append(f"Step {step.n}: prompt missing required Answer format components: {missing}")


def _validate_category_counts(steps: List[Step], errors: List[str]) -> None:
    counts: Dict[str, List[str]] = {c: [] for c in ALLOWED_CATEGORIES}
    for st in steps:
        cat = _parse_category_value(st.header_line)
        if cat in counts:
            counts[cat].append(st.n)

    bad = []
    for cat, ids in counts.items():
        if len(ids) != 2:
            bad.append(f"{cat}={len(ids)} (steps={ids})")
    if bad:
        errors.append(
            "Category distribution must be exactly 2 steps per category (20 total). Problems: " + ", ".join(bad)
        )


def _validate_coverage_check(outside_lines: List[str], errors: List[str]) -> None:
    text = "\n".join(outside_lines)
    m = re.search(r"^##\s+Coverage check\s*$", text, flags=re.IGNORECASE | re.MULTILINE)
    if m is None:
        errors.append('Missing "## Coverage check" section (must be outside the bash fence).')
        return

    after = text[m.end() :]
    for cat in ALLOWED_CATEGORIES:
        # Require a line like: "- <cat>: OK" OR "- <cat>: Missing(01,02)"
        pat = rf"^\s*[-*]\s+{re.escape(cat)}\s*:\s*(OK|Missing\([^)]*\))\s*$"
        if re.search(pat, after, flags=re.MULTILINE) is None:
            errors.append(f'Coverage check missing/invalid line for category: "{cat}"')


def validate_pack(path: Path) -> None:
    raw = _read_text(path)
    lines = raw.splitlines(True)

    try:
        _, _, fence_lines, outside_lines = _extract_single_bash_fence(lines)
    except ValueError as e:
        _fail([str(e)])

    try:
        steps = _parse_steps(fence_lines)
    except ValueError as e:
        _fail([str(e)])

    errors: List[str] = []
    for st in steps:
        _validate_header(st, errors)
        _validate_write_output(st, errors)
        _validate_ticket_bundle_reference(st, errors)
        _validate_answer_format(st, errors)

    _validate_category_counts(steps, errors)
    _validate_coverage_check(outside_lines, errors)

    if errors:
        _fail(errors)

    print("[OK] Pack validates against tickets Stage-1 contract.")

def main() -> None:
    p = argparse.ArgumentParser(
        description="Validate a ticket-driven oraclepack Stage-1 pack (single bash fence, 20 steps, strict headers/tokens, safe write paths, ticket bundle references, coverage check)."
    )
    p.add_argument("pack_path", help="Path to the Markdown pack file")
    args = p.parse_args()

    path = Path(args.pack_path)
    if not path.exists():
        _fail([f"File not found: {path}"])

    validate_pack(path)


if __name__ == "__main__":
    main()
```

.config/skills/oraclepack-tickets-pack/references/attachment-minimization.md
```
# Attachment minimization rules (Tickets Stage 1 packs)

Objective: keep oracle calls fast, portable, and deterministic by attaching the minimum evidence per step.

## Hard limits

- Default **native attachments**: **0–2 per step** (`-f/--file`).
- In tickets packs, the ticket bundle (`ticket_bundle_path`) is typically **the first native attachment**.
- If you need more than 2 native attachments, the step is not scoped tightly enough: split or reduce.

## extra_files (literal append)

- If `extra_files` is provided, it must be appended **literally** to every oracle command.
- It may contain additional `-f/--file` flags.
- To keep linting reliable and preserve the “native attachments ≤2” rule:
  - place `extra_files` on its own line in each command,
  - preceded by a comment line containing: `extra_files appended literally`.

This lets `scripts/lint_attachments.py` treat that line as “extra” and not part of the native attachment count.

## What to attach (rule of thumb)

For each step, prefer:
1) Ticket bundle: `-f "<ticket_bundle_path>"`
2) One repo file that best supports the question:
   - a definition/contract file (types, schemas, CLI/TUI surface), OR
   - a use-site/enforcement file

If you can’t pick confidently:
- attach only the ticket bundle
- set `reference=Unknown`
- ensure the prompt requests the exact missing file/path pattern(s) to attach next

## Avoid these attachment anti-patterns

- Attaching entire directories when one file is enough.
- Attaching duplicates.
- Attaching generated/lock files unless the ticket explicitly requires it.
- Attaching secrets.
```

.config/skills/oraclepack-tickets-pack/references/ticket-bundling.md
```
# Ticket bundling (deterministic)

Objective: create a single Markdown file (`ticket_bundle_path`) that provides stable, minimal, high-signal context for all 20 oracle steps.

## Inputs

- `ticket_root` (default `.tickets`)
- `ticket_glob` (default `**/*.md`, relative to `ticket_root`)
- `ticket_paths` (optional; comma-separated explicit files; if present, ignore `ticket_glob`)
- `ticket_bundle_path` (default `<out_dir>/_tickets_bundle.md`)

## Deterministic selection rules

1) If `ticket_paths` is non-empty:
- Split on commas, trim whitespace.
- Use that list exactly.
- Sort lexicographically by path string.

2) Else:
- If `ticket_root` does not exist: select nothing.
- Glob `ticket_root/ticket_glob`.
- Sort lexicographically by path string.

Hard rule: do not use timestamps, mtimes, file sizes, or “newest” semantics.

## Bundle format

The bundle should include:

1) Header:
- codebase name (if available)
- the selection rules and resolved values:
  - ticket_root, ticket_glob, ticket_paths (or “(none)”)
  - ordering: lexicographic by path

2) Per-ticket sections (in lex order):
- ticket title (best-effort):
  - first Markdown heading (`# ...`) if present, else first non-empty line, else “Untitled”
- ticket path
- key sections or excerpt:
  - if ticket content is small, include full content
  - otherwise include common sections when present (examples):
    - Description / Context / Problem
    - Proposal / Solution
    - Acceptance Criteria
    - Repro steps / Expected / Actual
    - Notes / Links
  - and include a “[... truncated ...]” marker when partial

## Failure handling requirements

If `ticket_root` is missing OR no tickets matched:
- Still create `ticket_bundle_path`.
- Include a **WARNING** section explaining:
  - what was attempted (root + glob or explicit paths)
  - that the bundle is empty
  - that Step 01 should request which ticket paths to attach next (exact missing file/path pattern(s))

## Why bundling exists

- Ensures every step uses the same primary evidence.
- Reduces per-step attachments (bundle is 1 attachment).
- Improves determinism and portability of oracle calls.
```

.config/skills/oraclepack-tickets-pack/references/tickets-pack-template.md
```
# Oracle Pack — {{codebase_name}} (Tickets Stage 1)

## Parsed args
- codebase_name: {{codebase_name}}
- out_dir: {{out_dir}}
- oracle_cmd: {{oracle_cmd}}
- oracle_flags: {{oracle_flags}}
- extra_files: {{extra_files}}
- ticket_root: {{ticket_root}}
- ticket_glob: {{ticket_glob}}
- ticket_paths: {{ticket_paths}}
- ticket_bundle_path: {{ticket_bundle_path}}
- mode: {{mode}}

Notes (contract):
- Exactly one fenced `bash` block in this document.
- No other ``` fences anywhere.
- Exactly 20 steps, numbered 01..20 in order.
- Step header: `# NN) ROI=... impact=... confidence=... effort=... horizon=... category=... reference=...`
- Every step includes: `--write-output "{{out_dir}}/NN-<slug>.md"` (double quotes required).
- Steps must be self-contained and must not rely on shell variables created in previous steps.
- Pack ends with a Coverage check section listing all 10 categories as OK or Missing(<step ids>).

```bash
# Prelude (allowed inside the single bash fence)
# - Creates out_dir deterministically
# - Builds ticket_bundle_path deterministically from ticket_root/ticket_glob OR ticket_paths
# - Uses lexicographic ordering only (no mtime/timestamps)

set -euo pipefail

mkdir -p "{{out_dir}}"

python3 - <<'PY'
from __future__ import annotations

import os
from pathlib import Path

CODEBASE_NAME = "{{codebase_name}}"
OUT_DIR = "{{out_dir}}"
TICKET_ROOT = "{{ticket_root}}"
TICKET_GLOB = "{{ticket_glob}}"
TICKET_PATHS = "{{ticket_paths}}".strip()
BUNDLE_PATH = "{{ticket_bundle_path}}"

root = Path(TICKET_ROOT)

def read_text(p: Path) -> str:
    try:
        return p.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return p.read_text(encoding="utf-8", errors="replace")

def title_from_md(text: str) -> str:
    for ln in text.splitlines():
        s = ln.strip()
        if s.startswith("#"):
            return s.lstrip("#").strip()[:160] or "Untitled"
    for ln in text.splitlines():
        s = ln.strip()
        if s:
            return s[:160]
    return "Untitled"

def select_key_sections(text: str) -> str:
    # Heuristic: if small, include all; else include common ticket sections + top excerpt.
    lines = text.splitlines()
    if len(text) <= 8000 and len(lines) <= 250:
        return text

    keep = []
    wanted = {"description", "context", "problem", "proposal", "solution", "acceptance criteria", "ac", "steps", "repro", "expected", "actual", "notes", "links"}
    i = 0
    while i < len(lines):
        ln = lines[i]
        s = ln.strip()
        if s.startswith("##"):
            hdr = s.lstrip("#").strip().lower()
            if hdr in wanted:
                keep.append(ln)
                i += 1
                # capture until next heading
                while i < len(lines) and not lines[i].lstrip().startswith("#"):
                    keep.append(lines[i])
                    i += 1
                continue
        i += 1

    # Fallback excerpt if no sections matched
    if not any(l.strip() for l in keep):
        excerpt = "\n".join(lines[:200])
        return excerpt + "\n\n[... truncated ...]\n"
    return "\n".join(keep) + "\n\n[... truncated ...]\n"

def resolve_ticket_files() -> list[Path]:
    if TICKET_PATHS:
        items = [p.strip() for p in TICKET_PATHS.split(",") if p.strip()]
        return sorted([Path(p) for p in items], key=lambda p: str(p))
    if not root.exists():
        return []
    return sorted(list(root.glob(TICKET_GLOB)), key=lambda p: str(p))

tickets = resolve_ticket_files()

bundle_lines = []
bundle_lines.append(f"# Tickets bundle — {CODEBASE_NAME}")
bundle_lines.append("")
bundle_lines.append("## Selection rules (deterministic)")
bundle_lines.append(f"- ticket_root: {TICKET_ROOT}")
bundle_lines.append(f"- ticket_glob: {TICKET_GLOB}")
bundle_lines.append(f"- ticket_paths: {TICKET_PATHS or '(none)'}")
bundle_lines.append("- ordering: lexicographic by path")
bundle_lines.append("")

if not tickets:
    bundle_lines.append("## WARNING")
    if TICKET_PATHS:
        bundle_lines.append("- No tickets were found from ticket_paths (check paths).")
    else:
        bundle_lines.append("- ticket_root missing or no tickets matched the glob.")
    bundle_lines.append("- This bundle is empty; Step 01 should request which ticket paths to attach next.")
    bundle_lines.append("")

for p in tickets:
    try:
        txt = read_text(p)
    except Exception as e:
        txt = f"[ERROR reading file: {e}]"
    title = title_from_md(txt)
    body = select_key_sections(txt)
    bundle_lines.append(f"## {title}")
    bundle_lines.append(f"- path: {p}")
    bundle_lines.append("")
    bundle_lines.append(body)
    bundle_lines.append("")
    bundle_lines.append("---")
    bundle_lines.append("")

out_path = Path(BUNDLE_PATH)
out_path.parent.mkdir(parents=True, exist_ok=True)
out_path.write_text("\n".join(bundle_lines).rstrip() + "\n", encoding="utf-8")

print(f"OK: wrote ticket bundle: {out_path}")
PY

# 01) ROI=4.8 impact=6 confidence=0.80 effort=1 horizon=Immediate category=contracts/interfaces reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/01-contracts-interfaces-ticket-surface.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #01  (ticket-driven)

Reference: Unknown
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.8 (impact=6, confidence=0.80, effort=1)

Question:
Using the ticket bundle as the primary context, list the public surface changes implied by the tickets (CLI/TUI/API/interfaces/contracts). For each implied change:
- describe the new/changed interface shape
- identify the most likely code areas involved
- call out any backwards-compatibility constraints that must be preserved.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 02) ROI=4.6 impact=6 confidence=0.78 effort=1 horizon=Immediate category=contracts/interfaces reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/02-contracts-interfaces-integration-points.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #02  (ticket-driven)

Reference: Unknown
Category: contracts/interfaces
Horizon: Immediate
ROI: 4.6 (impact=6, confidence=0.78, effort=1)

Question:
Using the ticket bundle as the primary context, identify any external integrations implied by the tickets (e.g., calling new agents/tools, new CLIs, new services). For each:
- what contract/config must be added or changed?
- what failure/timeout behavior should be defined?
- what should be the minimal “compat-safe” rollout approach?

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 03) ROI=5.2 impact=7 confidence=0.75 effort=2 horizon=NearTerm category=invariants reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/03-invariants-correctness-guardrails.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #03  (ticket-driven)

Reference: Unknown
Category: invariants
Horizon: NearTerm
ROI: 5.2 (impact=7, confidence=0.75, effort=2)

Question:
From the tickets, derive the key correctness invariants that must hold while implementing them (e.g., “runner-ingestible pack constraints”, “no schema drift”, “no unsafe paths”). For each invariant:
- define it precisely
- state how to enforce it (validation, linting, runtime checks)
- identify where it should live in the codebase (by file/path patterns if evidence is missing).

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 04) ROI=5.0 impact=7 confidence=0.72 effort=2 horizon=NearTerm category=invariants reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/04-invariants-validation-boundaries.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #04  (ticket-driven)

Reference: Unknown
Category: invariants
Horizon: NearTerm
ROI: 5.0 (impact=7, confidence=0.72, effort=2)

Question:
Using the tickets, identify validation boundaries that must exist (ticket parsing, pack generation, pack validation). Where could invalid inputs slip through (missing tickets, malformed headers, extra fences)? Propose a minimal validation plan that preserves backward compatibility.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 05) ROI=4.4 impact=6 confidence=0.78 effort=2 horizon=NearTerm category=caching/state reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/05-caching-state-ticket-artifacts.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #05  (ticket-driven)

Reference: Unknown
Category: caching/state
Horizon: NearTerm
ROI: 4.4 (impact=6, confidence=0.78, effort=2)

Question:
Based on the tickets, what state/artifacts must be produced and preserved (ticket bundle, generated pack, validator outputs, runner outputs)? Identify any schema/format expectations that must remain backward compatible and how to keep them stable.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 06) ROI=4.1 impact=5 confidence=0.80 effort=2 horizon=NearTerm category=caching/state reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/06-caching-state-determinism-consistency.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #06  (ticket-driven)

Reference: Unknown
Category: caching/state
Horizon: NearTerm
ROI: 4.1 (impact=5, confidence=0.80, effort=2)

Question:
Using the tickets, identify determinism risks (non-deterministic ticket selection, unstable ordering, environment-dependent paths). Propose a minimal deterministic selection and bundling approach and how to test it.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 07) ROI=3.6 impact=5 confidence=0.70 effort=3 horizon=NearTerm category=background jobs reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/07-background-jobs-ticket-implications.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #07  (ticket-driven)

Reference: Unknown
Category: background jobs
Horizon: NearTerm
ROI: 3.6 (impact=5, confidence=0.70, effort=3)

Question:
Do any tickets imply background processing, worker modes, scheduled validation, or CI pipelines (e.g., generating packs from tickets in CI)? If yes, define:
- trigger mechanism
- inputs/outputs
- retries/idempotency constraints
If no, explicitly confirm based on the ticket bundle.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 08) ROI=3.9 impact=5 confidence=0.72 effort=3 horizon=NearTerm category=background jobs reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/08-background-jobs-reliability-controls.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #08  (ticket-driven)

Reference: Unknown
Category: background jobs
Horizon: NearTerm
ROI: 3.9 (impact=5, confidence=0.72, effort=3)

Question:
If tickets imply background/CI execution, what reliability controls are required (concurrency limits, backoff, reprocessing, artifact retention)? Tie each control to a specific ticket requirement and suggest minimal implementation points.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 09) ROI=4.7 impact=6 confidence=0.82 effort=2 horizon=Immediate category=observability reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/09-observability-required-signals.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #09  (ticket-driven)

Reference: Unknown
Category: observability
Horizon: Immediate
ROI: 4.7 (impact=6, confidence=0.82, effort=2)

Question:
From the tickets, define the minimum observability required for implementing and operating ticketed changes (logs, warnings, structured outputs, correlation/run IDs). What signals must be emitted on:
- missing tickets
- validation failures
- unsafe path detection
- runner ingestion failures?

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 10) ROI=4.5 impact=6 confidence=0.80 effort=2 horizon=Immediate category=observability reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/10-observability-gaps-and-metrics.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #10  (ticket-driven)

Reference: Unknown
Category: observability
Horizon: Immediate
ROI: 4.5 (impact=6, confidence=0.80, effort=2)

Question:
Using the ticket bundle, identify observability gaps that would block shipping the ticketed work safely (missing structured errors, missing per-step diagnostics, missing coverage/mismatch reporting). Recommend the smallest additions with high debugging value.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 11) ROI=5.0 impact=7 confidence=0.76 effort=2 horizon=Immediate category=permissions reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/11-permissions-security-constraints.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #11  (ticket-driven)

Reference: Unknown
Category: permissions
Horizon: Immediate
ROI: 5.0 (impact=7, confidence=0.76, effort=2)

Question:
From the tickets, determine what security/permissions constraints must exist (e.g., exec gating, tool invocation restrictions, file access restrictions, safe write paths). Define “who can do what” minimally and where enforcement should live.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 12) ROI=4.8 impact=7 confidence=0.74 effort=2 horizon=Immediate category=permissions reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/12-permissions-enforcement-chokepoints.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #12  (ticket-driven)

Reference: Unknown
Category: permissions
Horizon: Immediate
ROI: 4.8 (impact=7, confidence=0.74, effort=2)

Question:
Using the tickets, identify where permissions must be enforced (CLI command gating, TUI actions, runner execution, filesystem writes). Call out bypass risks and propose the minimal enforcement chokepoints and tests.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 13) ROI=4.2 impact=6 confidence=0.72 effort=3 horizon=NearTerm category=migrations reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/13-migrations-schema-changes.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #13  (ticket-driven)

Reference: Unknown
Category: migrations
Horizon: NearTerm
ROI: 4.2 (impact=6, confidence=0.72, effort=3)

Question:
Do tickets imply schema/version changes (pack schema, state/report schema, actions artifacts)? Identify what can change vs must remain backward-compatible, and propose a minimal migration strategy (if any).

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 14) ROI=4.0 impact=6 confidence=0.70 effort=3 horizon=NearTerm category=migrations reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/14-migrations-compat-guardrails.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #14  (ticket-driven)

Reference: Unknown
Category: migrations
Horizon: NearTerm
ROI: 4.0 (impact=6, confidence=0.70, effort=3)

Question:
Using the ticket bundle, define the compatibility expectations (backward/forward, rolling upgrades, mixed versions). Where are the risky edges, and what guardrails/tests should be required before shipping ticketed changes?

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

# 15) ROI=4.6 impact=6 confidence=0.80 effort=2 horizon=NearTerm category=UX flows reference=Unknown
{{oracle_cmd}} \
  {{oracle_flags}} \
  --write-output "{{out_dir}}/15-ux-flows-ticketed-user-journeys.md" \
  -f "{{ticket_bundle_path}}" \
  # optional (at most one): -f "<best_repo_file_path>" \
  # extra_files appended literally (may be empty; may include -f/--file):
  {{extra_files}} \
  -p "$(cat <<'PROMPT'
Strategist question #15  (ticket-driven)

Reference: Unknown
Category: UX flows
Horizon: NearTerm
ROI: 4.6 (impact=6, confidence=0.80, effort=2)

Question:
From the ticket bundle, identify which user/operator flows are affected (TUI flows, CLI flows, non-interactive mode). For each flow:
- outline steps and state transitions
- identify key UX requirements implied by tickets
- call out compatibility constraints with existing workflows.

Constraints: None
Non-goals: None

Answer format:
1) Direct answer (1–10 bullets, evidence-cited)
2) Risks/unknowns (bullets)
3) Next smallest concrete experiment (exactly one action)
4) If evidence is insufficient, name the exact missing file/path pattern(s) to attach next.
PROMPT
)"

[TRUNCATED]
```

.mypy_cache/3.12/importlib/resources/__init__.data.json
```
{".class":"MypyFile","_fullname":"importlib.resources","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","AbstractContextManager":{".class":"SymbolTableNode","cross_ref":"contextlib.AbstractContextManager","kind":"Gdef","module_hidden":true,"module_public":false},"Any":{".class":"SymbolTableNode","cross_ref":"typing.Any","kind":"Gdef","module_hidden":true,"module_public":false},"BinaryIO":{".class":"SymbolTableNode","cross_ref":"typing.BinaryIO","kind":"Gdef","module_hidden":true,"module_public":false},"Iterator":{".class":"SymbolTableNode","cross_ref":"typing.Iterator","kind":"Gdef","module_hidden":true,"module_public":false},"ModuleType":{".class":"SymbolTableNode","cross_ref":"types.ModuleType","kind":"Gdef","module_hidden":true,"module_public":false},"Package":{".class":"SymbolTableNode","cross_ref":"importlib.resources._common.Package","kind":"Gdef"},"Path":{".class":"SymbolTableNode","cross_ref":"pathlib.Path","kind":"Gdef","module_hidden":true,"module_public":false},"Resource":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeAlias","alias_tvars":[],"column":4,"fullname":"importlib.resources.Resource","line":32,"no_args":true,"normalized":false,"python_3_12_type_alias":false,"target":"builtins.str"}},"ResourceReader":{".class":"SymbolTableNode","cross_ref":"importlib.abc.ResourceReader","kind":"Gdef"},"TextIO":{".class":"SymbolTableNode","cross_ref":"typing.TextIO","kind":"Gdef","module_hidden":true,"module_public":false},"Traversable":{".class":"SymbolTableNode","cross_ref":"importlib.abc.Traversable","kind":"Gdef","module_hidden":true,"module_public":false},"TypeAlias":{".class":"SymbolTableNode","cross_ref":"typing.TypeAlias","kind":"Gdef","module_hidden":true,"module_public":false},"__all__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"importlib.resources.__all__","name":"__all__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.__package__","name":"__package__","type":"builtins.str"}},"__path__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.__path__","name":"__path__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"as_file":{".class":"SymbolTableNode","cross_ref":"importlib.resources._common.as_file","kind":"Gdef"},"contents":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["package"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources.contents","name":"contents","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["package"],"arg_types":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Package"}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"contents","ret_type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"typing.Iterator"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"files":{".class":"SymbolTableNode","cross_ref":"importlib.resources._common.files","kind":"Gdef"},"is_resource":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["package","name"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources.is_resource","name":"is_resource","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["package","name"],"arg_types":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Package"},"builtins.str"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"is_resource","ret_type":"builtins.bool","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"open_binary":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["package","resource"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources.open_binary","name":"open_binary","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["package","resource"],"arg_types":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Package"},"builtins.str"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"open_binary","ret_type":"typing.BinaryIO","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"open_text":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,1,1],"arg_names":["package","resource","encoding","errors"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources.open_text","name":"open_text","type":{".class":"CallableType","arg_kinds":[0,0,1,1],"arg_names":["package","resource","encoding","errors"],"arg_types":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Package"},"builtins.str","builtins.str","builtins.str"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"open_text","ret_type":"typing.TextIO","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"os":{".class":"SymbolTableNode","cross_ref":"os","kind":"Gdef","module_hidden":true,"module_public":false},"path":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["package","resource"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources.path","name":"path","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["package","resource"],"arg_types":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Package"},"builtins.str"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"path","ret_type":{".class":"Instance","args":["pathlib.Path",{".class":"UnionType","items":["builtins.bool",{".class":"NoneType"}],"uses_pep604_syntax":false}],"extra_attrs":null,"type_ref":"contextlib.AbstractContextManager"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"read_binary":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["package","resource"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources.read_binary","name":"read_binary","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["package","resource"],"arg_types":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Package"},"builtins.str"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"read_binary","ret_type":"builtins.bytes","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"read_text":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,1,1],"arg_names":["package","resource","encoding","errors"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources.read_text","name":"read_text","type":{".class":"CallableType","arg_kinds":[0,0,1,1],"arg_names":["package","resource","encoding","errors"],"arg_types":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Package"},"builtins.str","builtins.str","builtins.str"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"read_text","ret_type":"builtins.str","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/resources/__init__.pyi"}
```

.mypy_cache/3.12/importlib/resources/__init__.meta.json
```
{"data_mtime":1767891128,"dep_lines":[11,3,16,1,2,4,5,6,7,8,1,1,1,1,1],"dep_prios":[5,5,5,10,10,5,5,5,5,5,5,30,30,30,30],"dependencies":["importlib.resources._common","collections.abc","importlib.abc","os","sys","contextlib","pathlib","types","typing","typing_extensions","builtins","_collections_abc","_frozen_importlib","_typeshed","abc"],"hash":"09729156e3798abfc8666cd3458f6108e653f02a","id":"importlib.resources","ignore_all":true,"interface_hash":"7dfd904ab9f28047241f02eaf07d4613420b0e77","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/resources/__init__.pyi","plugin_data":null,"size":2385,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/resources/_common.data.json
```
{".class":"MypyFile","_fullname":"importlib.resources._common","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","AbstractContextManager":{".class":"SymbolTableNode","cross_ref":"contextlib.AbstractContextManager","kind":"Gdef","module_hidden":true,"module_public":false},"Anchor":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeAlias","alias_tvars":[],"column":8,"fullname":"importlib.resources._common.Anchor","line":16,"no_args":false,"normalized":false,"python_3_12_type_alias":false,"target":{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Package"}}},"Callable":{".class":"SymbolTableNode","cross_ref":"typing.Callable","kind":"Gdef","module_hidden":true,"module_public":false},"Package":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeAlias","alias_tvars":[],"column":4,"fullname":"importlib.resources._common.Package","line":13,"no_args":false,"normalized":false,"python_3_12_type_alias":false,"target":{".class":"UnionType","items":["builtins.str","types.ModuleType"],"uses_pep604_syntax":true}}},"Path":{".class":"SymbolTableNode","cross_ref":"pathlib.Path","kind":"Gdef","module_hidden":true,"module_public":false},"ResourceReader":{".class":"SymbolTableNode","cross_ref":"importlib.abc.ResourceReader","kind":"Gdef","module_hidden":true,"module_public":false},"Traversable":{".class":"SymbolTableNode","cross_ref":"importlib.abc.Traversable","kind":"Gdef","module_hidden":true,"module_public":false},"TypeAlias":{".class":"SymbolTableNode","cross_ref":"typing.TypeAlias","kind":"Gdef","module_hidden":true,"module_public":false},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources._common.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources._common.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources._common.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources._common.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources._common.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources._common.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"as_file":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["path"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources._common.as_file","name":"as_file","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["path"],"arg_types":["importlib.abc.Traversable"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"as_file","ret_type":{".class":"Instance","args":["pathlib.Path",{".class":"UnionType","items":["builtins.bool",{".class":"NoneType"}],"uses_pep604_syntax":false}],"extra_attrs":null,"type_ref":"contextlib.AbstractContextManager"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"deprecated":{".class":"SymbolTableNode","cross_ref":"typing_extensions.deprecated","kind":"Gdef","module_hidden":true,"module_public":false},"files":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"OverloadedFuncDef","deprecated":null,"flags":[],"fullname":"importlib.resources._common.files","impl":null,"items":[{".class":"Decorator","func":{".class":"FuncDef","abstract_status":0,"arg_kinds":[1],"arg_names":["anchor"],"dataclass_transform_spec":null,"deprecated":null,"flags":["is_overload","is_decorated"],"fullname":"importlib.resources._common.files","name":"files","type":{".class":"CallableType","arg_kinds":[1],"arg_names":["anchor"],"arg_types":[{".class":"UnionType","items":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Anchor"},{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"files","ret_type":"importlib.abc.Traversable","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}},"is_overload":true,"var":{".class":"Var","flags":["is_ready","is_inferred"],"fullname":"importlib.resources._common.files","name":"files","type":{".class":"CallableType","arg_kinds":[1],"arg_names":["anchor"],"arg_types":[{".class":"UnionType","items":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Anchor"},{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"files","ret_type":"importlib.abc.Traversable","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},{".class":"Decorator","func":{".class":"FuncDef","abstract_status":0,"arg_kinds":[1],"arg_names":["package"],"dataclass_transform_spec":null,"deprecated":"overload def (package: Union[Union[builtins.str, types.ModuleType], None] =) -> importlib.abc.Traversable of function importlib.resources._common.files is deprecated: First parameter to files is renamed to 'anchor'","flags":["is_overload","is_decorated"],"fullname":"importlib.resources._common.files","name":"files","type":{".class":"CallableType","arg_kinds":[1],"arg_names":["package"],"arg_types":[{".class":"UnionType","items":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Anchor"},{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"files","ret_type":"importlib.abc.Traversable","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}},"is_overload":true,"var":{".class":"Var","flags":["is_ready","is_inferred"],"fullname":"importlib.resources._common.files","name":"files","type":{".class":"CallableType","arg_kinds":[1],"arg_names":["package"],"arg_types":[{".class":"UnionType","items":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Anchor"},{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"files","ret_type":"importlib.abc.Traversable","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}],"type":{".class":"Overloaded","items":[{".class":"CallableType","arg_kinds":[1],"arg_names":["anchor"],"arg_types":[{".class":"UnionType","items":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Anchor"},{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"files","ret_type":"importlib.abc.Traversable","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]},{".class":"CallableType","arg_kinds":[1],"arg_names":["package"],"arg_types":[{".class":"UnionType","items":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Anchor"},{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"files","ret_type":"importlib.abc.Traversable","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}]}}},"from_package":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["package"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources._common.from_package","name":"from_package","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["package"],"arg_types":["types.ModuleType"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"from_package","ret_type":"importlib.abc.Traversable","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"get_resource_reader":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["package"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources._common.get_resource_reader","name":"get_resource_reader","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["package"],"arg_types":["types.ModuleType"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"get_resource_reader","ret_type":{".class":"UnionType","items":["importlib.abc.ResourceReader",{".class":"NoneType"}],"uses_pep604_syntax":true},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"overload":{".class":"SymbolTableNode","cross_ref":"typing.overload","kind":"Gdef","module_hidden":true,"module_public":false},"package_to_anchor":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["func"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources._common.package_to_anchor","name":"package_to_anchor","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["func"],"arg_types":[{".class":"CallableType","arg_kinds":[0],"arg_names":[null],"arg_types":[{".class":"UnionType","items":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Anchor"},{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":null,"ret_type":"importlib.abc.Traversable","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"package_to_anchor","ret_type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":[null,null],"arg_types":[{".class":"UnionType","items":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Anchor"},{".class":"NoneType"}],"uses_pep604_syntax":true},{".class":"UnionType","items":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Anchor"},{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":null,"ret_type":"importlib.abc.Traversable","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"resolve":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["cand"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"importlib.resources._common.resolve","name":"resolve","type":{".class":"CallableType","arg_kinds":[0],"arg_names":["cand"],"arg_types":[{".class":"UnionType","items":[{".class":"TypeAliasType","args":[],"type_ref":"importlib.resources._common.Anchor"},{".class":"NoneType"}],"uses_pep604_syntax":true}],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"resolve","ret_type":"types.ModuleType","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false},"types":{".class":"SymbolTableNode","cross_ref":"types","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/resources/_common.pyi"}
```

.mypy_cache/3.12/importlib/resources/_common.meta.json
```
{"data_mtime":1767891128,"dep_lines":[6,8,1,5,7,9,10,11,1,1,1,1,1],"dep_prios":[5,5,10,10,5,5,5,5,5,30,30,30,30],"dependencies":["collections.abc","importlib.abc","sys","types","contextlib","pathlib","typing","typing_extensions","builtins","_frozen_importlib","_typeshed","abc","os"],"hash":"e7087e18dc33e0a7404dcf3d432815374348c910","id":"importlib.resources._common","ignore_all":true,"interface_hash":"0017916353de98c5688348b377bfb02998c94023","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/resources/_common.pyi","plugin_data":null,"size":1518,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/resources/abc.data.json
```
{".class":"MypyFile","_fullname":"importlib.resources.abc","future_import_flags":[],"is_partial_stub_package":false,"is_stub":true,"names":{".class":"SymbolTable","ResourceReader":{".class":"SymbolTableNode","cross_ref":"importlib.abc.ResourceReader","kind":"Gdef"},"Traversable":{".class":"SymbolTableNode","cross_ref":"importlib.abc.Traversable","kind":"Gdef"},"TraversableResources":{".class":"SymbolTableNode","cross_ref":"importlib.abc.TraversableResources","kind":"Gdef"},"__all__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"importlib.resources.abc.__all__","name":"__all__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.abc.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.abc.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.abc.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.abc.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.abc.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"importlib.resources.abc.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"sys":{".class":"SymbolTableNode","cross_ref":"sys","kind":"Gdef","module_hidden":true,"module_public":false}},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/resources/abc.pyi"}
```

.mypy_cache/3.12/importlib/resources/abc.meta.json
```
{"data_mtime":1767891128,"dep_lines":[8,1,1,1,1,1,1],"dep_prios":[5,10,5,30,30,30,30],"dependencies":["importlib.abc","sys","builtins","_frozen_importlib","_typeshed","abc","typing"],"hash":"a45509748ab7029a1aa56d5883c154bd20a3a2ae","id":"importlib.resources.abc","ignore_all":true,"interface_hash":"b48fdd6f9bc8523f2011bc294ab10d888e682139","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/resources/abc.pyi","plugin_data":null,"size":549,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/metadata/__init__.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/importlib/metadata/__init__.meta.json
```
{"data_mtime":1767891128,"dep_lines":[37,7,8,9,1,2,3,4,5,6,10,12,13,14,1,1],"dep_prios":[5,5,5,5,10,5,10,10,5,5,5,5,5,5,5,30],"dependencies":["importlib.metadata._meta","collections.abc","email.message","importlib.abc","abc","pathlib","sys","types","_collections_abc","_typeshed","os","re","typing","typing_extensions","builtins","_frozen_importlib"],"hash":"5416a38893c2182fc301e16118320b69d5d4a8c6","id":"importlib.metadata","ignore_all":true,"interface_hash":"bb51644d32e8ffeae6160e073056c2f5d31cf78e","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/metadata/__init__.pyi","plugin_data":null,"size":9382,"suppressed":[],"version_id":"1.15.0"}
```

.mypy_cache/3.12/importlib/metadata/_meta.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/importlib/metadata/_meta.meta.json
```
{"data_mtime":1767891128,"dep_lines":[3,1,2,4,5,6,1,1,1,1],"dep_prios":[5,10,5,5,5,5,5,30,30,30],"dependencies":["collections.abc","sys","_typeshed","os","typing","typing_extensions","builtins","_frozen_importlib","abc","types"],"hash":"776d16d8b3327bdf2554440e5860ecc3d293b163","id":"importlib.metadata._meta","ignore_all":true,"interface_hash":"5399b26f16fa43cd060562beb5de30f6b64d2062","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/importlib/metadata/_meta.pyi","plugin_data":null,"size":2552,"suppressed":[],"version_id":"1.15.0"}
```

oraclepack-mcp-server/.pytest_cache/v/cache/lastfailed
```
{}
```

oraclepack-mcp-server/.pytest_cache/v/cache/nodeids
```
[
  "tests/test_cli.py::test_run_oraclepack_success",
  "tests/test_cli.py::test_run_oraclepack_timeout",
  "tests/test_cli.py::test_run_oraclepack_truncation",
  "tests/test_config.py::test_default_config",
  "tests/test_config.py::test_env_override",
  "tests/test_integration.py::test_oraclepack_read_file_unauthorized",
  "tests/test_integration.py::test_server_tools_list",
  "tests/test_security.py::test_is_exec_enabled",
  "tests/test_security.py::test_safe_read_file",
  "tests/test_security.py::test_validate_path_allowed",
  "tests/test_security.py::test_validate_path_denied",
  "tests/test_security.py::test_validate_path_traversal",
  "tests/test_taskify.py::test_detect_stage2_auto",
  "tests/test_taskify.py::test_validate_action_pack_multiple_fences",
  "tests/test_taskify.py::test_validate_action_pack_ok",
  "tests/test_taskify.py::test_validate_stage2_dir_ambiguous",
  "tests/test_taskify.py::test_validate_stage2_dir_missing",
  "tests/test_taskify.py::test_validate_stage2_dir_ok"
]
```

.mypy_cache/3.12/zipfile/_path/__init__.data.json
```
[TRUNCATED]
```

.mypy_cache/3.12/zipfile/_path/__init__.meta.json
```
{"data_mtime":1767891128,"dep_lines":[3,1,2,4,5,6,7,8,1,1,1,1,1],"dep_prios":[5,10,5,5,5,5,5,5,5,30,30,30,30],"dependencies":["collections.abc","sys","_typeshed","io","os","typing","typing_extensions","zipfile","builtins","_frozen_importlib","_io","abc","types"],"hash":"3270f9c480b6422db9446d3607ad07e8e1867afb","id":"zipfile._path","ignore_all":true,"interface_hash":"44fe79deed98f9fb67436ce6e17344f1b9726db9","mtime":1762029371,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":false,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":false,"disallow_any_unimported":false,"disallow_incomplete_defs":false,"disallow_subclassing_any":false,"disallow_untyped_calls":false,"disallow_untyped_decorators":false,"disallow_untyped_defs":false,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":false,"implicit_optional":false,"implicit_reexport":true,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"linux","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":false,"strict_optional":true,"warn_no_return":true,"warn_return_any":false,"warn_unreachable":false,"warn_unused_ignores":false},"path":"/home/user/.cursor-server/extensions/ms-python.mypy-type-checker-2025.2.0-universal/bundled/libs/mypy/typeshed/stdlib/zipfile/_path/__init__.pyi","plugin_data":null,"size":3840,"suppressed":[],"version_id":"1.15.0"}
```

</source_code>