{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Initialize Go Module and Core Error Handling",
        "description": "Set up the Go module structure and implement the foundational error handling package with typed errors and exit codes.",
        "details": "Initialize the `go.mod` file with `go mod init`. Create the directory structure `internal/errors`. Define custom error types representing different failure domains (e.g., `ErrInvalidPack`, `ErrExecutionFailed`). Implement an `ExitCode(err error) int` function to map these errors to specific integer exit codes for the CLI. Add unit tests to ensure correct mapping.",
        "testStrategy": "Unit tests verifying that specific error types map to the expected integer exit codes.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Go Module",
            "description": "Initialize the Go module for the project using the standard Go toolchain.",
            "dependencies": [],
            "details": "Run `go mod init <module-name>` (likely `oraclepack` or similar based on context) in the project root. This creates the `go.mod` file which tracks dependencies. Ensure the Go version is set to a recent stable version (e.g., 1.21+).",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:37:57.613Z"
          },
          {
            "id": 2,
            "title": "Create Error Handling Package Structure",
            "description": "Set up the directory structure for the custom error handling package.",
            "dependencies": [
              1
            ],
            "details": "Create the directory `internal/errors`. Inside this directory, create the initial Go file, likely `errors.go`, which will house the custom error definitions and logic. This establishes the package `errors` (or `apierrors` to avoid conflict with stdlib).",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:38:15.207Z"
          },
          {
            "id": 3,
            "title": "Define Domain-Specific Error Types",
            "description": "Implement custom error types and sentinel errors representing specific failure domains.",
            "dependencies": [
              2
            ],
            "details": "In `internal/errors`, define error variables or structs for expected failure modes. Examples include `ErrInvalidPack` (parsing errors), `ErrExecutionFailed` (runtime errors), `ErrConfigInvalid`. Ensure these implement the standard `error` interface.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:38:15.209Z"
          },
          {
            "id": 4,
            "title": "Implement Exit Code Mapping Logic",
            "description": "Create a function to map specific errors to integer exit codes for CLI termination.",
            "dependencies": [
              3
            ],
            "details": "Implement a function signature like `func ExitCode(err error) int`. Use `errors.Is` or type switching to determine the error type and return a specific integer code (e.g., 1 for generic, 2 for config, 3 for parsing). Default to 1 for unknown errors and 0 for nil.",
            "status": "done",
            "testStrategy": "Unit tests passing various error types into ExitCode and asserting the returned integer matches the specification.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:38:15.210Z"
          },
          {
            "id": 5,
            "title": "Add Unit Tests for Error Handling",
            "description": "Write comprehensive unit tests to verify the error types and exit code mapping.",
            "dependencies": [
              4
            ],
            "details": "Create `internal/errors/errors_test.go`. Test that wrapped errors are correctly identified by the `ExitCode` function using `fmt.Errorf(\"%w\", err)`. Verify that the correct exit codes are returned for `ErrInvalidPack`, `ErrExecutionFailed`, etc.",
            "status": "done",
            "testStrategy": "Run `go test ./internal/errors` and ensure 100% pass rate.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:38:31.645Z"
          }
        ],
        "updatedAt": "2025-12-30T21:38:31.645Z"
      },
      {
        "id": 2,
        "title": "Implement Pack Parsing and Validation",
        "description": "Develop the Markdown parser to extract bash blocks, parse steps/prelude, and validate structure.",
        "details": "Implement `internal/pack`. Use a library like `github.com/yuin/goldmark` or standard regex to locate the first bash fence. Parse the content to separate the 'prelude' (before first `# NN)`) from 'steps'. Create structs `Pack`, `Step`, and `Prelude`. Implement `Validate(p Pack)` to enforce rules (1+ steps, 2-digit numbering, no duplicates). Implement `DeriveMetadata` to extract `out_dir` and `--write-output` using regex. Handle edge cases like missing fences.",
        "testStrategy": "Table-driven unit tests with various Markdown inputs (valid, missing fence, malformed headers, duplicate steps) to verify parsing accuracy and error reporting.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Pack, Step, and Prelude Structures",
            "description": "Create the core data structures in `internal/pack` to represent the parsed Markdown content.",
            "dependencies": [],
            "details": "Create `internal/pack/types.go`. Define structs `Pack` (containing Prelude, Steps, Source path), `Step` (ID, Number, Code, OriginalLine), and `Prelude` (Code, Metadata). Include fields for derived metadata like `OutDir` and `WriteOutput`.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:39:47.853Z"
          },
          {
            "id": 2,
            "title": "Implement Markdown Parsing Logic",
            "description": "Develop the parser to read a Markdown file and extract the first bash code block.",
            "dependencies": [
              1
            ],
            "details": "Implement `Parse(content []byte) (*Pack, error)` in `internal/pack/parser.go`. Use a library like `goldmark` or regex to identify the first ````bash` fence. Extract the content within the fence for further processing. Handle errors for missing fences.",
            "status": "done",
            "testStrategy": "Unit tests with sample Markdown files containing valid and invalid bash blocks.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:39:47.855Z"
          },
          {
            "id": 3,
            "title": "Implement Step and Prelude Separation",
            "description": "Logic to split the extracted bash block into a prelude and individual numbered steps.",
            "dependencies": [
              2
            ],
            "details": "In `internal/pack/parser.go`, implement logic to iterate through lines of the extracted bash block. Identify steps using the `# NN)` pattern. Everything before the first step is `Prelude`. Populate the `Step` slice in the `Pack` struct.",
            "status": "done",
            "testStrategy": "Unit tests with various internal structures: prelude only, steps only, mixed, and malformed step headers.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:39:47.857Z"
          },
          {
            "id": 4,
            "title": "Implement Metadata Extraction and Derivation",
            "description": "Extract specific configuration values like output directory from the parsed content.",
            "dependencies": [
              3
            ],
            "details": "Implement `DeriveMetadata` method on the `Pack` or `Prelude` struct. Use regex to scan the prelude or specific comments for `out_dir` assignments and `--write-output` flags. Populate the corresponding fields in the `Pack` struct.",
            "status": "done",
            "testStrategy": "Unit tests verifying that metadata variables are correctly extracted from shell assignment syntax.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:39:47.860Z"
          },
          {
            "id": 5,
            "title": "Implement Pack Validation Rules",
            "description": "Enforce structural rules on the parsed Pack object to ensure integrity.",
            "dependencies": [
              3
            ],
            "details": "Implement `Validate() error` method for `Pack`. Check requirements: at least one step exists, step numbers are sequential and valid 2-digit format, and no duplicate step numbers. Return specific errors for violations.",
            "status": "done",
            "testStrategy": "Table-driven tests covering edge cases: missing steps, non-sequential numbers, duplicate IDs, and invalid numbering formats.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:39:47.862Z"
          }
        ],
        "updatedAt": "2025-12-30T21:39:47.862Z"
      },
      {
        "id": 3,
        "title": "Implement State Persistence and Reporting Models",
        "description": "Create the data models for run state and reporting, including atomic JSON persistence.",
        "details": "Implement `internal/state` and `internal/report`. Define `RunState` struct with schema version, pack hash, and step statuses. Implement `SaveStateAtomic(path, state)` using a temp-file-rename strategy to prevent corruption. Define `ReportV1` struct for the machine-readable summary. Include JSON tags. Use `encoding/json` for serialization.",
        "testStrategy": "Unit tests checking serialization/deserialization cycles and atomic write behavior (simulating write failures if possible).",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define RunState Structure",
            "description": "Create the data model for the execution state in `internal/state` package, including schema versioning and step tracking.",
            "dependencies": [],
            "details": "Define a `RunState` struct in `internal/state/types.go`. It should include fields for `SchemaVersion` (string or int), `PackHash` (string), `StartTime` (time.Time), and `StepStatuses` (map[string]StepStatus or a slice). Define `StepStatus` struct to hold individual step outcomes (Pending, Running, Success, Failed, Skipped), exit codes, and timestamps. Use proper JSON tags.",
            "status": "done",
            "testStrategy": "Unit tests verifying struct initialization and JSON marshaling/unmarshaling.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:42:14.950Z"
          },
          {
            "id": 2,
            "title": "Implement Atomic State Persistence",
            "description": "Develop functionality to save the run state to a file atomically to prevent data corruption.",
            "dependencies": [
              1
            ],
            "details": "Implement `SaveStateAtomic(path string, state *RunState) error` in `internal/state/persist.go`. Use `encoding/json` to marshal the state. Write to a temporary file first (e.g., using `os.CreateTemp` or appending `.tmp` to the path), ensure the write is flushed (`file.Sync`), and then use `os.Rename` to replace the target file atomically. Handle file permission setup.",
            "status": "done",
            "testStrategy": "Unit tests creating a state, saving it, and verifying the file exists. Simulate concurrent writes or interruptions if possible (though difficult in pure unit tests), or verify temp file cleanup.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:42:14.952Z"
          },
          {
            "id": 3,
            "title": "Implement State Loading Logic",
            "description": "Create functionality to load and validate existing run state from disk.",
            "dependencies": [
              1
            ],
            "details": "Implement `LoadState(path string) (*RunState, error)` in `internal/state/persist.go`. Read the file using `os.ReadFile` or `os.Open`. Decode using `encoding/json`. Validate the `SchemaVersion` to ensure compatibility. If the file doesn't exist, return a specific error or a default empty state depending on the design decision (usually specific error `ErrStateNotFound`).",
            "status": "done",
            "testStrategy": "Unit tests loading valid JSON files, corrupted JSON files, and non-existent files.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:42:14.954Z"
          },
          {
            "id": 4,
            "title": "Define ReportV1 Data Model",
            "description": "Create the machine-readable reporting data model in `internal/report`.",
            "dependencies": [],
            "details": "Define `ReportV1` struct in `internal/report/types.go`. This should be distinct from `RunState` but potentially overlapping. It is intended for final output. Fields should include `Summary` (total steps, success count, duration), `PackInfo` (name, hash), and `Steps` (a simplified list of executed steps and their results). Ensure strict JSON tagging for external consumption.",
            "status": "done",
            "testStrategy": "Unit test checking the JSON structure matches the expected schema output.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:42:14.956Z"
          },
          {
            "id": 5,
            "title": "Implement Report Generation Logic",
            "description": "Implement the logic to generate a ReportV1 object from a RunState.",
            "dependencies": [
              1,
              4
            ],
            "details": "Implement a function `GenerateReport(state *state.RunState, packInfo ...interface{}) *ReportV1` in `internal/report/generate.go`. This function maps the internal `RunState` data to the public `ReportV1` format, calculating derived metrics like total duration or success rates if they aren't explicitly stored in RunState.",
            "status": "done",
            "testStrategy": "Unit tests passing a populated RunState and asserting the fields in the generated ReportV1 are correct.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:42:14.958Z"
          }
        ],
        "updatedAt": "2025-12-30T21:42:14.958Z"
      },
      {
        "id": 4,
        "title": "Implement Shell Execution Engine",
        "description": "Build the execution runner to run bash scripts, stream output, and manage log files.",
        "details": "Implement `internal/exec`. Create `Runner` struct with fields for Shell, WorkDir, and Env. Implement `RunPrelude` and `RunStep`. Use `os/exec` to invoke `bash -lc`. Pipe `Cmd.Stdout` and `Cmd.Stderr`. Implement a streaming mechanism (e.g., `io.MultiWriter` to file and a callback function) to capture logs in real-time. Ensure process termination handling.",
        "testStrategy": "Integration tests executing simple shell scripts (e.g., echo, exit 1) and verifying that output is captured in the log file and the callback receives lines.",
        "priority": "high",
        "dependencies": [
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Runner Interface and Structs",
            "description": "Create the basic Runner structure and interface in `internal/exec` to define how the shell execution will be structured.",
            "dependencies": [],
            "details": "Create `internal/exec/runner.go`. Define `Runner` struct with fields: `Shell` (defaulting to /bin/bash), `WorkDir` (string), and `Env` (map[string]string or []string). Define `RunnerOptions` for configuration. Create a `NewRunner` factory function. Define the basic method signatures `RunPrelude` and `RunStep` without full implementation yet. Ensure compatibility with the `Pack` and `Step` structs from `internal/pack`.",
            "status": "done",
            "testStrategy": "Unit tests ensuring the Runner is initialized with correct default values and options.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:41:02.561Z"
          },
          {
            "id": 2,
            "title": "Implement Output Streaming Mechanism",
            "description": "Develop a helper to capture stdout/stderr from a command, streaming it simultaneously to a writer (file) and a callback function.",
            "dependencies": [
              1
            ],
            "details": "In `internal/exec/stream.go`, implement a custom `io.Writer` or use `io.MultiWriter` logic. Create a function `StreamOutput(reader io.Reader, writers ...io.Writer) error` or similar. Implement a line-scanning mechanism (using `bufio.Scanner`) that allows passing a callback function `OnLine(line string)` for real-time log processing (needed for the TUI later). Ensure it handles concurrency properly if reading stdout and stderr simultaneously.",
            "status": "done",
            "testStrategy": "Unit tests writing to a pipe and asserting that data appears in both the destination buffer and the callback function.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:41:02.564Z"
          },
          {
            "id": 3,
            "title": "Implement Basic Command Execution Logic",
            "description": "Implement the core logic to invoke a shell command using `os/exec` within the Runner context.",
            "dependencies": [
              2
            ],
            "details": "In `internal/exec/exec.go` (or `runner.go`), implement a private method `execCommand(script string, env []string) error`. This should construct `exec.Command` using `bash -lc` (or configured shell). It must attach the `WorkDir` and merge the process environment with the Runner's `Env`. Wire up the `Stdout` and `Stderr` pipes to the streaming mechanism defined in the previous subtask. Handle process start and wait.",
            "status": "done",
            "testStrategy": "Integration test: Run a simple `echo hello` command and verify successful exit code and captured output.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:41:02.565Z"
          },
          {
            "id": 4,
            "title": "Implement RunPrelude and RunStep Methods",
            "description": "Flesh out the public methods to execute specific parts of a Pack.",
            "dependencies": [
              3
            ],
            "details": "Implement `RunPrelude(p *pack.Prelude, logWriter io.Writer)` and `RunStep(s *pack.Step, logWriter io.Writer)`. These methods should construct the shell script string from the provided model (concatenating commands if necessary, or passing the raw script block). They should invoke the internal command execution logic, passing the appropriate log writers. Ensure `RunStep` handles errors by returning a specific error type that indicates failure.",
            "status": "done",
            "testStrategy": "Mock the `pack` structs and verify that `RunStep` executes the script content contained in the step.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:41:02.567Z"
          },
          {
            "id": 5,
            "title": "Implement Process Termination and Context Handling",
            "description": "Add support for context-based cancellation to handle interrupts and timeouts gracefully.",
            "dependencies": [
              4
            ],
            "details": "Update the Runner methods to accept `context.Context`. Modify the `os/exec` command creation to use `exec.CommandContext`. Ensure that if the context is cancelled, the underlying process is killed (using `cmd.Wait` and potentially process group killing if the shell spawns children). This is crucial for stopping a run gracefully via Ctrl+C.",
            "status": "done",
            "testStrategy": "Test starting a long-running command (e.g., `sleep 10`) and cancelling the context immediately, verifying the process terminates quickly.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:41:02.568Z"
          }
        ],
        "updatedAt": "2025-12-30T21:41:02.568Z"
      },
      {
        "id": 5,
        "title": "Implement Flag Injection Logic",
        "description": "Add logic to safely inject user-provided flags into `oracle` command invocations within steps.",
        "details": "Extend `internal/exec` or `internal/pack` with a transformation function. It should scan step body lines; if a line matches `^\\s*oracle\\s+`, append the extra flags. Ensure it handles whitespace correctly and does not modify non-oracle lines. This must be conservative to avoid breaking scripts.",
        "testStrategy": "Unit tests with various step bodies, asserting that only 'oracle' lines are modified and others remain untouched.",
        "priority": "medium",
        "dependencies": [
          "4"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze and Define Regex Strategy for Oracle Command Detection",
            "description": "Create a robust regular expression strategy to correctly identify `oracle` command invocations within a shell script body.",
            "dependencies": [],
            "details": "Analyze various shell command patterns (e.g., `oracle ...`, `  oracle ...`, `path/to/oracle ...`). Define a regex pattern, likely `^\\s*oracle(\\s+|$)`, to safely target lines calling the oracle binary without matching false positives like comments or strings. Document edge cases.",
            "status": "done",
            "testStrategy": "Create a list of test strings (positive and negative matches) to verify regex behavior before implementation.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:43:01.568Z"
          },
          {
            "id": 2,
            "title": "Implement Script Transformation Function in `internal/exec`",
            "description": "Develop the core function `InjectFlags(script string, flags []string) string` to process script bodies.",
            "dependencies": [
              1
            ],
            "details": "In `internal/exec`, add a new file or utility function. The function should accept the raw script content and a list of flags. It must iterate line-by-line, detect lines matching the defined regex, and append the provided flags to the end of the command line, preserving existing whitespace and arguments.",
            "status": "done",
            "testStrategy": "Unit test the function with string inputs representing shell scripts, ensuring output strings contain injected flags on correct lines.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:43:01.570Z"
          },
          {
            "id": 3,
            "title": "Integrate Flag Injection into Runner Execution Flow",
            "description": "Modify the `Runner` struct and `RunStep` method to accept and apply extra flags.",
            "dependencies": [
              2
            ],
            "details": "Update the `Runner` struct in `internal/exec/runner.go` (or equivalent) to hold an `OracleFlags` field (slice of strings). Update the `RunStep` method to call the transformation function on the step's script body before passing it to `os/exec` or writing it to a temporary file.",
            "status": "done",
            "testStrategy": "Integration test: Instantiate a Runner with specific flags, run a mock step containing `oracle`, and verify the executed command includes the flags (e.g., via echoed output or log inspection).",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:43:01.572Z"
          },
          {
            "id": 4,
            "title": "Add Configuration Support for Oracle Flags",
            "description": "Ensure the application configuration can pass these flags down to the execution engine.",
            "dependencies": [
              3
            ],
            "details": "Update the main application config structure (likely in `internal/app` or `internal/config`) to include a field for user-provided flags (e.g., from CLI args). Ensure this configuration is correctly propagated when initializing the `Runner` instance.",
            "status": "done",
            "testStrategy": "Verify that a configured list of flags in the App struct results in a populated `OracleFlags` field in the Runner.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:43:01.577Z"
          },
          {
            "id": 5,
            "title": "Verify Injection Safety and Side Effects",
            "description": "Conduct comprehensive testing to ensure non-oracle lines and complex scripts remain unbroken.",
            "dependencies": [
              2,
              3
            ],
            "details": "Write a suite of test cases covering edge cases: multi-line scripts, indentation, other commands starting with 'o', and scripts with no oracle calls. Ensure the transformation is idempotent or harmless if run multiple times (though it should only run once per execution).",
            "status": "done",
            "testStrategy": "Run a regression test suite with complex step bodies to ensure the script syntax remains valid and only target lines are modified.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:43:01.574Z"
          }
        ],
        "updatedAt": "2025-12-30T21:43:01.577Z"
      },
      {
        "id": 6,
        "title": "Wire Application Core (Plain Mode)",
        "description": "Connect parser, executor, and state modules to create a functional non-TUI application runner.",
        "details": "Implement `internal/app`. Create `RunPlain` method. Orchestrate the flow: Load Pack -> Load State (if resume) -> Iterate Steps -> (Prompt/Confirm if interactive) -> Execute -> Update State -> Write Report. Handle `stop-on-fail` logic. This forms the business logic layer independent of the UI.",
        "testStrategy": "Integration tests running the full flow with a mock executor or simple scripts, verifying state updates and report generation.",
        "priority": "high",
        "dependencies": [
          "3",
          "5"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Application Context and Config Structures",
            "description": "Create the core App struct in internal/app containing configuration for execution mode, paths, and dependencies.",
            "dependencies": [],
            "details": "Create `internal/app/app.go`. Define a `Config` struct holding flags like `Verbose`, `DryRun`, `StopOnFail`, and `Resume`. Define the `App` struct that aggregates `parser.Pack`, `state.Manager`, and `exec.Runner`. Include a constructor `New(config Config)` that initializes these components.",
            "status": "done",
            "testStrategy": "Unit tests ensuring configuration options are correctly applied to the App struct.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:44:25.768Z"
          },
          {
            "id": 2,
            "title": "Implement Workflow Orchestration Logic",
            "description": "Develop the RunPlain method to iterate through pack steps and manage the execution flow.",
            "dependencies": [
              1
            ],
            "details": "In `internal/app/run.go`, implement `RunPlain() error`. This method should load the pack using `internal/parser`, initialize or load the state using `internal/state`, and loop through `Pack.Steps`. Inside the loop, check if the step is already completed (if resuming) before proceeding.",
            "status": "done",
            "testStrategy": "Mock dependencies (Parser, State) to test flow logic: skipping completed steps on resume, and stopping on error.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:44:25.770Z"
          },
          {
            "id": 3,
            "title": "Integrate Step Execution and Logging",
            "description": "Connect the orchestration loop to the executor engine to actually run step commands.",
            "dependencies": [
              2
            ],
            "details": "Within the `RunPlain` loop, invoke `exec.Runner.RunStep`. Configure the runner to stream output to stdout (for plain mode) and write logs to the file defined in the state/config. Handle `exec` errors by wrapping them in domain specific errors defined in `internal/errors`.",
            "status": "done",
            "testStrategy": "Integration test with a mock script to verify that the executor is called and logs are directed to the correct writer.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:44:25.772Z"
          },
          {
            "id": 4,
            "title": "Implement State Transitions and Persistence",
            "description": "Update the state manager after each step execution to record success or failure.",
            "dependencies": [
              3
            ],
            "details": "After `exec.Runner.RunStep` returns, update the current step's status in `internal/state`. Call `state.Save()` to persist progress to disk immediately. Ensure that the 'running' status is set before execution and 'completed'/'failed' after execution to support crash recovery.",
            "status": "done",
            "testStrategy": "Verify that the state file on disk reflects the progress after each step in a multi-step workflow.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:44:25.774Z"
          },
          {
            "id": 5,
            "title": "Generate Final Report and Cleanup",
            "description": "Implement the logic to finalize the run and generate a summary report.",
            "dependencies": [
              4
            ],
            "details": "At the end of `RunPlain`, regardless of success or failure (use `defer` or final block), generate a run report. This should summarize total time, steps completed, and any errors. Use the report format defined in `internal/parser` or `internal/state` if available, or create a simple text summary.",
            "status": "done",
            "testStrategy": "Run a full flow and assert that the report file/output exists and contains accurate summary data.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:44:25.776Z"
          }
        ],
        "updatedAt": "2025-12-30T21:44:25.776Z"
      },
      {
        "id": 7,
        "title": "Implement CLI Entrypoint and Subcommands",
        "description": "Set up the CLI framework using Cobra or standard flag parsing to expose functionality.",
        "details": "Implement `internal/cli`. Use `github.com/spf13/cobra` for robust command handling. Create `root` command and subcommands `run`, `validate`, `list`. specific flags: `--yes`, `--resume`, `--no-tui`, `--oracle-bin`. Map these flags to the `app` configuration. Ensure `help` text is auto-generated.",
        "testStrategy": "CLI tests parsing arguments and flags, asserting that the correct app configuration object is constructed.",
        "priority": "medium",
        "dependencies": [
          "6"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Cobra CLI Structure and Root Command",
            "description": "Set up the internal/cli package, create the root command, and define the global flags structure.",
            "dependencies": [],
            "details": "Create `internal/cli/root.go`. Initialize the root `cobra.Command` representing the entry point. Define a `Config` struct (or use an existing one from `internal/app` if available) to hold flag values. Define global flags like `--no-tui` and `--oracle-bin` here if they apply globally, or prepare them for specific subcommands. Ensure `Execute()` function is exported for `main.go`.",
            "status": "done",
            "testStrategy": "Unit test verifying the root command executes and displays help text without errors.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:45:35.697Z"
          },
          {
            "id": 2,
            "title": "Implement 'run' Subcommand with Flags",
            "description": "Create the 'run' subcommand to execute the pack, binding specific flags like --yes and --resume.",
            "dependencies": [
              1
            ],
            "details": "Create `internal/cli/run.go`. Define the `runCmd` struct. Register flags `--yes` (bool), `--resume` (bool), `--oracle-bin` (string), and `--no-tui` (bool) specifically for this command if they are not global. In the `RunE` handler, validate arguments (path to markdown file). This handler will eventually call the application logic.",
            "status": "done",
            "testStrategy": "Unit test invoking the run command with various flag combinations and asserting the config struct is populated correctly.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:45:35.699Z"
          },
          {
            "id": 3,
            "title": "Implement 'validate' and 'list' Subcommands",
            "description": "Add the 'validate' and 'list' subcommands to check pack integrity and list steps without execution.",
            "dependencies": [
              1
            ],
            "details": "Create `internal/cli/validate.go` and `internal/cli/list.go`. `validate` should accept a file path and call the parser's validation logic. `list` should parse the file and print steps. Ensure both commands inherit necessary global settings but generally require fewer flags than `run`.",
            "status": "done",
            "testStrategy": "Unit tests ensuring commands parse arguments correctly and fail on missing file arguments.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:45:35.702Z"
          },
          {
            "id": 4,
            "title": "Connect CLI to Application Logic",
            "description": "Map the parsed CLI flags and arguments to the main application controller or configuration object.",
            "dependencies": [
              2,
              3
            ],
            "details": "In each command's `RunE` method, instantiate the necessary components (e.g., `PackParser`, `Runner`, `App`). Pass the flag values (e.g., `resume`, `oracleBinary`) into an options struct used to initialize the application. Ensure the `run` command conditionally initializes the TUI based on the `--no-tui` flag.",
            "status": "done",
            "testStrategy": "Integration test mocking the internal app controller and verifying it receives the correct parameters from the CLI execution.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:45:35.703Z"
          },
          {
            "id": 5,
            "title": "Create Main Entrypoint",
            "description": "Implement the main.go file to invoke the CLI entry point.",
            "dependencies": [
              1
            ],
            "details": "Create `cmd/oraclepack/main.go`. This file should be minimal, importing `internal/cli` and calling `cli.Execute()`. It should handle the top-level error exit code (e.g., `os.Exit(1)` if `Execute` returns an error).",
            "status": "done",
            "testStrategy": "Build test (go build ./cmd/oraclepack) to ensure the binary compiles and basic manual execution test.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:45:35.705Z"
          }
        ],
        "updatedAt": "2025-12-30T21:45:35.705Z"
      },
      {
        "id": 8,
        "title": "Develop Markdown Rendering for Terminal",
        "description": "Implement a renderer to display Markdown content (previews) as ANSI-styled text.",
        "details": "Implement `internal/render`. integrate `github.com/charmbracelet/glamour`. Create a function `RenderMarkdown(text string) string` that returns ANSI strings. Configure a style (dark/light mode aware if possible, or fixed high-contrast).",
        "testStrategy": "Golden file tests comparing raw Markdown input against expected ANSI output strings.",
        "priority": "low",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add Glamour Dependency and Create Render Package",
            "description": "Initialize the internal/render package and add the github.com/charmbracelet/glamour dependency to the project.",
            "dependencies": [],
            "details": "Run `go get github.com/charmbracelet/glamour` to update go.mod. Create the directory `internal/render`. Create a `render.go` file within this package. This sets up the foundational environment for markdown rendering.",
            "status": "done",
            "testStrategy": "Verify go.mod contains the dependency and the package compiles.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:46:38.916Z"
          },
          {
            "id": 2,
            "title": "Define RenderMarkdown Interface and Setup Glamour Renderer",
            "description": "Implement the core RenderMarkdown function and initialize the glamour renderer with a specific style.",
            "dependencies": [
              1
            ],
            "details": "In `internal/render/render.go`, define `func RenderMarkdown(text string) (string, error)`. Inside, initialize a glamour renderer using `glamour.NewTermRenderer`. Configure it to use a standard style like 'dark' or 'notty' initially. This function should take raw markdown text and return the ANSI string.",
            "status": "done",
            "testStrategy": "Unit test passing a simple markdown string (**bold**) and asserting the output contains ANSI escape codes.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:46:38.918Z"
          },
          {
            "id": 3,
            "title": "Implement Custom Style Configuration",
            "description": "Configure the glamour renderer to attempt auto-detection of the terminal background or fallback to a high-contrast style.",
            "dependencies": [
              2
            ],
            "details": "Enhance the renderer initialization logic. Use `glamour.WithAutoStyle()` if appropriate, or allow passing a style preference (Light/Dark) via a configuration struct/parameter. Ensure the style ensures readability in standard terminal environments. Handle initialization errors gracefully.",
            "status": "done",
            "testStrategy": "Manual verification in a terminal or unit tests checking that different styles produce different ANSI codes.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:46:38.920Z"
          },
          {
            "id": 4,
            "title": "Integrate Rendering with Pack Structures",
            "description": "Create a helper to render the description or content of a Pack Step directly.",
            "dependencies": [
              2
            ],
            "details": "Import `internal/pack`. Add a function `RenderStepDescription(step pack.Step) (string, error)` (or similar) in `internal/render`. This function should extract the relevant text field from the Step struct (e.g., the markdown body or prelude) and pass it to `RenderMarkdown`. This bridges the domain model with the view logic.",
            "status": "done",
            "testStrategy": "Unit test creating a mock Step object and verifying its markdown content is correctly rendered to ANSI.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:46:38.922Z"
          },
          {
            "id": 5,
            "title": "Create Golden File Tests for Markdown Rendering",
            "description": "Establish a robust testing suite using golden files to ensure rendering output remains consistent.",
            "dependencies": [
              2,
              3
            ],
            "details": "Create `internal/render/render_test.go`. Setup a test data directory `testdata/`. Add `.md` files with various markdown features (lists, code blocks, headers) and corresponding `.golden` files containing the expected ANSI output. Write a test function that renders the input and compares it to the golden file.",
            "status": "done",
            "testStrategy": "Run `go test ./internal/render` and verify that changes to styles break tests (prompting golden file updates) and output matches expectations.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:46:38.923Z"
          }
        ],
        "updatedAt": "2025-12-30T21:46:38.923Z"
      },
      {
        "id": 9,
        "title": "Build TUI with Bubble Tea",
        "description": "Create the interactive terminal UI using Bubble Tea, featuring step lists and log streaming.",
        "details": "Implement `internal/tui`. Define the Bubble Tea `Model`. Use `github.com/charmbracelet/bubbles/list` for the step list and `github.com/charmbracelet/bubbles/viewport` for logs. Implement `Update` loop to handle messages (KeyMsg, WindowSizeMsg, custom StatusMsg). Bind the `app` logic to trigger execution commands that return `Cmd`s. Show step status (spinner for running, check for success). Integrate `internal/render` for previews.",
        "testStrategy": "Manual testing of UI flows. Unit tests for Update function state transitions based on messages.",
        "priority": "high",
        "dependencies": [
          "6",
          "8"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define TUI Model and Initialize Layout",
            "description": "Create the base Bubble Tea model structure and initialize the list and viewport components.",
            "dependencies": [],
            "details": "Create `internal/tui/model.go`. Define a `Model` struct containing state fields: `pack` (from internal/pack), `steps` (list.Model), `logs` (viewport.Model), `spinner` (spinner.Model), `currentStepIdx` int, and `running` bool. Implement `Init()`, returning a batch command to start the spinner. In `NewModel(pack)`, initialize the `list.Model` with step items derived from the pack and the `viewport.Model` for log output. Configure default styles for the list and viewport.",
            "status": "done",
            "testStrategy": "Unit test `NewModel` to verify initial state configuration.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:48:37.631Z"
          },
          {
            "id": 2,
            "title": "Implement Update Loop and Key Bindings",
            "description": "Implement the Update method to handle key presses and window resizing.",
            "dependencies": [
              1
            ],
            "details": "In `internal/tui/update.go`, implement `Update(msg tea.Msg) (tea.Model, tea.Cmd)`. Handle `tea.KeyMsg`: 'q'/Ctrl+C to quit, 'enter' to run selected step (if not running), up/down to navigate list. Handle `tea.WindowSizeMsg` to resize the list and viewport dynamically (e.g., list takes 1/3 width, viewport 2/3). Handle `spinner.TickMsg` to update the spinner if a step is running. Ensure navigation is disabled while a step is executing.",
            "status": "done",
            "testStrategy": "Unit tests simulating KeyMsg inputs to verify model state changes (e.g., selection index updates).",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:48:37.633Z"
          },
          {
            "id": 3,
            "title": "Integrate Step Execution and Command Triggering",
            "description": "Bind the execution logic to the TUI model using Bubble Tea Commands.",
            "dependencies": [
              2
            ],
            "details": "Define custom messages: `StepStartedMsg`, `LogLineMsg`, `StepFinishedMsg`. Create a `runStepCmd(runner, step)` function that returns a `tea.Cmd`. This command should invoke `internal/exec` logic. Since `exec` streams logs, wrap the execution in a way that it sends `LogLineMsg` back to the Update loop via a channel or callback, finally returning `StepFinishedMsg`. Update the Model to handle `StepStartedMsg` (set running=true), `StepFinishedMsg` (set running=false, update status icon), and append content to viewport on `LogLineMsg`.",
            "status": "done",
            "testStrategy": "Integration test mocking the executor to verify messages flow correctly through the Update loop.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:48:37.635Z"
          },
          {
            "id": 4,
            "title": "Implement View Rendering with Styles",
            "description": "Construct the UI layout string in the View method using Lip Gloss for styling.",
            "dependencies": [
              1
            ],
            "details": "In `internal/tui/view.go`, implement `View() string`. Use `lipgloss` to create a split view: left pane for the step list, right pane for the log viewport. Apply borders and colors. Render the current step's status (pending, running, success, fail) using icons next to list items. Display a help footer (e.g., 'Enter: Run, q: Quit'). Ensure the view handles the current terminal dimensions correctly based on previous WindowSizeMsg.",
            "status": "done",
            "testStrategy": "Visual inspection via manual run; Snapshot testing of View output string if feasible.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:48:37.637Z"
          },
          {
            "id": 5,
            "title": "Connect TUI to Main Application Entrypoint",
            "description": "Wire the TUI into the main CLI command to launch the interface.",
            "dependencies": [
              3,
              4
            ],
            "details": "Update `cmd/oraclepack/main.go` (or wherever the root command runs). Add a flag or command to start interactive mode. Load the `Pack` using `internal/pack`. Initialize `internal/exec.Runner`. Create the TUI model via `tui.NewModel`. Start the program with `tea.NewProgram(model).Run()`. Ensure graceful shutdown and error reporting if TUI fails to initialize.",
            "status": "done",
            "testStrategy": "Manual verification: Run the binary with a sample pack and check if the TUI launches and interacts correctly.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:48:37.639Z"
          }
        ],
        "updatedAt": "2025-12-30T21:48:37.639Z"
      },
      {
        "id": 10,
        "title": "Setup Release Automation",
        "description": "Configure GoReleaser to automate builds and packaging for distribution.",
        "details": "Create `.goreleaser.yaml`. Configure builds for Linux (amd64/arm64), macOS (amd64/arm64), and Windows. Set up archive formats (tar.gz, zip). Configure Homebrew tap integration. Ensure binary is stripped and optimized.",
        "testStrategy": "Run `goreleaser release --snapshot --clean` locally to verify artifact generation.",
        "priority": "low",
        "dependencies": [
          "7",
          "9"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize GoReleaser Configuration",
            "description": "Generate and configure the initial .goreleaser.yaml file for the project.",
            "dependencies": [],
            "details": "Run `goreleaser init` or manually create `.goreleaser.yaml` at the project root. define the `project_name` as 'oraclepack'. Configure the `before` hooks to run `go mod tidy`. Set up the basic `builds` section pointing to the main package entry point (e.g., `cmd/oraclepack` or `.`).",
            "status": "done",
            "testStrategy": "Run `goreleaser check` to validate the syntax of the configuration file.",
            "updatedAt": "2025-12-30T21:48:59.868Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Configure Cross-Platform Builds",
            "description": "Define build targets for Linux, macOS, and Windows with appropriate architectures.",
            "dependencies": [
              1
            ],
            "details": "Update the `builds` section in `.goreleaser.yaml`. Enable `env` with `CGO_ENABLED=0` for static binaries. specific `goos` as [linux, darwin, windows] and `goarch` as [amd64, arm64]. Ensure binary names follow the standard convention (e.g., `oraclepack`).",
            "status": "done",
            "testStrategy": "Run `goreleaser build --snapshot --clean` and inspect the `dist/` folder to verify binaries are created for all targets.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:48:59.870Z"
          },
          {
            "id": 3,
            "title": "Configure Archives and Checksums",
            "description": "Set up archive formats (tar.gz, zip) and name templates for distribution.",
            "dependencies": [
              2
            ],
            "details": "Configure the `archives` section. Use `tar.gz` for Linux/macOS and `zip` for Windows. Define `name_template` to include project name, version, OS, and architecture. Add files like `README.md` and `LICENSE` to the archive. Enable `checksum` generation.",
            "status": "done",
            "testStrategy": "Run `goreleaser release --snapshot --clean` and verify the structure and contents of the generated archives in `dist/`.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:48:59.872Z"
          },
          {
            "id": 4,
            "title": "Enable Binary Optimization and Stripping",
            "description": "Configure linker flags to strip debug information and reduce binary size.",
            "dependencies": [
              2
            ],
            "details": "In the `builds` section, add `ldflags` to strip the binary (e.g., `-s -w`). Also, inject version information (version, commit, date) into the main package variables if applicable (e.g., `-X main.version={{.Version}}`).",
            "status": "done",
            "testStrategy": "Build a snapshot and check binary size comparison with/without flags. Use `go tool objdump` or `file` to confirm symbols are stripped.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:48:59.874Z"
          },
          {
            "id": 5,
            "title": "Configure Homebrew Tap Integration",
            "description": "Add Homebrew formula generation to the release process.",
            "dependencies": [
              3
            ],
            "details": "Configure the `brews` section in `.goreleaser.yaml`. Define the tap repository (e.g., `github.com/user/homebrew-tap`). Set the formula description and homepage. ensure the install instructions copy the binary properly. Note: This requires a GitHub token which should be configured in the CI environment, not hardcoded.",
            "status": "done",
            "testStrategy": "Dry-run the release locally using `goreleaser release --snapshot --skip-publish` to verify the formula is generated correctly in `dist/`.",
            "parentId": "undefined",
            "updatedAt": "2025-12-30T21:48:59.876Z"
          }
        ],
        "updatedAt": "2025-12-30T21:48:59.876Z"
      },
      {
        "id": 11,
        "title": "Implement 'Run All' Sequential Execution in TUI",
        "description": "Add capability to execute all steps sequentially in TUI mode, triggered by CLI flag or keybinding.",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze and Refactor TUI Model for Sequential Execution State",
            "description": "Examine the current Bubble Tea model in `internal/tui` and add state fields necessary to track a 'Run All' process.",
            "dependencies": [],
            "details": "Update the TUI model struct to include fields like `runningAll bool`, `pendingSteps []int` (indices or IDs), and `stopOnFailure bool`. This state will track whether the TUI is currently in the auto-advance mode. Review `internal/tui/model.go` (or equivalent) to ensure the `Update` loop can distinguish between a single manual run and a sequential run.",
            "status": "done",
            "testStrategy": "Unit tests for the model's initial state and state transitions when `runningAll` flags are toggled.",
            "parentId": "undefined",
            "updatedAt": "2025-12-31T03:49:55.837Z"
          },
          {
            "id": 2,
            "title": "Implement CLI Flag for Auto-Start and Pass to TUI",
            "description": "Add a `--run-all` or similar flag to the CLI and propagate this configuration to the TUI initialization.",
            "dependencies": [
              1
            ],
            "details": "Modify `internal/cli` to accept a new boolean flag (e.g., `--run-all` or `--auto`). Pass this boolean value into the function that constructs the TUI model. Ensure that if this flag is true, the TUI initializes in the `runningAll` state immediately upon startup.",
            "status": "done",
            "testStrategy": "Integration test invoking the binary with `--run-all`, verifying via mock or logs that the TUI enters the auto-run state immediately.",
            "parentId": "undefined",
            "updatedAt": "2025-12-31T03:49:55.839Z"
          },
          {
            "id": 3,
            "title": "Implement 'Run All' Keybinding in TUI",
            "description": "Register a new keybinding in the Bubble Tea application to trigger the sequential execution mode manually.",
            "dependencies": [
              1
            ],
            "details": "In `internal/tui/update.go` (or wherever key messages are handled), add a case for the chosen key (e.g., 'a' or 'r'). When pressed, set `model.runningAll = true`, identify the first pending step, and trigger the `Cmd` to run that step. Add visual feedback (e.g., a status line update) indicating 'Running All Steps'.",
            "status": "done",
            "testStrategy": "Manual verification or UI test harness (if available) pressing the key and observing the state change.",
            "parentId": "undefined",
            "updatedAt": "2025-12-31T03:49:55.841Z"
          },
          {
            "id": 4,
            "title": "Implement Sequential Step Chaining Logic",
            "description": "Modify the TUI Update loop to automatically trigger the next step upon the successful completion of the current step when in 'Run All' mode.",
            "dependencies": [
              1,
              3
            ],
            "details": "In the `Update` function, locate the message handling for a step completion (e.g., `StepFinishedMsg`). If `model.runningAll` is true and the step succeeded, locate the next step index. Return a command to run the next step immediately. If the step failed or was the last one, set `runningAll = false` and update the status message.",
            "status": "done",
            "testStrategy": "Unit tests for the `Update` function: simulate a `StepFinishedMsg` (success) while `runningAll` is true, asserting that the returned command is the execution of the next step.",
            "parentId": "undefined",
            "updatedAt": "2025-12-31T03:49:55.844Z"
          },
          {
            "id": 5,
            "title": "Implement User Interruption Handling",
            "description": "Allow the user to interrupt the sequential execution flow using a keybinding (e.g., Esc or Ctrl+C).",
            "dependencies": [
              4
            ],
            "details": "In the `Update` loop, ensure that key presses like `Esc` or `q` are checked during the 'Run All' sequence. If pressed, set `runningAll = false` to stop the chain after the current step finishes (or attempt to cancel the current running step if the execution engine supports cancellation context).",
            "status": "done",
            "testStrategy": "Unit test simulating an interrupt key press during `runningAll` state, verifying that the state resets to `runningAll = false` and no further steps are queued.",
            "parentId": "undefined",
            "updatedAt": "2025-12-31T03:49:55.846Z"
          }
        ],
        "updatedAt": "2025-12-31T03:49:55.846Z"
      },
      {
        "id": 12,
        "title": "Fix Step Header Parsing for Em-Dash Support",
        "description": "Update the Markdown parser to correctly handle step headers formatted with an em-dash (e.g., '# 01  Step Title') in addition to the existing parenthesis format.",
        "details": "The current `ExtractSteps` function in `internal/parser/parser.go` uses a regular expression that strictly expects a closing parenthesis after the step number (e.g., `^#\\s+(\\d+)\\)\\s+(.*)`). This causes validation failures for files using the em-dash format commonly found in some documentation styles (e.g., `^#\\s+(\\d+)\\s+[-]\\s+(.*)`).\n\nImplementation Steps:\n1.  Locate `stepRegex` in `internal/parser/parser.go`.\n2.  Modify the regular expression to allow for alternate separators. A proposed pattern is `^#\\s+(\\d+)(?:\\)|\\.|\\s+[-])\\s+(.*)`, covering `1)`, `1.`, and `1 ` formats.\n3.  Update the logic that parses the captured groups to ensure the step number and title are correctly extracted regardless of the separator used.\n4.  Ensure that the change does not break existing support for parenthesis-based headers.\n5.  (Optional) If strict formatting is desired, normalize the stored title, but the primary goal is parsing flexibility.",
        "testStrategy": "1. Add a new test case in `internal/parser/parser_test.go` specifically using a sample Markdown content with em-dash headers (e.g., `# 01  Install Dependencies`).\n2. Verify that the parser correctly extracts the ID `1` and the title `Install Dependencies`.\n3. Run existing tests to ensure no regression for `# 01) Title` formats.\n4. specific CLI test: Run `oraclepack validate` against a file with em-dash headers to confirm it passes.",
        "status": "done",
        "dependencies": [
          "7"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-31T20:08:52.250Z"
      },
      {
        "id": 13,
        "title": "Implement ROI Extraction and Execution Filtering",
        "description": "Parse ROI values from step headers and add CLI flags to filter step execution based on an ROI threshold.",
        "details": "Update the core parser and execution engine to support value-based step filtering.\n\n1. **Parser Update (`internal/parser`)**: Modify `ExtractSteps` and the `Step` struct. Update the header regex (building on Task 12's em-dash support) to capture an optional `ROI=(\\d+(\\.\\d+)?)` pattern. Store this as a `float64` in the `Step` struct. Ideally, strip the 'ROI=...' substring from the final `Step.Title` for cleaner UI display.\n\n2. **CLI Flags (`internal/cli`)**: Add new flags to the `run` command: `--roi-threshold` (float, default 0) and `--roi-mode` (string, options: 'over', 'under', default 'over'). Bind these to the application configuration.\n\n3. **Filtering Logic (`internal/app`)**: In the `RunPlain` loop (and TUI equivalent), inject a filtering check before execution. \n   - If `mode` is 'over', skip steps where `step.ROI < threshold`.\n   - If `mode` is 'under', skip steps where `step.ROI > threshold`.\n   - Treat steps without an explicit ROI tag as having an ROI of 0.0.",
        "testStrategy": "1. **Unit Tests**: Extend `internal/parser/parser_test.go` with table-driven tests containing headers like `# 01) Task ROI=5.5` and `# 02  Low Value ROI=0.1`. Assert that `ROI` fields are populated correctly.\n2. **Integration Tests**: Create a dummy pack with varying ROI values. Execute the CLI with `--roi-threshold=1.0 --roi-mode=over` and verify via logs or report output that only high-ROI steps were executed.",
        "status": "done",
        "dependencies": [
          "6",
          "7",
          "12"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Update Step Struct and Header Regex for ROI",
            "description": "Modify the Step struct to include an ROI float64 field and update the header parsing regex to capture 'ROI=value' patterns.",
            "dependencies": [],
            "details": "In `internal/parser`, add `ROI float64` to the `Step` struct. Update the regex in `ExtractSteps` (or helper function) to identify `ROI=(\\d+(\\.\\d+)?)` within the header line. Ensure the parsing logic converts the captured string to a float using `strconv.ParseFloat`. The regex must support existing formats (parenthesis, em-dash) while optionally capturing this new tag.",
            "status": "pending",
            "testStrategy": "Unit tests in `internal/parser` checking that `Step.ROI` is correctly populated for headers like `# 01) Title ROI=5.5` and defaults to 0.0 otherwise.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement ROI Tag Stripping from Step Titles",
            "description": "Clean up the step title by removing the raw ROI tag string after extraction to ensure clean UI output.",
            "dependencies": [
              1
            ],
            "details": "After extracting the ROI value in `internal/parser`, implement string manipulation to remove the substring `ROI=...` from the `Step.Title`. Use `strings.Replace` or regex replacement to trim this tag and any surrounding extra whitespace so the user sees `# 01) Task Name` instead of `# 01) Task Name ROI=5.5`.",
            "status": "pending",
            "testStrategy": "Extend parser unit tests to assert `Step.Title` does not contain the 'ROI=' substring after parsing.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add ROI Flags to CLI Configuration",
            "description": "Define `--roi-threshold` and `--roi-mode` flags in the CLI and bind them to the application configuration.",
            "dependencies": [
              1
            ],
            "details": "In `internal/cli`, specifically within the `run` command setup, add two new flags: `--roi-threshold` (float, default 0.0) and `--roi-mode` (string, default 'over', validation options: 'over', 'under'). Ensure these values are propagated to the `app.Config` or `RunConfig` struct passed to the execution engine.",
            "status": "pending",
            "testStrategy": "CLI tests invoking the run command with these flags and asserting the config object reflects the provided values.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Execution Filtering Logic in Run Loop",
            "description": "Inject logic into the main execution loop to skip steps based on the configured ROI threshold and mode.",
            "dependencies": [
              1,
              3
            ],
            "details": "In `internal/app` (within `RunPlain` and potentially TUI logic), add a conditional check before executing a step. If `roi-mode` is 'over', continue only if `step.ROI >= threshold`. If 'under', continue only if `step.ROI <= threshold`. Log a specific message when a step is skipped due to ROI filtering.",
            "status": "pending",
            "testStrategy": "Integration test with a mock pack containing high and low ROI steps. Verify via logs that steps failing the threshold check are skipped.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Verify ROI Filtering in TUI/Interactive Mode",
            "description": "Ensure the ROI filtering logic is correctly applied or visualized in the TUI mode if applicable.",
            "dependencies": [
              4
            ],
            "details": "Review the TUI implementation in `internal/tui` or the shared execution logic in `internal/app` to ensure the filtering condition applies consistently across both plain and TUI modes. If the TUI displays a list of steps beforehand, consider visually dimming or marking skipped steps, or simply enforcing the skip during execution.",
            "status": "pending",
            "testStrategy": "Manual verification or integration test running in TUI mode (if testable) to ensure consistency with the plain runner.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-12-31T20:45:25.293Z"
      },
      {
        "id": 14,
        "title": "Restore CLI Run-All Flag and TUI Auto-Execution Logic",
        "description": "Re-implement the `--run-all` CLI flag and connect it to the TUI's initialization sequence to enable immediate, sequential execution of all steps upon startup, fixing a regression from recent commits.",
        "details": "This task focuses on rewiring the bridge between the CLI entry point and the TUI's state machine to support unattended (visual) execution.\n\n1. **CLI Layer (`internal/cli/run.go`)**: \n   - Re-introduce the `--run-all` (bool) flag in the `run` command configuration.\n   - Update the `runAction` function to capture this boolean and pass it into the `tui.NewModel` factory function.\n\n2. **TUI Initialization (`internal/tui/tui.go` & `model.go`)**:\n   - Update `NewModel` signature to accept `autoRun bool`.\n   - Store this boolean in the `Model` struct.\n   - Define a `StartAutoRunMsg` struct (empty struct).\n   - In the `Init()` method of the Bubble Tea model: if `autoRun` is true, return a `Cmd` that emits `StartAutoRunMsg` immediately. This ensures the TUI renders at least one frame before execution starts.\n\n3. **TUI Update Loop (`internal/tui/update.go`)**:\n   - Handle `StartAutoRunMsg`: Set the internal `runningAll` state to true (bridging the `autoAdvance` logic) and trigger the execution of the step at `currentIdx`.\n   - Verify the `Update` loop handles the completion of a step (`StepSuccessMsg`) by checking if `runningAll` is active. If so, increment `currentIdx` and immediately dispatch the command to run the next step, ensuring the sequential flow continues without user input.",
        "testStrategy": "1. **Unit Test**: In `internal/tui/tui_test.go`, initialize a model with `autoRun=true` and verify that `Init()` returns the `StartAutoRunMsg` command.\n2. **Manual Integration**: Run `oraclepack run --run-all --pack ./examples/simple` and verify that the UI opens and immediately begins executing steps 1..N without requiring the user to press 'r' or 'enter'.\n3. **Regression Check**: Ensure running without the flag still requires manual initiation.",
        "status": "done",
        "dependencies": [
          "7",
          "9",
          "11",
          "13"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Add Run-All Flag to CLI Configuration",
            "description": "Re-introduce the --run-all boolean flag to the run command and propagate it to the action handler.",
            "dependencies": [],
            "details": "In `internal/cli/run.go`, define a `runAll` boolean variable. Register it in the `init()` function for the `runCmd` using `runCmd.Flags().BoolVar`. Ensure the description clearly indicates it triggers immediate sequential execution. This flag will be used to signal the TUI to start automatically.",
            "status": "pending",
            "testStrategy": "Verify via `oraclepack run --help` that the flag exists and parses correctly in a unit test for the CLI command.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update TUI Model and Factory for Auto-Run State",
            "description": "Modify the TUI Model struct and NewModel factory to accept and store the auto-run configuration.",
            "dependencies": [
              1
            ],
            "details": "In `internal/tui/model.go` (and `tui.go` if the factory is there), add an `autoRun bool` field to the `Model` struct. Update the `NewModel` function signature to accept this boolean argument. Update the call site in `internal/cli/run.go` to pass the captured `runAll` flag value.",
            "status": "pending",
            "testStrategy": "Unit test `NewModel` to ensure the returned model has the `autoRun` field set correctly based on the input.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement StartAutoRunMsg and Init Trigger",
            "description": "Create a message type for auto-start and trigger it in the Bubble Tea Init method if configured.",
            "dependencies": [
              2
            ],
            "details": "In `internal/tui/model.go`, define `type StartAutoRunMsg struct{}`. In the `Init()` method of the `Model`, check if `m.autoRun` is true. If so, return a command that sends `StartAutoRunMsg` (e.g., `func() tea.Msg { return StartAutoRunMsg{} }`). If false, return `nil` or existing init commands.",
            "status": "pending",
            "testStrategy": "Unit test the `Init()` method of the model. When `autoRun` is true, assert that the returned `tea.Cmd` produces a `StartAutoRunMsg`.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Handle Auto-Run Message in Update Loop",
            "description": "Implement the logic to catch StartAutoRunMsg and transition the state to running all steps.",
            "dependencies": [
              3
            ],
            "details": "In `internal/tui/update.go`, add a case for `StartAutoRunMsg` in the `Update` function. This handler should set `m.runningAll = true` (or equivalent state tracking variable) and return the command to execute the current step (likely `m.executeStep(m.currentIdx)`). Ensure this sets the UI into the correct 'running' mode visually.",
            "status": "pending",
            "testStrategy": "Unit test the `Update` loop. Pass `StartAutoRunMsg` to a model and assert that the resulting model state indicates 'running' and returns an execution command.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Ensure Sequential Execution in Step Completion",
            "description": "Verify and fix the step completion logic to continue execution if the run-all mode is active.",
            "dependencies": [
              4
            ],
            "details": "In `internal/tui/update.go`, within the `StepSuccessMsg` (or equivalent) handler, check if `m.runningAll` is true. If so, and if there are more steps, increment the index and return the command to execute the next step immediately. This ensures the loop continues without user intervention until all steps are done or failure occurs.",
            "status": "pending",
            "testStrategy": "Integration test: Initialize model with `autoRun=true` and mock step execution. Verify that multiple steps execute in sequence without intermediate input.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-01T00:21:59.762Z"
      },
      {
        "id": 15,
        "title": "Implement Interactive ROI Filtering in TUI",
        "description": "Enable real-time filtering of the step list within the TUI using a new keybinding to set ROI thresholds, updating the view dynamically.",
        "details": "Extend the Bubble Tea model in `internal/tui` to support dynamic list filtering based on the ROI data structure from Task 13.\n\n1. **Model Extension**: Update `internal/tui/model.go`. Add fields to preserve the full list of steps (`allSteps []list.Item`) separate from the displayed list. Add state for `roiThreshold` (float64), `roiFilterActive` (bool), and an input bubble (`textinput.Model`) to capture user input.\n\n2. **Input Handling**: In `internal/tui/update.go`, bind the key 'f'. When pressed, switch the view mode to show the text input. On 'Enter' in the input, parse the value as a float, update `roiThreshold`, and trigger a list rebuild. On 'Esc', cancel the filter input.\n\n3. **Filtering Logic**: Create a method `filterList()` that iterates over `allSteps`. Type-assert items to the Step concrete type (from `internal/pack` or `internal/tui` wrapper). If `step.ROI >= roiThreshold` (or logic matches the existing CLI filter logic), keep the item. Call `m.list.SetItems(filtered)` to update the view immediately.\n\n4. **Visual Feedback**: Modify `internal/tui/view.go`. Add a status indicator (e.g., using `lipgloss` styles) in the header or footer showing the active filter state (e.g., \"Filter: ROI >= 5.0\") so the user knows why steps might be hidden.",
        "testStrategy": "1. **Unit Tests**: Create `internal/tui/filter_test.go`. Initialize the model with a mocked list of steps having known ROI values (e.g., 1.0, 5.5, 10.0). Invoke the filtering function with various thresholds and assert that the `list.Model` items slice contains the correct subset of steps.\n2. **Interactive Verification**: Run the TUI with a sample pack. Press 'f', enter a value, and verify the list shrinks. Verify that navigating the filtered list and selecting a step works correctly (indices map to the correct underlying step).",
        "status": "done",
        "dependencies": [
          "9",
          "13"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Extend TUI Model with ROI Filtering State",
            "description": "Modify the Bubble Tea model to hold filtering state including all steps, threshold value, and input field.",
            "dependencies": [],
            "details": "Update `internal/tui/model.go`. Add `allSteps []list.Item` to store the original unfiltered list. Add `roiThreshold` (float64, default 0), `isFiltering` (bool), and `filterInput` (textinput.Model). Initialize the text input with standard styles in `NewModel`.",
            "status": "pending",
            "testStrategy": "Unit test ensuring `NewModel` initializes the new fields correctly and the text input model is ready.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Filter Input Keybinding and State Switching",
            "description": "Add key handling to toggle the filter input mode when 'f' is pressed.",
            "dependencies": [
              1
            ],
            "details": "In `internal/tui/update.go`, inside the `Update` loop, check for key 'f'. If not filtering, set `isFiltering = true`, focus `filterInput`, and prevent list navigation. If 'Esc' is pressed while filtering, clear input, reset `isFiltering = false`, and blur input.",
            "status": "pending",
            "testStrategy": "Unit test verifying that sending KeyMsg('f') changes the model state to `isFiltering=true`.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement List Filtering Logic",
            "description": "Create the logic to filter the displayed list based on the ROI threshold.",
            "dependencies": [
              1
            ],
            "details": "Create a method `applyFilter()` in `internal/tui/model.go` (or a helper). It should iterate `m.allSteps`. Type assert items to `StepItem` (or the specific item wrapper). Check if `item.Step.ROI >= m.roiThreshold`. Collect matching items and update `m.list.SetItems(filtered)`. Handle invalid float input gracefully.",
            "status": "pending",
            "testStrategy": "Unit test creating a model with known steps (ROI 1.0, 5.0, 10.0), calling `applyFilter` with threshold 5.0, and asserting list contains 2 items.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Connect Filter Input to Update Loop",
            "description": "Process the text input submission to trigger the filter logic.",
            "dependencies": [
              2,
              3
            ],
            "details": "In `internal/tui/update.go`, when `isFiltering` is true, pass messages to `m.filterInput.Update(msg)`. If 'Enter' is pressed, parse `m.filterInput.Value()` as float64, update `m.roiThreshold`, call `m.applyFilter()`, and set `isFiltering = false`. If parsing fails, perhaps show an error or ignore.",
            "status": "pending",
            "testStrategy": "Integration test: Simulate 'f', type '2.5', press 'Enter', verify `roiThreshold` is 2.5 and list items are updated.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Update TUI View for Filter Status",
            "description": "Render the filter input box or the active filter status in the UI.",
            "dependencies": [
              1
            ],
            "details": "Modify `internal/tui/view.go`. If `isFiltering`, render `m.filterInput.View()`. If `!isFiltering` and `roiThreshold > 0`, render a status line (e.g., using `lipgloss`) indicating 'ROI Filter: >= X.X'. Ensure this fits within the layout without breaking the list view.",
            "status": "pending",
            "testStrategy": "Visual verification or string containment test on `View()` output to ensure the input field or status text appears when appropriate.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-01T00:30:34.168Z"
      },
      {
        "id": 16,
        "title": "Implement Robust Output Directory Handling and CLI Override",
        "description": "Implement logic to parse `out_dir` from the pack prelude, support a CLI override flag, and propagate the resolved path to the execution environment with a safe default.",
        "details": "1. **CLI Extension (`internal/cli`)**: Add a global `--out-dir` string flag to the root or `run` command using Cobra. Map this flag to the application configuration.\n2. **Configuration Resolution (`internal/app`)**: In the application entry point (wired in Task 6), implement precedence logic: `CLI Flag` > `Prelude Metadata (out_dir)` > `Default (.)`. Ensure that if no value is provided, it defaults to the current working directory (`.`) rather than an empty string (which could imply root).\n3. **Directory Provisioning**: Before starting the `internal/exec.Runner`, ensure the target directory exists using `os.MkdirAll(path, 0755)`. Handle permission errors gracefully.\n4. **Execution Context (`internal/exec`)**: Pass the resolved path to the `Runner` struct. Ensure the `os/exec.Cmd` uses this path as its `Dir` field so that scripts run relative to the output directory. Alternatively, export it as an environment variable (e.g., `ORACLE_OUT_DIR`).\n5. **Parser Integration**: Verify `internal/pack.DeriveMetadata` correctly extracts the `out_dir` pattern from the Markdown prelude as implemented in Task 2.",
        "testStrategy": "1. **Unit Tests (`internal/app`)**: Create a test case validating the precedence logic (e.g., define `out_dir` in a mock pack, provide a different CLI flag, assertion should match CLI flag). Test the default case ensuring it resolves to `.`.\n2. **Integration Tests**: Create a temporary test pack with `out_dir: ./subdir`. Run it and verify `subdir` is created and output files appear there. Repeat with the `--out-dir` flag overriding it to `./override`.",
        "status": "done",
        "dependencies": [
          "2",
          "4",
          "6",
          "7"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Add Output Directory Flag to CLI",
            "description": "Extend the root command in internal/cli/root.go to include a global string flag '--out-dir' (shorthand '-o') and bind it to the configuration.",
            "dependencies": [],
            "details": "In 'internal/cli/root.go', define a 'outDir' variable. Add 'rootCmd.PersistentFlags().StringVarP(&outDir, \"out-dir\", \"o\", \"\", ...)' in the init function. Ensure this value is accessible when commands execute, potentially by binding it to viper or passing it to the config struct.",
            "status": "pending",
            "testStrategy": "Unit test in 'internal/cli/root_test.go' verifying that parsing arguments with '--out-dir' correctly sets the variable.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Verify and Expose Pack Metadata Extraction",
            "description": "Review internal/pack to ensure the Pack struct includes an OutDir field populated from the prelude, and ensure it is accessible to the app layer.",
            "dependencies": [
              1
            ],
            "details": "Check 'internal/pack/parser.go' and the 'Pack' struct definition. Verify 'DeriveMetadata' regex matches 'out_dir: <path>'. If missing, implement the regex extraction logic. Ensure the 'Pack' struct has a public 'OutDir' field (string) that holds this value.",
            "status": "pending",
            "testStrategy": "Unit test in 'internal/pack/parser_test.go' with a sample markdown containing 'out_dir: ./build' in the prelude and asserting the parsed Pack struct reflects this.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Configuration Resolution Logic",
            "description": "Create a resolution function in internal/app that determines the final output directory based on precedence rules.",
            "dependencies": [
              2
            ],
            "details": "In 'internal/app/config.go' (or similar), implement 'ResolveOutDir(cliFlag string, packOutDir string) string'. Logic: If cliFlag != \"\", use cliFlag. Else if packOutDir != \"\", use packOutDir. Else return \".\" (current directory). Ensure absolute path resolution is considered if needed.",
            "status": "pending",
            "testStrategy": "Table-driven unit tests in 'internal/app/config_test.go' covering all permutation cases (CLI only, Pack only, Both, None).",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Provision Output Directory",
            "description": "Add logic to the application flow to create the resolved output directory before execution begins.",
            "dependencies": [
              3
            ],
            "details": "In the main execution flow (likely 'internal/app/app.go' or 'internal/cli/run.go'), call 'ResolveOutDir'. Then use 'os.MkdirAll(resolvedPath, 0755)' to ensure the directory exists. Return a user-friendly error if creation fails (e.g., permissions issues).",
            "status": "pending",
            "testStrategy": "Integration test creating a temporary directory structure, running the provisioning logic, and verifying the directory is created on the filesystem.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Propagate Directory to Execution Runner",
            "description": "Update the Runner initialization in internal/exec to accept the resolved working directory and use it during command execution.",
            "dependencies": [
              4
            ],
            "details": "Modify 'internal/exec/runner.go': Update the 'Runner' struct to include a 'WorkDir' field. Update 'NewRunner' signature. In the 'Run' or 'execCmd' method, set 'cmd.Dir = r.WorkDir'. Optionally set an 'ORACLE_OUT_DIR' environment variable in 'cmd.Env'. Update call sites in 'internal/app' to pass the resolved path.",
            "status": "pending",
            "testStrategy": "Integration test in 'internal/exec/runner_test.go': Configure a Runner with a specific temporary WorkDir, execute 'pwd', and assert the output matches the WorkDir.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-01T01:17:49.560Z"
      },
      {
        "id": 17,
        "title": "Implement TUI Post-Run Navigation and State Reset",
        "description": "Implement a state machine within the TUI to manage transitions between list, running, and summary views, including logic for resetting the run state.",
        "details": "Extend the Bubble Tea model in `internal/tui` to support distinct application states: `ViewSteps`, `ViewRunning`, and `ViewDone`.\n\n1. **State Machine (`internal/tui/model.go`)**: Introduce an enumerated type for the view state. Refactor the `Update` method to process key messages differently based on the current state.\n2. **Done Screen**: Create a new view function `viewDone()` that displays a summary of the execution (e.g., 'All steps completed', 'Failed at step X').\n3. **Navigation Logic (`internal/tui/update.go`)**:\n   - **'b' (Back)**: Transition from `ViewDone` to `ViewSteps` without resetting state, allowing the user to review the list.\n   - **'n' (New Run)**: Trigger a `ResetState()` function. This function must traverse the `internal/state.RunState` and mark all steps as `StatusPending`, clear the execution logs in the UI, reset the list cursor to index 0, and transition to `ViewSteps`.\n   - **'r' (Rerun)**: If in `ViewDone`, trigger the execution logic for the specific failed step or restart the sequence (depending on context), transitioning back to `ViewRunning`.\n   - **'q' (Quit)**: Terminate the application.\n4. **Integration**: Ensure that the completion of the `Run All` command (Task 11) automatically transitions the state to `ViewDone`.",
        "testStrategy": "1. **Unit Tests (`internal/tui/model_test.go`)**: Create a test initializing the model in `ViewDone`. Send the 'n' KeyMsg and assert that the view state changes to `ViewSteps` and the step status map is cleared. Send 'b' and assert the view changes but state remains.\n2. **Manual Integration**: Run the full tool. Execute all steps. Verify the UI automatically switches to the Done screen. Press 'n' and verify all green checkmarks reset to empty/pending. Press 'q' to ensure clean exit.",
        "status": "done",
        "dependencies": [
          "3",
          "11",
          "15"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Define TUI View States and Refactor Model",
            "description": "Introduce an enumerated type for application states and update the Model struct to track the current view state.",
            "dependencies": [],
            "details": "In `internal/tui/model.go`, define an enum (e.g., `ViewState`) with values `ViewSteps`, `ViewRunning`, and `ViewDone`. Add a `state ViewState` field to the `Model` struct. Refactor `NewModel` to initialize the state to `ViewSteps`.",
            "status": "pending",
            "testStrategy": "Unit test verifying that NewModel initializes with the correct default ViewState.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Update Loop State Routing",
            "description": "Refactor the Bubble Tea Update method to delegate logic based on the current ViewState.",
            "dependencies": [
              1
            ],
            "details": "In `internal/tui/update.go`, modify the `Update` function to switch on `m.state`. Create separate handler methods (e.g., `updateSteps`, `updateRunning`, `updateDone`) for handling key messages specific to each view. Ensure global keys like Ctrl+C still work universally.",
            "status": "pending",
            "testStrategy": "Unit tests mocking key presses in different states to ensure only relevant handlers are triggered.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement ViewDone UI Rendering",
            "description": "Create the view logic for the summary screen displayed after execution completes.",
            "dependencies": [
              1
            ],
            "details": "In `internal/tui/view.go`, implement a `viewDone()` function. It should render a summary string based on the `RunState` (e.g., success message or error details). Update the main `View()` method to call `viewDone()` when the state is `ViewDone`.",
            "status": "pending",
            "testStrategy": "Manual verification by forcing the state to ViewDone and checking the rendered output for correct summary information.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement State Transitions and Reset Logic",
            "description": "Add logic to handle transitions between views, including a complete state reset for new runs.",
            "dependencies": [
              2
            ],
            "details": "In `internal/tui/update.go`, implement the 'n' key logic in `ViewDone` to call a new method `resetState()`. This method must iterate through `m.store.Steps`, resetting their status to `StatusPending` and clearing logs. It should then switch `m.state` back to `ViewSteps`. Implement 'b' to switch to `ViewSteps` without resetting.",
            "status": "pending",
            "testStrategy": "Unit test initializing model in ViewDone with executed steps, sending 'n', and verifying steps are pending and state is ViewSteps.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Integrate Run Completion with ViewDone Transition",
            "description": "Ensure the TUI automatically transitions to the Done view when the runner finishes execution.",
            "dependencies": [
              2
            ],
            "details": "Modify the `Update` method in `internal/tui/update.go`. Listen for a specific completion message (e.g., `RunFinishedMsg`) generated by the execution command. Upon receipt, update `m.state` to `ViewDone`. Ensure this transition preserves the final execution status for display.",
            "status": "pending",
            "testStrategy": "Integration test simulating a run completion message and asserting the model state transitions to ViewDone.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-01T01:21:52.861Z"
      },
      {
        "id": 19,
        "title": "Fix Regression in Relative Path Handling and Output Directory Context",
        "description": "Modify the application core to prevent the runner from changing the working directory to out_dir, ensuring relative paths resolve from the project root while preserving output directory availability via environment variables.",
        "details": "This task addresses a regression where setting an output directory changed the execution working directory, breaking scripts that rely on relative paths for sourcing files or reading project assets.\n\n1. **Modify App Wiring (`internal/app/app.go`)**: Locate the `RunPlain` method and any TUI initialization logic where the `exec.Runner` is constructed. Identify the line where `Runner.WorkDir` is currently set to `config.OutDir`.\n2. **Restore Working Directory**: Change the `WorkDir` assignment to use the project root (current working directory `.`) regardless of whether `out_dir` is set. This ensures paths like `./internal/...` resolve correctly.\n3. **Environment Variable Injection**: Ensure that `config.OutDir` is passed into the runner's `Env` map (e.g., as `ORACLE_OUT_DIR`). This allows scripts to explicitly target the output directory for artifacts (e.g., `cp result.json $ORACLE_OUT_DIR/`).\n4. **Directory Creation**: Retain the `os.MkdirAll(config.OutDir, 0755)` call to ensure the target directory exists before execution begins.",
        "testStrategy": "Create a regression test pack `examples/test_paths_regression`.\n1. **Setup**: The pack should contain a step that attempts to read a known file from the project root using a relative path (e.g., `cat ./README.md`).\n2. **Output Verification**: The step should also write a file to the configured output path variable: `echo 'test' > \"$ORACLE_OUT_DIR/verification.txt\"`.\n3. **Execution**: Run this pack with the CLI flag `--out-dir ./temp_output`.\n4. **Assertions**: Verify the command succeeds (exit code 0), proving `README.md` was found. Verify `./temp_output/verification.txt` exists, proving the environment variable was passed correctly.",
        "status": "done",
        "dependencies": [
          "4",
          "6",
          "16"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-01T18:50:16.938Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-01-01T18:50:16.939Z",
      "taskCount": 19,
      "completedCount": 18,
      "tags": [
        "master"
      ],
      "created": "2026-01-01T19:43:53.899Z",
      "description": "Tasks for master context",
      "updated": "2026-01-01T19:43:53.899Z"
    }
  },
  "bugfix-tui": {
    "tasks": [
      {
        "id": 1,
        "title": "Define Runtime Overrides Data Model & Step-Aware Merge Logic",
        "description": "Create the core data structures to hold runtime overrides and implement the logic to merge them with baseline flags on a per-step basis.",
        "details": "Create a new package `internal/overrides`. Define `RuntimeOverrides` struct containing `AddedFlags` ([]string), `RemovedFlags` ([]string), `ChatGPTURL` (string), and `ApplyToSteps` (map[string]bool). Implement `EffectiveFlags(stepID string, baseline []string) []string` which returns the final flag set for a given step. If the step is not in `ApplyToSteps`, return baseline. Otherwise, append added flags, remove removed flags, and inject `--chatgpt-url` if set. Add unit tests covering various combinations (add/remove intersection, empty sets).",
        "testStrategy": "Unit tests in `internal/overrides/merge_test.go` verifying that `EffectiveFlags` correctly computes the final slice for targeted and non-targeted steps.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "complexity": 3,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed.",
        "updatedAt": "2026-01-02T16:21:30.521Z"
      },
      {
        "id": 2,
        "title": "Implement Oracle Invocation Extraction (Scanning)",
        "description": "Develop a robust scanner to identify and extract `oracle` command invocations from bash scripts, handling multi-line continuations.",
        "details": "Create `internal/exec/oracle_scan.go`. Implement `ExtractOracleInvocations(script string) []OracleInvocation`. It must detect lines starting with `oracle` (allowing for indentation) and capture the full command including multi-line continuations (lines ending with `\\`). The struct `OracleInvocation` should hold the `Raw` command string and a `Display` version for UI. Use regex or a simple line-by-line state machine. Ensure it handles edge cases like trailing spaces before backslashes.\n\n[2026-01-02] Fixed scanner compile/test issues: corrected backslash suffix literal in internal/overrides/scanner.go; converted multiline expected command to raw string in internal/overrides/scanner_test.go. go test ./internal/overrides now passes.\n\n[2026-01-02] Implemented ExtractOracleInvocations in internal/exec/oracle_scan.go, moved scanner from overrides to exec package, updated tests, and removed overrides OracleInvocation type. go test ./internal/exec ./internal/overrides passes.",
        "testStrategy": "Unit tests in `oracle_scan_test.go` with table-driven tests containing various shell script snippets (single line, multiline, indented) to assert correct extraction.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Core State Machine for Line Parsing",
            "description": "Develop the low-level state machine logic to identify the start of 'oracle' commands and track multi-line continuations.",
            "dependencies": [],
            "details": "Implement a state tracker (e.g., boolean flag `inCommand`) in `internal/exec/oracle_scan.go`. The logic must handle indentation (leading whitespace), identify lines starting with the token `oracle`, and detect the line continuation character `\\` at the end of the line (ignoring trailing whitespace) to determine if the next line belongs to the same command.",
            "status": "pending",
            "testStrategy": "Unit tests verifying state transitions on specific string inputs, ensuring indentation and trailing backslashes trigger the correct state changes.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement ExtractOracleInvocations Function",
            "description": "Develop the public extractor function that processes full scripts to return structured OracleInvocation objects.",
            "dependencies": [
              1
            ],
            "details": "Implement `ExtractOracleInvocations(script string) []OracleInvocation` in `internal/exec/oracle_scan.go`. This function should split the script by lines, utilize the core state machine to aggregate lines into full commands, filter out comments (lines starting with `#`), and populate the `Raw` and `Display` fields of the `OracleInvocation` struct.",
            "status": "pending",
            "testStrategy": "Table-driven tests in `oracle_scan_test.go` using realistic bash script fixtures containing mixed commands, comments, and multi-line oracle invocations.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 2,
        "expansionPrompt": "Break down the scanner implementation into: 1. A core line-parsing state machine that handles indentation, command detection, and line continuation logic (handling backslashes). 2. A higher-level extractor that processes whole scripts and returns structured `OracleInvocation` objects, including edge case handling for comments or quoting.",
        "updatedAt": "2026-01-02T18:14:10.000Z"
      },
      {
        "id": 3,
        "title": "Upgrade Flag Injection to Support Multi-line Commands",
        "description": "Refactor the existing flag injection logic to safely insert flags into multi-line `oracle` commands without breaking shell syntax.",
        "details": "Modify `internal/exec/inject.go` (or create a new version if preferred). The `InjectFlags` function should use the logic from the scanner to locate the insertion point. For multi-line commands (ending with `\\`), inject flags before the backslash on the first line or append to the argument list in a way that preserves valid shell syntax. Ensure it still handles single-line commands correctly. This replaces the naive line-replacement approach.\n\n[2026-01-02] Implemented multi-line flag injection: insert flags after oracle token, preserve indentation, handle continuation backslashes, and skip commented lines. Updated inject tests for multiline and comment cases. go test ./internal/exec passes.",
        "testStrategy": "Enhance `inject_test.go`. specific cases: `oracle \\` -> `oracle --flag \\`, `  oracle arg \\` -> `  oracle --flag arg \\`. Verify syntax validity.",
        "priority": "high",
        "dependencies": [
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Establish Injection Test Suite",
            "description": "Create a comprehensive test suite in `inject_test.go` covering target scenarios.",
            "dependencies": [],
            "details": "Define a table-driven test structure with cases for: simple single-line commands, multi-line commands with backslash continuations, indented commands, and commands with existing arguments. These tests should currently fail or define the expected behavior for the TDD process.",
            "status": "pending",
            "testStrategy": "Create `inject_test.go` ensuring it compiles and fails on the new logic requirements.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Insertion Point Logic",
            "description": "Develop the logic to locate the precise insertion index within the command string.",
            "dependencies": [
              1
            ],
            "details": "Modify `internal/exec/inject.go` to analyze the command string. It must identify the end of the `oracle` binary token while skipping leading whitespace. It should distinguish between immediate arguments and line continuation characters (\\) to determine where flags can be safely added.",
            "status": "pending",
            "testStrategy": "Unit tests verifying that the correct index is returned for various command string formats.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Single-Line Injection",
            "description": "Refactor `InjectFlags` to handle standard single-line command strings safely.",
            "dependencies": [
              2
            ],
            "details": "Implement the string manipulation logic for cases without newlines. Ensure that the generated string inserts the provided flags at the determined index with exactly one space of padding on either side, preventing double-spacing issues or concatenated words.",
            "status": "pending",
            "testStrategy": "Run `inject_test.go` focusing on single-line cases like `oracle arg` -> `oracle --flag arg`.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Multi-Line Injection",
            "description": "Extend `InjectFlags` to safely handle commands using backslash line continuations.",
            "dependencies": [
              3
            ],
            "details": "Add logic to detect if the command line ends with a backslash `\\`. The injection routine must insert the flags *before* the backslash on that specific line, ensuring the shell interprets the flags as part of the initial command call without breaking the continuation syntax.",
            "status": "pending",
            "testStrategy": "Run `inject_test.go` focusing on multi-line cases like `oracle \\` -> `oracle --flag \\`.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Finalize Formatting and Edge Cases",
            "description": "Polish the injection logic to handle indentation and irregular whitespace.",
            "dependencies": [
              4
            ],
            "details": "Ensure that if the original command was indented (e.g., inside a shell function), the injection process preserves this indentation. Handle edge cases where multiple spaces exist between `oracle` and the backslash, ensuring the resulting command is syntactically valid bash.",
            "status": "pending",
            "testStrategy": "Pass all tests in `inject_test.go` including indentation and whitespace variation cases.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed.",
        "updatedAt": "2026-01-02T18:03:59.000Z"
      },
      {
        "id": 4,
        "title": "Implement Mode 2 Validation Runner",
        "description": "Create a validation routine that runs `oracle --dry-run summary` to verify that overrides result in valid commands.",
        "details": "Create `internal/exec/oracle_validate.go`. Implement `ValidateOverrides(ctx, ...)` which iterates through targeted steps, extracts oracle invocations using the scanner from Task 2, applies overrides using the model from Task 1, and executes the resulting command with `--dry-run summary`. It should capture specific error output if the command fails. This ensures the user's configuration is valid before execution.\n\n[2026-01-02] Added validation runner in internal/exec/oracle_validate.go with ValidationError struct, dry-run execution, PATH export, and tests in internal/exec/oracle_validate_test.go. go test ./internal/exec ./internal/overrides passes.",
        "testStrategy": "Integration tests mocking the `oracle` binary (e.g., using a helper script in `testdata` that checks for `--dry-run` arg). Verify that it returns specific errors for invalid flags.",
        "priority": "high",
        "dependencies": [
          "1",
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold Validation Interface and Types",
            "description": "Define the function signature and result structures for the validation runner in a new file.",
            "dependencies": [],
            "details": "Create `internal/exec/oracle_validate.go`. Define the public function `ValidateOverrides(ctx context.Context, steps []model.Step, overrides model.Overrides) ([]ValidationError, error)`. Define the `ValidationError` struct to hold StepID, Command, and ErrorMessage. This establishes the contract for the validation logic.",
            "status": "pending",
            "testStrategy": "None (structural setup only)",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Step Iteration and Command Preparation",
            "description": "Implement the logic to loop through targeted steps and prepare the oracle commands for validation.",
            "dependencies": [
              1
            ],
            "details": "In `ValidateOverrides`, iterate through the provided steps. call `oracle_scan.ExtractOracleInvocations` (from Task 2) to get the raw command. Apply the overrides (from the model) to construct the temporary command string that includes the new flags. This step ensures we have the exact string that needs testing.",
            "status": "pending",
            "testStrategy": "Unit test verifying that the correct number of commands are prepared from a given set of steps and overrides.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Dry-Run Execution Logic",
            "description": "Create the helper function to execute the constructed command with the dry-run flag.",
            "dependencies": [
              1
            ],
            "details": "Implement a private function, e.g., `execDryRun(ctx, command string) (string, error)`. This should parse the command string, append the `--dry-run summary` argument, and execute it using `os/exec`. It must capture both Stdout and Stderr to return distinct failure reasons if the process exits with a non-zero code.",
            "status": "pending",
            "testStrategy": "Unit test with a simple echo command to verify arguments are appended and output is captured.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Error Parsing and Result Aggregation",
            "description": "Connect the execution logic to the iteration loop and handle failure scenarios.",
            "dependencies": [
              2,
              3
            ],
            "details": "Call `execDryRun` within the iteration loop from Subtask 2. If the command fails, extract the relevant error message from Stderr, populate a `ValidationError` struct with the Step ID, and append it to the results slice. Ensure the loop continues to validate remaining steps even if one fails.",
            "status": "pending",
            "testStrategy": "Unit test simulating mixed results (some pass, some fail) to ensure aggregation works correctly.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create Integration Tests with Mock Oracle",
            "description": "Verify the full validation flow using a mock script to simulate the oracle binary.",
            "dependencies": [
              4
            ],
            "details": "Create `internal/exec/oracle_validate_test.go`. Use `GO_EXEC_TEST` pattern or a shell script in `testdata` that acts as the `oracle` binary. It should return exit code 0 when `--dry-run` is present and valid flags are used, and exit code 1 with an error message for specific 'invalid' flags. Verify `ValidateOverrides` correctly identifies these failures.",
            "status": "pending",
            "testStrategy": "Integration test using a mock executable to simulate external process behavior.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed.",
        "updatedAt": "2026-01-02T18:18:21.000Z"
      },
      {
        "id": 5,
        "title": "Implement TUI State Machine for Overrides Flow",
        "description": "Scaffold the Bubble Tea model for the overrides wizard, managing transitions between main screen and overrides sub-screens.",
        "details": "In `internal/tui/overrides_flow.go`, define a `Model` that wraps the specific sub-models (picker, url, confirm). Define messages `OverridesStartedMsg`, `OverridesAppliedMsg`, `OverridesCancelledMsg`. Implement the `Update` loop to handle switching between steps: Flags -> Steps -> URL -> Confirm. Integrate this as a new state in the main `internal/tui/tui.go` model.\n\n[2026-01-02] Added overrides flow scaffold (internal/tui/overrides_flow.go) with steps, messages, and basic navigation. Integrated into main TUI with ViewOverrides state and key 'o' to start; handles apply/cancel transitions. go test ./internal/tui passes.",
        "testStrategy": "Unit/Model tests verifying state transitions (e.g., sending `NextMsg` moves from Flags to Steps).",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Overrides Flow Model and Message Types",
            "description": "Scaffold the basic structures and message types required for the overrides wizard in the TUI.",
            "dependencies": [],
            "details": "Create `internal/tui/overrides_flow.go`. Define a `Model` struct that includes fields to track the current wizard step (e.g., Flags, Steps, URL, Confirm) and placeholders for sub-models. Define the Bubble Tea messages: `OverridesStartedMsg`, `OverridesAppliedMsg` (which should include the final configuration), and `OverridesCancelledMsg`.",
            "status": "pending",
            "testStrategy": "Unit tests ensuring the Model initializes correctly and messages are defined with appropriate payloads.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Navigation Logic and Update Loop",
            "description": "Develop the state machine logic to handle transitions between the different steps of the overrides wizard.",
            "dependencies": [
              1
            ],
            "details": "In `internal/tui/overrides_flow.go`, implement the `Update` method. Handle specific key bindings (e.g., Enter/Tab for Next, Esc for Back) to modify the state variable. Ensure the `View` method switches rendering based on the active step (Flags -> Steps -> URL -> Confirm).",
            "status": "pending",
            "testStrategy": "Write model tests that simulate key presses and assert that the model state transitions from one step to the next correctly.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Overrides Flow into Main Application",
            "description": "Connect the independent overrides flow into the main application loop to enable user access.",
            "dependencies": [
              2
            ],
            "details": "Update `internal/tui/tui.go` to include the `OverridesFlow` model. Modify the root `Update` function to listen for `OverridesStartedMsg` to switch the view to the wizard, and handle `OverridesAppliedMsg` or `OverridesCancelledMsg` to return focus to the main dashboard.",
            "status": "pending",
            "testStrategy": "Manual verification or integration tests to confirm that triggering the flow switches the UI context and completing it returns to the main screen.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Split this into: 1. Defining the message types and the top-level parent model for the overrides flow. 2. Implementing the navigation logic (Next/Back transitions) and state management between sub-screens. 3. Integrating this new flow into the existing `internal/tui/tui.go` main loop without regressing current functionality.",
        "updatedAt": "2026-01-02T18:20:00.000Z"
      },
      {
        "id": 6,
        "title": "Develop Multi-select Flags Picker UI",
        "description": "Build a TUI component to allow users to select/deselect common oracle flags.",
        "details": "Create `internal/tui/overrides_flags.go`. Use `github.com/charmbracelet/bubbles/list` or a custom component. It should display a curated list of flags (e.g., `--debug`, `--json`). Allow multi-selection. Visually distinguish between baseline flags (pre-selected/immutable context) and override flags. Store selection in the `RuntimeOverrides` model.\n\n[2026-01-02] Added flags picker component in internal/tui/overrides_flags.go with multi-select, baseline handling, and custom delegate. Integrated into overrides flow flags step view. go test ./internal/tui passes.",
        "testStrategy": "Manual visual testing + Unit tests for the list selection logic (toggling items updates the model correctly).",
        "priority": "medium",
        "dependencies": [
          "5"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold Flags Picker Component",
            "description": "Initialize the Bubble Tea component for the flags picker using the bubbles/list library.",
            "dependencies": [],
            "details": "Create `internal/tui/overrides_flags.go`. Define a `FlagsPickerModel` struct that embeds `list.Model`. Implement the standard `Init`, `Update`, and `View` methods. Initialize the list with a default width and height in a constructor function `NewFlagsPicker`. Ensure imports for `github.com/charmbracelet/bubbles/list` are correct.",
            "status": "pending",
            "testStrategy": "Verify the component compiles and renders an empty list in a standalone main harness.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Define Flag Items and Data Source",
            "description": "Create the data structures for list items and populate the curated list of oracle flags.",
            "dependencies": [
              1
            ],
            "details": "Define a `FlagItem` struct that implements `list.Item` (FilterValue, Title, Description). Include fields for `Flag` (string), `Description` (string), and `IsBaseline` (bool). Populate a slice of these items with common flags like `--debug`, `--json`, `--no-color`. The constructor should accept a `baseline []string` argument to mark matching flags as `IsBaseline = true`.",
            "status": "pending",
            "testStrategy": "Unit test to ensure baseline flags passed to the constructor are correctly marked as `IsBaseline` in the generated items list.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Multi-selection Toggling Logic",
            "description": "Add logic to handle key events for selecting and deselecting flags within the list.",
            "dependencies": [
              2
            ],
            "details": "In the `Update` method, intercept the `Space` key event. If the currently selected item is NOT a baseline flag (immutable), toggle a boolean state indicating selection. Maintain a map or slice within the model to track which non-baseline flags are currently active.",
            "status": "pending",
            "testStrategy": "Unit test the Update loop: send a KeyMsg(Space) and assert the item's selection state changes appropriately.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Customize Delegate for Visual Status",
            "description": "Create a custom list delegate to visually distinguish selected, unselected, and baseline flags.",
            "dependencies": [
              3
            ],
            "details": "Implement a custom `list.ItemDelegate`. The `Render` method should display a checkbox `[x]` for selected items and `[ ]` for unselected ones. For baseline flags, use a distinct visual indicator (e.g., a lock icon or dimmed color) to show they are active but immutable.",
            "status": "pending",
            "testStrategy": "Manual visual verification to ensure selected items and locked baseline items are rendered with distinct styles.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Connect to RuntimeOverrides Model",
            "description": "Implement the state export logic to update the shared RuntimeOverrides struct.",
            "dependencies": [
              3
            ],
            "details": "Add a method `GetSelectedFlags() []string` or a message handler that triggers on confirmation (Enter key). This logic should filter the list for all selected override flags (excluding baseline ones, or managing them based on the `RuntimeOverrides` requirements) and prepare them for the shared state model.",
            "status": "pending",
            "testStrategy": "Unit test calling the export method after modifying selection state to verify it returns the correct list of strings.",
            "parentId": "undefined"
          }
        ],
        "complexity": 4,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed.",
        "updatedAt": "2026-01-02T18:22:11.000Z"
      },
      {
        "id": 7,
        "title": "Develop Step Targeting and URL Input UI",
        "description": "Build TUI components for selecting target steps and entering the ChatGPT Project URL.",
        "details": "Create `internal/tui/overrides_steps.go` (list of steps from the pack, multi-select) and `internal/tui/overrides_url.go` (text input using `bubbles/textinput`). The step picker defaults to 'all selected'. The URL input validates simple URL format. Both update the shared `RuntimeOverrides` state.\n\n[2026-01-02] Added steps picker and URL input components (internal/tui/overrides_steps.go, internal/tui/overrides_url.go) and integrated into overrides flow with basic validation and navigation. Updated flow constructor to accept pack steps. go test ./internal/tui passes.",
        "testStrategy": "Unit tests for the component models. Verify text input validation and list selection state persistence.",
        "priority": "medium",
        "dependencies": [
          "5"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define TUI Model State for URL and Step Inputs",
            "description": "Extend the main TUI model to include state fields for the URL input and step selection components.",
            "dependencies": [],
            "details": "Modify the TUI model struct (likely in `internal/tui/model.go`) to hold a `bubbles/textinput` model for the URL and a list model for steps. Ensure there are methods or fields to pass the available steps from the execution pack into the TUI initialization phase.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement URL Input Component with Validation",
            "description": "Create the text input component for entering the ChatGPT Project URL, including basic format validation.",
            "dependencies": [
              1
            ],
            "details": "Create `internal/tui/overrides_url.go`. Initialize a `textinput.Model` with appropriate placeholder text. Implement a validation function that ensures the input starts with 'http://' or 'https://'. Expose an Update/View method compatible with the Bubble Tea runtime.",
            "status": "pending",
            "testStrategy": "Unit test the validation logic in `overrides_url_test.go` to ensure malformed URLs are flagged.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Step Selection List Component",
            "description": "Build the multi-select list component to toggle which steps the overrides apply to.",
            "dependencies": [
              1
            ],
            "details": "Create `internal/tui/overrides_steps.go`. Use a custom model or `bubbles/list` to display steps. Maintain a `map[string]bool` or slice for selection state. Implement logic to default all steps to 'selected' upon initialization. Include visual indicators (e.g., [x] vs [ ]) for selection status.",
            "status": "pending",
            "testStrategy": "Unit test the toggle logic ensuring the underlying selection map updates correctly when items are selected/deselected.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate Components into Main TUI Update Loop",
            "description": "Wire the new components into the main application loop to handle focus and state updates.",
            "dependencies": [
              2,
              3
            ],
            "details": "Update the main `Update` function to route key messages to the URL input or Step list when they are focused. Implement navigation logic (e.g., Tab to switch between inputs). Ensure that changes in these components propagate to the shared `RuntimeOverrides` data structure defined in Task 1.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Finalize View Rendering and Visual Testing",
            "description": "Combine the component views into the main UI layout and verify visual correctness.",
            "dependencies": [
              4
            ],
            "details": "Update the main `View` function to render the URL input and Step list alongside existing components. Apply styles to indicate focus. Perform manual verification to ensure the URL input accepts text and the step list toggles visually respond to user input.",
            "status": "pending",
            "testStrategy": "Manual verification by running the TUI and cycling through inputs.",
            "parentId": "undefined"
          }
        ],
        "complexity": 4,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed.",
        "updatedAt": "2026-01-02T18:24:41.000Z"
      },
      {
        "id": 8,
        "title": "Implement Confirmation Screen with Validation Trigger",
        "description": "Build the final summary screen that shows the diff and runs the validation logic before applying.",
        "details": "Create `internal/tui/overrides_confirm.go`. Display a summary of Added/Removed flags, URL, and count of targeted steps. On confirm key press (e.g., 'Enter'), trigger the validation runner (Task 4) via a `Cmd`. If validation fails, display the error (Step ID + Output) and allow retry. If success, return `OverridesAppliedMsg`.\n\n[2026-01-02] Added confirmation view and validation flow (internal/tui/overrides_confirm.go) with validation cmd, error handling, and OverridesAppliedMsg payload. Integrated confirm step into overrides flow and stored applied overrides in main model. go test ./internal/tui passes.",
        "testStrategy": "Mock the validation runner in tests to simulate pass/fail scenarios and verify the UI response (error message vs state transition).",
        "priority": "high",
        "dependencies": [
          "4",
          "5",
          "6",
          "7"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Overrides Confirmation View",
            "description": "Implement the read-only UI component that summarizes the proposed changes before execution.",
            "dependencies": [],
            "details": "Create `internal/tui/overrides_confirm.go` and define the model struct. Implement the `View()` method to render a clear summary of the overrides: list added/removed flags (using color coding for diffs), show the target URL, and display the count of targeted steps. Ensure the layout clearly separates configuration data from the 'Press Enter to Confirm' prompt.",
            "status": "pending",
            "testStrategy": "Visual verification or snapshot testing of the View output using a Bubble Tea test harness with mock override data.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Validation Command and State Management",
            "description": "Add the asynchronous logic to trigger validation on confirmation and handle the resulting states.",
            "dependencies": [
              1
            ],
            "details": "Update `internal/tui/overrides_confirm.go` to handle the 'Enter' key event. Return a `tea.Cmd` that executes the validation runner (Task 4). Implement a loading state (e.g., a spinner) in the view while validation is pending. Process the resulting message: if validation fails, display the specific error (Step ID + Output) and allow the user to retry; if successful, return `OverridesAppliedMsg` to proceed.",
            "status": "pending",
            "testStrategy": "Unit tests for the `Update` function, mocking the validation command response to verify transitions between loading, error, and success states.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 2,
        "expansionPrompt": "Divide into: 1. Building the read-only summary view (Diff UI) that renders the proposed changes clearly. 2. Implementing the async command triggering for validation, handling the loading state (spinner), and processing the success/failure messages to either block or allow the final apply action.",
        "updatedAt": "2026-01-02T18:27:40.000Z"
      },
      {
        "id": 9,
        "title": "Integrate Overrides into Execution Engine",
        "description": "Wire the runtime overrides into the actual step execution logic in the runner.",
        "details": "Modify `internal/app/app.go` or `internal/runner/runner.go` (where `RunStep` is called). The runner needs access to the `RuntimeOverrides` object. Inside the execution loop, before running a step script, call `overrides.EffectiveFlags(step.ID, baseline)`. Pass these effective flags to `InjectFlags` (Task 3). Ensure non-targeted steps run as normal.\n\n[2026-01-02] Integrated RuntimeOverrides into exec.Runner and RunStep (effective flags per step). Wired OverridesAppliedMsg to set runner overrides in TUI. go test ./internal/exec ./internal/tui passes.",
        "testStrategy": "E2E/Integration test: Run a dummy pack with overrides enabled. Verify via logs or output that the `oracle` command received the extra flags only on targeted steps.",
        "priority": "high",
        "dependencies": [
          "3",
          "8"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Update Runner Configuration to Support Runtime Overrides",
            "description": "Refactor the runner struct and initialization functions to accept and store the RuntimeOverrides configuration object.",
            "dependencies": [],
            "details": "Modify `internal/runner/runner.go` to add a field `Overrides *overrides.RuntimeOverrides` to the Runner struct. Update the `NewRunner` constructor and the call site in `internal/app/app.go` to pass this configuration object down from the application context. Ensure the runner handles nil overrides gracefully.",
            "status": "pending",
            "testStrategy": "Unit test ensuring the runner initializes correctly with and without overrides provided.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Effective Flag Resolution in Execution Loop",
            "description": "Update the step iteration loop to calculate effective flags for the current step based on the overrides configuration.",
            "dependencies": [
              1
            ],
            "details": "Inside the main execution loop in `internal/runner/runner.go`, locate the point before a step is executed. Insert logic to call `r.Overrides.EffectiveFlags(step.ID, baselineFlags)` using the logic from Task 1. This prepares the specific flags needed for the current step ID.",
            "status": "pending",
            "testStrategy": "Unit test mocking the Overrides object to verify `EffectiveFlags` is called with the correct Step ID during iteration.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Apply Flag Injection and Execute Modified Command",
            "description": "Integrate the flag injection utility to modify the command string with the resolved effective flags and ensure correct execution.",
            "dependencies": [
              2
            ],
            "details": "Take the resolved flags from the previous subtask and pass them to `exec.InjectFlags` (from Task 3) along with the original step script. Replace the command execution payload with this modified string. Add logging to indicate when a command has been altered by overrides.",
            "status": "pending",
            "testStrategy": "Integration test using a mock executor to verify that the final command string passed to the shell contains the injected flags.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down into: 1. Refactoring the Runner signature/struct to accept the `RuntimeOverrides` configuration. 2. Modifying the step execution loop to resolve `EffectiveFlags` dynamically for every step. 3. Integrating the injection logic (Task 3) safely into the command preparation phase, ensuring logging and error handling cover the modified commands.",
        "updatedAt": "2026-01-02T18:29:02.000Z"
      },
      {
        "id": 10,
        "title": "Add Main Screen Indicators and Final Polish",
        "description": "Update the main run screen to indicate when overrides are active to prevent user confusion.",
        "details": "In `internal/tui/tui.go`, checking `OverridesAppliedMsg` to update the main model state. Render a small status bar or badge (e.g., \"Overrides Active: +2 flags\") on the main view. Ensure the keybinding to open the overrides flow is visible in the help footer.\n\n[2026-01-02] Added overrides status indicator in main view, updated help text, and cleared overrides on cancel/reset. go test ./internal/tui passes.",
        "testStrategy": "Visual verification. Ensure the indicator appears after applying overrides and disappears if they are cleared/reset.",
        "priority": "low",
        "dependencies": [
          "5",
          "9"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Update Main Model to Store Override State",
            "description": "Modify the main application model to persist the configuration of applied overrides received from the wizard flow.",
            "dependencies": [],
            "details": "In `internal/tui/tui.go`, update the main `Model` struct to include fields for active overrides (e.g., `overrideSummary string` or `activeOverrideCount int`). Implement the `Update` method case for `OverridesAppliedMsg` to populate these fields based on the message payload.",
            "status": "pending",
            "testStrategy": "Unit test the `Update` function to ensure state changes correctly upon receiving `OverridesAppliedMsg`.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Overrides Active Badge Component",
            "description": "Create a styled UI component that renders a visual indicator when overrides are active to alert the user.",
            "dependencies": [
              1
            ],
            "details": "Define a `lipgloss` style for a status badge (e.g., yellow text or background). In the main `View` function, conditionally render this badge (e.g., \"Overrides Active: +2 flags\") only if the model's override state is non-empty/non-zero.",
            "status": "pending",
            "testStrategy": "Visual verification using a Golden file test or manual inspection to ensure the badge appears only when state is set.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Update Keybindings and Help Footer",
            "description": "Ensure the keybinding to open the overrides configuration is registered and visible in the help bubble.",
            "dependencies": [],
            "details": "Update the `KeyMap` in `internal/tui/keys.go` (or equivalent) to include the Overrides trigger (e.g., 'o'). Add this key to the `ShortHelp` and `FullHelp` return values so the Bubble Tea help component renders it in the footer.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Handle Overrides Reset and Cancellation",
            "description": "Implement logic to clear the visual indicator if the user cancels or resets the overrides during the session.",
            "dependencies": [
              1
            ],
            "details": "In `internal/tui/tui.go`, handle `OverridesCancelledMsg` or a specific clear signal. Ensure the model resets the override summary/count fields to zero/nil, causing the UI badge to disappear in the next render cycle.",
            "status": "pending",
            "testStrategy": "Unit test sending a cancellation/reset message and asserting the model state returns to empty.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Apply Final Visual Polish and Layout Integration",
            "description": "Fine-tune the layout and colors of the indicator to ensure it fits the theme and does not break existing UI elements.",
            "dependencies": [
              2,
              3
            ],
            "details": "Adjust margins and padding for the new badge component. Ensure it displays correctly in the header or status bar area without overlapping with the progress bar or log output view. Apply theme-consistent colors.",
            "status": "pending",
            "testStrategy": "Manual visual regression testing with various window sizes.",
            "parentId": "undefined"
          }
        ],
        "complexity": 2,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed.",
        "updatedAt": "2026-01-02T18:31:12.000Z"
      },
      {
        "id": 11,
        "title": "Post-implementation improvements",
        "description": "Capture follow-up improvements identified after overrides wizard work.",
        "details": "Improvements list:\\n- Add persistent help bar on main screen (outside viewport) for key shortcuts.\\n- Overrides confirm: show effective oracle flags + summarize validation errors (count/list).\\n- Clipboard fallback: write temp file on copy failure and notify.\\n- ROI filter persistence: save ROI mode/threshold on toggle + load on start.\\n- Add tests for URL picker, step preview, ROI persistence.\\n- Any other UI polish discovered during scan.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-01-02T22:30:18.523Z"
      },
      {
        "id": 12,
        "title": "Integrate Glow Markdown Rendering for TUI Viewport",
        "description": "Implement a width-aware Markdown rendering utility using Glamour and integrate it into the Bubble Tea viewport to display formatted content.",
        "details": "1. Create a new package `internal/render` and implement `RenderMarkdown(text string, width int, style string) (string, error)`. Use `github.com/charmbracelet/glamour` as the underlying engine. \n2. Configure Glamour to use a standard terminal style (e.g., 'dark' or 'light' based on TUI defaults) while ensuring the `glamour.WithWordWrap(width)` option is utilized to handle the viewport's dynamic sizing. \n3. In `internal/tui/tui.go`, modify the `Update` function to trigger a re-render of the current selection's description whenever a `tea.WindowSizeMsg` is received or the cursor selection changes. \n4. Update the viewport content using `viewport.SetContent()` with the output from the `render` package. \n5. Ensure the renderer is strictly a library call; do not invoke the Glow binary or TUI program directly. \n6. Handle potential rendering errors by falling back to raw text display to ensure the TUI remains functional.",
        "testStrategy": "1. Unit Tests: Create `internal/render/markdown_test.go` to verify that `RenderMarkdown` correctly wraps text at specific widths and handles various Markdown elements (headers, lists, code blocks). \n2. Manual TUI Verification: Run the application and navigate between steps. Verify that Markdown styling is applied. \n3. Resize Testing: Drag the terminal window to different sizes and ensure the text in the viewport re-wraps and re-renders correctly without clipping. \n4. Edge Case: Provide empty strings or malformed Markdown to the renderer and verify the system handles it gracefully.",
        "status": "done",
        "dependencies": [
          "5",
          "10",
          "11"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-01-04T09:14:17.791Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-01-04T09:14:17.792Z",
      "taskCount": 12,
      "completedCount": 12,
      "tags": [
        "bugfix-tui"
      ],
      "created": "2026-01-08T01:17:51.784Z",
      "description": "Tasks for bugfix-tui context",
      "updated": "2026-01-08T01:17:51.784Z"
    }
  },
  "feat-mcp": {
    "tasks": [
      {
        "id": "1",
        "title": "Initialize Project Structure and Environment Configuration",
        "description": "Set up the oraclepack-mcp-server directory structure and implement the configuration loader for environment variables.",
        "details": "Create the project structure: `oraclepack_mcp_server/` package, `requirements.txt`, and `README.md`. Implement `config.py` using `pydantic-settings` or a similar pattern to load: `ORACLEPACK_BIN`, `ORACLEPACK_ALLOWED_ROOTS` (comma-separated list), `ORACLEPACK_ENABLE_EXEC` (bool), `ORACLEPACK_MAX_READ_BYTES` (default 64KB), and `ORACLEPACK_MAX_OUTPUT_CHARS` (default 32000). Ensure the config loader handles defaults according to the PRD.",
        "testStrategy": "Unit test the configuration loader to verify environment variables are correctly mapped to internal settings and defaults are applied when variables are missing.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold Project Directory and Metadata Files",
            "description": "Initialize the base project structure including the main package directory and initial README.",
            "dependencies": [],
            "details": "Create the root directory 'oraclepack-mcp-server', the python package directory 'oraclepack_mcp_server/', an empty '__init__.py', and a 'README.md' documenting the purpose of the server.",
            "status": "done",
            "testStrategy": "Verify directory structure exists using 'ls -R' and ensure README.md is present.",
            "updatedAt": "2026-01-08T01:25:12.977Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Define Project Dependencies and Requirements",
            "description": "Create the requirements.txt file with all necessary libraries for the MCP server and configuration management.",
            "dependencies": [
              1
            ],
            "details": "Include 'pydantic-settings', 'mcp', and 'pytest' in 'requirements.txt'. Ensure versions are pinned or compatible with the target environment.",
            "status": "done",
            "testStrategy": "Run 'pip install -r requirements.txt' in a virtual environment to ensure all dependencies resolve without conflict.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:25:19.087Z"
          },
          {
            "id": 3,
            "title": "Implement Base Configuration Model with Pydantic",
            "description": "Create oraclepack_mcp_server/config.py using pydantic-settings to manage environment variables.",
            "dependencies": [
              2
            ],
            "details": "Define a 'Settings' class that inherits from 'BaseSettings'. Map the variables: ORACLEPACK_BIN, ORACLEPACK_ALLOWED_ROOTS, ORACLEPACK_ENABLE_EXEC, ORACLEPACK_MAX_READ_BYTES, and ORACLEPACK_MAX_OUTPUT_CHARS.",
            "status": "done",
            "testStrategy": "Instantiate the Settings class in a script and print the default values to ensure they match the PRD requirements.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:25:36.703Z"
          },
          {
            "id": 4,
            "title": "Configure Type Parsing and Default Values",
            "description": "Implement specific parsing logic for list and boolean environment variables in config.py.",
            "dependencies": [
              3
            ],
            "details": "Ensure ORACLEPACK_ALLOWED_ROOTS handles comma-separated strings into a list of strings/paths. Set defaults: MAX_READ_BYTES to 65536 and MAX_OUTPUT_CHARS to 32000. Set 'env_prefix' to '' if needed.",
            "status": "done",
            "testStrategy": "Manually set environment variables like 'ORACLEPACK_ALLOWED_ROOTS=/tmp,/var' and verify the loaded model contains a list of two items.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:25:36.708Z"
          },
          {
            "id": 5,
            "title": "Develop Configuration Unit Test Suite",
            "description": "Create a test suite to validate the environment configuration loader.",
            "dependencies": [
              4
            ],
            "details": "Create 'tests/test_config.py'. Write tests to check default value assignment and ensure that providing environment variables correctly overrides the defaults. Test the parsing of the comma-separated roots.",
            "status": "done",
            "testStrategy": "Run 'pytest tests/test_config.py' and ensure all assertions for value mapping and type conversion pass.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:26:18.788Z"
          }
        ],
        "updatedAt": "2026-01-08T01:26:18.788Z"
      },
      {
        "id": "2",
        "title": "Implement Security and Path Resolution Service",
        "description": "Develop the security module to handle path validation and execution gating.",
        "details": "Implement `security.py`. Create a `validate_path` function that resolves paths and ensures they reside within `ORACLEPACK_ALLOWED_ROOTS` using `pathlib.Path.resolve()` and `os.path.commonpath`. Implement an `is_exec_enabled` check that strictly evaluates `ORACLEPACK_ENABLE_EXEC`. Logic must reject any path escaping the allowed roots with a clear error.",
        "testStrategy": "Test `validate_path` with relative paths, symlinks (if applicable), and paths outside the allowed roots. Verify that `is_exec_enabled` reflects the boolean state of the environment flag.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize security module and configuration loading",
            "description": "Create the security.py module and implement configuration retrieval for security settings.",
            "dependencies": [],
            "details": "Create 'src/oraclepack/security.py'. Implement logic to parse 'ORACLEPACK_ALLOWED_ROOTS' from the environment as a list of absolute paths. Ensure 'ORACLEPACK_ENABLE_EXEC' is correctly interpreted as a boolean value.",
            "status": "done",
            "testStrategy": "Verify that environment variables are correctly parsed into internal constants within the security module.",
            "updatedAt": "2026-01-08T01:27:27.798Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement execution gating logic",
            "description": "Develop the is_exec_enabled function to control access to execution features.",
            "dependencies": [
              1
            ],
            "details": "Implement 'is_exec_enabled()' in 'security.py'. This function should return the boolean state of 'ORACLEPACK_ENABLE_EXEC'. It must strictly evaluate the setting to prevent unauthorized subprocess execution.",
            "status": "done",
            "testStrategy": "Unit test is_exec_enabled with various environment configurations (True, False, unset).",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:27:27.803Z"
          },
          {
            "id": 3,
            "title": "Implement secure path resolution and validation",
            "description": "Develop the validate_path function using pathlib and os.path.commonpath for root enforcement.",
            "dependencies": [
              1
            ],
            "details": "Implement 'validate_path(user_path: str) -> Path'. Use 'pathlib.Path(user_path).resolve()' to obtain the absolute path. Compare this resolved path against the list of 'ORACLEPACK_ALLOWED_ROOTS' using 'os.path.commonpath' to ensure no path traversal or root escapes occur.",
            "status": "done",
            "testStrategy": "Test with valid internal paths, relative paths, and paths attempting traversal (e.g., ../../etc/passwd).",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:27:27.808Z"
          },
          {
            "id": 4,
            "title": "Implement security exception handling",
            "description": "Define and integrate custom security exceptions for path and execution violations.",
            "dependencies": [
              3
            ],
            "details": "Define a 'SecurityError' exception class. Update 'validate_path' to raise this exception with a clear, descriptive message when a path is found outside the allowed roots. Ensure messages do not leak sensitive system structure.",
            "status": "done",
            "testStrategy": "Assert that SecurityError is raised when providing paths outside the defined ORACLEPACK_ALLOWED_ROOTS.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:27:27.812Z"
          },
          {
            "id": 5,
            "title": "Create comprehensive security test suite",
            "description": "Develop a dedicated test file to verify all security constraints and edge cases.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Create 'tests/test_security.py'. Include test cases for symlink resolution, multiple allowed roots, empty root lists, and the interaction between relative paths and the current working directory in 'validate_path'.",
            "status": "done",
            "testStrategy": "Execute pytest on the new test file and ensure 100% coverage of security logic branches.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:27:27.816Z"
          }
        ],
        "updatedAt": "2026-01-08T01:27:27.816Z"
      },
      {
        "id": "3",
        "title": "Develop Oraclepack CLI Async Subprocess Wrapper",
        "description": "Create a robust wrapper for calling the oraclepack CLI with timeout and truncation handling.",
        "details": "Implement `oraclepack_cli.py`. Use `asyncio.create_subprocess_exec` to run the `oraclepack` binary. Capture stdout/stderr. Implement character-based truncation logic for tool outputs based on `ORACLEPACK_MAX_OUTPUT_CHARS`. Handle timeouts by returning exit code 124. The runner should return a structured object: `{ok, exit_code, duration_s, stdout, stderr, stdout_truncated, stderr_truncated}`.",
        "testStrategy": "Mock the subprocess call to test truncation logic, timeout handling (using `asyncio.wait_for`), and successful capture of exit codes/output.",
        "priority": "high",
        "dependencies": [
          "1",
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define OraclepackResult Dataclass and Config Constants",
            "description": "Create the data structure for the CLI output and initialize configuration from environment variables.",
            "dependencies": [],
            "details": "In oraclepack_cli.py, define a dataclass 'OraclepackResult' with fields: ok (bool), exit_code (int), duration_s (float), stdout (str), stderr (str), stdout_truncated (bool), and stderr_truncated (bool). Load 'ORACLEPACK_MAX_OUTPUT_CHARS' from the environment with a sensible default.",
            "status": "done",
            "testStrategy": "Verify that the dataclass can be instantiated and environment variables are correctly read using unit tests.",
            "updatedAt": "2026-01-08T01:28:32.443Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Output Truncation Logic",
            "description": "Develop a helper function to truncate stdout/stderr based on character limits.",
            "dependencies": [
              1
            ],
            "details": "Implement a helper function that takes a string and the max character limit. It should return a tuple of (truncated_string, was_truncated_bool). This logic will be applied to both stdout and stderr independently to ensure compliance with ORACLEPACK_MAX_OUTPUT_CHARS.",
            "status": "done",
            "testStrategy": "Unit test the truncation function with strings smaller than, equal to, and larger than the character limit.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:28:32.448Z"
          },
          {
            "id": 3,
            "title": "Implement Async Subprocess Execution Core",
            "description": "Create the core runner using asyncio.create_subprocess_exec.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement the async function 'run_oraclepack_cli' that accepts a list of arguments. Use 'asyncio.create_subprocess_exec' with 'stdout=asyncio.subprocess.PIPE' and 'stderr=asyncio.subprocess.PIPE'. Capture the raw bytes and decode them using UTF-8 (handling errors gracefully).",
            "status": "done",
            "testStrategy": "Execute a simple command like 'echo' and verify that output is captured and decoded correctly.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:28:32.452Z"
          },
          {
            "id": 4,
            "title": "Add Timeout Handling and Execution Timing",
            "description": "Integrate duration tracking and timeout logic using asyncio.wait_for.",
            "dependencies": [
              3
            ],
            "details": "Wrap the subprocess execution in 'asyncio.wait_for' using a configurable timeout. Use 'time.perf_counter()' to calculate 'duration_s'. If a 'TimeoutError' occurs, ensure the process is terminated and return an 'OraclepackResult' with 'exit_code' 124 and 'ok' set to False.",
            "status": "done",
            "testStrategy": "Test with a mock subprocess that sleeps longer than the timeout to verify 'exit_code' 124 and proper cleanup.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:28:32.456Z"
          },
          {
            "id": 5,
            "title": "Integrate Result Construction and Error Mapping",
            "description": "Finalize the 'run_oraclepack_cli' function to return the structured result object.",
            "dependencies": [
              4
            ],
            "details": "Combine the captured exit code, timed duration, and truncated outputs into the 'OraclepackResult' object. Ensure 'ok' is True only if 'exit_code' is 0. Ensure all exceptions (like FileNotFoundError if the binary is missing) are caught and mapped to a failed 'OraclepackResult'.",
            "status": "done",
            "testStrategy": "Comprehensive unit tests using 'unittest.mock' to simulate various exit codes and output sizes.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:28:32.459Z"
          }
        ],
        "updatedAt": "2026-01-08T01:28:32.459Z"
      },
      {
        "id": "4",
        "title": "Implement Action Pack Validation and Detection Logic",
        "description": "Implement the logic for Stage-2 validation and directory/file detection for Action Packs.",
        "details": "Develop validation logic to enforce exactly one file per prefix `01..20`. Implement detection for 'auto', explicit directory, and explicit file modes. Validation must check for the 'single bash fence' constraint and valid step headers in markdown files. If invalid, return a dictionary containing `missing` and `ambiguous` sets for the prefixes.",
        "testStrategy": "Create a test suite with various directory structures: missing prefixes, multiple files with same prefix, invalid bash fences, and correct structures to verify deterministic results.",
        "priority": "medium",
        "dependencies": [
          "3"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Validation Result Schemas and Constants",
            "description": "Establish the data structures and constants required for Stage-2 validation, including prefix ranges and error reporting structures.",
            "dependencies": [],
            "details": "Create or update a module (e.g., `src/models.py` or `src/validator.py`) to define a `ValidationResult` object. This must include fields for 'missing' and 'ambiguous' sets to track prefixes 01 through 20. Define constants for the supported prefix regex and range limits.",
            "status": "done",
            "testStrategy": "Unit tests to verify that the ValidationResult object correctly handles set operations and serialization.",
            "updatedAt": "2026-01-08T01:29:43.273Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Action Pack Path Detection Logic",
            "description": "Develop the logic to resolve Action Pack locations based on 'auto', explicit directory, and explicit file modes.",
            "dependencies": [
              1
            ],
            "details": "Implement a resolver that: 1. In 'auto' mode, searches the current and parent directories for valid Action Pack structures. 2. In 'directory' mode, validates the contents of a specific path. 3. In 'file' mode, treats a single file as an Action Pack. Ensure integration with the security module's path validation.",
            "status": "done",
            "testStrategy": "Test with various filesystem layouts: single files, nested directories, and missing paths to ensure correct mode selection.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:29:43.278Z"
          },
          {
            "id": 3,
            "title": "Implement Prefix Collision and Gap Detection",
            "description": "Create the scanner that enforces the 'exactly one file per prefix' rule for prefixes 01..20.",
            "dependencies": [
              2
            ],
            "details": "Implement logic to iterate through files in a detected directory, extract numerical prefixes (01-20), and group them. Return prefixes with multiple file matches in the 'ambiguous' set and prefixes with zero matches in the 'missing' set. Ignore files that do not follow the prefix convention.",
            "status": "done",
            "testStrategy": "Provide directories with duplicate prefixes (e.g., 01-a.md and 01-b.md) and skipped prefixes (e.g., 01, 03) to verify set populations.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:29:43.282Z"
          },
          {
            "id": 4,
            "title": "Implement Markdown Content and Step Header Validation",
            "description": "Develop the parser to enforce the 'single bash fence' and valid header constraints within markdown files.",
            "dependencies": [
              3
            ],
            "details": "For each file in the Action Pack, parse the markdown content to ensure it contains exactly one triple-backtick bash code block. Additionally, verify that the file begins with a valid step header (e.g., '# Step XX: Title'). Return specific errors if multiple fences or invalid headers are found.",
            "status": "done",
            "testStrategy": "Unit tests using raw strings of markdown representing valid, multiple-fence, zero-fence, and malformed header scenarios.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:29:43.286Z"
          },
          {
            "id": 5,
            "title": "Integrate Validation Engine and Execute Comprehensive Test Suite",
            "description": "Combine detection, prefix, and content validation into a single workflow and verify against the requirements.",
            "dependencies": [
              4
            ],
            "details": "Expose a main `validate_action_pack` function that orchestrates the previous steps. Implement a full test suite as described in the parent task, covering all edge cases (missing prefixes, ambiguity, invalid fences) to ensure deterministic results as required by the spec.",
            "status": "done",
            "testStrategy": "Integration tests using temporary directories and files to simulate real-world Action Pack structures and verify the final dictionary output.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:29:43.291Z"
          }
        ],
        "updatedAt": "2026-01-08T01:29:43.291Z"
      },
      {
        "id": "5",
        "title": "Implement MCP Server Core and Transports",
        "description": "Set up the MCP server using the Python SDK, supporting both stdio and streamable-http transports.",
        "details": "Implement `server.py` and `__main__.py` using the `mcp` Python library (Anthropic). Support `--transport stdio` and `--transport streamable-http`. For HTTP, implement Origin validation and localhost binding with basic authentication as specified. Ensure `stdio` mode does not interleave logs on stdout by redirecting application logs to stderr.",
        "testStrategy": "Start the server in both modes. Use an MCP inspector or client to verify connection. Test HTTP origin validation by sending requests with unauthorized Origin headers.",
        "priority": "high",
        "dependencies": [
          "1",
          "2",
          "3"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize MCP Server and Configure Stderr Logging",
            "description": "Create the core MCP server instance and set up logging to stderr.",
            "dependencies": [],
            "details": "Initialize `mcp.server.Server` in `oraclepack/server.py`. Configure the Python logging module to direct all logs to `sys.stderr` to prevent interference with the `stdio` transport protocol on `stdout`. Set the server name and version metadata.",
            "status": "done",
            "testStrategy": "Verify that logging output appears in the terminal's stderr while stdout remains empty or reserved for MCP frames.",
            "updatedAt": "2026-01-08T01:31:52.674Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement CLI Argument Parsing in __main__.py",
            "description": "Develop the entry point for the MCP server with support for transport selection.",
            "dependencies": [
              1
            ],
            "details": "Use `argparse` to implement CLI flags: `--transport` (choices: `stdio`, `streamable-http`), `--host`, `--port`, `--auth-token`, and `--allowed-origins`. Ensure the script correctly routes execution to the selected transport handler.",
            "status": "done",
            "testStrategy": "Run the module with various flag combinations and verify correct argument parsing using print/log statements.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:31:52.679Z"
          },
          {
            "id": 3,
            "title": "Implement Stdio Transport Runner",
            "description": "Set up the asynchronous loop for handling MCP communication over standard input/output.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement the logic to run the server using `mcp.server.stdio.stdio_server`. Ensure that the server handles the initialization handshake and gracefully shuts down on EOF or SIGINT.",
            "status": "done",
            "testStrategy": "Use the MCP Inspector or a simple Python client to connect via stdio and verify the 'initialize' request-response cycle.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:31:52.684Z"
          },
          {
            "id": 4,
            "title": "Implement Streamable-HTTP Transport with Security Controls",
            "description": "Develop the HTTP transport layer with Origin validation and basic authentication.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement an SSE-based transport (Server-Sent Events) for the MCP server. Add middleware or logic to validate the 'Origin' header against `--allowed-origins`. Enforce localhost binding by default and implement basic token-based authentication for incoming HTTP connections.",
            "status": "done",
            "testStrategy": "Attempt to connect via HTTP with unauthorized Origin headers or missing auth tokens and verify 403/401 responses. Verify successful connection from allowed origins.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:31:52.689Z"
          },
          {
            "id": 5,
            "title": "Register Tools and Integrate Oraclepack Business Logic",
            "description": "Expose the CLI wrapper and validation logic as MCP tools.",
            "dependencies": [
              3,
              4
            ],
            "details": "Register tools on the server instance using `@server.list_tools()` and `@server.call_tool()`. Map MCP tool calls to the `oraclepack_cli` wrapper (Task 3) and validation services (Task 4). Ensure output truncation and security path checks are applied to all tool executions.",
            "status": "done",
            "testStrategy": "Invoke registered tools via an MCP client and verify that the output matches expected results from the oraclepack CLI, including proper error handling for invalid paths.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:31:52.694Z"
          }
        ],
        "updatedAt": "2026-01-08T01:31:52.694Z"
      },
      {
        "id": "6",
        "title": "Expose Read-Only MCP Tools",
        "description": "Register and implement the read-only tools: oraclepack_list_packs, oraclepack_read_file, and oraclepack_validate.",
        "details": "Annotate tools as 'read-only' in MCP metadata. `oraclepack_read_file` must enforce `ORACLEPACK_MAX_READ_BYTES` and `ORACLEPACK_ALLOWED_ROOTS`. `oraclepack_validate` uses logic from Task 4. Implement response formatters that support Markdown and JSON output with truncation indicators.",
        "testStrategy": "Call each read-only tool via an MCP client. Verify that `oraclepack_read_file` rejects unauthorized paths and truncates large files.",
        "priority": "medium",
        "dependencies": [
          "4",
          "5"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-08T01:32:32.688Z"
      },
      {
        "id": "7",
        "title": "Expose Execution and Taskify MCP Tools",
        "description": "Register and implement destructive tools: oraclepack_run_pack and oraclepack_taskify_run_action_pack.",
        "details": "Annotate tools as destructive/open-world. These tools MUST check `ORACLEPACK_ENABLE_EXEC` before proceeding. Implement `taskify.py` helpers to facilitate action pack execution. The tools should map CLI flags like `--no-tui`, `--out-dir`, and `--oracle-bin` from MCP arguments to the subprocess call.",
        "testStrategy": "Verify that execution fails with a clear error when `ORACLEPACK_ENABLE_EXEC=0`. When enabled, verify the subprocess receives the correct flags and returns the expected result payload.",
        "priority": "medium",
        "dependencies": [
          "4",
          "5"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-08T01:32:32.692Z"
      },
      {
        "id": "8",
        "title": "Implement Oraclepack Prompt Generator",
        "description": "Develop a utility to generate prompts for agents based on action pack structures.",
        "details": "Implement a helper within `taskify.py` or a new module that generates a system prompt or instruction block. This should describe how the agent should interact with the validated action pack and what artifacts to expect. Integrate this into the tool outputs where relevant.",
        "testStrategy": "Validate that the generated prompt correctly reflects the action pack's steps and requirements.",
        "priority": "low",
        "dependencies": [
          "4"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Prompt Templates for Action Pack Interaction",
            "description": "Create a collection of string templates that describe how an agent should handle Action Packs.",
            "dependencies": [],
            "details": "Establish constant string templates in a new 'prompts.py' module or within 'taskify.py'. These templates must explain the '01-20' prefix sequencing, the single-bash-fence requirement, and the handling of markdown headers.",
            "status": "done",
            "testStrategy": "Verify that templates contain placeholders for dynamic content like step names and pack descriptions.",
            "updatedAt": "2026-01-08T01:33:40.953Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement the Prompt Generation Logic",
            "description": "Develop a function to assemble the final system prompt based on validated Action Pack metadata.",
            "dependencies": [
              1
            ],
            "details": "Implement 'generate_action_pack_prompt(metadata: dict) -> str'. This function will take the output from the Task 4 validator (prefixes, file paths, step titles) and inject them into the templates to create a coherent instruction block.",
            "status": "done",
            "testStrategy": "Unit test with various mock metadata structures to ensure correct string interpolation and formatting.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:33:40.959Z"
          },
          {
            "id": 3,
            "title": "Integrate Prompt Generator into Taskify Workflow",
            "description": "Ensure the prompt is generated immediately after successful Action Pack validation.",
            "dependencies": [
              2
            ],
            "details": "Modify the main execution flow in 'taskify.py' to call the prompt generator once an Action Pack is identified and validated. Store the resulting string in the Action Pack state object.",
            "status": "done",
            "testStrategy": "Trace execution in 'taskify.py' to confirm the prompt is available in the final result object after validation.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:33:40.963Z"
          },
          {
            "id": 4,
            "title": "Expose Generated Prompt via MCP Tool Outputs",
            "description": "Update the MCP server tool responses to include the generated instructions for the calling agent.",
            "dependencies": [
              3
            ],
            "details": "Modify 'server.py' or the tool registration logic so that tools returning Action Pack information include the generated prompt as part of the 'description' or a dedicated 'instructions' field in the JSON output.",
            "status": "done",
            "testStrategy": "Use an MCP inspector or client to call the tool and verify the 'instructions' field is present and correctly populated.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:33:40.967Z"
          },
          {
            "id": 5,
            "title": "End-to-End Validation of Agent Instructions",
            "description": "Perform a full test to ensure the generated prompt effectively guides an agent through a sample Action Pack.",
            "dependencies": [
              4
            ],
            "details": "Create a complex sample Action Pack with 3+ steps. Run the generation logic and manually verify the prompt accurately describes the steps and constraints (bash fences, sequence).",
            "status": "done",
            "testStrategy": "Functional test using a real or mocked LLM agent to see if it follows the generated instructions for the sample pack.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:33:40.970Z"
          }
        ],
        "updatedAt": "2026-01-08T01:33:40.970Z"
      },
      {
        "id": "9",
        "title": "Verbose Payload Rendering and Artifact Summarizer",
        "description": "Implement the Verbose Payload Rendering TUI and the artifact summarizer.",
        "details": "Create a summarizer that reports the presence/absence of expected artifacts (e.g., reports, logs). For the TUI aspect (if consumed via MCP), ensure the JSON response includes a 'verbose_rendering' field containing a Markdown-formatted summary of the execution payload for easier reading by the agent/user.",
        "testStrategy": "Run a pack and check that the artifact summary accurately reflects the files created on disk. Verify the markdown rendering is valid and legible.",
        "priority": "low",
        "dependencies": [
          "7"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Artifact Summarizer Interface",
            "description": "Create a module to define expected artifacts and check their presence on the filesystem.",
            "dependencies": [],
            "details": "Implement an `ArtifactSummarizer` class that accepts a list of expected file patterns or paths. It should provide a `summarize()` method that returns a dictionary mapping file paths to their status (exists, missing) and basic metadata (size).",
            "status": "done",
            "testStrategy": "Unit test with mock filesystem to verify that the summarizer correctly identifies present and absent files based on patterns.",
            "updatedAt": "2026-01-08T01:34:30.654Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Markdown Rendering Utility",
            "description": "Develop a utility function to convert execution results into a formatted Markdown string.",
            "dependencies": [
              1
            ],
            "details": "Create a `render_verbose_summary` function that takes execution outputs, artifact status, and pack metadata to produce a structured Markdown document. Use tables for artifacts and code blocks for log snippets.",
            "status": "done",
            "testStrategy": "Verify the generated Markdown string against a schema and ensure it renders correctly in a standard Markdown viewer.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:34:30.658Z"
          },
          {
            "id": 3,
            "title": "Integrate Summarizer into Execution Flow",
            "description": "Update the core execution logic to trigger artifact summarization after a pack run.",
            "dependencies": [
              1
            ],
            "details": "Modify the main execution entry point (e.g., in `taskify.py` or `runner.py`) to call the `ArtifactSummarizer` once the process completes. Capture the results for inclusion in the final response payload.",
            "status": "done",
            "testStrategy": "Integration test: Run a sample pack and verify that the internal result object contains the summarized artifact information.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:34:30.663Z"
          },
          {
            "id": 4,
            "title": "Update MCP Server Response Payload",
            "description": "Modify the MCP server tool handlers to include the 'verbose_rendering' field.",
            "dependencies": [
              2,
              3
            ],
            "details": "Update the tool execution logic in `server.py` to include the 'verbose_rendering' key in the JSON response. This field should contain the Markdown output from the rendering utility.",
            "status": "done",
            "testStrategy": "Use an MCP client to call a tool and verify that the JSON response includes a valid 'verbose_rendering' Markdown string.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:34:30.666Z"
          },
          {
            "id": 5,
            "title": "Implement File-Based Log Summarization",
            "description": "Add logic to extract and summarize tail-end logs or specific report contents into the verbose rendering.",
            "dependencies": [
              2,
              4
            ],
            "details": "Enhance the summarizer to read the last N lines of log files or extract key metrics from report files (like JSON summaries) and inject them into the Markdown rendering for immediate visibility.",
            "status": "done",
            "testStrategy": "Run a pack that generates a log file; verify that the 'verbose_rendering' includes the expected log tail or report summary.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:34:30.671Z"
          }
        ],
        "updatedAt": "2026-01-08T01:34:30.671Z"
      },
      {
        "id": "10",
        "title": "Final Integration and MCP Compliance Testing",
        "description": "Perform end-to-end testing of the MCP server to ensure all derived actions (A01-A26) are satisfied.",
        "details": "Conduct a full pass of the derived actions. Verify deterministic outputs, truncation flags, timeout exit codes, and prefix validation logic. Ensure the repository includes final documentation in README.md explaining how to connect an agent (like Claude Desktop) to the MCP server.",
        "testStrategy": "Automated integration test suite that spins up the server and uses an MCP client to execute a battery of tool calls against a controlled filesystem environment.",
        "priority": "high",
        "dependencies": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Establish E2E Integration Test Harness",
            "description": "Create a robust integration test suite that spawns the MCP server as a subprocess and interacts with it using a client mock.",
            "dependencies": [],
            "details": "Implement a testing framework in `tests/integration/` using `pytest` and `pytest-asyncio`. Use the `mcp` Python SDK to create a client that connects via stdio to the server. Include utility functions to prepare a temporary 'sandbox' filesystem environment.",
            "status": "done",
            "testStrategy": "Verify the harness can successfully launch the server, call the 'list_tools' method, and receive a valid JSON-RPC response.",
            "updatedAt": "2026-01-08T01:36:03.222Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Validate Path Security and Sandbox Constraints (A01-A08)",
            "description": "Verify that all file-based actions strictly adhere to ORACLEPACK_ALLOWED_ROOTS and prevent path traversal.",
            "dependencies": [
              1
            ],
            "details": "Create test cases that attempt to access files outside of the configured `ORACLEPACK_ALLOWED_ROOTS`. Specifically test relative paths (`../`), symlinks (if supported), and absolute paths. Ensure the server returns deterministic error codes and does not leak system information.",
            "status": "done",
            "testStrategy": "Automated tests asserting that calls to tools like 'cat' or 'ls' outside the sandbox return a 'Permission Denied' or similar structured error.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:36:03.227Z"
          },
          {
            "id": 3,
            "title": "Verify Output Truncation and Timeout Logic (A09-A20)",
            "description": "Ensure the server correctly handles large outputs and long-running subprocesses according to configuration.",
            "dependencies": [
              1
            ],
            "details": "Implement tests for `ORACLEPACK_MAX_OUTPUT_CHARS` limits. Verify that stdout is truncated correctly and the 'truncated' flag is set in the response. Test timeout scenarios where a command exceeds the allowed duration, ensuring the exit code 124 is caught and reported correctly.",
            "status": "done",
            "testStrategy": "Execute commands generating large byte streams and commands with 'sleep' to verify truncation thresholds and timeout triggers.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:36:03.231Z"
          },
          {
            "id": 4,
            "title": "Perform MCP Protocol Compliance Audit (A21-A26)",
            "description": "Ensure the server's tool definitions and JSON-RPC messaging fully comply with the Model Context Protocol specification.",
            "dependencies": [
              1
            ],
            "details": "Validate the schema of every tool exposed by the server. Ensure that types, required fields, and descriptions are present. Verify that logs are correctly directed to stderr to avoid corrupting the stdio transport channel.",
            "status": "done",
            "testStrategy": "Use an MCP Inspector tool or a protocol validator script to check the JSON-RPC message formats and schema definitions.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:36:03.235Z"
          },
          {
            "id": 5,
            "title": "Finalize README and Connection Documentation",
            "description": "Update the project documentation to provide clear instructions for agent integration, specifically for Claude Desktop.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Add a 'Deployment' section to `README.md`. Include a sample `claude_desktop_config.json` block showing how to configure the environment variables and the path to the executable. Document the purpose of each environment variable (ROOTS, EXEC, MAX_BYTES).",
            "status": "done",
            "testStrategy": "Manual verification by copying the documented configuration into a local Claude Desktop setup and confirming the server initializes and tools appear.",
            "parentId": "undefined",
            "updatedAt": "2026-01-08T01:36:03.239Z"
          }
        ],
        "updatedAt": "2026-01-08T01:36:03.239Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-01-08T01:36:03.240Z",
      "taskCount": 10,
      "completedCount": 10,
      "tags": [
        "feat-mcp"
      ]
    }
  }
}